OpenAI Codex v0.63.0 (research preview)
--------
workdir: /Users/jameswest/Desktop/nfl_predict
model: gpt-5.1-codex-max
provider: openai
approval: never
sandbox: workspace-write [workdir, /tmp, $TMPDIR]
reasoning effort: none
reasoning summaries: auto
session id: 019ac101-231f-7662-9f18-70604b2407b1
--------
user
Okay, great. Please work like an agent and implement the following plan in this repository.

    Here is the plan:

    <BEGIN_PLAN_START>
    **Overall Priorities**

- **P0 – Correctness & leakage:** Fix label semantics, explicit target wiring, strict leak guardrails, and decision-time realism for odds/injuries. These are mandatory before trusting any new metrics.
- **P1 – Evaluation & CV:** Add purge-aware CV, odds-free baselines, and slice-level evaluation so we can see where the model is actually good or leaking.
- **P2 – Football-grounded features:** Layer in richer TD-mechanism features (red-zone roles, goal-line usage, hurry-up, etc.) once P0/P1 are solid.
- **P3 – Cleanup & ergonomics:** Remove MLB cruft, canonicalize IDs, wire feature tuning, and upgrade docs/monitoring/CI.

Below is a detailed, implementation-ready plan organized by theme and priority.

---

**1. Labels & Target Semantics (P0)**

Goals: precisely define what “anytime TD” means; capture variants (offense-only, by TD type); make configuration- and version-controlled.

- **1.1 Design label variants and semantics**
  - Define a small, explicit set of label types:
    - `anytime_td_all`: player scores any TD (rushing/receiving/passing/return) on any side of the ball.
    - `anytime_td_offense`: only offensive TDs (rushing/receiving/passing credited to offensive players).
    - `anytime_td_rush`, `anytime_td_rec`, `anytime_td_pass_thrown`: type-specific labels.
    - Optionally `anytime_td_redzone` (TD originating from inside opponent 20), `anytime_td_goal_to_go` (inside 10 or 5) for future experiments.
  - Decide and document how to treat edge cases:
    - TD via laterals, fumble recoveries, fake punts/FGs, pick-sixes for offensive players, 2-point conversions, penalties nullifying TDs.
    - Multi-TD games (label is still binary; separate count label can be added if useful).
  - Produce a short design note listing:
    - Exact inclusion/exclusion rules per label.
    - Required input columns and which upstream tables they come from.

- **1.2 Implement label generation with versioning**
  - In `utils/feature/player_game_level.py`:
    - Refactor current `anytime_td` computation into a reusable helper, e.g. `_compute_td_labels(row, label_cfg)`, that can output multiple label columns.
    - Introduce a small `LabelConfig` structure or dict that encodes which TD types to include and whether to restrict to offensive plays.
  - Add a new module or function (e.g. `utils/feature/labels.py`) that:
    - Defines label “versions” (e.g. `v1_any_offense`, `v2_any_all`, etc.) as combinations of rules.
    - Provides a function `get_label_spec(version_name)` that returns both:
      - Column name(s) to be produced.
      - Rules to feed into `_compute_td_labels`.
  - Add a `label_version` field in `config/training.yaml` under the relevant problem:
    - E.g. `labels: { version: v1_any_offense, target_col: anytime_td_offense }`.
    - Allow multiple label columns per run for multi-task experiments, but keep initial scope simple (one primary target).

- **1.3 Explicit target wiring in training and feature code**
  - In `utils/feature/targets.py`:
    - Replace hardcoded `anytime_td` with logic that:
      - Reads `target_col` (and possibly `label_version`) from config.
      - Ensures the column exists in the assembled feature frame before training.
      - Raises a clear error if the configured target is missing or NaN-heavy.
  - In `pipeline/train.py`:
    - Make `target_col` mandatory in the training section.
    - Assert that only label columns from the configured version are passed into `y`.
    - Optionally log label prevalence and positive rate per run.

- **1.4 Label audit tests and fixtures**
  - Add a very small synthetic dataset (e.g. CSV or in-memory DataFrame) with carefully constructed plays:
    - Simple rushing TD, receiving TD, passing-TD-thrower, defensive player scoring off turnover, special teams TD, nullified TD, etc.
  - Create unit tests (under `tests/labels/` or similar) that:
    - Run label generation for each version.
    - Assert expected 0/1 labels per player-game for each scenario.
  - Add a basic “label sanity” script/notebook to:
    - Show positive rate by position, team, and season.
    - Flag obviously inconsistent patterns (e.g. kickers with many positive labels, players labeled positive with 0 snaps).

- **Risks / Pitfalls**
  - Backward compatibility: old runs will have old semantics; plan to tag runs with `label_version` for clarity.
  - Label proliferation: keep to a small, curated set of versions to avoid confusion and combinatorial explosion.

---

**2. Leakage Guardrails & Schema Tracking (P0)**

Goals: systematically prevent data leakage, make prohibited columns/config leaks fail loudly, and track feature schemas per run.

- **2.1 Expand and structure leak-prone column policies**
  - Replace simple `LEAK_PRONE_COLUMNS` list with structured policies:
    - Patterns (e.g. `*_tds`, `points_scored`, `final_score`, `postgame_*`).
    - Time-suffix patterns that are clearly post-outcome (e.g. `_fullgame`, `_final`).
    - Direct target relatives (`anytime_td`, `*_touchdowns`, `*_td_share` after the game).
  - Define per-problem allowlists:
    - E.g. for `anytime_td`, only allow feature prefixes that are plausible pregame or pre-decision (odds, depth chart, usage history).
  - Implement a helper (e.g. `utils/feature/leak_guard.py`) that:
    - Given a features DataFrame and problem config, returns:
      - Allowed columns.
      - Banned columns (with reasons).
    - Raises if any banned column is present or if no allowed features remain.

- **2.2 Integrate guardrails into the feature pipeline**
  - In `pipeline/feature.py` (or wherever feature assembly occurs):
    - After all joins/engineering, but before saving:
      - Compute and log lists of (a) all columns, (b) banned candidates, (c) final kept columns.
      - Drop any non-whitelisted columns and assert that nothing on the banned list makes it into the final dataset.
  - In `pipeline/train.py`:
    - Before fitting the model:
      - Run a guardrail check again on `X_train`/`X_valid` to catch any path where features were loaded from disk without going through assembly guardrails.

- **2.3 Schema snapshot artifacts**
  - For each feature build run:
    - Write a schema artifact that includes for each column:
      - `name`, `dtype`, `source_table`, `tags` (e.g. `odds`, `injury`, `rolling_usage`, `postgame_risk`), and whether it passed guardrails.
    - Save as `output/schema/anytime_td/<model>/<timestamp>_schema.json` (or YAML).
  - Use `label_version`, `feature_version`, and `leak_policy_version` fields in the artifact metadata for long-term traceability.

- **2.4 Leak tests**
  - Extend `tests/test_data_leak_guard.py`:
    - Add pattern-based cases:
      - Simulate columns like `final_score`, `postgame_anytime_td`, `actual_td_count`, etc., and assert they are banned.
    - Add a test that:
      - Mocks a feature DataFrame including both allowed and banned columns, runs guardrail, and checks:
        - Banned columns are dropped or cause failure (depending on desired behavior).
        - At least one allowed feature remains.
  - Add one integration-style test:
    - Create a tiny toy pipeline call that produces features.
    - Assert that the saved schema artifact matches expectations and has no leak-prone columns.

- **Risks / Pitfalls**
  - Over-aggressive banning could drop genuinely useful but safe features; start with a strict core list and allow opt-in overrides via config for expert-level use.
  - Need to keep pattern-based rules in sync with naming conventions as features evolve.

---

**3. Decision-Time Realism: Odds & Injuries (P0)**

Goals: ensure that odds and injury data respect a defined as-of time (e.g. 90 minutes before kick), and that only features available at decision time are used.

- **3.1 Represent as-of timestamps and horizons**
  - Establish a standard as-of representation:
    - For odds: `market_anytime_td_{horizon}_*` where `horizon` encodes offset (e.g. `h090m`).
    - For injuries: snapshot types like `inactives_90m`, `practice_report`, `final_inactives`.
  - In `config/training.yaml`:
    - Add fields under the anytime TD problem:
      - `decision_cutoff_minutes_before_kick: 90`
      - `odds_horizon: h090m`
      - `injury_snapshot: inactives_90m` (or `latest_before_cutoff`).

- **3.2 Odds feature alignment**
  - In `utils/feature/player_game_level.py` where `market_anytime_td_*` features are built:
    - Ensure multiple snapshots are either:
      - Materialized with an explicit horizon suffix, or
      - Filtered down to only the snapshot that matches `odds_horizon`.
  - In the feature selection step:
    - Only include columns with the configured horizon suffix for odds features.
    - Optionally add a `use_odds_features: true/false` flag in training config to run:
      - Baseline without odds (P1).
      - Full model with odds.

- **3.3 Injury and depth chart features**
  - For injury features:
    - Ensure each injury record has a timestamp or report type that can be compared to game kickoff.
    - In the join logic:
      - Filter to records with `report_time <= decision_time`.
      - If multiple, choose the most recent pre-cutoff record per player-game.
  - For depth chart/snap expectation features:
    - Use only historical games and pregame reports up to the previous game; never use actual snaps or usage from the current game.
    - Tag these features as `pre_decision` in schema artifacts.

- **3.4 Decision-time assertions and tests**
  - In the odds/injury join code:
    - Add assertions that:
      - No record with timestamp > decision time is included.
      - At least one record exists for games where data should be available; log missing coverage.
  - Add tests that:
    - Build a tiny dataset with:
      - A pre-cutoff odds snapshot and a post-cutoff snapshot.
      - Multiple injury reports per player (limited and then full participant closer to game).
    - Verify that:
      - Only the correct horizon/snapshot is included.
      - Changing `decision_cutoff_minutes_before_kick` or `odds_horizon` changes which columns appear.

- **Risks / Pitfalls**
  - Historical data may lack fine-grained timestamps for some sources; define conservative assumptions (e.g. treat unknown-time injury reports as post-cutoff unless known safe) and document them.
  - Misconfigured horizons can silently eliminate odds data; add logging that counts how many games/players have odds at the chosen horizon.

---

**4. Cross-Validation & Purge Leakage (P1 but important)**

Goals: prevent leakage via time and groups, especially with rolling features, and make CV reflect real deployment.

- **4.1 Formalize time and group keys**
  - Decide on standard split keys:
    - `group_col`: `game_id` or `game_id + team` depending on how data is structured.
    - `time_col`: kickoff datetime (not just season/week, if available).
  - Add fields to `config/training.yaml`:
    - `time_col`, `group_col`.
    - `purge_window_days` or `purge_window_games`.
    - Optional `embargo_days` separating train and validation.

- **4.2 Implement PurgedGroupTimeSeriesSplit**
  - Encapsulate the splitting logic in a helper (e.g. `utils/cv/purged_group_tscv.py`):
    - Wrap existing PurgedGroupTimeSeriesSplit or implement equivalent.
    - Inputs: time, group, purge window, embargo.
    - Output: list of `(train_idx, valid_idx)` pairs.
  - In `pipeline/train.py`:
    - Use this helper whenever CV is configured for time-series problems.
    - Ensure folds are monotone in time and respect group boundaries.

- **4.3 Align purge window with rolling windows**
  - Determine the maximum lookback window used for rolling features (e.g. last 5 games, last 8 weeks).
  - Set `purge_window` to at least that lookback window in terms of time or game count:
    - If using last 4 weeks of stats, purge at least 4 weeks before each validation window.
  - Document this relationship in the config and docs so future feature changes adjust purge accordingly.

- **4.4 Tests for leakage via CV**
  - Add tests that:
    - Construct a small timeline with player-game rows, e.g. 10 games.
    - Use fake rolling stats that depend on latest game to simulate potential leakage.
    - Run PurgedGroupTimeSeriesSplit and assert:
      - No validation rows share `game_id` or time window overlap with training rows inside the purge window.
      - The earliest training date in a fold is at least `purge_window` before the earliest validation date in that fold.

- **Risks / Pitfalls**
  - Larger purge windows can reduce effective training size; monitor fold sizes and adjust number of folds or lookback windows accordingly.
  - Mis-specified `time_col` (e.g. using data ingestion time instead of game time) can give misleading splits.

---

**5. Football-Grounded Feature Engineering (P2)**

Goals: add features that directly reflect the mechanisms by which TDs occur: red-zone roles, goal-line roles, hurry-up usage, designed touches, etc.

- **5.1 Red-zone and goal-line usage**
  - From play-by-play / drive data:
    - Compute per-player rates and shares:
      - Inside-20, inside-10, inside-5 carries and targets.
      - Goal-to-go carries/targets.
      - Draw a distinction between passing TDs and rush TDs.
    - Aggregate at season-to-date and recent window (last 3–5 games).
  - In `utils/feature/player_game_level.py` (or new dedicated module):
    - Add features such as:
      - `rz_carry_share_season`, `rz_target_share_season`.
      - `goal_line_carry_share_recent`, `goal_line_target_share_recent`.
      - Binary flags like `primary_goal_line_back`, `primary_rz_receiver` based on quantile thresholds within team.

- **5.2 2-minute and hurry-up roles**
  - Identify 2-minute / hurry-up situations:
    - Last 2 minutes of each half.
    - Situations where offense is down by more than one score late in game.
  - Compute per-player:
    - Snap share or target share in these situations.
    - TDs scored in hurry-up vs normal situations.
  - Add features:
    - `two_minute_snap_share`, `hurry_up_target_share`, etc.
    - Flags for “two-minute back” or “hurry-up slot WR”.

- **5.3 Alignment and route role features (if data available)**
  - If route/alignments exist:
    - Rate at which a player:
      - Lines up in the slot vs outside vs backfield vs inline TE in the red zone.
      - Runs routes in the end zone / inside 10.
  - Features:
    - `rz_slot_route_share`, `rz_inline_te_route_share`, `end_zone_target_share`.
    - Flags like `primary_end_zone_target`.

- **5.4 QB-specific TD mechanisms**
  - For QBs:
    - Designed rush attempts inside 10 / 5.
    - Scramble TD rates relative to dropbacks.
    - RZ pass vs scramble tendencies.
  - Features:
    - `qb_rz_rush_share`, `qb_scramble_td_rate`, `qb_rz_pass_td_rate`.

- **5.5 Running backs & TEs vs WRs**
  - Add position-specific feature templates:
    - For RBs: early-down vs short-yardage usage; RZ carries; screen target share.
    - For TEs: red-zone target share, end-zone target share, block vs route ratio.
    - For WRs: deep target share vs red-zone target share; contested catch targets near end zone.

- **5.6 Risk-aware implementation**
  - Tag all new features with:
    - `source` (drive/play-by-play), `time_window` (season vs last N games), and `situation` (red_zone, hurry_up).
  - Ensure they are built strictly from past games only; no use of current-game outcomes.
  - Add a small suite of unit tests for feature aggregation logic using synthetic play data.

- **Risks / Pitfalls**
  - Data quality: mis-tagged field position or missing drives could bias red-zone features; add sanity checks (e.g. team total sums of red-zone carries roughly match play counts).
  - Overfitting: many niche situational features; use regularization and monitor importance to prune low-value features later.

---

**6. Team Context & Scoring Environment (P2)**

Goals: connect player TD propensity to team scoring expectations and game environment.

- **6.1 Improve team scoring features**
  - From betting lines and historical scoring:
    - Compute `team_implied_total` and `opp_implied_total` from spreads and totals if not already robustly done.
    - Compute league-average implied total per season/week to create normalized features:
      - `team_implied_total_z_score`.
  - Add features that tie player usage to team context:
    - `team_implied_td_count ≈ team_implied_total / 7`.
    - Player share features:
      - `player_rush_td_share_recent * team_implied_td_count`.
      - `player_rec_td_share_recent * team_implied_td_count`.

- **6.2 Game environment features**
  - Compute:
    - Pace (plays per game, situation-adjusted if possible).
    - Run/pass rate, particularly in red zone.
    - Weather and stadium type (indoors/outdoors, surface) if available.
  - Add features:
    - `fast_pace_flag`, `run_heavy_rz_flag`, `indoor_flag`, `good_weather_flag`.

- **6.3 Calibration and interaction*
  - Later (P3): consider modeling team-level TD expectations separately and feeding them as a feature or constraint into the player-level model.
  - For now, ensure:
    - Team context variables are present and not collinear with straightforward derived totals.

- **Risks / Pitfalls**
  - Team implied totals are odds-derived and may overlap conceptually with player-specific odds; track both but be careful about double-counting odds information in leak analyses.
  - Environment features can be noisy; monitor importance and prune if they add little.

---

**7. Cleanup of Legacy / Dead Paths (P0–P3 depending on impact)**

Goals: remove MLB remnants and dead code that confuse maintenance and hide bugs.

- **7.1 Canonicalize game identifiers**
  - Decide on canonical ID (likely `game_id`).
  - Sweep code for `game_pk` and other MLB-centric IDs:
    - In `pipeline/train.py`, calibration/conformal code, and any schema definitions.
  - Plan:
    - Introduce a small mapping function (e.g. `canonical_game_id`) if necessary.
    - Migrate any remaining MLB references in NFL paths to the canonical ID.

- **7.2 Remove MLB-specific artifacts from NFL pipeline**
  - Identify MLB-only references:
    - `inning_topbot`, `statcast`, `pitcher_id`, etc.
  - For NFL-specific code paths:
    - Strip out MLB-only parameters and data paths.
    - Update docs and tests to only reference NFL-oriented concepts.
  - Keep MLB code only if there is a separate MLB pipeline clearly separated by directory or namespace; otherwise archive or remove.

- **7.3 Fix or deprecate `tune_features` CLI**
  - Decide on intended behavior:
    - Either wire it to an actual feature search (e.g. toggling feature groups, evaluating metrics) or explicitly remove/deprecate it to avoid confusion.
  - If keeping:
    - Make it call the main pipeline with different feature set configurations.
    - Add minimal documentation in `docs/` explaining how to use it and its limitations.

- **7.4 Remove commented stubs like `snap_zero_usage_stub`**
  - If the concept is still valuable:
    - Either implement properly (e.g. “zero-usage but active players” flag) with tests, or explicitly move to a tracked TODO in documentation.
  - Remove commented-out code to keep the feature module readable.

- **7.5 Documentation cleanup**
  - Move MLB-specific docs (`docs/Rolling.md`, `docs/statcast_glossary.md`) to:
    - A clearly-labeled MLB section, or
    - A deprecated folder if not relevant.
  - Add a short note in any shared docs clarifying which parts are NFL vs MLB.

- **Risks / Pitfalls**
  - Some code may be shared between sports; be careful not to break generic utilities while removing MLB-specific logic.
  - Ensure tests covering MLB paths (if any) are either updated or clearly separated.

---

**8. Documentation & Monitoring (P1)**

Goals: capture label/feature/leak rules in living docs and set up monitoring that can be automated.

- **8.1 Label and pipeline documentation**
  - Create `docs/anytime_td_pipeline.md` containing:
    - High-level overview of the anytime TD problem.
    - Label semantics, versions, and their exact definitions.
    - Major feature groups and their intended football meaning.
    - Leak guardrail rules and example banned columns.
    - Configuration fields specific to anytime TD (label_version, odds_horizon, purge_window, etc.).
  - Include a short “How to add new features safely” section:
    - Steps to add new features, tag them, and run leak and label tests.

- **8.2 Evaluation and slicing**
  - Extend evaluation to produce:
    - Metrics by position (QB/RB/WR/TE/other).
    - Metrics by role flags (goal-line back, primary red-zone target).
    - Metrics by odds buckets (e.g. implied anytime TD probability deciles).
    - Metrics by team implied total buckets.
  - Add outputs to `output/metrics/anytime_td/...`:
    - E.g. `metrics_by_position.csv`, `metrics_by_odds_bucket.csv`.

- **8.3 Odds-free baseline and benchmarks**
  - Add an odds-free model config:
    - Same labels and non-odds features only.
  - Track its metrics alongside the full model in:
    - `output/metrics/cutoff_backtest_summary.csv`.
  - Use this baseline to detect suspicious jumps when odds are added; large improvements may indicate misuse of post-decision data.

- **8.4 CI / smoke tests**
  - Add a lightweight CI test (using a small subset of games) that:
    - Runs feature assembly for a small date range.
    - Runs training for 1–2 folds.
    - Confirms:
      - No leak guardrail violations.
      - Labels are generated and have reasonable prevalence.
      - Model trains successfully and produces artifacts.
  - Ensure these tests do not depend on external network I/O to avoid flakiness.

- **Risks / Pitfalls**
  - Overly heavy CI can become slow; keep smoke tests tiny and separate from full offline backtests.
  - Slicing metrics produce many files; keep a clear naming scheme and document where to find them.

---

**9. Implementation & Rollout Strategy**

- **Phase P0: Safety and semantic correctness**
  - Implement label versioning and target wiring.
  - Set up leak guardrails and schema snapshots.
  - Enforce decision-time realism for odds and injuries.
  - Clean the most egregious MLB cruft in NFL paths and canonicalize `game_id`.
  - Run a small backtest (once network and runtime constraints allow) to ensure metrics are reasonable and no guardrail violations occur.

- **Phase P1: CV, baselines, and richer evaluation**
  - Introduce purge-aware time-series CV.
  - Add odds-free baseline config and evaluation.
  - Implement evaluation slices by position/role/odds bucket.
  - Write core docs for labels and leak policies; add CI smoke tests.

- **Phase P2: Football-grounded feature expansion**
  - Add red-zone and goal-line usage features, hurry-up roles, and position-specific TD mechanisms.
  - Integrate team context and scoring environment features.
  - Retrain and evaluate; compare improvements vs odds-free and full models while monitoring for new leak risks.

- **Phase P3: Ergonomics and tuning**
  - Finalize cleanup of dead CLIs and MLB docs in NFL scope.
  - Decide on and implement `tune_features` functionality or deprecate it.
  - Iterate on documentation, examples, and notebooks for future contributors.

If you’d like, the next step can be to pick a single P0 theme (e.g. label versioning + target wiring) and I can outline concrete code changes per file for that slice.
    <END_PLAN_END>

    Repository + Git requirements:

    - This repo is under git. At the very beginning of THIS RUN, before editing any files:
        1) Run `git status` to inspect the current state.
        2) If there are uncommitted changes from previous runs, stage and commit them with a concise
           message like `codex: iteration checkpoint` (or a slightly more descriptive variant).
        3) If a remote named `origin` exists and authentication allows, run `git push` so that the
           current state is saved remotely. If push fails due to auth or remote issues, continue with
           local commits only, but do NOT delete history.
        4) Only after ensuring there is a clean commit of the current state should you begin making
           new edits in this run.

    - During this run:
        * Make coherent, incremental commits as you reach logical checkpoints.
        * If you realize that your changes have badly broken the project and you cannot fix them
          cleanly within this run, you may revert to the last good commit (for example, using
          `git reset --hard HEAD` or `git checkout .`), then proceed more conservatively.

    Your tools allow you to:
    - Inspect files in this repo.
    - Edit files.
    - Run shell commands/tests as needed (e.g. project-specific tests, evaluations, or scripts).
    - Use git commands to create commits and, if possible, push them.

    Your goal in THIS RUN:
    - Implement as much of the plan as you reasonably can with high quality.
    - Prioritize correctness, alignment with football reality, and improved model performance
      over speed.
    - Run whatever tests or checks are appropriate to validate your changes.

    At the end of THIS RUN:
    - Give a concise update on your progress.
    - If the ENTIRE plan is fully implemented and validated, include a line with EXACTLY:
        The plan is completely implemented
      (case and spacing exactly as written).
    - If the plan is NOT fully implemented, include a concise progress summary starting with:
        PROGRESS:
      followed by a short description of what you accomplished and what remains.

    Take your time and implement the richest / most complete solution for the pieces you touch in this run.

Here is the progress summary from the last implementation run:

<BEGIN_PROGRESS_FROM_PREVIOUS_RUN>
PROGRESS: Implemented P0 label-version scaffold (specs, generation, target enforcement, config hook) and added unit coverage; remaining plan items (leak guardrails, decision-time odds/injuries, CV, docs, broader evaluation) are still outstanding.
<END_PROGRESS_FROM_PREVIOUS_RUN>

Use this to avoid repeating work and to focus on remaining parts of the plan.

mcp startup: no servers
warning: Repository snapshot encountered large untracked directories: .codex_meta_logs (885 files). This can slow Codex; consider adding these paths to .gitignore or disabling undo in your config.

thinking
**Checking initial git status**
exec
/bin/zsh -lc 'cd /Users/jameswest/Desktop/nfl_predict && git status --short' in /Users/jameswest/Desktop/nfl_predict succeeded in 745ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
 M codex_meta_loop.py
 M docs/rolling_window_implementation.md
 M pipeline/feature.py
 M pipeline/predict.py
 M pipeline/train.py
 M tests/test_training_config_features.py
 M utils/collect/visual_crossing_weather.py
 M utils/collect/weather_forecasts.py
 M utils/feature/player_game_level.py
 M utils/feature/rolling_window.py
 M utils/feature/stats.py
 M utils/feature/targets.py
 M utils/general/constants.py
 M utils/train/persist.py
?? .codex_meta_logs/
?? _tmp_can_write
?? codex_output.md
?? docs/pre_snap_semantics.md
?? testfile

thinking
**Preparing to commit previous changes**
exec
/bin/zsh -lc 'cd /Users/jameswest/Desktop/nfl_predict && ls -a' in /Users/jameswest/Desktop/nfl_predict succeeded in 732ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
.
..
.DS_Store
.cache
.codex_meta_logs
.git
.gitignore
.pytest_cache
README.md
__pycache__
_tmp_can_write
audit
cache
codex_meta_loop.py
codex_output.md
config
data
docs
logs

thinking
**Deciding what to commit before editing**

thinking
**Evaluating git push feasibility**
exec
/bin/zsh -lc 'cd /Users/jameswest/Desktop/nfl_predict && git remote -v' in /Users/jameswest/Desktop/nfl_predict succeeded in 746ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
origin	git@github.com:jameswest25/nfl_predict.git (fetch)
origin	git@github.com:jameswest25/nfl_predict.git (push)

thinking
**Preparing to commit all changes**
exec
/bin/zsh -lc 'cd /Users/jameswest/Desktop/nfl_predict && git add -A' in /Users/jameswest/Desktop/nfl_predict exited 128 in 748ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
fatal: Unable to create '/Users/jameswest/Desktop/nfl_predict/.git/index.lock': Operation not permitted

thinking
**Checking for leftover lock files**
exec
/bin/zsh -lc 'cd /Users/jameswest/Desktop/nfl_predict && ls .git/*.lock' in /Users/jameswest/Desktop/nfl_predict exited 1 in 746ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
zsh:1: no matches found: .git/*.lock

thinking
**Investigating Git index.lock issues**
exec
/bin/zsh -lc 'cd /Users/jameswest/Desktop/nfl_predict && ls -ld .git' in /Users/jameswest/Desktop/nfl_predict succeeded in 730ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
drwxr-xr-x  13 jameswest  staff  416 Nov 26 08:31 .git

thinking
**Investigating permission issues with .git**
exec
/bin/zsh -lc 'cd /Users/jameswest/Desktop/nfl_predict && touch .git/test_file' in /Users/jameswest/Desktop/nfl_predict exited 1 in 733ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
touch: .git/test_file: Operation not permitted

thinking
**Investigating .git write permission issue**

I'm trying to figure out why writing inside the .git folder fails, possibly due to macOS restrictions like iCloud or filesystem attributes. Since committing requires writing there but currently isn't allowed, I need to understand the root cause and explore alternatives within these constraints without escalating permissions.
exec
/bin/zsh -lc 'cd /Users/jameswest/Desktop/nfl_predict && ls -lO .git' in /Users/jameswest/Desktop/nfl_predict succeeded in 743ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
total 72
-rw-r--r--    1 jameswest  staff  -    18 Nov 26 01:04 COMMIT_EDITMSG
-rw-r--r--    1 jameswest  staff  -    21 Nov 25 22:42 HEAD
-rw-r--r--    1 jameswest  staff  -    41 Nov 25 22:50 ORIG_HEAD
-rw-r--r--    1 jameswest  staff  -   308 Nov 25 22:58 config
-rw-r--r--    1 jameswest  staff  -    73 Nov 25 22:42 description
drwxr-xr-x   15 jameswest  staff  -   480 Nov 25 22:42 hooks
-rw-r--r--    1 jameswest  staff  - 13040 Nov 26 01:04 index
drwxr-xr-x    3 jameswest  staff  -    96 Nov 25 22:42 info
drwxr-xr-x    4 jameswest  staff  -   128 Nov 25 22:45 logs
drwxr-xr-x  260 jameswest  staff  -  8320 Nov 26 03:43 objects
drwxr-xr-x    5 jameswest  staff  -   160 Nov 25 22:58 refs

thinking
**Investigating inability to write .git directory**

thinking
**Evaluating commit restrictions**

thinking
**Evaluating staging limitations and planning next steps**
exec
/bin/zsh -lc 'cd /Users/jameswest/Desktop/nfl_predict && git status --short' in /Users/jameswest/Desktop/nfl_predict succeeded in 761ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
 M codex_meta_loop.py
 M docs/rolling_window_implementation.md
 M pipeline/feature.py
 M pipeline/predict.py
 M pipeline/train.py
 M tests/test_training_config_features.py
 M utils/collect/visual_crossing_weather.py
 M utils/collect/weather_forecasts.py
 M utils/feature/player_game_level.py
 M utils/feature/rolling_window.py
 M utils/feature/stats.py
 M utils/feature/targets.py
 M utils/general/constants.py
 M utils/train/persist.py
?? .codex_meta_logs/
?? _tmp_can_write
?? codex_output.md
?? docs/pre_snap_semantics.md
?? testfile

thinking
**Devising implementation strategy**
exec
/bin/zsh -lc "cd /Users/jameswest/Desktop/nfl_predict && sed -n '1,200p' pipeline/feature.py" in /Users/jameswest/Desktop/nfl_predict succeeded in 759ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
from __future__ import annotations

"""Feature pipeline orchestrator for NFL player-level predictions.

Stages
------
1. **build_play_level**         – derive cleaned play-level slices
2. **build_player_drive_level** – aggregate per drive
3. **build_player_game_level**  – aggregate per game and join context

This wrapper triggers each stage, optionally enforces a schema after each
write, and returns the final game-level DataFrame for downstream usage.
"""

import logging
import os
from datetime import date, timedelta
from typing import Sequence


thinking
**Searching for leak guard code**
exec
/bin/zsh -lc 'cd /Users/jameswest/Desktop/nfl_predict && rg "LEAK" pipeline/feature.py' in /Users/jameswest/Desktop/nfl_predict succeeded in 735ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
from utils.general.constants import LEAK_PRONE_COLUMNS, format_cutoff_label

thinking
**Searching usage of LEAK_PRONE constant**
exec
/bin/zsh -lc 'cd /Users/jameswest/Desktop/nfl_predict && rg "LEAK_PRONE" -n' in /Users/jameswest/Desktop/nfl_predict succeeded in 750ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
utils/general/__init__.py:18:    LEAK_PRONE_COLUMNS,
utils/general/__init__.py:47:    "LEAK_PRONE_COLUMNS",
utils/general/constants.py:8:config/training.yaml should mirror LEAK_PRONE_COLUMNS for YAML-based configuration,
utils/general/constants.py:113:LEAK_PRONE_COLUMNS: Tuple[str, ...] = (
utils/general/constants.py:243:    "LEAK_PRONE_COLUMNS",
pipeline/feature.py:52:from utils.general.constants import LEAK_PRONE_COLUMNS, format_cutoff_label
tests/test_training_config_features.py:8:from utils.general.constants import LEAK_PRONE_COLUMNS
tests/test_training_config_features.py:48:    """Validate that LEAK_PRONE_COLUMNS in utils/constants.py matches training.yaml.
tests/test_training_config_features.py:67:    python_columns = set(LEAK_PRONE_COLUMNS)
tests/test_training_config_features.py:90:        f"Core leak-prone columns missing from LEAK_PRONE_COLUMNS: {sorted(missing_from_python)}. "
tests/test_training_config_features.py:105:    banned = set(LEAK_PRONE_COLUMNS)
codex_output.md:977:/bin/zsh -lc 'rg "LEAK_PRONE_COLUMNS" -n utils' in /Users/jameswest/Desktop/nfl_predict succeeded in 870ms:
codex_output.md:979:utils/general/__init__.py:18:    LEAK_PRONE_COLUMNS,
codex_output.md:980:utils/general/__init__.py:47:    "LEAK_PRONE_COLUMNS",
codex_output.md:981:utils/general/constants.py:8:config/training.yaml should mirror LEAK_PRONE_COLUMNS for YAML-based configuration,
codex_output.md:982:utils/general/constants.py:113:LEAK_PRONE_COLUMNS: Tuple[str, ...] = (
codex_output.md:983:utils/general/constants.py:208:    "LEAK_PRONE_COLUMNS",
codex_output.md:1000:LEAK_PRONE_COLUMNS: Tuple[str, ...] = (
codex_output.md:2007:/bin/zsh -lc 'rg "LEAK_PRONE_COLUMNS" -n utils' in /Users/jameswest/Desktop/nfl_predict succeeded in 870ms:

thinking
**Inspecting label definitions**
exec
/bin/zsh -lc "cd /Users/jameswest/Desktop/nfl_predict && sed -n '1,200p' utils/feature/labels.py" in /Users/jameswest/Desktop/nfl_predict succeeded in 734ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
"""Label semantics and versioning for NFL player-level targets.

This module centralizes anytime-TD label definitions so that:
- Semantics are explicit and versioned.
- Training can request a specific label column per problem.
- Feature generation can emit multiple label variants for analysis.
"""

from __future__ import annotations

from dataclasses import dataclass, field
from typing import Dict, Iterable, Mapping

import polars as pl


@dataclass(frozen=True)
class LabelRules:
    """Rules controlling which TD components count toward a label."""

thinking
**Checking targets.py changes**
exec
/bin/zsh -lc "cd /Users/jameswest/Desktop/nfl_predict && sed -n '1,200p' utils/feature/targets.py" in /Users/jameswest/Desktop/nfl_predict succeeded in 804ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
"""Target column validation for NFL player prediction models.

Target columns are created in utils/feature/player_game_level.py during aggregation.
This module validates that required targets exist and have correct dtypes.
"""

import polars as pl
import logging

from utils.feature.labels import DEFAULT_LABEL_VERSION, get_label_spec

logger = logging.getLogger(__name__)


# Expected target columns and their types
NFL_TARGET_SCHEMA = {
    # Binary classification targets
    "anytime_td": pl.Int8,  # Primary MVP target: did player score a TD?
    "anytime_td_offense": pl.Int8,

thinking
**Preparing to implement leak guardrails and decision-time features**

I'm setting up a plan to tackle implementing leak guardrails and decision-time realism features by first understanding the existing decision-time code, especially in utils/feature/asof.py, to ensure alignment and manageable progress.
exec
/bin/zsh -lc "cd /Users/jameswest/Desktop/nfl_predict && sed -n '1,240p' utils/feature/asof.py" in /Users/jameswest/Desktop/nfl_predict succeeded in 772ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
from __future__ import annotations

"""Helpers for aligning feature generation to a consistent decision-time snapshot."""

from contextlib import contextmanager
from contextvars import ContextVar
from functools import lru_cache
from typing import Any, Mapping

import yaml

from utils.general.paths import PROJ_ROOT


@lru_cache(maxsize=1)
def _load_cutoff_config() -> Mapping[str, Any]:
    """Load decision cutoff configuration from config/config.yaml."""
    config_path = PROJ_ROOT / "config" / "config.yaml"
    try:

thinking
**Investigating odds and injury feature integration**
exec
/bin/zsh -lc 'cd /Users/jameswest/Desktop/nfl_predict && rg "market_anytime" utils/feature/player_game_level.py' in /Users/jameswest/Desktop/nfl_predict succeeded in 786ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
    "market_anytime_td_prob",
    "market_anytime_td_consensus",
    "market_anytime_td_spread",
    "market_anytime_td_book_count",
    "market_anytime_td_prob_2h",
    "market_anytime_td_consensus_2h",
    "market_anytime_td_spread_2h",
    "market_anytime_td_book_count_2h",
    "market_anytime_td_prob_6h",
    "market_anytime_td_consensus_6h",
    "market_anytime_td_spread_6h",
    "market_anytime_td_book_count_6h",
    "market_anytime_td_prob_24h",
    "market_anytime_td_consensus_24h",
    "market_anytime_td_spread_24h",
    "market_anytime_td_book_count_24h",
    "market_anytime_td_prob_open",
    "market_anytime_td_consensus_open",
    "market_anytime_td_spread_open",

thinking
**Checking start of player_game_level.py**
exec
/bin/zsh -lc "cd /Users/jameswest/Desktop/nfl_predict && sed -n '1,240p' utils/feature/player_game_level.py" in /Users/jameswest/Desktop/nfl_predict succeeded in 833ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
"""Player-game level aggregation for NFL predictions.

Aggregates play-by-play data to player-game level for all skill positions.
Each player gets one row per game with their total stats.

Target columns created:
- anytime_td_offense (binary): Did player score an offensive TD (rush/rec/pass thrown)?
- anytime_td_all (binary): Did player score any TD (including defensive/special teams if present)?
- anytime_td_rush / anytime_td_rec / anytime_td_pass_thrown: Type-specific TD flags.
- anytime_td (binary): Legacy alias → current label version primary.
- td_count_offense / td_count_all: TD counts aligned to label semantics.
- td_count (int): Legacy alias for the primary td_count.
- passing_td (int): Number of passing TDs (for QBs)
- receiving_yards (float): Total receiving yards
- rushing_yards (float): Total rushing yards
- passing_yards (float): Total passing yards
"""

from __future__ import annotations

thinking
**Searching for compute_td_labels usage**
exec
/bin/zsh -lc 'cd /Users/jameswest/Desktop/nfl_predict && rg "compute_td_labels" -n utils/feature/player_game_level.py' in /Users/jameswest/Desktop/nfl_predict succeeded in 805ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
40:from utils.feature.labels import DEFAULT_LABEL_VERSION, compute_td_labels
3446:    merged = compute_td_labels(merged, version=label_version)

thinking
**Checking label generation area**
exec
/bin/zsh -lc "cd /Users/jameswest/Desktop/nfl_predict && sed -n '3380,3490p' utils/feature/player_game_level.py" in /Users/jameswest/Desktop/nfl_predict succeeded in 811ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted

def _merge_multi_role_players(df: pl.DataFrame, *, label_version: str | None = None) -> pl.DataFrame:
    """Merge stats for players who had multiple roles in same game.
    
    Example: QB who passed and rushed, WR who received and rushed.
    """
    
    # Group by (player, game) and sum all stats
    merged = (
        df
        .group_by(["season", "week", "game_id", "game_date", "player_id", "player_name"])
        .agg([
            # Sum all yardage
            pl.col("passing_yards").fill_null(0).sum().alias("passing_yards"),
            pl.col("rushing_yards").fill_null(0).sum().alias("rushing_yards"),
            pl.col("receiving_yards").fill_null(0).sum().alias("receiving_yards"),
            
            # Sum counts
            pl.col("pass_attempt").fill_null(0).sum().alias("pass_attempt"),

thinking
**Planning leak guardrails implementation**

I'll focus on implementing leak guardrails and partial decision-time logic for odds and injury, splitting the work into clear steps using a plan tool. I’ll also examine the training config to handle label versions properly.
exec
/bin/zsh -lc "cd /Users/jameswest/Desktop/nfl_predict && sed -n '1,200p' config/training.yaml" in /Users/jameswest/Desktop/nfl_predict succeeded in 3.27s:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
# config/training.yaml
# Configuration for the model training pipeline (pipeline/train.py)
# NFL Player Prediction Targets

# --- Data I/O ---
data:
  raw_pbp_dir: 'data/raw/pbp_by_day'  # NFL play-by-play raw data
  feature_matrix_path: 'data/processed/final/processed.parquet'  # NFL feature matrix
  
  # Directory to save trained model artifacts (models and feature lists).
  model_output_dir: 'output/models'
  
  # Directory to save evaluation reports and metrics.
  metrics_output_dir: 'output/metrics/'

# =============================================================================
# SHARED COLUMN DEFINITIONS (using YAML anchors to avoid duplication)
# =============================================================================
# These columns leak same-game outcomes and must be excluded from training.

thinking
**Searching for anytime_td in config**
exec
/bin/zsh -lc 'cd /Users/jameswest/Desktop/nfl_predict && rg "anytime_td" -n config/training.yaml' in /Users/jameswest/Desktop/nfl_predict succeeded in 2.21s:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
476:  - name: 'anytime_td'
477:    target_col: 'anytime_td'
667:    - 'anytime_td'

thinking
**Reviewing new configuration fields**
exec
/bin/zsh -lc "cd /Users/jameswest/Desktop/nfl_predict && sed -n '440,540p' config/training.yaml" in /Users/jameswest/Desktop/nfl_predict succeeded in 2.17s:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
      - 'availability_snapshare'
      - 'usage_targets'
      - 'usage_carries'
      - 'efficiency_rec_yards'
      - 'efficiency_rush_yards'
    feature_prefixes_to_include:
      - 'pred_'
      - 'expected_'
      - 'opp_def_'
      - 'red_zone_'
      - 'goal_to_go_'
      - 'off_ctx_'
      - 'qb_profile_'
      - 'drive_hist_'
      - 'weather_'
      - 'travel_'
    other_features_to_include:
      - 'week'
      - 'season'

thinking
**Preparing leak guard implementation**
exec
/bin/zsh -lc "cd /Users/jameswest/Desktop/nfl_predict && sed -n '90,170p' utils/general/constants.py" in /Users/jameswest/Desktop/nfl_predict succeeded in 2.45s:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
    "ARI": True,  # State Farm Stadium (retractable)
    "ATL": True,  # Mercedes-Benz Stadium (fixed)
    "DAL": True,  # AT&T Stadium (retractable)
    "DET": True,  # Ford Field (fixed)
    "HOU": True,  # NRG Stadium (retractable)
    "IND": True,  # Lucas Oil Stadium (retractable)
    "LAR": True,  # SoFi Stadium (fixed)
    "LVR": True,  # Allegiant Stadium (fixed)
    "MIN": True,  # U.S. Bank Stadium (fixed)
    "NO": True,   # Caesars Superdome (fixed)
}


# =============================================================================
# Leak-Prone Columns (Same-Game Outcomes)
# =============================================================================
# Stats that leak same-game outcomes and must be excluded from training features.
# These represent what happened in the game we're trying to predict.
#
exec
/bin/zsh -lc "cd /Users/jameswest/Desktop/nfl_predict && sed -n '170,260p' utils/general/constants.py" in /Users/jameswest/Desktop/nfl_predict succeeded in 780ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
    "ps_game_targets_inline_count",
    "ps_game_targets_backfield_count",
    "ps_game_targets_slot_share",
    "ps_game_targets_wide_share",
    "ps_game_targets_inline_share",
    "ps_game_targets_backfield_share",
    "ps_game_total_touches",
    "ps_game_scripted_touches",
    "ps_game_scripted_touch_share",
)


# =============================================================================
# Formatting Utilities
# =============================================================================

def format_cutoff_label(hours: float) -> str:
    """Format cutoff horizon hours into a compact label.
    

thinking
**Reviewing leak prevention and test coverage**
exec
/bin/zsh -lc "cd /Users/jameswest/Desktop/nfl_predict && sed -n '1,240p' tests/test_data_leak_guard.py" in /Users/jameswest/Desktop/nfl_predict succeeded in 775ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
from __future__ import annotations

import yaml
from pathlib import Path


PROJECT_ROOT = Path(__file__).resolve().parents[1]
TRAINING_CONFIG = PROJECT_ROOT / "config" / "training.yaml"
BANNED_FEATURES = {
    "status",
    "injury_game_status",
    "injury_is_inactive_designation",
    "injury_is_inactive_prob",
    "touchdown_player_id",
}


def _load_training_problem(name: str) -> dict:
    with TRAINING_CONFIG.open("r") as fp:

thinking
**Outlining implementation plan steps**

I'll prioritize building and testing the leak guard module first, then add schema artifact generation to the pipeline, and finally touch on decision-time settings for odds features, keeping scope realistic given time constraints. I'll update the plan tool accordingly to reflect these phased steps.
Plan update
Focusing this pass on P0 guardrails and decision-time realism for odds, plus schema artifacts and tests.
  → Add structured leak-guard policy helper and integrate into feature/train pipelines with schema snapshots.
  • Align odds features to decision-time horizons from config and add assertions/logging.
  • Expand tests for leak patterns and odds snapshot selection; document new config knobs briefly.

thinking
**Designing leak_guard module structures**

I'm outlining how to build the leak_guard module by defining structured leak policies using dataclasses with banned patterns, prefixes, and suffixes. I want to replace the simple leak-prone columns list with richer pattern-based policies while maintaining backward compatibility for tests and configs. I'll consider helper functions to identify allowed and banned columns with reasons, carefully balancing new structures with existing constants.

thinking
**Planning leak guard integration**
exec
/bin/zsh -lc 'cd /Users/jameswest/Desktop/nfl_predict && rg "def build_feature_matrix" -n pipeline/feature.py' in /Users/jameswest/Desktop/nfl_predict succeeded in 731ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
971:def build_feature_matrix(
exec
/bin/zsh -lc "cd /Users/jameswest/Desktop/nfl_predict && sed -n '920,1100p' pipeline/feature.py" in /Users/jameswest/Desktop/nfl_predict succeeded in 754ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
        market_exprs.append(
            (pl.col("team_implied_total") * pl.col("hist_target_share_l3"))
            .cast(pl.Float32)
            .alias("market_team_total_x_hist_target_l3")
        )
    if {"team_implied_total", "hist_carry_share_l3"} <= available_cols:
        market_exprs.append(
            (pl.col("team_implied_total") * pl.col("hist_carry_share_l3"))
            .cast(pl.Float32)
            .alias("market_team_total_x_hist_carry_l3")
        )
    if market_exprs:
        df_player_game_all = df_player_game_all.with_columns(market_exprs)
    
    # Write final feature matrix
    df_player_game_all = df_player_game_all.with_columns(
        pl.lit(current_cutoff_hours).cast(pl.Float32).alias("decision_horizon_hours")
    )


thinking
**Locating feature matrix function**
exec
/bin/zsh -lc 'cd /Users/jameswest/Desktop/nfl_predict && rg "_build_feature_matrix_internal" -n pipeline/feature.py' in /Users/jameswest/Desktop/nfl_predict succeeded in 750ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
227:def _build_feature_matrix_internal(
998:            df = _build_feature_matrix_internal(
exec
/bin/zsh -lc "cd /Users/jameswest/Desktop/nfl_predict && sed -n '227,360p' pipeline/feature.py" in /Users/jameswest/Desktop/nfl_predict succeeded in 735ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
def _build_feature_matrix_internal(
    *,
    start_date: date | None = None,
    end_date: date | None = None,
    chunk_days: int = 7,
    recompute_intermediate: bool = True,
    build_rolling: bool = True,
    output_path: Path | None = None,
    primary_output_path: Path | None = None,
    cutoff_label: str | None = None,
    label_version: str | None = None,
) -> pl.DataFrame:
    """Run full feature pipeline up to *inclusive* `end_date` for a single cutoff window.

    Parameters
    ----------
    end_date : date | None
        Last `game_date` to include in rolling windows (default: today).
    save_output : bool

thinking
**Searching for feature assembly and final steps**
exec
/bin/zsh -lc 'cd /Users/jameswest/Desktop/nfl_predict && rg "columns_to_discard" -n pipeline/feature.py' in /Users/jameswest/Desktop/nfl_predict exited 1 in 726ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted

thinking
**Checking pipeline for feature handling**
exec
/bin/zsh -lc "cd /Users/jameswest/Desktop/nfl_predict && sed -n '1,200p' pipeline/train.py" in /Users/jameswest/Desktop/nfl_predict succeeded in 700ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
import os
import random
import inspect
import sys
import logging
import math


# Move logging to top and remove global thread pinning
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# Add project root to sys.path to allow module imports when running as script
sys.path.append(os.getcwd())

import pandas as pd
import numpy as np
import yaml
import joblib
import optuna

thinking
**Searching for column filtering usage**
exec
/bin/zsh -lc 'cd /Users/jameswest/Desktop/nfl_predict && rg "columns_to_discard" -n pipeline/train.py' in /Users/jameswest/Desktop/nfl_predict exited 1 in 702ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted

thinking
**Checking training data utilities**
exec
/bin/zsh -lc 'cd /Users/jameswest/Desktop/nfl_predict && rg "feature_prefixes_to_include" -n utils/train' in /Users/jameswest/Desktop/nfl_predict succeeded in 718ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
utils/train/feature_artifacts.py:25:    include_prefixes = tuple(problem_config.get("feature_prefixes_to_include") or [])
utils/train/rolling_forward_calibration.py:146:    Uses `feature_prefixes_to_include` and `other_features_to_include`.
utils/train/rolling_forward_calibration.py:153:    prefixes = problem.get("feature_prefixes_to_include", []) or []
exec
/bin/zsh -lc "cd /Users/jameswest/Desktop/nfl_predict && sed -n '1,200p' utils/train/feature_artifacts.py" in /Users/jameswest/Desktop/nfl_predict succeeded in 702ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
from __future__ import annotations

import logging
from dataclasses import dataclass
from typing import Dict, List, Tuple

import numpy as np
import pandas as pd

logger = logging.getLogger(__name__)


@dataclass
class FeatureArtifacts:
    feature_columns: List[str]
    datetime_features: List[str]
    categorical_features: List[str]
    category_levels: Dict[str, List[str]]


thinking
**Planning leak detection helper**

thinking
**Designing leak guard for feature filtering**

I’m mapping out a LeakGuard class to enforce which feature columns are allowed per problem config, focusing on filtering out banned columns but also allowing relevant prefixes and inputs. I want to validate columns post-engineering, drop banned ones, and raise errors if forbidden columns slip through or no allowed columns remain. This will help keep datasets clean from leakage risks before saving or training.

thinking
**Evaluating feature filter strategy**

thinking
**Planning schema artifact writing**

I’m thinking about adding a "banned" tag and capturing column names and types for schema artifacts. I'll explore writing these artifacts to a timestamped JSON path under output/schema, potentially using metadata like label version and cutoff label. I want to do this after feature matrix building, so I’ll check for existing path constants like FEATURE_AUDIT_DIR to pick the right place for output files. Let’s look at the repo for FEATURE_AUDIT_DIR next.
exec
/bin/zsh -lc 'cd /Users/jameswest/Desktop/nfl_predict && rg "FEATURE_AUDIT_DIR"' in /Users/jameswest/Desktop/nfl_predict succeeded in 732ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
pipeline/feature.py:    FEATURE_AUDIT_DIR,
pipeline/feature.py:            "roster": FEATURE_AUDIT_DIR / "roster_cutoff_violations.parquet",
pipeline/feature.py:            "odds": FEATURE_AUDIT_DIR / "odds_cutoff_violations.parquet",
utils/general/paths.py:FEATURE_AUDIT_DIR = AUDIT_ROOT / "feature"
utils/general/paths.py:for d in (COLLECT_AUDIT_DIR, CLEAN_AUDIT_DIR, FEATURE_AUDIT_DIR, TRAIN_AUDIT_DIR, PREDICT_AUDIT_DIR):
exec
/bin/zsh -lc "cd /Users/jameswest/Desktop/nfl_predict && sed -n '1,120p' utils/general/paths.py" in /Users/jameswest/Desktop/nfl_predict succeeded in 704ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
#!/usr/bin/env python3
"""Central project path definitions (moved from utils.collect.paths)."""

from __future__ import annotations

from pathlib import Path
from typing import Final
import os

# ------------------------------------------------------------------------------------
# Core directories (project root, raw data, config, etc.)
# ------------------------------------------------------------------------------------

PROJ_ROOT: Final[Path] = Path(__file__).resolve().parents[2]

# Raw data tree
DATA_RAW: Final[Path] = PROJ_ROOT / "data" / "raw"
DATA_CONFIG: Final[Path] = DATA_RAW / "config"
DATA_PBP: Final[Path] = DATA_RAW / "pbp"  # NFL play-by-play data

thinking
**Designing leak guard feature and schema paths**

I’m planning to implement a leak guard by creating a new utility module with policies to detect banned columns using exact matches, prefixes, suffixes, and regex patterns. I’m also figuring out how to organize schema artifact paths within existing or new directory constants to keep things tidy and writable. I want to keep the policies precise to avoid being too broad while covering key leakage cases.

thinking
**Analyzing data sanitization and allowlist strategy**

thinking
**Designing leak guard integration**

I'm thinking about how to integrate leak guard checks into the feature pipeline, focusing on enforcing banned columns after feature creation but before dataset write-out. I'll consider using a function that applies leak guard logic with configurable allowlists, handling Polars DataFrames, and ensuring banned features get filtered or flagged appropriately while preserving necessary columns for downstream use.

thinking
**Reviewing feature filtering and leak guard integration**
exec
/bin/zsh -lc 'cd /Users/jameswest/Desktop/nfl_predict && rg "train_problem" -n pipeline/train.py' in /Users/jameswest/Desktop/nfl_predict exited 1 in 761ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted

thinking
**Searching for training loop indications**
exec
/bin/zsh -lc 'cd /Users/jameswest/Desktop/nfl_predict && rg "problems" -n pipeline/train.py' in /Users/jameswest/Desktop/nfl_predict succeeded in 729ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
236:        if "problems" in overrides and overrides["problems"]:
237:            self.config["problems"] = [p for p in self.config["problems"] if p["name"] in set(overrides["problems"])]
297:        self.problems = self.config['problems']
299:        # Store predictions + merge keys for downstream problems
980:        """Prepare team total adjustment configuration for classification problems."""
2130:        """Execute the full training pipeline for all defined problems."""
2152:        for problem in self.problems:
2244:            # Check if this problem requires input predictions from previous problems
2420:        # --- NEW: build composite & team conformal sum artifacts after all problems trained ---
2509:                for p in self.problems:
2530:    problem_config = next((p for p in base_trainer.config['problems'] if p['name'] == problem_name), None)
2667:    parser.add_argument('--problems', type=str, default='', help="Comma-separated subset of problems to run.")
2688:                "problems": [p.strip() for p in args.problems.split(",") if p.strip()] if args.problems else None,
exec
/bin/zsh -lc "cd /Users/jameswest/Desktop/nfl_predict && sed -n '2100,2250p' pipeline/train.py" in /Users/jameswest/Desktop/nfl_predict succeeded in 739ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
                if 'clf' in model.named_steps:
                    return model.named_steps['clf']
                else:
                    return model.steps[-1][1]
        except Exception:
            pass

        # 3) Our custom calibration wrappers
        try:
            if isinstance(model, (IsotonicCalibratedModel, BetaCalibratedModel, HistogramBinningCalibratedModel)):
                return model.base_estimator
        except Exception:
            pass

        try:
            if isinstance(model, (IsotonicMeanCalibratedRegressor, SplitConformalRegressor)):
                return model.base_estimator
        except Exception:
            pass

thinking
**Searching for feature filtering in training**
exec
/bin/zsh -lc "cd /Users/jameswest/Desktop/nfl_predict && sed -n '2250,2390p' pipeline/train.py" in /Users/jameswest/Desktop/nfl_predict succeeded in 700ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
                    needed_cols.append('player_id')

# 👇 NEW: add team meta columns if present
            if needed_cols is not None and all_parquet_cols is not None:
                for _c in ["away_team_abbr", "home_team_abbr", "inning_topbot"]:
                    if _c in all_parquet_cols:
                        needed_cols.append(_c)

            # Load problem-scoped frame with only the required columns
            logger.info(f"Loading problem-scoped columns from Parquet (cols={len(needed_cols) if needed_cols else 'ALL'}) …")
            if needed_cols:
                needed_cols = sorted(list(set(needed_cols)))
                logger.info(f"Unique needed_cols count: {len(needed_cols)}")

            df_problem = load_feature_matrix(
                path=feature_matrix_path,
                time_col=self.time_col,
                columns=needed_cols,
            )

thinking
**Designing column leak guard**

thinking
**Designing schema building and drop logic**

I’m figuring out how to build a schema artifact that includes column metadata and banned flags, decide on an optional dropping of non-allowlisted columns to avoid accidental data loss, and plan to add tags based on heuristics for identifiers and labels. I also want to pass feature pipeline metadata into the schema and carefully integrate new imports and tests that check pattern detection and proper dropping of banned features.

thinking
**Planning leak guard implementation**

I’m figuring out how to build functions and tests for the leak guard, including handling allowlists and ensuring no real file writes during tests by returning schema data structures instead. I’m preparing to create a new module with dataclasses and a default policy version, aiming to integrate the guard in the pipeline’s train step while managing data type conversions.

thinking
**Reviewing regex patterns for leak policy**

thinking
**Adjusting column filtering and drop logic**

I'm refining how allowed columns are gathered and dropped from the DataFrame, ensuring compatibility with both pandas and polars. I’m double-checking that dropping columns works seamlessly without requiring pandas explicitly, and planning a helper to render schema info including policy metadata and banned flags.

thinking
**Designing schema snapshot functions**
file update
A /Users/jameswest/Desktop/nfl_predict/utils/feature/leak_guard.py
"""Leak guardrails for feature matrices.

This module centralizes pattern-based leak detection so both feature assembly
and training can fail fast when post-outcome columns sneak into the data.
"""

from __future__ import annotations

from dataclasses import dataclass
from datetime import datetime
import json
import re
from typing import Iterable, Mapping, Sequence

import polars as pl

from utils.general.constants import IDENTIFIER_COLUMNS, LEAK_PRONE_COLUMNS, NFL_TARGET_COLUMNS

try:  # Optional dependency when imported from training (pandas path)
    import pandas as pd  # type: ignore
except Exception:  # pragma: no cover - optional dependency
    pd = None


@dataclass(frozen=True)
class LeakPolicy:
    version: str
    banned_exact: set[str]
    banned_prefixes: tuple[str, ...]
    banned_suffixes: tuple[str, ...]
    banned_regex: tuple[tuple[re.Pattern[str], str], ...]
    description: str = ""


@dataclass
class LeakCheckResult:
    policy_version: str
    banned: dict[str, str]
    kept: list[str]
    dropped: list[str]
    allowlist_kept: list[str]


# Core policy tuned for anytime-TD style problems (can be extended per-problem).
_BASE_BANNED_EXACT = set(LEAK_PRONE_COLUMNS) | {
    "final_score",
    "final_total",
    "points_scored",
    "actual_td_count",
    "actual_anytime_td",
    "postgame_anytime_td",
    "postgame_td_count",
}
_BASE_BANNED_PREFIXES = (
    "postgame_",
    "post_game_",
    "post_",
    "live_",
    "actual_",
    "realized_",
    "final_",
    "postmatch_",
)
_BASE_BANNED_SUFFIXES = (
    "_post",
    "_postgame",
    "_final",
    "_fullgame",
    "_actual",
)
_BASE_BANNED_REGEX: tuple[tuple[re.Pattern[str], str], ...] = (
    (re.compile(r".*post.?game.*", flags=re.IGNORECASE), "postgame marker"),
    (re.compile(r".*final_score.*", flags=re.IGNORECASE), "final score"),
    (re.compile(r".*actual.*td.*", flags=re.IGNORECASE), "actual TD total"),
    (re.compile(r".*anytime_td.*(post|final|actual).*", flags=re.IGNORECASE), "post-decision anytime TD"),
    (re.compile(r".*fullgame.*", flags=re.IGNORECASE), "full game cumulative value"),
)

DEFAULT_LEAK_POLICY = LeakPolicy(
    version="v1",
    description="Core post-outcome leak guard for NFL anytime TD features.",
    banned_exact=_BASE_BANNED_EXACT,
    banned_prefixes=_BASE_BANNED_PREFIXES,
    banned_suffixes=_BASE_BANNED_SUFFIXES,
    banned_regex=_BASE_BANNED_REGEX,
)


def _ensure_sequence(value: Sequence[str] | str | None) -> tuple[str, ...]:
    if value is None:
        return ()
    if isinstance(value, str):
        return (value,)
    return tuple(value)


def evaluate_leak_prone_columns(
    columns: Iterable[str],
    *,
    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
) -> LeakCheckResult:
    """Identify leak-prone columns using the configured policy."""

    banned: dict[str, str] = {}
    columns_list = list(columns)
    for col in columns_list:
        if col in policy.banned_exact:
            banned[col] = "exact"
            continue
        for prefix in policy.banned_prefixes:
            if col.startswith(prefix):
                banned[col] = f"prefix:{prefix}"
                break
        if col in banned:
            continue
        for suffix in policy.banned_suffixes:
            if col.endswith(suffix):
                banned[col] = f"suffix:{suffix}"
                break
        if col in banned:
            continue
        for pattern, reason in policy.banned_regex:
            if pattern.match(col):
                banned[col] = reason
                break

    kept = [c for c in columns_list if c not in banned]
    return LeakCheckResult(
        policy_version=policy.version,
        banned=banned,
        kept=kept,
        dropped=[],
        allowlist_kept=[],
    )


def enforce_leak_guard(
    df: pl.DataFrame | "pd.DataFrame",
    *,
    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
    allow_prefixes: Sequence[str] | str | None = None,
    allow_exact: Sequence[str] | str | None = None,
    drop_banned: bool = True,
    drop_non_allowlisted: bool = False,
    raise_on_banned: bool = True,
) -> tuple[pl.DataFrame | "pd.DataFrame", LeakCheckResult]:
    """Apply leak guardrails to a feature frame.

    Parameters
    ----------
    df : DataFrame
        Polars or pandas DataFrame.
    policy : LeakPolicy
        Leak policy to apply.
    allow_prefixes : Sequence[str] | str | None
        Optional prefixes that define the allowed feature surface for a problem.
    allow_exact : Sequence[str] | str | None
        Explicitly allowed columns (e.g., identifiers).
    drop_banned : bool
        If True, drop any banned columns automatically.
    drop_non_allowlisted : bool
        If True, drop columns that are not covered by allow_prefixes/allow_exact/identifiers/targets.
    raise_on_banned : bool
        If True, raise when banned columns are detected (after optional drop).
    """

    result = evaluate_leak_prone_columns(df.columns, policy=policy)
    dropped: list[str] = []

    if result.banned and drop_banned:
        df = df.drop(list(result.banned.keys()))
        dropped.extend(result.banned.keys())

    if result.banned and raise_on_banned:
        raise ValueError(
            f"Leak-prone columns detected: {sorted(result.banned.items())}"
        )

    allow_prefixes = _ensure_sequence(allow_prefixes)
    allow_exact = set(_ensure_sequence(allow_exact))
    allow_exact.update({col for col in IDENTIFIER_COLUMNS if col in df.columns})
    allow_exact.update({col for col in NFL_TARGET_COLUMNS if col in df.columns})

    allowlist_cols: set[str] = set()
    if allow_prefixes:
        allowlist_cols.update({c for c in df.columns if c.startswith(allow_prefixes)})
    allowlist_cols.update({c for c in allow_exact if c in df.columns})

    if drop_non_allowlisted and allowlist_cols:
        drop_candidates = [c for c in df.columns if c not in allowlist_cols]
        if drop_candidates:
            df = df.drop(drop_candidates)
            dropped.extend(drop_candidates)

    if drop_non_allowlisted and not allowlist_cols:
        raise ValueError("No allowlisted columns remain after applying leak guard allowlist.")

    result.dropped = dropped
    result.kept = [c for c in df.columns]
    result.allowlist_kept = sorted(list(allowlist_cols)) if allowlist_cols else []
    return df, result


def build_schema_snapshot(
    df: pl.DataFrame | "pd.DataFrame",
    *,
    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
    metadata: Mapping[str, object] | None = None,
    banned: Mapping[str, str] | None = None,
) -> dict:
    """Render a schema snapshot describing each column and whether it was flagged."""

    banned = banned or {}
    meta = {
        "generated_at_utc": datetime.utcnow().isoformat(),
        "policy_version": policy.version,
    }
    meta.update(metadata or {})

    # Extract columns / dtypes
    if isinstance(df, pl.DataFrame):
        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
    else:  # pandas or pandas-like
        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]

    schema = {
        "metadata": meta,
        "columns": [],
    }

    for col, dtype in cols_and_dtypes:
        tags: list[str] = []
        if col in IDENTIFIER_COLUMNS:
            tags.append("id")
        if col in NFL_TARGET_COLUMNS:
            tags.append("label")
        if col.startswith("market_"):
            tags.append("odds")
        if col.startswith("injury_") or col.startswith("practice_"):
            tags.append("injury")
        if col.startswith("weather_"):
            tags.append("weather")
        if col.startswith("ps_"):
            tags.append("pre_snap")
        schema["columns"].append(
            {
                "name": col,
                "dtype": dtype,
                "banned": col in banned,
                "tags": tags,
            }
        )
    return schema


def write_schema_snapshot(path, schema: Mapping[str, object]) -> None:
    path.parent.mkdir(parents=True, exist_ok=True)
    with open(path, "w") as fp:
        json.dump(schema, fp, indent=2, sort_keys=True)


__all__ = [
    "DEFAULT_LEAK_POLICY",
    "LeakPolicy",
    "LeakCheckResult",
    "evaluate_leak_prone_columns",
    "enforce_leak_guard",
    "build_schema_snapshot",
    "write_schema_snapshot",
]
apply_patch(auto_approved=true) exited 0 in 42ms:
Success. Updated the following files:
A utils/feature/leak_guard.py
file update:
diff --git a/utils/feature/leak_guard.py b/utils/feature/leak_guard.py
new file mode 100644
index 0000000000000000000000000000000000000000..89233777af882237f211e3f4fc097e0b8f553e4b
--- /dev/null
+++ b/utils/feature/leak_guard.py
@@ -0,0 +1,270 @@
+"""Leak guardrails for feature matrices.
+
+This module centralizes pattern-based leak detection so both feature assembly
+and training can fail fast when post-outcome columns sneak into the data.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+from datetime import datetime
+import json
+import re
+from typing import Iterable, Mapping, Sequence
+
+import polars as pl
+
+from utils.general.constants import IDENTIFIER_COLUMNS, LEAK_PRONE_COLUMNS, NFL_TARGET_COLUMNS
+
+try:  # Optional dependency when imported from training (pandas path)
+    import pandas as pd  # type: ignore
+except Exception:  # pragma: no cover - optional dependency
+    pd = None
+
+
+@dataclass(frozen=True)
+class LeakPolicy:
+    version: str
+    banned_exact: set[str]
+    banned_prefixes: tuple[str, ...]
+    banned_suffixes: tuple[str, ...]
+    banned_regex: tuple[tuple[re.Pattern[str], str], ...]
+    description: str = ""
+
+
+@dataclass
+class LeakCheckResult:
+    policy_version: str
+    banned: dict[str, str]
+    kept: list[str]
+    dropped: list[str]
+    allowlist_kept: list[str]
+
+
+# Core policy tuned for anytime-TD style problems (can be extended per-problem).
+_BASE_BANNED_EXACT = set(LEAK_PRONE_COLUMNS) | {
+    "final_score",
+    "final_total",
+    "points_scored",
+    "actual_td_count",
+    "actual_anytime_td",
+    "postgame_anytime_td",
+    "postgame_td_count",
+}
+_BASE_BANNED_PREFIXES = (
+    "postgame_",
+    "post_game_",
+    "post_",
+    "live_",
+    "actual_",
+    "realized_",
+    "final_",
+    "postmatch_",
+)
+_BASE_BANNED_SUFFIXES = (
+    "_post",
+    "_postgame",
+    "_final",
+    "_fullgame",
+    "_actual",
+)
+_BASE_BANNED_REGEX: tuple[tuple[re.Pattern[str], str], ...] = (
+    (re.compile(r".*post.?game.*", flags=re.IGNORECASE), "postgame marker"),
+    (re.compile(r".*final_score.*", flags=re.IGNORECASE), "final score"),
+    (re.compile(r".*actual.*td.*", flags=re.IGNORECASE), "actual TD total"),
+    (re.compile(r".*anytime_td.*(post|final|actual).*", flags=re.IGNORECASE), "post-decision anytime TD"),
+    (re.compile(r".*fullgame.*", flags=re.IGNORECASE), "full game cumulative value"),
+)
+
+DEFAULT_LEAK_POLICY = LeakPolicy(
+    version="v1",
+    description="Core post-outcome leak guard for NFL anytime TD features.",
+    banned_exact=_BASE_BANNED_EXACT,
+    banned_prefixes=_BASE_BANNED_PREFIXES,
+    banned_suffixes=_BASE_BANNED_SUFFIXES,
+    banned_regex=_BASE_BANNED_REGEX,
+)
+
+
+def _ensure_sequence(value: Sequence[str] | str | None) -> tuple[str, ...]:
+    if value is None:
+        return ()
+    if isinstance(value, str):
+        return (value,)
+    return tuple(value)
+
+
+def evaluate_leak_prone_columns(
+    columns: Iterable[str],
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+) -> LeakCheckResult:
+    """Identify leak-prone columns using the configured policy."""
+
+    banned: dict[str, str] = {}
+    columns_list = list(columns)
+    for col in columns_list:
+        if col in policy.banned_exact:
+            banned[col] = "exact"
+            continue
+        for prefix in policy.banned_prefixes:
+            if col.startswith(prefix):
+                banned[col] = f"prefix:{prefix}"
+                break
+        if col in banned:
+            continue
+        for suffix in policy.banned_suffixes:
+            if col.endswith(suffix):
+                banned[col] = f"suffix:{suffix}"
+                break
+        if col in banned:
+            continue
+        for pattern, reason in policy.banned_regex:
+            if pattern.match(col):
+                banned[col] = reason
+                break
+
+    kept = [c for c in columns_list if c not in banned]
+    return LeakCheckResult(
+        policy_version=policy.version,
+        banned=banned,
+        kept=kept,
+        dropped=[],
+        allowlist_kept=[],
+    )
+
+
+def enforce_leak_guard(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    allow_prefixes: Sequence[str] | str | None = None,
+    allow_exact: Sequence[str] | str | None = None,
+    drop_banned: bool = True,
+    drop_non_allowlisted: bool = False,
+    raise_on_banned: bool = True,
+) -> tuple[pl.DataFrame | "pd.DataFrame", LeakCheckResult]:
+    """Apply leak guardrails to a feature frame.
+
+    Parameters
+    ----------
+    df : DataFrame
+        Polars or pandas DataFrame.
+    policy : LeakPolicy
+        Leak policy to apply.
+    allow_prefixes : Sequence[str] | str | None
+        Optional prefixes that define the allowed feature surface for a problem.
+    allow_exact : Sequence[str] | str | None
+        Explicitly allowed columns (e.g., identifiers).
+    drop_banned : bool
+        If True, drop any banned columns automatically.
+    drop_non_allowlisted : bool
+        If True, drop columns that are not covered by allow_prefixes/allow_exact/identifiers/targets.
+    raise_on_banned : bool
+        If True, raise when banned columns are detected (after optional drop).
+    """
+
+    result = evaluate_leak_prone_columns(df.columns, policy=policy)
+    dropped: list[str] = []
+
+    if result.banned and drop_banned:
+        df = df.drop(list(result.banned.keys()))
+        dropped.extend(result.banned.keys())
+
+    if result.banned and raise_on_banned:
+        raise ValueError(
+            f"Leak-prone columns detected: {sorted(result.banned.items())}"
+        )
+
+    allow_prefixes = _ensure_sequence(allow_prefixes)
+    allow_exact = set(_ensure_sequence(allow_exact))
+    allow_exact.update({col for col in IDENTIFIER_COLUMNS if col in df.columns})
+    allow_exact.update({col for col in NFL_TARGET_COLUMNS if col in df.columns})
+
+    allowlist_cols: set[str] = set()
+    if allow_prefixes:
+        allowlist_cols.update({c for c in df.columns if c.startswith(allow_prefixes)})
+    allowlist_cols.update({c for c in allow_exact if c in df.columns})
+
+    if drop_non_allowlisted and allowlist_cols:
+        drop_candidates = [c for c in df.columns if c not in allowlist_cols]
+        if drop_candidates:
+            df = df.drop(drop_candidates)
+            dropped.extend(drop_candidates)
+
+    if drop_non_allowlisted and not allowlist_cols:
+        raise ValueError("No allowlisted columns remain after applying leak guard allowlist.")
+
+    result.dropped = dropped
+    result.kept = [c for c in df.columns]
+    result.allowlist_kept = sorted(list(allowlist_cols)) if allowlist_cols else []
+    return df, result
+
+
+def build_schema_snapshot(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    metadata: Mapping[str, object] | None = None,
+    banned: Mapping[str, str] | None = None,
+) -> dict:
+    """Render a schema snapshot describing each column and whether it was flagged."""
+
+    banned = banned or {}
+    meta = {
+        "generated_at_utc": datetime.utcnow().isoformat(),
+        "policy_version": policy.version,
+    }
+    meta.update(metadata or {})
+
+    # Extract columns / dtypes
+    if isinstance(df, pl.DataFrame):
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+    else:  # pandas or pandas-like
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+
+    schema = {
+        "metadata": meta,
+        "columns": [],
+    }
+
+    for col, dtype in cols_and_dtypes:
+        tags: list[str] = []
+        if col in IDENTIFIER_COLUMNS:
+            tags.append("id")
+        if col in NFL_TARGET_COLUMNS:
+            tags.append("label")
+        if col.startswith("market_"):
+            tags.append("odds")
+        if col.startswith("injury_") or col.startswith("practice_"):
+            tags.append("injury")
+        if col.startswith("weather_"):
+            tags.append("weather")
+        if col.startswith("ps_"):
+            tags.append("pre_snap")
+        schema["columns"].append(
+            {
+                "name": col,
+                "dtype": dtype,
+                "banned": col in banned,
+                "tags": tags,
+            }
+        )
+    return schema
+
+
+def write_schema_snapshot(path, schema: Mapping[str, object]) -> None:
+    path.parent.mkdir(parents=True, exist_ok=True)
+    with open(path, "w") as fp:
+        json.dump(schema, fp, indent=2, sort_keys=True)
+
+
+__all__ = [
+    "DEFAULT_LEAK_POLICY",
+    "LeakPolicy",
+    "LeakCheckResult",
+    "evaluate_leak_prone_columns",
+    "enforce_leak_guard",
+    "build_schema_snapshot",
+    "write_schema_snapshot",
+]

file update:
diff --git a/utils/feature/leak_guard.py b/utils/feature/leak_guard.py
new file mode 100644
index 0000000000000000000000000000000000000000..89233777af882237f211e3f4fc097e0b8f553e4b
--- /dev/null
+++ b/utils/feature/leak_guard.py
@@ -0,0 +1,270 @@
+"""Leak guardrails for feature matrices.
+
+This module centralizes pattern-based leak detection so both feature assembly
+and training can fail fast when post-outcome columns sneak into the data.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+from datetime import datetime
+import json
+import re
+from typing import Iterable, Mapping, Sequence
+
+import polars as pl
+
+from utils.general.constants import IDENTIFIER_COLUMNS, LEAK_PRONE_COLUMNS, NFL_TARGET_COLUMNS
+
+try:  # Optional dependency when imported from training (pandas path)
+    import pandas as pd  # type: ignore
+except Exception:  # pragma: no cover - optional dependency
+    pd = None
+
+
+@dataclass(frozen=True)
+class LeakPolicy:
+    version: str
+    banned_exact: set[str]
+    banned_prefixes: tuple[str, ...]
+    banned_suffixes: tuple[str, ...]
+    banned_regex: tuple[tuple[re.Pattern[str], str], ...]
+    description: str = ""
+
+
+@dataclass
+class LeakCheckResult:
+    policy_version: str
+    banned: dict[str, str]
+    kept: list[str]
+    dropped: list[str]
+    allowlist_kept: list[str]
+
+
+# Core policy tuned for anytime-TD style problems (can be extended per-problem).
+_BASE_BANNED_EXACT = set(LEAK_PRONE_COLUMNS) | {
+    "final_score",
+    "final_total",
+    "points_scored",
+    "actual_td_count",
+    "actual_anytime_td",
+    "postgame_anytime_td",
+    "postgame_td_count",
+}
+_BASE_BANNED_PREFIXES = (
+    "postgame_",
+    "post_game_",
+    "post_",
+    "live_",
+    "actual_",
+    "realized_",
+    "final_",
+    "postmatch_",
+)
+_BASE_BANNED_SUFFIXES = (
+    "_post",
+    "_postgame",
+    "_final",
+    "_fullgame",
+    "_actual",
+)
+_BASE_BANNED_REGEX: tuple[tuple[re.Pattern[str], str], ...] = (
+    (re.compile(r".*post.?game.*", flags=re.IGNORECASE), "postgame marker"),
+    (re.compile(r".*final_score.*", flags=re.IGNORECASE), "final score"),
+    (re.compile(r".*actual.*td.*", flags=re.IGNORECASE), "actual TD total"),
+    (re.compile(r".*anytime_td.*(post|final|actual).*", flags=re.IGNORECASE), "post-decision anytime TD"),
+    (re.compile(r".*fullgame.*", flags=re.IGNORECASE), "full game cumulative value"),
+)
+
+DEFAULT_LEAK_POLICY = LeakPolicy(
+    version="v1",
+    description="Core post-outcome leak guard for NFL anytime TD features.",
+    banned_exact=_BASE_BANNED_EXACT,
+    banned_prefixes=_BASE_BANNED_PREFIXES,
+    banned_suffixes=_BASE_BANNED_SUFFIXES,
+    banned_regex=_BASE_BANNED_REGEX,
+)
+
+
+def _ensure_sequence(value: Sequence[str] | str | None) -> tuple[str, ...]:
+    if value is None:
+        return ()
+    if isinstance(value, str):
+        return (value,)
+    return tuple(value)
+
+
+def evaluate_leak_prone_columns(
+    columns: Iterable[str],
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+) -> LeakCheckResult:
+    """Identify leak-prone columns using the configured policy."""
+
+    banned: dict[str, str] = {}
+    columns_list = list(columns)
+    for col in columns_list:
+        if col in policy.banned_exact:
+            banned[col] = "exact"
+            continue
+        for prefix in policy.banned_prefixes:
+            if col.startswith(prefix):
+                banned[col] = f"prefix:{prefix}"
+                break
+        if col in banned:
+            continue
+        for suffix in policy.banned_suffixes:
+            if col.endswith(suffix):
+                banned[col] = f"suffix:{suffix}"
+                break
+        if col in banned:
+            continue
+        for pattern, reason in policy.banned_regex:
+            if pattern.match(col):
+                banned[col] = reason
+                break
+
+    kept = [c for c in columns_list if c not in banned]
+    return LeakCheckResult(
+        policy_version=policy.version,
+        banned=banned,
+        kept=kept,
+        dropped=[],
+        allowlist_kept=[],
+    )
+
+
+def enforce_leak_guard(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    allow_prefixes: Sequence[str] | str | None = None,
+    allow_exact: Sequence[str] | str | None = None,
+    drop_banned: bool = True,
+    drop_non_allowlisted: bool = False,
+    raise_on_banned: bool = True,
+) -> tuple[pl.DataFrame | "pd.DataFrame", LeakCheckResult]:
+    """Apply leak guardrails to a feature frame.
+
+    Parameters
+    ----------
+    df : DataFrame
+        Polars or pandas DataFrame.
+    policy : LeakPolicy
+        Leak policy to apply.
+    allow_prefixes : Sequence[str] | str | None
+        Optional prefixes that define the allowed feature surface for a problem.
+    allow_exact : Sequence[str] | str | None
+        Explicitly allowed columns (e.g., identifiers).
+    drop_banned : bool
+        If True, drop any banned columns automatically.
+    drop_non_allowlisted : bool
+        If True, drop columns that are not covered by allow_prefixes/allow_exact/identifiers/targets.
+    raise_on_banned : bool
+        If True, raise when banned columns are detected (after optional drop).
+    """
+
+    result = evaluate_leak_prone_columns(df.columns, policy=policy)
+    dropped: list[str] = []
+
+    if result.banned and drop_banned:
+        df = df.drop(list(result.banned.keys()))
+        dropped.extend(result.banned.keys())
+
+    if result.banned and raise_on_banned:
+        raise ValueError(
+            f"Leak-prone columns detected: {sorted(result.banned.items())}"
+        )
+
+    allow_prefixes = _ensure_sequence(allow_prefixes)
+    allow_exact = set(_ensure_sequence(allow_exact))
+    allow_exact.update({col for col in IDENTIFIER_COLUMNS if col in df.columns})
+    allow_exact.update({col for col in NFL_TARGET_COLUMNS if col in df.columns})
+
+    allowlist_cols: set[str] = set()
+    if allow_prefixes:
+        allowlist_cols.update({c for c in df.columns if c.startswith(allow_prefixes)})
+    allowlist_cols.update({c for c in allow_exact if c in df.columns})
+
+    if drop_non_allowlisted and allowlist_cols:
+        drop_candidates = [c for c in df.columns if c not in allowlist_cols]
+        if drop_candidates:
+            df = df.drop(drop_candidates)
+            dropped.extend(drop_candidates)
+
+    if drop_non_allowlisted and not allowlist_cols:
+        raise ValueError("No allowlisted columns remain after applying leak guard allowlist.")
+
+    result.dropped = dropped
+    result.kept = [c for c in df.columns]
+    result.allowlist_kept = sorted(list(allowlist_cols)) if allowlist_cols else []
+    return df, result
+
+
+def build_schema_snapshot(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    metadata: Mapping[str, object] | None = None,
+    banned: Mapping[str, str] | None = None,
+) -> dict:
+    """Render a schema snapshot describing each column and whether it was flagged."""
+
+    banned = banned or {}
+    meta = {
+        "generated_at_utc": datetime.utcnow().isoformat(),
+        "policy_version": policy.version,
+    }
+    meta.update(metadata or {})
+
+    # Extract columns / dtypes
+    if isinstance(df, pl.DataFrame):
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+    else:  # pandas or pandas-like
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+
+    schema = {
+        "metadata": meta,
+        "columns": [],
+    }
+
+    for col, dtype in cols_and_dtypes:
+        tags: list[str] = []
+        if col in IDENTIFIER_COLUMNS:
+            tags.append("id")
+        if col in NFL_TARGET_COLUMNS:
+            tags.append("label")
+        if col.startswith("market_"):
+            tags.append("odds")
+        if col.startswith("injury_") or col.startswith("practice_"):
+            tags.append("injury")
+        if col.startswith("weather_"):
+            tags.append("weather")
+        if col.startswith("ps_"):
+            tags.append("pre_snap")
+        schema["columns"].append(
+            {
+                "name": col,
+                "dtype": dtype,
+                "banned": col in banned,
+                "tags": tags,
+            }
+        )
+    return schema
+
+
+def write_schema_snapshot(path, schema: Mapping[str, object]) -> None:
+    path.parent.mkdir(parents=True, exist_ok=True)
+    with open(path, "w") as fp:
+        json.dump(schema, fp, indent=2, sort_keys=True)
+
+
+__all__ = [
+    "DEFAULT_LEAK_POLICY",
+    "LeakPolicy",
+    "LeakCheckResult",
+    "evaluate_leak_prone_columns",
+    "enforce_leak_guard",
+    "build_schema_snapshot",
+    "write_schema_snapshot",
+]


thinking
**Planning leak guard integration**

I'm figuring out where to import and run the leak guard functions in the pipeline, probably near the end before writing out. I’m weighing whether to raise errors or drop banned columns—raising seems best to catch leaks explicitly, but I need to confirm how label columns fit into the banned list since they might be expected in the dataset without causing leak errors. I'll keep exploring this balance to avoid false positives while enforcing data safety.

thinking
**Analyzing leak guard behavior with label columns**

thinking
**Considering handling of banned columns in leak guard enforcement**

thinking
**Planning to modify enforcement logic**
file update
M /Users/jameswest/Desktop/nfl_predict/utils/feature/leak_guard.py
@@ -169,11 +169,2 @@
 
-    if result.banned and drop_banned:
-        df = df.drop(list(result.banned.keys()))
-        dropped.extend(result.banned.keys())
-
-    if result.banned and raise_on_banned:
-        raise ValueError(
-            f"Leak-prone columns detected: {sorted(result.banned.items())}"
-        )
-
     allow_prefixes = _ensure_sequence(allow_prefixes)
@@ -183,2 +174,12 @@
 
+    # Permit allowlisted columns even if they match a banned rule (e.g., labels)
+    banned = {col: reason for col, reason in result.banned.items() if col not in allow_exact}
+
+    if banned and drop_banned:
+        df = df.drop(list(banned.keys()))
+        dropped.extend(banned.keys())
+
+    if banned and raise_on_banned:
+        raise ValueError(f"Leak-prone columns detected: {sorted(banned.items())}")
+
     allowlist_cols: set[str] = set()
@@ -197,2 +198,4 @@
 
+    # Store adjusted banned info on the result
+    result.banned = banned
     result.dropped = dropped
apply_patch(auto_approved=true) exited 0 in 54ms:
Success. Updated the following files:
M utils/feature/leak_guard.py
file update:
diff --git a/utils/feature/leak_guard.py b/utils/feature/leak_guard.py
new file mode 100644
index 0000000000000000000000000000000000000000..9faf8cfffc436e0934b2f410aaf252e52f4f95df
--- /dev/null
+++ b/utils/feature/leak_guard.py
@@ -0,0 +1,273 @@
+"""Leak guardrails for feature matrices.
+
+This module centralizes pattern-based leak detection so both feature assembly
+and training can fail fast when post-outcome columns sneak into the data.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+from datetime import datetime
+import json
+import re
+from typing import Iterable, Mapping, Sequence
+
+import polars as pl
+
+from utils.general.constants import IDENTIFIER_COLUMNS, LEAK_PRONE_COLUMNS, NFL_TARGET_COLUMNS
+
+try:  # Optional dependency when imported from training (pandas path)
+    import pandas as pd  # type: ignore
+except Exception:  # pragma: no cover - optional dependency
+    pd = None
+
+
+@dataclass(frozen=True)
+class LeakPolicy:
+    version: str
+    banned_exact: set[str]
+    banned_prefixes: tuple[str, ...]
+    banned_suffixes: tuple[str, ...]
+    banned_regex: tuple[tuple[re.Pattern[str], str], ...]
+    description: str = ""
+
+
+@dataclass
+class LeakCheckResult:
+    policy_version: str
+    banned: dict[str, str]
+    kept: list[str]
+    dropped: list[str]
+    allowlist_kept: list[str]
+
+
+# Core policy tuned for anytime-TD style problems (can be extended per-problem).
+_BASE_BANNED_EXACT = set(LEAK_PRONE_COLUMNS) | {
+    "final_score",
+    "final_total",
+    "points_scored",
+    "actual_td_count",
+    "actual_anytime_td",
+    "postgame_anytime_td",
+    "postgame_td_count",
+}
+_BASE_BANNED_PREFIXES = (
+    "postgame_",
+    "post_game_",
+    "post_",
+    "live_",
+    "actual_",
+    "realized_",
+    "final_",
+    "postmatch_",
+)
+_BASE_BANNED_SUFFIXES = (
+    "_post",
+    "_postgame",
+    "_final",
+    "_fullgame",
+    "_actual",
+)
+_BASE_BANNED_REGEX: tuple[tuple[re.Pattern[str], str], ...] = (
+    (re.compile(r".*post.?game.*", flags=re.IGNORECASE), "postgame marker"),
+    (re.compile(r".*final_score.*", flags=re.IGNORECASE), "final score"),
+    (re.compile(r".*actual.*td.*", flags=re.IGNORECASE), "actual TD total"),
+    (re.compile(r".*anytime_td.*(post|final|actual).*", flags=re.IGNORECASE), "post-decision anytime TD"),
+    (re.compile(r".*fullgame.*", flags=re.IGNORECASE), "full game cumulative value"),
+)
+
+DEFAULT_LEAK_POLICY = LeakPolicy(
+    version="v1",
+    description="Core post-outcome leak guard for NFL anytime TD features.",
+    banned_exact=_BASE_BANNED_EXACT,
+    banned_prefixes=_BASE_BANNED_PREFIXES,
+    banned_suffixes=_BASE_BANNED_SUFFIXES,
+    banned_regex=_BASE_BANNED_REGEX,
+)
+
+
+def _ensure_sequence(value: Sequence[str] | str | None) -> tuple[str, ...]:
+    if value is None:
+        return ()
+    if isinstance(value, str):
+        return (value,)
+    return tuple(value)
+
+
+def evaluate_leak_prone_columns(
+    columns: Iterable[str],
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+) -> LeakCheckResult:
+    """Identify leak-prone columns using the configured policy."""
+
+    banned: dict[str, str] = {}
+    columns_list = list(columns)
+    for col in columns_list:
+        if col in policy.banned_exact:
+            banned[col] = "exact"
+            continue
+        for prefix in policy.banned_prefixes:
+            if col.startswith(prefix):
+                banned[col] = f"prefix:{prefix}"
+                break
+        if col in banned:
+            continue
+        for suffix in policy.banned_suffixes:
+            if col.endswith(suffix):
+                banned[col] = f"suffix:{suffix}"
+                break
+        if col in banned:
+            continue
+        for pattern, reason in policy.banned_regex:
+            if pattern.match(col):
+                banned[col] = reason
+                break
+
+    kept = [c for c in columns_list if c not in banned]
+    return LeakCheckResult(
+        policy_version=policy.version,
+        banned=banned,
+        kept=kept,
+        dropped=[],
+        allowlist_kept=[],
+    )
+
+
+def enforce_leak_guard(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    allow_prefixes: Sequence[str] | str | None = None,
+    allow_exact: Sequence[str] | str | None = None,
+    drop_banned: bool = True,
+    drop_non_allowlisted: bool = False,
+    raise_on_banned: bool = True,
+) -> tuple[pl.DataFrame | "pd.DataFrame", LeakCheckResult]:
+    """Apply leak guardrails to a feature frame.
+
+    Parameters
+    ----------
+    df : DataFrame
+        Polars or pandas DataFrame.
+    policy : LeakPolicy
+        Leak policy to apply.
+    allow_prefixes : Sequence[str] | str | None
+        Optional prefixes that define the allowed feature surface for a problem.
+    allow_exact : Sequence[str] | str | None
+        Explicitly allowed columns (e.g., identifiers).
+    drop_banned : bool
+        If True, drop any banned columns automatically.
+    drop_non_allowlisted : bool
+        If True, drop columns that are not covered by allow_prefixes/allow_exact/identifiers/targets.
+    raise_on_banned : bool
+        If True, raise when banned columns are detected (after optional drop).
+    """
+
+    result = evaluate_leak_prone_columns(df.columns, policy=policy)
+    dropped: list[str] = []
+
+    allow_prefixes = _ensure_sequence(allow_prefixes)
+    allow_exact = set(_ensure_sequence(allow_exact))
+    allow_exact.update({col for col in IDENTIFIER_COLUMNS if col in df.columns})
+    allow_exact.update({col for col in NFL_TARGET_COLUMNS if col in df.columns})
+
+    # Permit allowlisted columns even if they match a banned rule (e.g., labels)
+    banned = {col: reason for col, reason in result.banned.items() if col not in allow_exact}
+
+    if banned and drop_banned:
+        df = df.drop(list(banned.keys()))
+        dropped.extend(banned.keys())
+
+    if banned and raise_on_banned:
+        raise ValueError(f"Leak-prone columns detected: {sorted(banned.items())}")
+
+    allowlist_cols: set[str] = set()
+    if allow_prefixes:
+        allowlist_cols.update({c for c in df.columns if c.startswith(allow_prefixes)})
+    allowlist_cols.update({c for c in allow_exact if c in df.columns})
+
+    if drop_non_allowlisted and allowlist_cols:
+        drop_candidates = [c for c in df.columns if c not in allowlist_cols]
+        if drop_candidates:
+            df = df.drop(drop_candidates)
+            dropped.extend(drop_candidates)
+
+    if drop_non_allowlisted and not allowlist_cols:
+        raise ValueError("No allowlisted columns remain after applying leak guard allowlist.")
+
+    # Store adjusted banned info on the result
+    result.banned = banned
+    result.dropped = dropped
+    result.kept = [c for c in df.columns]
+    result.allowlist_kept = sorted(list(allowlist_cols)) if allowlist_cols else []
+    return df, result
+
+
+def build_schema_snapshot(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    metadata: Mapping[str, object] | None = None,
+    banned: Mapping[str, str] | None = None,
+) -> dict:
+    """Render a schema snapshot describing each column and whether it was flagged."""
+
+    banned = banned or {}
+    meta = {
+        "generated_at_utc": datetime.utcnow().isoformat(),
+        "policy_version": policy.version,
+    }
+    meta.update(metadata or {})
+
+    # Extract columns / dtypes
+    if isinstance(df, pl.DataFrame):
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+    else:  # pandas or pandas-like
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+
+    schema = {
+        "metadata": meta,
+        "columns": [],
+    }
+
+    for col, dtype in cols_and_dtypes:
+        tags: list[str] = []
+        if col in IDENTIFIER_COLUMNS:
+            tags.append("id")
+        if col in NFL_TARGET_COLUMNS:
+            tags.append("label")
+        if col.startswith("market_"):
+            tags.append("odds")
+        if col.startswith("injury_") or col.startswith("practice_"):
+            tags.append("injury")
+        if col.startswith("weather_"):
+            tags.append("weather")
+        if col.startswith("ps_"):
+            tags.append("pre_snap")
+        schema["columns"].append(
+            {
+                "name": col,
+                "dtype": dtype,
+                "banned": col in banned,
+                "tags": tags,
+            }
+        )
+    return schema
+
+
+def write_schema_snapshot(path, schema: Mapping[str, object]) -> None:
+    path.parent.mkdir(parents=True, exist_ok=True)
+    with open(path, "w") as fp:
+        json.dump(schema, fp, indent=2, sort_keys=True)
+
+
+__all__ = [
+    "DEFAULT_LEAK_POLICY",
+    "LeakPolicy",
+    "LeakCheckResult",
+    "evaluate_leak_prone_columns",
+    "enforce_leak_guard",
+    "build_schema_snapshot",
+    "write_schema_snapshot",
+]

file update:
diff --git a/utils/feature/leak_guard.py b/utils/feature/leak_guard.py
new file mode 100644
index 0000000000000000000000000000000000000000..9faf8cfffc436e0934b2f410aaf252e52f4f95df
--- /dev/null
+++ b/utils/feature/leak_guard.py
@@ -0,0 +1,273 @@
+"""Leak guardrails for feature matrices.
+
+This module centralizes pattern-based leak detection so both feature assembly
+and training can fail fast when post-outcome columns sneak into the data.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+from datetime import datetime
+import json
+import re
+from typing import Iterable, Mapping, Sequence
+
+import polars as pl
+
+from utils.general.constants import IDENTIFIER_COLUMNS, LEAK_PRONE_COLUMNS, NFL_TARGET_COLUMNS
+
+try:  # Optional dependency when imported from training (pandas path)
+    import pandas as pd  # type: ignore
+except Exception:  # pragma: no cover - optional dependency
+    pd = None
+
+
+@dataclass(frozen=True)
+class LeakPolicy:
+    version: str
+    banned_exact: set[str]
+    banned_prefixes: tuple[str, ...]
+    banned_suffixes: tuple[str, ...]
+    banned_regex: tuple[tuple[re.Pattern[str], str], ...]
+    description: str = ""
+
+
+@dataclass
+class LeakCheckResult:
+    policy_version: str
+    banned: dict[str, str]
+    kept: list[str]
+    dropped: list[str]
+    allowlist_kept: list[str]
+
+
+# Core policy tuned for anytime-TD style problems (can be extended per-problem).
+_BASE_BANNED_EXACT = set(LEAK_PRONE_COLUMNS) | {
+    "final_score",
+    "final_total",
+    "points_scored",
+    "actual_td_count",
+    "actual_anytime_td",
+    "postgame_anytime_td",
+    "postgame_td_count",
+}
+_BASE_BANNED_PREFIXES = (
+    "postgame_",
+    "post_game_",
+    "post_",
+    "live_",
+    "actual_",
+    "realized_",
+    "final_",
+    "postmatch_",
+)
+_BASE_BANNED_SUFFIXES = (
+    "_post",
+    "_postgame",
+    "_final",
+    "_fullgame",
+    "_actual",
+)
+_BASE_BANNED_REGEX: tuple[tuple[re.Pattern[str], str], ...] = (
+    (re.compile(r".*post.?game.*", flags=re.IGNORECASE), "postgame marker"),
+    (re.compile(r".*final_score.*", flags=re.IGNORECASE), "final score"),
+    (re.compile(r".*actual.*td.*", flags=re.IGNORECASE), "actual TD total"),
+    (re.compile(r".*anytime_td.*(post|final|actual).*", flags=re.IGNORECASE), "post-decision anytime TD"),
+    (re.compile(r".*fullgame.*", flags=re.IGNORECASE), "full game cumulative value"),
+)
+
+DEFAULT_LEAK_POLICY = LeakPolicy(
+    version="v1",
+    description="Core post-outcome leak guard for NFL anytime TD features.",
+    banned_exact=_BASE_BANNED_EXACT,
+    banned_prefixes=_BASE_BANNED_PREFIXES,
+    banned_suffixes=_BASE_BANNED_SUFFIXES,
+    banned_regex=_BASE_BANNED_REGEX,
+)
+
+
+def _ensure_sequence(value: Sequence[str] | str | None) -> tuple[str, ...]:
+    if value is None:
+        return ()
+    if isinstance(value, str):
+        return (value,)
+    return tuple(value)
+
+
+def evaluate_leak_prone_columns(
+    columns: Iterable[str],
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+) -> LeakCheckResult:
+    """Identify leak-prone columns using the configured policy."""
+
+    banned: dict[str, str] = {}
+    columns_list = list(columns)
+    for col in columns_list:
+        if col in policy.banned_exact:
+            banned[col] = "exact"
+            continue
+        for prefix in policy.banned_prefixes:
+            if col.startswith(prefix):
+                banned[col] = f"prefix:{prefix}"
+                break
+        if col in banned:
+            continue
+        for suffix in policy.banned_suffixes:
+            if col.endswith(suffix):
+                banned[col] = f"suffix:{suffix}"
+                break
+        if col in banned:
+            continue
+        for pattern, reason in policy.banned_regex:
+            if pattern.match(col):
+                banned[col] = reason
+                break
+
+    kept = [c for c in columns_list if c not in banned]
+    return LeakCheckResult(
+        policy_version=policy.version,
+        banned=banned,
+        kept=kept,
+        dropped=[],
+        allowlist_kept=[],
+    )
+
+
+def enforce_leak_guard(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    allow_prefixes: Sequence[str] | str | None = None,
+    allow_exact: Sequence[str] | str | None = None,
+    drop_banned: bool = True,
+    drop_non_allowlisted: bool = False,
+    raise_on_banned: bool = True,
+) -> tuple[pl.DataFrame | "pd.DataFrame", LeakCheckResult]:
+    """Apply leak guardrails to a feature frame.
+
+    Parameters
+    ----------
+    df : DataFrame
+        Polars or pandas DataFrame.
+    policy : LeakPolicy
+        Leak policy to apply.
+    allow_prefixes : Sequence[str] | str | None
+        Optional prefixes that define the allowed feature surface for a problem.
+    allow_exact : Sequence[str] | str | None
+        Explicitly allowed columns (e.g., identifiers).
+    drop_banned : bool
+        If True, drop any banned columns automatically.
+    drop_non_allowlisted : bool
+        If True, drop columns that are not covered by allow_prefixes/allow_exact/identifiers/targets.
+    raise_on_banned : bool
+        If True, raise when banned columns are detected (after optional drop).
+    """
+
+    result = evaluate_leak_prone_columns(df.columns, policy=policy)
+    dropped: list[str] = []
+
+    allow_prefixes = _ensure_sequence(allow_prefixes)
+    allow_exact = set(_ensure_sequence(allow_exact))
+    allow_exact.update({col for col in IDENTIFIER_COLUMNS if col in df.columns})
+    allow_exact.update({col for col in NFL_TARGET_COLUMNS if col in df.columns})
+
+    # Permit allowlisted columns even if they match a banned rule (e.g., labels)
+    banned = {col: reason for col, reason in result.banned.items() if col not in allow_exact}
+
+    if banned and drop_banned:
+        df = df.drop(list(banned.keys()))
+        dropped.extend(banned.keys())
+
+    if banned and raise_on_banned:
+        raise ValueError(f"Leak-prone columns detected: {sorted(banned.items())}")
+
+    allowlist_cols: set[str] = set()
+    if allow_prefixes:
+        allowlist_cols.update({c for c in df.columns if c.startswith(allow_prefixes)})
+    allowlist_cols.update({c for c in allow_exact if c in df.columns})
+
+    if drop_non_allowlisted and allowlist_cols:
+        drop_candidates = [c for c in df.columns if c not in allowlist_cols]
+        if drop_candidates:
+            df = df.drop(drop_candidates)
+            dropped.extend(drop_candidates)
+
+    if drop_non_allowlisted and not allowlist_cols:
+        raise ValueError("No allowlisted columns remain after applying leak guard allowlist.")
+
+    # Store adjusted banned info on the result
+    result.banned = banned
+    result.dropped = dropped
+    result.kept = [c for c in df.columns]
+    result.allowlist_kept = sorted(list(allowlist_cols)) if allowlist_cols else []
+    return df, result
+
+
+def build_schema_snapshot(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    metadata: Mapping[str, object] | None = None,
+    banned: Mapping[str, str] | None = None,
+) -> dict:
+    """Render a schema snapshot describing each column and whether it was flagged."""
+
+    banned = banned or {}
+    meta = {
+        "generated_at_utc": datetime.utcnow().isoformat(),
+        "policy_version": policy.version,
+    }
+    meta.update(metadata or {})
+
+    # Extract columns / dtypes
+    if isinstance(df, pl.DataFrame):
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+    else:  # pandas or pandas-like
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+
+    schema = {
+        "metadata": meta,
+        "columns": [],
+    }
+
+    for col, dtype in cols_and_dtypes:
+        tags: list[str] = []
+        if col in IDENTIFIER_COLUMNS:
+            tags.append("id")
+        if col in NFL_TARGET_COLUMNS:
+            tags.append("label")
+        if col.startswith("market_"):
+            tags.append("odds")
+        if col.startswith("injury_") or col.startswith("practice_"):
+            tags.append("injury")
+        if col.startswith("weather_"):
+            tags.append("weather")
+        if col.startswith("ps_"):
+            tags.append("pre_snap")
+        schema["columns"].append(
+            {
+                "name": col,
+                "dtype": dtype,
+                "banned": col in banned,
+                "tags": tags,
+            }
+        )
+    return schema
+
+
+def write_schema_snapshot(path, schema: Mapping[str, object]) -> None:
+    path.parent.mkdir(parents=True, exist_ok=True)
+    with open(path, "w") as fp:
+        json.dump(schema, fp, indent=2, sort_keys=True)
+
+
+__all__ = [
+    "DEFAULT_LEAK_POLICY",
+    "LeakPolicy",
+    "LeakCheckResult",
+    "evaluate_leak_prone_columns",
+    "enforce_leak_guard",
+    "build_schema_snapshot",
+    "write_schema_snapshot",
+]


thinking
**Adding imports for leak guard integration**
file update
M /Users/jameswest/Desktop/nfl_predict/pipeline/feature.py
@@ -39,2 +39,8 @@
 )
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    build_schema_snapshot,
+    enforce_leak_guard,
+    write_schema_snapshot,
+)
 from utils.feature.weather_features import (
apply_patch(auto_approved=true) exited 0 in 36ms:
Success. Updated the following files:
M pipeline/feature.py
file update:
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 5ba68e8bf1acd3a789a76a8857674e6f6433017b..f2358590f378eda3884c16511f228437c2b7aac5
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -37,6 +37,12 @@
     add_offense_context_features_training,
     _append_offense_context_columns,
 )
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    build_schema_snapshot,
+    enforce_leak_guard,
+    write_schema_snapshot,
+)
 from utils.feature.weather_features import (
     add_weather_forecast_features_training,
     append_weather_context_flags,
diff --git a/utils/feature/leak_guard.py b/utils/feature/leak_guard.py
new file mode 100644
index 0000000000000000000000000000000000000000..9faf8cfffc436e0934b2f410aaf252e52f4f95df
--- /dev/null
+++ b/utils/feature/leak_guard.py
@@ -0,0 +1,273 @@
+"""Leak guardrails for feature matrices.
+
+This module centralizes pattern-based leak detection so both feature assembly
+and training can fail fast when post-outcome columns sneak into the data.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+from datetime import datetime
+import json
+import re
+from typing import Iterable, Mapping, Sequence
+
+import polars as pl
+
+from utils.general.constants import IDENTIFIER_COLUMNS, LEAK_PRONE_COLUMNS, NFL_TARGET_COLUMNS
+
+try:  # Optional dependency when imported from training (pandas path)
+    import pandas as pd  # type: ignore
+except Exception:  # pragma: no cover - optional dependency
+    pd = None
+
+
+@dataclass(frozen=True)
+class LeakPolicy:
+    version: str
+    banned_exact: set[str]
+    banned_prefixes: tuple[str, ...]
+    banned_suffixes: tuple[str, ...]
+    banned_regex: tuple[tuple[re.Pattern[str], str], ...]
+    description: str = ""
+
+
+@dataclass
+class LeakCheckResult:
+    policy_version: str
+    banned: dict[str, str]
+    kept: list[str]
+    dropped: list[str]
+    allowlist_kept: list[str]
+
+
+# Core policy tuned for anytime-TD style problems (can be extended per-problem).
+_BASE_BANNED_EXACT = set(LEAK_PRONE_COLUMNS) | {
+    "final_score",
+    "final_total",
+    "points_scored",
+    "actual_td_count",
+    "actual_anytime_td",
+    "postgame_anytime_td",
+    "postgame_td_count",
+}
+_BASE_BANNED_PREFIXES = (
+    "postgame_",
+    "post_game_",
+    "post_",
+    "live_",
+    "actual_",
+    "realized_",
+    "final_",
+    "postmatch_",
+)
+_BASE_BANNED_SUFFIXES = (
+    "_post",
+    "_postgame",
+    "_final",
+    "_fullgame",
+    "_actual",
+)
+_BASE_BANNED_REGEX: tuple[tuple[re.Pattern[str], str], ...] = (
+    (re.compile(r".*post.?game.*", flags=re.IGNORECASE), "postgame marker"),
+    (re.compile(r".*final_score.*", flags=re.IGNORECASE), "final score"),
+    (re.compile(r".*actual.*td.*", flags=re.IGNORECASE), "actual TD total"),
+    (re.compile(r".*anytime_td.*(post|final|actual).*", flags=re.IGNORECASE), "post-decision anytime TD"),
+    (re.compile(r".*fullgame.*", flags=re.IGNORECASE), "full game cumulative value"),
+)
+
+DEFAULT_LEAK_POLICY = LeakPolicy(
+    version="v1",
+    description="Core post-outcome leak guard for NFL anytime TD features.",
+    banned_exact=_BASE_BANNED_EXACT,
+    banned_prefixes=_BASE_BANNED_PREFIXES,
+    banned_suffixes=_BASE_BANNED_SUFFIXES,
+    banned_regex=_BASE_BANNED_REGEX,
+)
+
+
+def _ensure_sequence(value: Sequence[str] | str | None) -> tuple[str, ...]:
+    if value is None:
+        return ()
+    if isinstance(value, str):
+        return (value,)
+    return tuple(value)
+
+
+def evaluate_leak_prone_columns(
+    columns: Iterable[str],
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+) -> LeakCheckResult:
+    """Identify leak-prone columns using the configured policy."""
+
+    banned: dict[str, str] = {}
+    columns_list = list(columns)
+    for col in columns_list:
+        if col in policy.banned_exact:
+            banned[col] = "exact"
+            continue
+        for prefix in policy.banned_prefixes:
+            if col.startswith(prefix):
+                banned[col] = f"prefix:{prefix}"
+                break
+        if col in banned:
+            continue
+        for suffix in policy.banned_suffixes:
+            if col.endswith(suffix):
+                banned[col] = f"suffix:{suffix}"
+                break
+        if col in banned:
+            continue
+        for pattern, reason in policy.banned_regex:
+            if pattern.match(col):
+                banned[col] = reason
+                break
+
+    kept = [c for c in columns_list if c not in banned]
+    return LeakCheckResult(
+        policy_version=policy.version,
+        banned=banned,
+        kept=kept,
+        dropped=[],
+        allowlist_kept=[],
+    )
+
+
+def enforce_leak_guard(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    allow_prefixes: Sequence[str] | str | None = None,
+    allow_exact: Sequence[str] | str | None = None,
+    drop_banned: bool = True,
+    drop_non_allowlisted: bool = False,
+    raise_on_banned: bool = True,
+) -> tuple[pl.DataFrame | "pd.DataFrame", LeakCheckResult]:
+    """Apply leak guardrails to a feature frame.
+
+    Parameters
+    ----------
+    df : DataFrame
+        Polars or pandas DataFrame.
+    policy : LeakPolicy
+        Leak policy to apply.
+    allow_prefixes : Sequence[str] | str | None
+        Optional prefixes that define the allowed feature surface for a problem.
+    allow_exact : Sequence[str] | str | None
+        Explicitly allowed columns (e.g., identifiers).
+    drop_banned : bool
+        If True, drop any banned columns automatically.
+    drop_non_allowlisted : bool
+        If True, drop columns that are not covered by allow_prefixes/allow_exact/identifiers/targets.
+    raise_on_banned : bool
+        If True, raise when banned columns are detected (after optional drop).
+    """
+
+    result = evaluate_leak_prone_columns(df.columns, policy=policy)
+    dropped: list[str] = []
+
+    allow_prefixes = _ensure_sequence(allow_prefixes)
+    allow_exact = set(_ensure_sequence(allow_exact))
+    allow_exact.update({col for col in IDENTIFIER_COLUMNS if col in df.columns})
+    allow_exact.update({col for col in NFL_TARGET_COLUMNS if col in df.columns})
+
+    # Permit allowlisted columns even if they match a banned rule (e.g., labels)
+    banned = {col: reason for col, reason in result.banned.items() if col not in allow_exact}
+
+    if banned and drop_banned:
+        df = df.drop(list(banned.keys()))
+        dropped.extend(banned.keys())
+
+    if banned and raise_on_banned:
+        raise ValueError(f"Leak-prone columns detected: {sorted(banned.items())}")
+
+    allowlist_cols: set[str] = set()
+    if allow_prefixes:
+        allowlist_cols.update({c for c in df.columns if c.startswith(allow_prefixes)})
+    allowlist_cols.update({c for c in allow_exact if c in df.columns})
+
+    if drop_non_allowlisted and allowlist_cols:
+        drop_candidates = [c for c in df.columns if c not in allowlist_cols]
+        if drop_candidates:
+            df = df.drop(drop_candidates)
+            dropped.extend(drop_candidates)
+
+    if drop_non_allowlisted and not allowlist_cols:
+        raise ValueError("No allowlisted columns remain after applying leak guard allowlist.")
+
+    # Store adjusted banned info on the result
+    result.banned = banned
+    result.dropped = dropped
+    result.kept = [c for c in df.columns]
+    result.allowlist_kept = sorted(list(allowlist_cols)) if allowlist_cols else []
+    return df, result
+
+
+def build_schema_snapshot(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    metadata: Mapping[str, object] | None = None,
+    banned: Mapping[str, str] | None = None,
+) -> dict:
+    """Render a schema snapshot describing each column and whether it was flagged."""
+
+    banned = banned or {}
+    meta = {
+        "generated_at_utc": datetime.utcnow().isoformat(),
+        "policy_version": policy.version,
+    }
+    meta.update(metadata or {})
+
+    # Extract columns / dtypes
+    if isinstance(df, pl.DataFrame):
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+    else:  # pandas or pandas-like
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+
+    schema = {
+        "metadata": meta,
+        "columns": [],
+    }
+
+    for col, dtype in cols_and_dtypes:
+        tags: list[str] = []
+        if col in IDENTIFIER_COLUMNS:
+            tags.append("id")
+        if col in NFL_TARGET_COLUMNS:
+            tags.append("label")
+        if col.startswith("market_"):
+            tags.append("odds")
+        if col.startswith("injury_") or col.startswith("practice_"):
+            tags.append("injury")
+        if col.startswith("weather_"):
+            tags.append("weather")
+        if col.startswith("ps_"):
+            tags.append("pre_snap")
+        schema["columns"].append(
+            {
+                "name": col,
+                "dtype": dtype,
+                "banned": col in banned,
+                "tags": tags,
+            }
+        )
+    return schema
+
+
+def write_schema_snapshot(path, schema: Mapping[str, object]) -> None:
+    path.parent.mkdir(parents=True, exist_ok=True)
+    with open(path, "w") as fp:
+        json.dump(schema, fp, indent=2, sort_keys=True)
+
+
+__all__ = [
+    "DEFAULT_LEAK_POLICY",
+    "LeakPolicy",
+    "LeakCheckResult",
+    "evaluate_leak_prone_columns",
+    "enforce_leak_guard",
+    "build_schema_snapshot",
+    "write_schema_snapshot",
+]

file update:
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 5ba68e8bf1acd3a789a76a8857674e6f6433017b..f2358590f378eda3884c16511f228437c2b7aac5
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -37,6 +37,12 @@
     add_offense_context_features_training,
     _append_offense_context_columns,
 )
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    build_schema_snapshot,
+    enforce_leak_guard,
+    write_schema_snapshot,
+)
 from utils.feature.weather_features import (
     add_weather_forecast_features_training,
     append_weather_context_flags,
diff --git a/utils/feature/leak_guard.py b/utils/feature/leak_guard.py
new file mode 100644
index 0000000000000000000000000000000000000000..9faf8cfffc436e0934b2f410aaf252e52f4f95df
--- /dev/null
+++ b/utils/feature/leak_guard.py
@@ -0,0 +1,273 @@
+"""Leak guardrails for feature matrices.
+
+This module centralizes pattern-based leak detection so both feature assembly
+and training can fail fast when post-outcome columns sneak into the data.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+from datetime import datetime
+import json
+import re
+from typing import Iterable, Mapping, Sequence
+
+import polars as pl
+
+from utils.general.constants import IDENTIFIER_COLUMNS, LEAK_PRONE_COLUMNS, NFL_TARGET_COLUMNS
+
+try:  # Optional dependency when imported from training (pandas path)
+    import pandas as pd  # type: ignore
+except Exception:  # pragma: no cover - optional dependency
+    pd = None
+
+
+@dataclass(frozen=True)
+class LeakPolicy:
+    version: str
+    banned_exact: set[str]
+    banned_prefixes: tuple[str, ...]
+    banned_suffixes: tuple[str, ...]
+    banned_regex: tuple[tuple[re.Pattern[str], str], ...]
+    description: str = ""
+
+
+@dataclass
+class LeakCheckResult:
+    policy_version: str
+    banned: dict[str, str]
+    kept: list[str]
+    dropped: list[str]
+    allowlist_kept: list[str]
+
+
+# Core policy tuned for anytime-TD style problems (can be extended per-problem).
+_BASE_BANNED_EXACT = set(LEAK_PRONE_COLUMNS) | {
+    "final_score",
+    "final_total",
+    "points_scored",
+    "actual_td_count",
+    "actual_anytime_td",
+    "postgame_anytime_td",
+    "postgame_td_count",
+}
+_BASE_BANNED_PREFIXES = (
+    "postgame_",
+    "post_game_",
+    "post_",
+    "live_",
+    "actual_",
+    "realized_",
+    "final_",
+    "postmatch_",
+)
+_BASE_BANNED_SUFFIXES = (
+    "_post",
+    "_postgame",
+    "_final",
+    "_fullgame",
+    "_actual",
+)
+_BASE_BANNED_REGEX: tuple[tuple[re.Pattern[str], str], ...] = (
+    (re.compile(r".*post.?game.*", flags=re.IGNORECASE), "postgame marker"),
+    (re.compile(r".*final_score.*", flags=re.IGNORECASE), "final score"),
+    (re.compile(r".*actual.*td.*", flags=re.IGNORECASE), "actual TD total"),
+    (re.compile(r".*anytime_td.*(post|final|actual).*", flags=re.IGNORECASE), "post-decision anytime TD"),
+    (re.compile(r".*fullgame.*", flags=re.IGNORECASE), "full game cumulative value"),
+)
+
+DEFAULT_LEAK_POLICY = LeakPolicy(
+    version="v1",
+    description="Core post-outcome leak guard for NFL anytime TD features.",
+    banned_exact=_BASE_BANNED_EXACT,
+    banned_prefixes=_BASE_BANNED_PREFIXES,
+    banned_suffixes=_BASE_BANNED_SUFFIXES,
+    banned_regex=_BASE_BANNED_REGEX,
+)
+
+
+def _ensure_sequence(value: Sequence[str] | str | None) -> tuple[str, ...]:
+    if value is None:
+        return ()
+    if isinstance(value, str):
+        return (value,)
+    return tuple(value)
+
+
+def evaluate_leak_prone_columns(
+    columns: Iterable[str],
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+) -> LeakCheckResult:
+    """Identify leak-prone columns using the configured policy."""
+
+    banned: dict[str, str] = {}
+    columns_list = list(columns)
+    for col in columns_list:
+        if col in policy.banned_exact:
+            banned[col] = "exact"
+            continue
+        for prefix in policy.banned_prefixes:
+            if col.startswith(prefix):
+                banned[col] = f"prefix:{prefix}"
+                break
+        if col in banned:
+            continue
+        for suffix in policy.banned_suffixes:
+            if col.endswith(suffix):
+                banned[col] = f"suffix:{suffix}"
+                break
+        if col in banned:
+            continue
+        for pattern, reason in policy.banned_regex:
+            if pattern.match(col):
+                banned[col] = reason
+                break
+
+    kept = [c for c in columns_list if c not in banned]
+    return LeakCheckResult(
+        policy_version=policy.version,
+        banned=banned,
+        kept=kept,
+        dropped=[],
+        allowlist_kept=[],
+    )
+
+
+def enforce_leak_guard(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    allow_prefixes: Sequence[str] | str | None = None,
+    allow_exact: Sequence[str] | str | None = None,
+    drop_banned: bool = True,
+    drop_non_allowlisted: bool = False,
+    raise_on_banned: bool = True,
+) -> tuple[pl.DataFrame | "pd.DataFrame", LeakCheckResult]:
+    """Apply leak guardrails to a feature frame.
+
+    Parameters
+    ----------
+    df : DataFrame
+        Polars or pandas DataFrame.
+    policy : LeakPolicy
+        Leak policy to apply.
+    allow_prefixes : Sequence[str] | str | None
+        Optional prefixes that define the allowed feature surface for a problem.
+    allow_exact : Sequence[str] | str | None
+        Explicitly allowed columns (e.g., identifiers).
+    drop_banned : bool
+        If True, drop any banned columns automatically.
+    drop_non_allowlisted : bool
+        If True, drop columns that are not covered by allow_prefixes/allow_exact/identifiers/targets.
+    raise_on_banned : bool
+        If True, raise when banned columns are detected (after optional drop).
+    """
+
+    result = evaluate_leak_prone_columns(df.columns, policy=policy)
+    dropped: list[str] = []
+
+    allow_prefixes = _ensure_sequence(allow_prefixes)
+    allow_exact = set(_ensure_sequence(allow_exact))
+    allow_exact.update({col for col in IDENTIFIER_COLUMNS if col in df.columns})
+    allow_exact.update({col for col in NFL_TARGET_COLUMNS if col in df.columns})
+
+    # Permit allowlisted columns even if they match a banned rule (e.g., labels)
+    banned = {col: reason for col, reason in result.banned.items() if col not in allow_exact}
+
+    if banned and drop_banned:
+        df = df.drop(list(banned.keys()))
+        dropped.extend(banned.keys())
+
+    if banned and raise_on_banned:
+        raise ValueError(f"Leak-prone columns detected: {sorted(banned.items())}")
+
+    allowlist_cols: set[str] = set()
+    if allow_prefixes:
+        allowlist_cols.update({c for c in df.columns if c.startswith(allow_prefixes)})
+    allowlist_cols.update({c for c in allow_exact if c in df.columns})
+
+    if drop_non_allowlisted and allowlist_cols:
+        drop_candidates = [c for c in df.columns if c not in allowlist_cols]
+        if drop_candidates:
+            df = df.drop(drop_candidates)
+            dropped.extend(drop_candidates)
+
+    if drop_non_allowlisted and not allowlist_cols:
+        raise ValueError("No allowlisted columns remain after applying leak guard allowlist.")
+
+    # Store adjusted banned info on the result
+    result.banned = banned
+    result.dropped = dropped
+    result.kept = [c for c in df.columns]
+    result.allowlist_kept = sorted(list(allowlist_cols)) if allowlist_cols else []
+    return df, result
+
+
+def build_schema_snapshot(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    metadata: Mapping[str, object] | None = None,
+    banned: Mapping[str, str] | None = None,
+) -> dict:
+    """Render a schema snapshot describing each column and whether it was flagged."""
+
+    banned = banned or {}
+    meta = {
+        "generated_at_utc": datetime.utcnow().isoformat(),
+        "policy_version": policy.version,
+    }
+    meta.update(metadata or {})
+
+    # Extract columns / dtypes
+    if isinstance(df, pl.DataFrame):
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+    else:  # pandas or pandas-like
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+
+    schema = {
+        "metadata": meta,
+        "columns": [],
+    }
+
+    for col, dtype in cols_and_dtypes:
+        tags: list[str] = []
+        if col in IDENTIFIER_COLUMNS:
+            tags.append("id")
+        if col in NFL_TARGET_COLUMNS:
+            tags.append("label")
+        if col.startswith("market_"):
+            tags.append("odds")
+        if col.startswith("injury_") or col.startswith("practice_"):
+            tags.append("injury")
+        if col.startswith("weather_"):
+            tags.append("weather")
+        if col.startswith("ps_"):
+            tags.append("pre_snap")
+        schema["columns"].append(
+            {
+                "name": col,
+                "dtype": dtype,
+                "banned": col in banned,
+                "tags": tags,
+            }
+        )
+    return schema
+
+
+def write_schema_snapshot(path, schema: Mapping[str, object]) -> None:
+    path.parent.mkdir(parents=True, exist_ok=True)
+    with open(path, "w") as fp:
+        json.dump(schema, fp, indent=2, sort_keys=True)
+
+
+__all__ = [
+    "DEFAULT_LEAK_POLICY",
+    "LeakPolicy",
+    "LeakCheckResult",
+    "evaluate_leak_prone_columns",
+    "enforce_leak_guard",
+    "build_schema_snapshot",
+    "write_schema_snapshot",
+]


thinking
**Planning schema snapshot insertion**

thinking
**Updating import statement**
file update
M /Users/jameswest/Desktop/nfl_predict/pipeline/feature.py
@@ -16,3 +16,3 @@
 import os
-from datetime import date, timedelta
+from datetime import date, datetime, timedelta
 from typing import Sequence
apply_patch(auto_approved=true) exited 0 in 41ms:
Success. Updated the following files:
M pipeline/feature.py
file update:
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 5ba68e8bf1acd3a789a76a8857674e6f6433017b..8bca7b35c507d61a9dd52312182ddf1599368a50
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -14,7 +14,7 @@
 
 import logging
 import os
-from datetime import date, timedelta
+from datetime import date, datetime, timedelta
 from typing import Sequence
 
 import polars as pl
@@ -37,6 +37,12 @@
     add_offense_context_features_training,
     _append_offense_context_columns,
 )
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    build_schema_snapshot,
+    enforce_leak_guard,
+    write_schema_snapshot,
+)
 from utils.feature.weather_features import (
     add_weather_forecast_features_training,
     append_weather_context_flags,
diff --git a/utils/feature/leak_guard.py b/utils/feature/leak_guard.py
new file mode 100644
index 0000000000000000000000000000000000000000..9faf8cfffc436e0934b2f410aaf252e52f4f95df
--- /dev/null
+++ b/utils/feature/leak_guard.py
@@ -0,0 +1,273 @@
+"""Leak guardrails for feature matrices.
+
+This module centralizes pattern-based leak detection so both feature assembly
+and training can fail fast when post-outcome columns sneak into the data.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+from datetime import datetime
+import json
+import re
+from typing import Iterable, Mapping, Sequence
+
+import polars as pl
+
+from utils.general.constants import IDENTIFIER_COLUMNS, LEAK_PRONE_COLUMNS, NFL_TARGET_COLUMNS
+
+try:  # Optional dependency when imported from training (pandas path)
+    import pandas as pd  # type: ignore
+except Exception:  # pragma: no cover - optional dependency
+    pd = None
+
+
+@dataclass(frozen=True)
+class LeakPolicy:
+    version: str
+    banned_exact: set[str]
+    banned_prefixes: tuple[str, ...]
+    banned_suffixes: tuple[str, ...]
+    banned_regex: tuple[tuple[re.Pattern[str], str], ...]
+    description: str = ""
+
+
+@dataclass
+class LeakCheckResult:
+    policy_version: str
+    banned: dict[str, str]
+    kept: list[str]
+    dropped: list[str]
+    allowlist_kept: list[str]
+
+
+# Core policy tuned for anytime-TD style problems (can be extended per-problem).
+_BASE_BANNED_EXACT = set(LEAK_PRONE_COLUMNS) | {
+    "final_score",
+    "final_total",
+    "points_scored",
+    "actual_td_count",
+    "actual_anytime_td",
+    "postgame_anytime_td",
+    "postgame_td_count",
+}
+_BASE_BANNED_PREFIXES = (
+    "postgame_",
+    "post_game_",
+    "post_",
+    "live_",
+    "actual_",
+    "realized_",
+    "final_",
+    "postmatch_",
+)
+_BASE_BANNED_SUFFIXES = (
+    "_post",
+    "_postgame",
+    "_final",
+    "_fullgame",
+    "_actual",
+)
+_BASE_BANNED_REGEX: tuple[tuple[re.Pattern[str], str], ...] = (
+    (re.compile(r".*post.?game.*", flags=re.IGNORECASE), "postgame marker"),
+    (re.compile(r".*final_score.*", flags=re.IGNORECASE), "final score"),
+    (re.compile(r".*actual.*td.*", flags=re.IGNORECASE), "actual TD total"),
+    (re.compile(r".*anytime_td.*(post|final|actual).*", flags=re.IGNORECASE), "post-decision anytime TD"),
+    (re.compile(r".*fullgame.*", flags=re.IGNORECASE), "full game cumulative value"),
+)
+
+DEFAULT_LEAK_POLICY = LeakPolicy(
+    version="v1",
+    description="Core post-outcome leak guard for NFL anytime TD features.",
+    banned_exact=_BASE_BANNED_EXACT,
+    banned_prefixes=_BASE_BANNED_PREFIXES,
+    banned_suffixes=_BASE_BANNED_SUFFIXES,
+    banned_regex=_BASE_BANNED_REGEX,
+)
+
+
+def _ensure_sequence(value: Sequence[str] | str | None) -> tuple[str, ...]:
+    if value is None:
+        return ()
+    if isinstance(value, str):
+        return (value,)
+    return tuple(value)
+
+
+def evaluate_leak_prone_columns(
+    columns: Iterable[str],
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+) -> LeakCheckResult:
+    """Identify leak-prone columns using the configured policy."""
+
+    banned: dict[str, str] = {}
+    columns_list = list(columns)
+    for col in columns_list:
+        if col in policy.banned_exact:
+            banned[col] = "exact"
+            continue
+        for prefix in policy.banned_prefixes:
+            if col.startswith(prefix):
+                banned[col] = f"prefix:{prefix}"
+                break
+        if col in banned:
+            continue
+        for suffix in policy.banned_suffixes:
+            if col.endswith(suffix):
+                banned[col] = f"suffix:{suffix}"
+                break
+        if col in banned:
+            continue
+        for pattern, reason in policy.banned_regex:
+            if pattern.match(col):
+                banned[col] = reason
+                break
+
+    kept = [c for c in columns_list if c not in banned]
+    return LeakCheckResult(
+        policy_version=policy.version,
+        banned=banned,
+        kept=kept,
+        dropped=[],
+        allowlist_kept=[],
+    )
+
+
+def enforce_leak_guard(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    allow_prefixes: Sequence[str] | str | None = None,
+    allow_exact: Sequence[str] | str | None = None,
+    drop_banned: bool = True,
+    drop_non_allowlisted: bool = False,
+    raise_on_banned: bool = True,
+) -> tuple[pl.DataFrame | "pd.DataFrame", LeakCheckResult]:
+    """Apply leak guardrails to a feature frame.
+
+    Parameters
+    ----------
+    df : DataFrame
+        Polars or pandas DataFrame.
+    policy : LeakPolicy
+        Leak policy to apply.
+    allow_prefixes : Sequence[str] | str | None
+        Optional prefixes that define the allowed feature surface for a problem.
+    allow_exact : Sequence[str] | str | None
+        Explicitly allowed columns (e.g., identifiers).
+    drop_banned : bool
+        If True, drop any banned columns automatically.
+    drop_non_allowlisted : bool
+        If True, drop columns that are not covered by allow_prefixes/allow_exact/identifiers/targets.
+    raise_on_banned : bool
+        If True, raise when banned columns are detected (after optional drop).
+    """
+
+    result = evaluate_leak_prone_columns(df.columns, policy=policy)
+    dropped: list[str] = []
+
+    allow_prefixes = _ensure_sequence(allow_prefixes)
+    allow_exact = set(_ensure_sequence(allow_exact))
+    allow_exact.update({col for col in IDENTIFIER_COLUMNS if col in df.columns})
+    allow_exact.update({col for col in NFL_TARGET_COLUMNS if col in df.columns})
+
+    # Permit allowlisted columns even if they match a banned rule (e.g., labels)
+    banned = {col: reason for col, reason in result.banned.items() if col not in allow_exact}
+
+    if banned and drop_banned:
+        df = df.drop(list(banned.keys()))
+        dropped.extend(banned.keys())
+
+    if banned and raise_on_banned:
+        raise ValueError(f"Leak-prone columns detected: {sorted(banned.items())}")
+
+    allowlist_cols: set[str] = set()
+    if allow_prefixes:
+        allowlist_cols.update({c for c in df.columns if c.startswith(allow_prefixes)})
+    allowlist_cols.update({c for c in allow_exact if c in df.columns})
+
+    if drop_non_allowlisted and allowlist_cols:
+        drop_candidates = [c for c in df.columns if c not in allowlist_cols]
+        if drop_candidates:
+            df = df.drop(drop_candidates)
+            dropped.extend(drop_candidates)
+
+    if drop_non_allowlisted and not allowlist_cols:
+        raise ValueError("No allowlisted columns remain after applying leak guard allowlist.")
+
+    # Store adjusted banned info on the result
+    result.banned = banned
+    result.dropped = dropped
+    result.kept = [c for c in df.columns]
+    result.allowlist_kept = sorted(list(allowlist_cols)) if allowlist_cols else []
+    return df, result
+
+
+def build_schema_snapshot(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    metadata: Mapping[str, object] | None = None,
+    banned: Mapping[str, str] | None = None,
+) -> dict:
+    """Render a schema snapshot describing each column and whether it was flagged."""
+
+    banned = banned or {}
+    meta = {
+        "generated_at_utc": datetime.utcnow().isoformat(),
+        "policy_version": policy.version,
+    }
+    meta.update(metadata or {})
+
+    # Extract columns / dtypes
+    if isinstance(df, pl.DataFrame):
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+    else:  # pandas or pandas-like
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+
+    schema = {
+        "metadata": meta,
+        "columns": [],
+    }
+
+    for col, dtype in cols_and_dtypes:
+        tags: list[str] = []
+        if col in IDENTIFIER_COLUMNS:
+            tags.append("id")
+        if col in NFL_TARGET_COLUMNS:
+            tags.append("label")
+        if col.startswith("market_"):
+            tags.append("odds")
+        if col.startswith("injury_") or col.startswith("practice_"):
+            tags.append("injury")
+        if col.startswith("weather_"):
+            tags.append("weather")
+        if col.startswith("ps_"):
+            tags.append("pre_snap")
+        schema["columns"].append(
+            {
+                "name": col,
+                "dtype": dtype,
+                "banned": col in banned,
+                "tags": tags,
+            }
+        )
+    return schema
+
+
+def write_schema_snapshot(path, schema: Mapping[str, object]) -> None:
+    path.parent.mkdir(parents=True, exist_ok=True)
+    with open(path, "w") as fp:
+        json.dump(schema, fp, indent=2, sort_keys=True)
+
+
+__all__ = [
+    "DEFAULT_LEAK_POLICY",
+    "LeakPolicy",
+    "LeakCheckResult",
+    "evaluate_leak_prone_columns",
+    "enforce_leak_guard",
+    "build_schema_snapshot",
+    "write_schema_snapshot",
+]

file update:
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 5ba68e8bf1acd3a789a76a8857674e6f6433017b..8bca7b35c507d61a9dd52312182ddf1599368a50
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -14,7 +14,7 @@
 
 import logging
 import os
-from datetime import date, timedelta
+from datetime import date, datetime, timedelta
 from typing import Sequence
 
 import polars as pl
@@ -37,6 +37,12 @@
     add_offense_context_features_training,
     _append_offense_context_columns,
 )
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    build_schema_snapshot,
+    enforce_leak_guard,
+    write_schema_snapshot,
+)
 from utils.feature.weather_features import (
     add_weather_forecast_features_training,
     append_weather_context_flags,
diff --git a/utils/feature/leak_guard.py b/utils/feature/leak_guard.py
new file mode 100644
index 0000000000000000000000000000000000000000..9faf8cfffc436e0934b2f410aaf252e52f4f95df
--- /dev/null
+++ b/utils/feature/leak_guard.py
@@ -0,0 +1,273 @@
+"""Leak guardrails for feature matrices.
+
+This module centralizes pattern-based leak detection so both feature assembly
+and training can fail fast when post-outcome columns sneak into the data.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+from datetime import datetime
+import json
+import re
+from typing import Iterable, Mapping, Sequence
+
+import polars as pl
+
+from utils.general.constants import IDENTIFIER_COLUMNS, LEAK_PRONE_COLUMNS, NFL_TARGET_COLUMNS
+
+try:  # Optional dependency when imported from training (pandas path)
+    import pandas as pd  # type: ignore
+except Exception:  # pragma: no cover - optional dependency
+    pd = None
+
+
+@dataclass(frozen=True)
+class LeakPolicy:
+    version: str
+    banned_exact: set[str]
+    banned_prefixes: tuple[str, ...]
+    banned_suffixes: tuple[str, ...]
+    banned_regex: tuple[tuple[re.Pattern[str], str], ...]
+    description: str = ""
+
+
+@dataclass
+class LeakCheckResult:
+    policy_version: str
+    banned: dict[str, str]
+    kept: list[str]
+    dropped: list[str]
+    allowlist_kept: list[str]
+
+
+# Core policy tuned for anytime-TD style problems (can be extended per-problem).
+_BASE_BANNED_EXACT = set(LEAK_PRONE_COLUMNS) | {
+    "final_score",
+    "final_total",
+    "points_scored",
+    "actual_td_count",
+    "actual_anytime_td",
+    "postgame_anytime_td",
+    "postgame_td_count",
+}
+_BASE_BANNED_PREFIXES = (
+    "postgame_",
+    "post_game_",
+    "post_",
+    "live_",
+    "actual_",
+    "realized_",
+    "final_",
+    "postmatch_",
+)
+_BASE_BANNED_SUFFIXES = (
+    "_post",
+    "_postgame",
+    "_final",
+    "_fullgame",
+    "_actual",
+)
+_BASE_BANNED_REGEX: tuple[tuple[re.Pattern[str], str], ...] = (
+    (re.compile(r".*post.?game.*", flags=re.IGNORECASE), "postgame marker"),
+    (re.compile(r".*final_score.*", flags=re.IGNORECASE), "final score"),
+    (re.compile(r".*actual.*td.*", flags=re.IGNORECASE), "actual TD total"),
+    (re.compile(r".*anytime_td.*(post|final|actual).*", flags=re.IGNORECASE), "post-decision anytime TD"),
+    (re.compile(r".*fullgame.*", flags=re.IGNORECASE), "full game cumulative value"),
+)
+
+DEFAULT_LEAK_POLICY = LeakPolicy(
+    version="v1",
+    description="Core post-outcome leak guard for NFL anytime TD features.",
+    banned_exact=_BASE_BANNED_EXACT,
+    banned_prefixes=_BASE_BANNED_PREFIXES,
+    banned_suffixes=_BASE_BANNED_SUFFIXES,
+    banned_regex=_BASE_BANNED_REGEX,
+)
+
+
+def _ensure_sequence(value: Sequence[str] | str | None) -> tuple[str, ...]:
+    if value is None:
+        return ()
+    if isinstance(value, str):
+        return (value,)
+    return tuple(value)
+
+
+def evaluate_leak_prone_columns(
+    columns: Iterable[str],
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+) -> LeakCheckResult:
+    """Identify leak-prone columns using the configured policy."""
+
+    banned: dict[str, str] = {}
+    columns_list = list(columns)
+    for col in columns_list:
+        if col in policy.banned_exact:
+            banned[col] = "exact"
+            continue
+        for prefix in policy.banned_prefixes:
+            if col.startswith(prefix):
+                banned[col] = f"prefix:{prefix}"
+                break
+        if col in banned:
+            continue
+        for suffix in policy.banned_suffixes:
+            if col.endswith(suffix):
+                banned[col] = f"suffix:{suffix}"
+                break
+        if col in banned:
+            continue
+        for pattern, reason in policy.banned_regex:
+            if pattern.match(col):
+                banned[col] = reason
+                break
+
+    kept = [c for c in columns_list if c not in banned]
+    return LeakCheckResult(
+        policy_version=policy.version,
+        banned=banned,
+        kept=kept,
+        dropped=[],
+        allowlist_kept=[],
+    )
+
+
+def enforce_leak_guard(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    allow_prefixes: Sequence[str] | str | None = None,
+    allow_exact: Sequence[str] | str | None = None,
+    drop_banned: bool = True,
+    drop_non_allowlisted: bool = False,
+    raise_on_banned: bool = True,
+) -> tuple[pl.DataFrame | "pd.DataFrame", LeakCheckResult]:
+    """Apply leak guardrails to a feature frame.
+
+    Parameters
+    ----------
+    df : DataFrame
+        Polars or pandas DataFrame.
+    policy : LeakPolicy
+        Leak policy to apply.
+    allow_prefixes : Sequence[str] | str | None
+        Optional prefixes that define the allowed feature surface for a problem.
+    allow_exact : Sequence[str] | str | None
+        Explicitly allowed columns (e.g., identifiers).
+    drop_banned : bool
+        If True, drop any banned columns automatically.
+    drop_non_allowlisted : bool
+        If True, drop columns that are not covered by allow_prefixes/allow_exact/identifiers/targets.
+    raise_on_banned : bool
+        If True, raise when banned columns are detected (after optional drop).
+    """
+
+    result = evaluate_leak_prone_columns(df.columns, policy=policy)
+    dropped: list[str] = []
+
+    allow_prefixes = _ensure_sequence(allow_prefixes)
+    allow_exact = set(_ensure_sequence(allow_exact))
+    allow_exact.update({col for col in IDENTIFIER_COLUMNS if col in df.columns})
+    allow_exact.update({col for col in NFL_TARGET_COLUMNS if col in df.columns})
+
+    # Permit allowlisted columns even if they match a banned rule (e.g., labels)
+    banned = {col: reason for col, reason in result.banned.items() if col not in allow_exact}
+
+    if banned and drop_banned:
+        df = df.drop(list(banned.keys()))
+        dropped.extend(banned.keys())
+
+    if banned and raise_on_banned:
+        raise ValueError(f"Leak-prone columns detected: {sorted(banned.items())}")
+
+    allowlist_cols: set[str] = set()
+    if allow_prefixes:
+        allowlist_cols.update({c for c in df.columns if c.startswith(allow_prefixes)})
+    allowlist_cols.update({c for c in allow_exact if c in df.columns})
+
+    if drop_non_allowlisted and allowlist_cols:
+        drop_candidates = [c for c in df.columns if c not in allowlist_cols]
+        if drop_candidates:
+            df = df.drop(drop_candidates)
+            dropped.extend(drop_candidates)
+
+    if drop_non_allowlisted and not allowlist_cols:
+        raise ValueError("No allowlisted columns remain after applying leak guard allowlist.")
+
+    # Store adjusted banned info on the result
+    result.banned = banned
+    result.dropped = dropped
+    result.kept = [c for c in df.columns]
+    result.allowlist_kept = sorted(list(allowlist_cols)) if allowlist_cols else []
+    return df, result
+
+
+def build_schema_snapshot(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    metadata: Mapping[str, object] | None = None,
+    banned: Mapping[str, str] | None = None,
+) -> dict:
+    """Render a schema snapshot describing each column and whether it was flagged."""
+
+    banned = banned or {}
+    meta = {
+        "generated_at_utc": datetime.utcnow().isoformat(),
+        "policy_version": policy.version,
+    }
+    meta.update(metadata or {})
+
+    # Extract columns / dtypes
+    if isinstance(df, pl.DataFrame):
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+    else:  # pandas or pandas-like
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+
+    schema = {
+        "metadata": meta,
+        "columns": [],
+    }
+
+    for col, dtype in cols_and_dtypes:
+        tags: list[str] = []
+        if col in IDENTIFIER_COLUMNS:
+            tags.append("id")
+        if col in NFL_TARGET_COLUMNS:
+            tags.append("label")
+        if col.startswith("market_"):
+            tags.append("odds")
+        if col.startswith("injury_") or col.startswith("practice_"):
+            tags.append("injury")
+        if col.startswith("weather_"):
+            tags.append("weather")
+        if col.startswith("ps_"):
+            tags.append("pre_snap")
+        schema["columns"].append(
+            {
+                "name": col,
+                "dtype": dtype,
+                "banned": col in banned,
+                "tags": tags,
+            }
+        )
+    return schema
+
+
+def write_schema_snapshot(path, schema: Mapping[str, object]) -> None:
+    path.parent.mkdir(parents=True, exist_ok=True)
+    with open(path, "w") as fp:
+        json.dump(schema, fp, indent=2, sort_keys=True)
+
+
+__all__ = [
+    "DEFAULT_LEAK_POLICY",
+    "LeakPolicy",
+    "LeakCheckResult",
+    "evaluate_leak_prone_columns",
+    "enforce_leak_guard",
+    "build_schema_snapshot",
+    "write_schema_snapshot",
+]


thinking
**Adding leak guard and schema snapshot integration**

I'm figuring out where to insert the leak guard patch just before writing the final dataset, reusing and repositioning the `spec` assignment to avoid duplication, then adding the schema snapshot write with metadata and logging. I'll carefully adjust existing code to integrate these changes smoothly.

thinking
**Optimizing spec creation and patch application**
file update
M /Users/jameswest/Desktop/nfl_predict/pipeline/feature.py
@@ -939,2 +939,28 @@
     
+    # Leak guard + schema snapshot before persisting
+    spec = get_label_spec(label_version)
+    allow_exact = {spec.primary, *spec.labels.keys(), *spec.aliases.keys()}
+    df_player_game_all, leak_result = enforce_leak_guard(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_exact=allow_exact,
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=True,
+    )
+
+    schema = build_schema_snapshot(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        metadata={
+            "cutoff_label": cutoff_label,
+            "label_version": spec.name,
+        },
+        banned=leak_result.banned,
+    )
+    schema_dir = FEATURE_AUDIT_DIR / "schema" / "anytime_td"
+    schema_path = schema_dir / f"{cutoff_label}_{datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')}.json"
+    write_schema_snapshot(schema_path, schema)
+    logging.info("    Schema snapshot written → %s", schema_path)
+
     # Write final feature matrix
@@ -959,3 +985,2 @@
     
-    spec = get_label_spec(label_version)
     label_candidates = {spec.primary, "anytime_td"}
apply_patch(auto_approved=true) exited 0 in 46ms:
Success. Updated the following files:
M pipeline/feature.py
file update:
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 5ba68e8bf1acd3a789a76a8857674e6f6433017b..0210d5b7e7ed60a8de7a126d64f5ed76326474c8
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -14,7 +14,7 @@
 
 import logging
 import os
-from datetime import date, timedelta
+from datetime import date, datetime, timedelta
 from typing import Sequence
 
 import polars as pl
@@ -37,6 +37,12 @@
     add_offense_context_features_training,
     _append_offense_context_columns,
 )
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    build_schema_snapshot,
+    enforce_leak_guard,
+    write_schema_snapshot,
+)
 from utils.feature.weather_features import (
     add_weather_forecast_features_training,
     append_weather_context_flags,
@@ -931,6 +937,32 @@
     if market_exprs:
         df_player_game_all = df_player_game_all.with_columns(market_exprs)
     
+    # Leak guard + schema snapshot before persisting
+    spec = get_label_spec(label_version)
+    allow_exact = {spec.primary, *spec.labels.keys(), *spec.aliases.keys()}
+    df_player_game_all, leak_result = enforce_leak_guard(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_exact=allow_exact,
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=True,
+    )
+
+    schema = build_schema_snapshot(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        metadata={
+            "cutoff_label": cutoff_label,
+            "label_version": spec.name,
+        },
+        banned=leak_result.banned,
+    )
+    schema_dir = FEATURE_AUDIT_DIR / "schema" / "anytime_td"
+    schema_path = schema_dir / f"{cutoff_label}_{datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')}.json"
+    write_schema_snapshot(schema_path, schema)
+    logging.info("    Schema snapshot written → %s", schema_path)
+
     # Write final feature matrix
     df_player_game_all = df_player_game_all.with_columns(
         pl.lit(current_cutoff_hours).cast(pl.Float32).alias("decision_horizon_hours")
@@ -951,7 +983,6 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    spec = get_label_spec(label_version)
     label_candidates = {spec.primary, "anytime_td"}
     for label_col in label_candidates:
         if label_col in df_player_game_all.columns:
diff --git a/utils/feature/leak_guard.py b/utils/feature/leak_guard.py
new file mode 100644
index 0000000000000000000000000000000000000000..9faf8cfffc436e0934b2f410aaf252e52f4f95df
--- /dev/null
+++ b/utils/feature/leak_guard.py
@@ -0,0 +1,273 @@
+"""Leak guardrails for feature matrices.
+
+This module centralizes pattern-based leak detection so both feature assembly
+and training can fail fast when post-outcome columns sneak into the data.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+from datetime import datetime
+import json
+import re
+from typing import Iterable, Mapping, Sequence
+
+import polars as pl
+
+from utils.general.constants import IDENTIFIER_COLUMNS, LEAK_PRONE_COLUMNS, NFL_TARGET_COLUMNS
+
+try:  # Optional dependency when imported from training (pandas path)
+    import pandas as pd  # type: ignore
+except Exception:  # pragma: no cover - optional dependency
+    pd = None
+
+
+@dataclass(frozen=True)
+class LeakPolicy:
+    version: str
+    banned_exact: set[str]
+    banned_prefixes: tuple[str, ...]
+    banned_suffixes: tuple[str, ...]
+    banned_regex: tuple[tuple[re.Pattern[str], str], ...]
+    description: str = ""
+
+
+@dataclass
+class LeakCheckResult:
+    policy_version: str
+    banned: dict[str, str]
+    kept: list[str]
+    dropped: list[str]
+    allowlist_kept: list[str]
+
+
+# Core policy tuned for anytime-TD style problems (can be extended per-problem).
+_BASE_BANNED_EXACT = set(LEAK_PRONE_COLUMNS) | {
+    "final_score",
+    "final_total",
+    "points_scored",
+    "actual_td_count",
+    "actual_anytime_td",
+    "postgame_anytime_td",
+    "postgame_td_count",
+}
+_BASE_BANNED_PREFIXES = (
+    "postgame_",
+    "post_game_",
+    "post_",
+    "live_",
+    "actual_",
+    "realized_",
+    "final_",
+    "postmatch_",
+)
+_BASE_BANNED_SUFFIXES = (
+    "_post",
+    "_postgame",
+    "_final",
+    "_fullgame",
+    "_actual",
+)
+_BASE_BANNED_REGEX: tuple[tuple[re.Pattern[str], str], ...] = (
+    (re.compile(r".*post.?game.*", flags=re.IGNORECASE), "postgame marker"),
+    (re.compile(r".*final_score.*", flags=re.IGNORECASE), "final score"),
+    (re.compile(r".*actual.*td.*", flags=re.IGNORECASE), "actual TD total"),
+    (re.compile(r".*anytime_td.*(post|final|actual).*", flags=re.IGNORECASE), "post-decision anytime TD"),
+    (re.compile(r".*fullgame.*", flags=re.IGNORECASE), "full game cumulative value"),
+)
+
+DEFAULT_LEAK_POLICY = LeakPolicy(
+    version="v1",
+    description="Core post-outcome leak guard for NFL anytime TD features.",
+    banned_exact=_BASE_BANNED_EXACT,
+    banned_prefixes=_BASE_BANNED_PREFIXES,
+    banned_suffixes=_BASE_BANNED_SUFFIXES,
+    banned_regex=_BASE_BANNED_REGEX,
+)
+
+
+def _ensure_sequence(value: Sequence[str] | str | None) -> tuple[str, ...]:
+    if value is None:
+        return ()
+    if isinstance(value, str):
+        return (value,)
+    return tuple(value)
+
+
+def evaluate_leak_prone_columns(
+    columns: Iterable[str],
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+) -> LeakCheckResult:
+    """Identify leak-prone columns using the configured policy."""
+
+    banned: dict[str, str] = {}
+    columns_list = list(columns)
+    for col in columns_list:
+        if col in policy.banned_exact:
+            banned[col] = "exact"
+            continue
+        for prefix in policy.banned_prefixes:
+            if col.startswith(prefix):
+                banned[col] = f"prefix:{prefix}"
+                break
+        if col in banned:
+            continue
+        for suffix in policy.banned_suffixes:
+            if col.endswith(suffix):
+                banned[col] = f"suffix:{suffix}"
+                break
+        if col in banned:
+            continue
+        for pattern, reason in policy.banned_regex:
+            if pattern.match(col):
+                banned[col] = reason
+                break
+
+    kept = [c for c in columns_list if c not in banned]
+    return LeakCheckResult(
+        policy_version=policy.version,
+        banned=banned,
+        kept=kept,
+        dropped=[],
+        allowlist_kept=[],
+    )
+
+
+def enforce_leak_guard(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    allow_prefixes: Sequence[str] | str | None = None,
+    allow_exact: Sequence[str] | str | None = None,
+    drop_banned: bool = True,
+    drop_non_allowlisted: bool = False,
+    raise_on_banned: bool = True,
+) -> tuple[pl.DataFrame | "pd.DataFrame", LeakCheckResult]:
+    """Apply leak guardrails to a feature frame.
+
+    Parameters
+    ----------
+    df : DataFrame
+        Polars or pandas DataFrame.
+    policy : LeakPolicy
+        Leak policy to apply.
+    allow_prefixes : Sequence[str] | str | None
+        Optional prefixes that define the allowed feature surface for a problem.
+    allow_exact : Sequence[str] | str | None
+        Explicitly allowed columns (e.g., identifiers).
+    drop_banned : bool
+        If True, drop any banned columns automatically.
+    drop_non_allowlisted : bool
+        If True, drop columns that are not covered by allow_prefixes/allow_exact/identifiers/targets.
+    raise_on_banned : bool
+        If True, raise when banned columns are detected (after optional drop).
+    """
+
+    result = evaluate_leak_prone_columns(df.columns, policy=policy)
+    dropped: list[str] = []
+
+    allow_prefixes = _ensure_sequence(allow_prefixes)
+    allow_exact = set(_ensure_sequence(allow_exact))
+    allow_exact.update({col for col in IDENTIFIER_COLUMNS if col in df.columns})
+    allow_exact.update({col for col in NFL_TARGET_COLUMNS if col in df.columns})
+
+    # Permit allowlisted columns even if they match a banned rule (e.g., labels)
+    banned = {col: reason for col, reason in result.banned.items() if col not in allow_exact}
+
+    if banned and drop_banned:
+        df = df.drop(list(banned.keys()))
+        dropped.extend(banned.keys())
+
+    if banned and raise_on_banned:
+        raise ValueError(f"Leak-prone columns detected: {sorted(banned.items())}")
+
+    allowlist_cols: set[str] = set()
+    if allow_prefixes:
+        allowlist_cols.update({c for c in df.columns if c.startswith(allow_prefixes)})
+    allowlist_cols.update({c for c in allow_exact if c in df.columns})
+
+    if drop_non_allowlisted and allowlist_cols:
+        drop_candidates = [c for c in df.columns if c not in allowlist_cols]
+        if drop_candidates:
+            df = df.drop(drop_candidates)
+            dropped.extend(drop_candidates)
+
+    if drop_non_allowlisted and not allowlist_cols:
+        raise ValueError("No allowlisted columns remain after applying leak guard allowlist.")
+
+    # Store adjusted banned info on the result
+    result.banned = banned
+    result.dropped = dropped
+    result.kept = [c for c in df.columns]
+    result.allowlist_kept = sorted(list(allowlist_cols)) if allowlist_cols else []
+    return df, result
+
+
+def build_schema_snapshot(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    metadata: Mapping[str, object] | None = None,
+    banned: Mapping[str, str] | None = None,
+) -> dict:
+    """Render a schema snapshot describing each column and whether it was flagged."""
+
+    banned = banned or {}
+    meta = {
+        "generated_at_utc": datetime.utcnow().isoformat(),
+        "policy_version": policy.version,
+    }
+    meta.update(metadata or {})
+
+    # Extract columns / dtypes
+    if isinstance(df, pl.DataFrame):
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+    else:  # pandas or pandas-like
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+
+    schema = {
+        "metadata": meta,
+        "columns": [],
+    }
+
+    for col, dtype in cols_and_dtypes:
+        tags: list[str] = []
+        if col in IDENTIFIER_COLUMNS:
+            tags.append("id")
+        if col in NFL_TARGET_COLUMNS:
+            tags.append("label")
+        if col.startswith("market_"):
+            tags.append("odds")
+        if col.startswith("injury_") or col.startswith("practice_"):
+            tags.append("injury")
+        if col.startswith("weather_"):
+            tags.append("weather")
+        if col.startswith("ps_"):
+            tags.append("pre_snap")
+        schema["columns"].append(
+            {
+                "name": col,
+                "dtype": dtype,
+                "banned": col in banned,
+                "tags": tags,
+            }
+        )
+    return schema
+
+
+def write_schema_snapshot(path, schema: Mapping[str, object]) -> None:
+    path.parent.mkdir(parents=True, exist_ok=True)
+    with open(path, "w") as fp:
+        json.dump(schema, fp, indent=2, sort_keys=True)
+
+
+__all__ = [
+    "DEFAULT_LEAK_POLICY",
+    "LeakPolicy",
+    "LeakCheckResult",
+    "evaluate_leak_prone_columns",
+    "enforce_leak_guard",
+    "build_schema_snapshot",
+    "write_schema_snapshot",
+]

file update:
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 5ba68e8bf1acd3a789a76a8857674e6f6433017b..0210d5b7e7ed60a8de7a126d64f5ed76326474c8
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -14,7 +14,7 @@
 
 import logging
 import os
-from datetime import date, timedelta
+from datetime import date, datetime, timedelta
 from typing import Sequence
 
 import polars as pl
@@ -37,6 +37,12 @@
     add_offense_context_features_training,
     _append_offense_context_columns,
 )
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    build_schema_snapshot,
+    enforce_leak_guard,
+    write_schema_snapshot,
+)
 from utils.feature.weather_features import (
     add_weather_forecast_features_training,
     append_weather_context_flags,
@@ -931,6 +937,32 @@
     if market_exprs:
         df_player_game_all = df_player_game_all.with_columns(market_exprs)
     
+    # Leak guard + schema snapshot before persisting
+    spec = get_label_spec(label_version)
+    allow_exact = {spec.primary, *spec.labels.keys(), *spec.aliases.keys()}
+    df_player_game_all, leak_result = enforce_leak_guard(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_exact=allow_exact,
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=True,
+    )
+
+    schema = build_schema_snapshot(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        metadata={
+            "cutoff_label": cutoff_label,
+            "label_version": spec.name,
+        },
+        banned=leak_result.banned,
+    )
+    schema_dir = FEATURE_AUDIT_DIR / "schema" / "anytime_td"
+    schema_path = schema_dir / f"{cutoff_label}_{datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')}.json"
+    write_schema_snapshot(schema_path, schema)
+    logging.info("    Schema snapshot written → %s", schema_path)
+
     # Write final feature matrix
     df_player_game_all = df_player_game_all.with_columns(
         pl.lit(current_cutoff_hours).cast(pl.Float32).alias("decision_horizon_hours")
@@ -951,7 +983,6 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    spec = get_label_spec(label_version)
     label_candidates = {spec.primary, "anytime_td"}
     for label_col in label_candidates:
         if label_col in df_player_game_all.columns:
diff --git a/utils/feature/leak_guard.py b/utils/feature/leak_guard.py
new file mode 100644
index 0000000000000000000000000000000000000000..9faf8cfffc436e0934b2f410aaf252e52f4f95df
--- /dev/null
+++ b/utils/feature/leak_guard.py
@@ -0,0 +1,273 @@
+"""Leak guardrails for feature matrices.
+
+This module centralizes pattern-based leak detection so both feature assembly
+and training can fail fast when post-outcome columns sneak into the data.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+from datetime import datetime
+import json
+import re
+from typing import Iterable, Mapping, Sequence
+
+import polars as pl
+
+from utils.general.constants import IDENTIFIER_COLUMNS, LEAK_PRONE_COLUMNS, NFL_TARGET_COLUMNS
+
+try:  # Optional dependency when imported from training (pandas path)
+    import pandas as pd  # type: ignore
+except Exception:  # pragma: no cover - optional dependency
+    pd = None
+
+
+@dataclass(frozen=True)
+class LeakPolicy:
+    version: str
+    banned_exact: set[str]
+    banned_prefixes: tuple[str, ...]
+    banned_suffixes: tuple[str, ...]
+    banned_regex: tuple[tuple[re.Pattern[str], str], ...]
+    description: str = ""
+
+
+@dataclass
+class LeakCheckResult:
+    policy_version: str
+    banned: dict[str, str]
+    kept: list[str]
+    dropped: list[str]
+    allowlist_kept: list[str]
+
+
+# Core policy tuned for anytime-TD style problems (can be extended per-problem).
+_BASE_BANNED_EXACT = set(LEAK_PRONE_COLUMNS) | {
+    "final_score",
+    "final_total",
+    "points_scored",
+    "actual_td_count",
+    "actual_anytime_td",
+    "postgame_anytime_td",
+    "postgame_td_count",
+}
+_BASE_BANNED_PREFIXES = (
+    "postgame_",
+    "post_game_",
+    "post_",
+    "live_",
+    "actual_",
+    "realized_",
+    "final_",
+    "postmatch_",
+)
+_BASE_BANNED_SUFFIXES = (
+    "_post",
+    "_postgame",
+    "_final",
+    "_fullgame",
+    "_actual",
+)
+_BASE_BANNED_REGEX: tuple[tuple[re.Pattern[str], str], ...] = (
+    (re.compile(r".*post.?game.*", flags=re.IGNORECASE), "postgame marker"),
+    (re.compile(r".*final_score.*", flags=re.IGNORECASE), "final score"),
+    (re.compile(r".*actual.*td.*", flags=re.IGNORECASE), "actual TD total"),
+    (re.compile(r".*anytime_td.*(post|final|actual).*", flags=re.IGNORECASE), "post-decision anytime TD"),
+    (re.compile(r".*fullgame.*", flags=re.IGNORECASE), "full game cumulative value"),
+)
+
+DEFAULT_LEAK_POLICY = LeakPolicy(
+    version="v1",
+    description="Core post-outcome leak guard for NFL anytime TD features.",
+    banned_exact=_BASE_BANNED_EXACT,
+    banned_prefixes=_BASE_BANNED_PREFIXES,
+    banned_suffixes=_BASE_BANNED_SUFFIXES,
+    banned_regex=_BASE_BANNED_REGEX,
+)
+
+
+def _ensure_sequence(value: Sequence[str] | str | None) -> tuple[str, ...]:
+    if value is None:
+        return ()
+    if isinstance(value, str):
+        return (value,)
+    return tuple(value)
+
+
+def evaluate_leak_prone_columns(
+    columns: Iterable[str],
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+) -> LeakCheckResult:
+    """Identify leak-prone columns using the configured policy."""
+
+    banned: dict[str, str] = {}
+    columns_list = list(columns)
+    for col in columns_list:
+        if col in policy.banned_exact:
+            banned[col] = "exact"
+            continue
+        for prefix in policy.banned_prefixes:
+            if col.startswith(prefix):
+                banned[col] = f"prefix:{prefix}"
+                break
+        if col in banned:
+            continue
+        for suffix in policy.banned_suffixes:
+            if col.endswith(suffix):
+                banned[col] = f"suffix:{suffix}"
+                break
+        if col in banned:
+            continue
+        for pattern, reason in policy.banned_regex:
+            if pattern.match(col):
+                banned[col] = reason
+                break
+
+    kept = [c for c in columns_list if c not in banned]
+    return LeakCheckResult(
+        policy_version=policy.version,
+        banned=banned,
+        kept=kept,
+        dropped=[],
+        allowlist_kept=[],
+    )
+
+
+def enforce_leak_guard(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    allow_prefixes: Sequence[str] | str | None = None,
+    allow_exact: Sequence[str] | str | None = None,
+    drop_banned: bool = True,
+    drop_non_allowlisted: bool = False,
+    raise_on_banned: bool = True,
+) -> tuple[pl.DataFrame | "pd.DataFrame", LeakCheckResult]:
+    """Apply leak guardrails to a feature frame.
+
+    Parameters
+    ----------
+    df : DataFrame
+        Polars or pandas DataFrame.
+    policy : LeakPolicy
+        Leak policy to apply.
+    allow_prefixes : Sequence[str] | str | None
+        Optional prefixes that define the allowed feature surface for a problem.
+    allow_exact : Sequence[str] | str | None
+        Explicitly allowed columns (e.g., identifiers).
+    drop_banned : bool
+        If True, drop any banned columns automatically.
+    drop_non_allowlisted : bool
+        If True, drop columns that are not covered by allow_prefixes/allow_exact/identifiers/targets.
+    raise_on_banned : bool
+        If True, raise when banned columns are detected (after optional drop).
+    """
+
+    result = evaluate_leak_prone_columns(df.columns, policy=policy)
+    dropped: list[str] = []
+
+    allow_prefixes = _ensure_sequence(allow_prefixes)
+    allow_exact = set(_ensure_sequence(allow_exact))
+    allow_exact.update({col for col in IDENTIFIER_COLUMNS if col in df.columns})
+    allow_exact.update({col for col in NFL_TARGET_COLUMNS if col in df.columns})
+
+    # Permit allowlisted columns even if they match a banned rule (e.g., labels)
+    banned = {col: reason for col, reason in result.banned.items() if col not in allow_exact}
+
+    if banned and drop_banned:
+        df = df.drop(list(banned.keys()))
+        dropped.extend(banned.keys())
+
+    if banned and raise_on_banned:
+        raise ValueError(f"Leak-prone columns detected: {sorted(banned.items())}")
+
+    allowlist_cols: set[str] = set()
+    if allow_prefixes:
+        allowlist_cols.update({c for c in df.columns if c.startswith(allow_prefixes)})
+    allowlist_cols.update({c for c in allow_exact if c in df.columns})
+
+    if drop_non_allowlisted and allowlist_cols:
+        drop_candidates = [c for c in df.columns if c not in allowlist_cols]
+        if drop_candidates:
+            df = df.drop(drop_candidates)
+            dropped.extend(drop_candidates)
+
+    if drop_non_allowlisted and not allowlist_cols:
+        raise ValueError("No allowlisted columns remain after applying leak guard allowlist.")
+
+    # Store adjusted banned info on the result
+    result.banned = banned
+    result.dropped = dropped
+    result.kept = [c for c in df.columns]
+    result.allowlist_kept = sorted(list(allowlist_cols)) if allowlist_cols else []
+    return df, result
+
+
+def build_schema_snapshot(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    metadata: Mapping[str, object] | None = None,
+    banned: Mapping[str, str] | None = None,
+) -> dict:
+    """Render a schema snapshot describing each column and whether it was flagged."""
+
+    banned = banned or {}
+    meta = {
+        "generated_at_utc": datetime.utcnow().isoformat(),
+        "policy_version": policy.version,
+    }
+    meta.update(metadata or {})
+
+    # Extract columns / dtypes
+    if isinstance(df, pl.DataFrame):
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+    else:  # pandas or pandas-like
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+
+    schema = {
+        "metadata": meta,
+        "columns": [],
+    }
+
+    for col, dtype in cols_and_dtypes:
+        tags: list[str] = []
+        if col in IDENTIFIER_COLUMNS:
+            tags.append("id")
+        if col in NFL_TARGET_COLUMNS:
+            tags.append("label")
+        if col.startswith("market_"):
+            tags.append("odds")
+        if col.startswith("injury_") or col.startswith("practice_"):
+            tags.append("injury")
+        if col.startswith("weather_"):
+            tags.append("weather")
+        if col.startswith("ps_"):
+            tags.append("pre_snap")
+        schema["columns"].append(
+            {
+                "name": col,
+                "dtype": dtype,
+                "banned": col in banned,
+                "tags": tags,
+            }
+        )
+    return schema
+
+
+def write_schema_snapshot(path, schema: Mapping[str, object]) -> None:
+    path.parent.mkdir(parents=True, exist_ok=True)
+    with open(path, "w") as fp:
+        json.dump(schema, fp, indent=2, sort_keys=True)
+
+
+__all__ = [
+    "DEFAULT_LEAK_POLICY",
+    "LeakPolicy",
+    "LeakCheckResult",
+    "evaluate_leak_prone_columns",
+    "enforce_leak_guard",
+    "build_schema_snapshot",
+    "write_schema_snapshot",
+]


thinking
**Verifying spec assignment removal**
exec
/bin/zsh -lc "cd /Users/jameswest/Desktop/nfl_predict && sed -n '900,1050p' pipeline/feature.py" in /Users/jameswest/Desktop/nfl_predict succeeded in 745ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
        "pass_attempt_share",
        "red_zone_target_share",
        "red_zone_carry_share",
        "goal_to_go_target_share",
        "goal_to_go_carry_share",
    ]
    df_player_game_all = df_player_game_all.drop(leakage_cols, strict=False)
    # Keep raw outcome columns (targets, carries, etc.) in the feature matrix so they can
    # serve as supervised targets. These columns are excluded from model inputs later via
    # training configuration, so we avoid dropping them here to retain label availability.

    available_cols = set(df_player_game_all.columns)
    market_exprs: list[pl.Expr] = []
    if {"team_implied_total", "hist_target_share_prev"} <= available_cols:
        market_exprs.append(
            (pl.col("team_implied_total") * pl.col("hist_target_share_prev"))
            .cast(pl.Float32)
            .alias("market_team_total_x_hist_target_prev")
        )
file update:
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 5ba68e8bf1acd3a789a76a8857674e6f6433017b..0210d5b7e7ed60a8de7a126d64f5ed76326474c8
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -14,7 +14,7 @@
 
 import logging
 import os
-from datetime import date, timedelta
+from datetime import date, datetime, timedelta
 from typing import Sequence
 
 import polars as pl
@@ -37,6 +37,12 @@
     add_offense_context_features_training,
     _append_offense_context_columns,
 )
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    build_schema_snapshot,
+    enforce_leak_guard,
+    write_schema_snapshot,
+)
 from utils.feature.weather_features import (
     add_weather_forecast_features_training,
     append_weather_context_flags,
@@ -931,6 +937,32 @@
     if market_exprs:
         df_player_game_all = df_player_game_all.with_columns(market_exprs)
     
+    # Leak guard + schema snapshot before persisting
+    spec = get_label_spec(label_version)
+    allow_exact = {spec.primary, *spec.labels.keys(), *spec.aliases.keys()}
+    df_player_game_all, leak_result = enforce_leak_guard(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_exact=allow_exact,
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=True,
+    )
+
+    schema = build_schema_snapshot(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        metadata={
+            "cutoff_label": cutoff_label,
+            "label_version": spec.name,
+        },
+        banned=leak_result.banned,
+    )
+    schema_dir = FEATURE_AUDIT_DIR / "schema" / "anytime_td"
+    schema_path = schema_dir / f"{cutoff_label}_{datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')}.json"
+    write_schema_snapshot(schema_path, schema)
+    logging.info("    Schema snapshot written → %s", schema_path)
+
     # Write final feature matrix
     df_player_game_all = df_player_game_all.with_columns(
         pl.lit(current_cutoff_hours).cast(pl.Float32).alias("decision_horizon_hours")
@@ -951,7 +983,6 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    spec = get_label_spec(label_version)
     label_candidates = {spec.primary, "anytime_td"}
     for label_col in label_candidates:
         if label_col in df_player_game_all.columns:
diff --git a/utils/feature/leak_guard.py b/utils/feature/leak_guard.py
new file mode 100644
index 0000000000000000000000000000000000000000..9faf8cfffc436e0934b2f410aaf252e52f4f95df
--- /dev/null
+++ b/utils/feature/leak_guard.py
@@ -0,0 +1,273 @@
+"""Leak guardrails for feature matrices.
+
+This module centralizes pattern-based leak detection so both feature assembly
+and training can fail fast when post-outcome columns sneak into the data.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+from datetime import datetime
+import json
+import re
+from typing import Iterable, Mapping, Sequence
+
+import polars as pl
+
+from utils.general.constants import IDENTIFIER_COLUMNS, LEAK_PRONE_COLUMNS, NFL_TARGET_COLUMNS
+
+try:  # Optional dependency when imported from training (pandas path)
+    import pandas as pd  # type: ignore
+except Exception:  # pragma: no cover - optional dependency
+    pd = None
+
+
+@dataclass(frozen=True)
+class LeakPolicy:
+    version: str
+    banned_exact: set[str]
+    banned_prefixes: tuple[str, ...]
+    banned_suffixes: tuple[str, ...]
+    banned_regex: tuple[tuple[re.Pattern[str], str], ...]
+    description: str = ""
+
+
+@dataclass
+class LeakCheckResult:
+    policy_version: str
+    banned: dict[str, str]
+    kept: list[str]
+    dropped: list[str]
+    allowlist_kept: list[str]
+
+
+# Core policy tuned for anytime-TD style problems (can be extended per-problem).
+_BASE_BANNED_EXACT = set(LEAK_PRONE_COLUMNS) | {
+    "final_score",
+    "final_total",
+    "points_scored",
+    "actual_td_count",
+    "actual_anytime_td",
+    "postgame_anytime_td",
+    "postgame_td_count",
+}
+_BASE_BANNED_PREFIXES = (
+    "postgame_",
+    "post_game_",
+    "post_",
+    "live_",
+    "actual_",
+    "realized_",
+    "final_",
+    "postmatch_",
+)
+_BASE_BANNED_SUFFIXES = (
+    "_post",
+    "_postgame",
+    "_final",
+    "_fullgame",
+    "_actual",
+)
+_BASE_BANNED_REGEX: tuple[tuple[re.Pattern[str], str], ...] = (
+    (re.compile(r".*post.?game.*", flags=re.IGNORECASE), "postgame marker"),
+    (re.compile(r".*final_score.*", flags=re.IGNORECASE), "final score"),
+    (re.compile(r".*actual.*td.*", flags=re.IGNORECASE), "actual TD total"),
+    (re.compile(r".*anytime_td.*(post|final|actual).*", flags=re.IGNORECASE), "post-decision anytime TD"),
+    (re.compile(r".*fullgame.*", flags=re.IGNORECASE), "full game cumulative value"),
+)
+
+DEFAULT_LEAK_POLICY = LeakPolicy(
+    version="v1",
+    description="Core post-outcome leak guard for NFL anytime TD features.",
+    banned_exact=_BASE_BANNED_EXACT,
+    banned_prefixes=_BASE_BANNED_PREFIXES,
+    banned_suffixes=_BASE_BANNED_SUFFIXES,
+    banned_regex=_BASE_BANNED_REGEX,
+)
+
+
+def _ensure_sequence(value: Sequence[str] | str | None) -> tuple[str, ...]:
+    if value is None:
+        return ()
+    if isinstance(value, str):
+        return (value,)
+    return tuple(value)
+
+
+def evaluate_leak_prone_columns(
+    columns: Iterable[str],
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+) -> LeakCheckResult:
+    """Identify leak-prone columns using the configured policy."""
+
+    banned: dict[str, str] = {}
+    columns_list = list(columns)
+    for col in columns_list:
+        if col in policy.banned_exact:
+            banned[col] = "exact"
+            continue
+        for prefix in policy.banned_prefixes:
+            if col.startswith(prefix):
+                banned[col] = f"prefix:{prefix}"
+                break
+        if col in banned:
+            continue
+        for suffix in policy.banned_suffixes:
+            if col.endswith(suffix):
+                banned[col] = f"suffix:{suffix}"
+                break
+        if col in banned:
+            continue
+        for pattern, reason in policy.banned_regex:
+            if pattern.match(col):
+                banned[col] = reason
+                break
+
+    kept = [c for c in columns_list if c not in banned]
+    return LeakCheckResult(
+        policy_version=policy.version,
+        banned=banned,
+        kept=kept,
+        dropped=[],
+        allowlist_kept=[],
+    )
+
+
+def enforce_leak_guard(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    allow_prefixes: Sequence[str] | str | None = None,
+    allow_exact: Sequence[str] | str | None = None,
+    drop_banned: bool = True,
+    drop_non_allowlisted: bool = False,
+    raise_on_banned: bool = True,
+) -> tuple[pl.DataFrame | "pd.DataFrame", LeakCheckResult]:
+    """Apply leak guardrails to a feature frame.
+
+    Parameters
+    ----------
+    df : DataFrame
+        Polars or pandas DataFrame.
+    policy : LeakPolicy
+        Leak policy to apply.
+    allow_prefixes : Sequence[str] | str | None
+        Optional prefixes that define the allowed feature surface for a problem.
+    allow_exact : Sequence[str] | str | None
+        Explicitly allowed columns (e.g., identifiers).
+    drop_banned : bool
+        If True, drop any banned columns automatically.
+    drop_non_allowlisted : bool
+        If True, drop columns that are not covered by allow_prefixes/allow_exact/identifiers/targets.
+    raise_on_banned : bool
+        If True, raise when banned columns are detected (after optional drop).
+    """
+
+    result = evaluate_leak_prone_columns(df.columns, policy=policy)
+    dropped: list[str] = []
+
+    allow_prefixes = _ensure_sequence(allow_prefixes)
+    allow_exact = set(_ensure_sequence(allow_exact))
+    allow_exact.update({col for col in IDENTIFIER_COLUMNS if col in df.columns})
+    allow_exact.update({col for col in NFL_TARGET_COLUMNS if col in df.columns})
+
+    # Permit allowlisted columns even if they match a banned rule (e.g., labels)
+    banned = {col: reason for col, reason in result.banned.items() if col not in allow_exact}
+
+    if banned and drop_banned:
+        df = df.drop(list(banned.keys()))
+        dropped.extend(banned.keys())
+
+    if banned and raise_on_banned:
+        raise ValueError(f"Leak-prone columns detected: {sorted(banned.items())}")
+
+    allowlist_cols: set[str] = set()
+    if allow_prefixes:
+        allowlist_cols.update({c for c in df.columns if c.startswith(allow_prefixes)})
+    allowlist_cols.update({c for c in allow_exact if c in df.columns})
+
+    if drop_non_allowlisted and allowlist_cols:
+        drop_candidates = [c for c in df.columns if c not in allowlist_cols]
+        if drop_candidates:
+            df = df.drop(drop_candidates)
+            dropped.extend(drop_candidates)
+
+    if drop_non_allowlisted and not allowlist_cols:
+        raise ValueError("No allowlisted columns remain after applying leak guard allowlist.")
+
+    # Store adjusted banned info on the result
+    result.banned = banned
+    result.dropped = dropped
+    result.kept = [c for c in df.columns]
+    result.allowlist_kept = sorted(list(allowlist_cols)) if allowlist_cols else []
+    return df, result
+
+
+def build_schema_snapshot(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    metadata: Mapping[str, object] | None = None,
+    banned: Mapping[str, str] | None = None,
+) -> dict:
+    """Render a schema snapshot describing each column and whether it was flagged."""
+
+    banned = banned or {}
+    meta = {
+        "generated_at_utc": datetime.utcnow().isoformat(),
+        "policy_version": policy.version,
+    }
+    meta.update(metadata or {})
+
+    # Extract columns / dtypes
+    if isinstance(df, pl.DataFrame):
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+    else:  # pandas or pandas-like
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+
+    schema = {
+        "metadata": meta,
+        "columns": [],
+    }
+
+    for col, dtype in cols_and_dtypes:
+        tags: list[str] = []
+        if col in IDENTIFIER_COLUMNS:
+            tags.append("id")
+        if col in NFL_TARGET_COLUMNS:
+            tags.append("label")
+        if col.startswith("market_"):
+            tags.append("odds")
+        if col.startswith("injury_") or col.startswith("practice_"):
+            tags.append("injury")
+        if col.startswith("weather_"):
+            tags.append("weather")
+        if col.startswith("ps_"):
+            tags.append("pre_snap")
+        schema["columns"].append(
+            {
+                "name": col,
+                "dtype": dtype,
+                "banned": col in banned,
+                "tags": tags,
+            }
+        )
+    return schema
+
+
+def write_schema_snapshot(path, schema: Mapping[str, object]) -> None:
+    path.parent.mkdir(parents=True, exist_ok=True)
+    with open(path, "w") as fp:
+        json.dump(schema, fp, indent=2, sort_keys=True)
+
+
+__all__ = [
+    "DEFAULT_LEAK_POLICY",
+    "LeakPolicy",
+    "LeakCheckResult",
+    "evaluate_leak_prone_columns",
+    "enforce_leak_guard",
+    "build_schema_snapshot",
+    "write_schema_snapshot",
+]


thinking
**Analyzing leak guard enforcement and integration**

I'm verifying how the leak guard handles LEAK_PRONE columns, ensuring allowed columns like NFL_TARGET_COLUMNS are exempt from raising errors while truly banned columns trigger enforcement. I'm also considering how this might affect the pipeline if banned columns appear and planning to import and integrate the leak guard into the training pipeline next.
file update
M /Users/jameswest/Desktop/nfl_predict/pipeline/train.py
@@ -100,2 +100,3 @@
 )
+from utils.feature.leak_guard import DEFAULT_LEAK_POLICY, enforce_leak_guard
 from utils.feature.targets import require_target_column
apply_patch(auto_approved=true) exited 0 in 55ms:
Success. Updated the following files:
M pipeline/train.py
file update:
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 5ba68e8bf1acd3a789a76a8857674e6f6433017b..0210d5b7e7ed60a8de7a126d64f5ed76326474c8
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -14,7 +14,7 @@
 
 import logging
 import os
-from datetime import date, timedelta
+from datetime import date, datetime, timedelta
 from typing import Sequence
 
 import polars as pl
@@ -37,6 +37,12 @@
     add_offense_context_features_training,
     _append_offense_context_columns,
 )
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    build_schema_snapshot,
+    enforce_leak_guard,
+    write_schema_snapshot,
+)
 from utils.feature.weather_features import (
     add_weather_forecast_features_training,
     append_weather_context_flags,
@@ -931,6 +937,32 @@
     if market_exprs:
         df_player_game_all = df_player_game_all.with_columns(market_exprs)
     
+    # Leak guard + schema snapshot before persisting
+    spec = get_label_spec(label_version)
+    allow_exact = {spec.primary, *spec.labels.keys(), *spec.aliases.keys()}
+    df_player_game_all, leak_result = enforce_leak_guard(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_exact=allow_exact,
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=True,
+    )
+
+    schema = build_schema_snapshot(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        metadata={
+            "cutoff_label": cutoff_label,
+            "label_version": spec.name,
+        },
+        banned=leak_result.banned,
+    )
+    schema_dir = FEATURE_AUDIT_DIR / "schema" / "anytime_td"
+    schema_path = schema_dir / f"{cutoff_label}_{datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')}.json"
+    write_schema_snapshot(schema_path, schema)
+    logging.info("    Schema snapshot written → %s", schema_path)
+
     # Write final feature matrix
     df_player_game_all = df_player_game_all.with_columns(
         pl.lit(current_cutoff_hours).cast(pl.Float32).alias("decision_horizon_hours")
@@ -951,7 +983,6 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    spec = get_label_spec(label_version)
     label_candidates = {spec.primary, "anytime_td"}
     for label_col in label_candidates:
         if label_col in df_player_game_all.columns:
diff --git a/pipeline/train.py b/pipeline/train.py
index fe70207dcdf25d209ee3ad55080b7ce826347c44..db24b7a473a82741febb827ac90b1cad36f1e466
--- a/pipeline/train.py
+++ b/pipeline/train.py
@@ -98,6 +98,7 @@
     fit_team_conformal_sums,
     composite_sum_interval,
 )
+from utils.feature.leak_guard import DEFAULT_LEAK_POLICY, enforce_leak_guard
 from utils.feature.targets import require_target_column
 
 # Ignore specific, noisy warnings from dependencies
diff --git a/utils/feature/leak_guard.py b/utils/feature/leak_guard.py
new file mode 100644
index 0000000000000000000000000000000000000000..9faf8cfffc436e0934b2f410aaf252e52f4f95df
--- /dev/null
+++ b/utils/feature/leak_guard.py
@@ -0,0 +1,273 @@
+"""Leak guardrails for feature matrices.
+
+This module centralizes pattern-based leak detection so both feature assembly
+and training can fail fast when post-outcome columns sneak into the data.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+from datetime import datetime
+import json
+import re
+from typing import Iterable, Mapping, Sequence
+
+import polars as pl
+
+from utils.general.constants import IDENTIFIER_COLUMNS, LEAK_PRONE_COLUMNS, NFL_TARGET_COLUMNS
+
+try:  # Optional dependency when imported from training (pandas path)
+    import pandas as pd  # type: ignore
+except Exception:  # pragma: no cover - optional dependency
+    pd = None
+
+
+@dataclass(frozen=True)
+class LeakPolicy:
+    version: str
+    banned_exact: set[str]
+    banned_prefixes: tuple[str, ...]
+    banned_suffixes: tuple[str, ...]
+    banned_regex: tuple[tuple[re.Pattern[str], str], ...]
+    description: str = ""
+
+
+@dataclass
+class LeakCheckResult:
+    policy_version: str
+    banned: dict[str, str]
+    kept: list[str]
+    dropped: list[str]
+    allowlist_kept: list[str]
+
+
+# Core policy tuned for anytime-TD style problems (can be extended per-problem).
+_BASE_BANNED_EXACT = set(LEAK_PRONE_COLUMNS) | {
+    "final_score",
+    "final_total",
+    "points_scored",
+    "actual_td_count",
+    "actual_anytime_td",
+    "postgame_anytime_td",
+    "postgame_td_count",
+}
+_BASE_BANNED_PREFIXES = (
+    "postgame_",
+    "post_game_",
+    "post_",
+    "live_",
+    "actual_",
+    "realized_",
+    "final_",
+    "postmatch_",
+)
+_BASE_BANNED_SUFFIXES = (
+    "_post",
+    "_postgame",
+    "_final",
+    "_fullgame",
+    "_actual",
+)
+_BASE_BANNED_REGEX: tuple[tuple[re.Pattern[str], str], ...] = (
+    (re.compile(r".*post.?game.*", flags=re.IGNORECASE), "postgame marker"),
+    (re.compile(r".*final_score.*", flags=re.IGNORECASE), "final score"),
+    (re.compile(r".*actual.*td.*", flags=re.IGNORECASE), "actual TD total"),
+    (re.compile(r".*anytime_td.*(post|final|actual).*", flags=re.IGNORECASE), "post-decision anytime TD"),
+    (re.compile(r".*fullgame.*", flags=re.IGNORECASE), "full game cumulative value"),
+)
+
+DEFAULT_LEAK_POLICY = LeakPolicy(
+    version="v1",
+    description="Core post-outcome leak guard for NFL anytime TD features.",
+    banned_exact=_BASE_BANNED_EXACT,
+    banned_prefixes=_BASE_BANNED_PREFIXES,
+    banned_suffixes=_BASE_BANNED_SUFFIXES,
+    banned_regex=_BASE_BANNED_REGEX,
+)
+
+
+def _ensure_sequence(value: Sequence[str] | str | None) -> tuple[str, ...]:
+    if value is None:
+        return ()
+    if isinstance(value, str):
+        return (value,)
+    return tuple(value)
+
+
+def evaluate_leak_prone_columns(
+    columns: Iterable[str],
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+) -> LeakCheckResult:
+    """Identify leak-prone columns using the configured policy."""
+
+    banned: dict[str, str] = {}
+    columns_list = list(columns)
+    for col in columns_list:
+        if col in policy.banned_exact:
+            banned[col] = "exact"
+            continue
+        for prefix in policy.banned_prefixes:
+            if col.startswith(prefix):
+                banned[col] = f"prefix:{prefix}"
+                break
+        if col in banned:
+            continue
+        for suffix in policy.banned_suffixes:
+            if col.endswith(suffix):
+                banned[col] = f"suffix:{suffix}"
+                break
+        if col in banned:
+            continue
+        for pattern, reason in policy.banned_regex:
+            if pattern.match(col):
+                banned[col] = reason
+                break
+
+    kept = [c for c in columns_list if c not in banned]
+    return LeakCheckResult(
+        policy_version=policy.version,
+        banned=banned,
+        kept=kept,
+        dropped=[],
+        allowlist_kept=[],
+    )
+
+
+def enforce_leak_guard(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    allow_prefixes: Sequence[str] | str | None = None,
+    allow_exact: Sequence[str] | str | None = None,
+    drop_banned: bool = True,
+    drop_non_allowlisted: bool = False,
+    raise_on_banned: bool = True,
+) -> tuple[pl.DataFrame | "pd.DataFrame", LeakCheckResult]:
+    """Apply leak guardrails to a feature frame.
+
+    Parameters
+    ----------
+    df : DataFrame
+        Polars or pandas DataFrame.
+    policy : LeakPolicy
+        Leak policy to apply.
+    allow_prefixes : Sequence[str] | str | None
+        Optional prefixes that define the allowed feature surface for a problem.
+    allow_exact : Sequence[str] | str | None
+        Explicitly allowed columns (e.g., identifiers).
+    drop_banned : bool
+        If True, drop any banned columns automatically.
+    drop_non_allowlisted : bool
+        If True, drop columns that are not covered by allow_prefixes/allow_exact/identifiers/targets.
+    raise_on_banned : bool
+        If True, raise when banned columns are detected (after optional drop).
+    """
+
+    result = evaluate_leak_prone_columns(df.columns, policy=policy)
+    dropped: list[str] = []
+
+    allow_prefixes = _ensure_sequence(allow_prefixes)
+    allow_exact = set(_ensure_sequence(allow_exact))
+    allow_exact.update({col for col in IDENTIFIER_COLUMNS if col in df.columns})
+    allow_exact.update({col for col in NFL_TARGET_COLUMNS if col in df.columns})
+
+    # Permit allowlisted columns even if they match a banned rule (e.g., labels)
+    banned = {col: reason for col, reason in result.banned.items() if col not in allow_exact}
+
+    if banned and drop_banned:
+        df = df.drop(list(banned.keys()))
+        dropped.extend(banned.keys())
+
+    if banned and raise_on_banned:
+        raise ValueError(f"Leak-prone columns detected: {sorted(banned.items())}")
+
+    allowlist_cols: set[str] = set()
+    if allow_prefixes:
+        allowlist_cols.update({c for c in df.columns if c.startswith(allow_prefixes)})
+    allowlist_cols.update({c for c in allow_exact if c in df.columns})
+
+    if drop_non_allowlisted and allowlist_cols:
+        drop_candidates = [c for c in df.columns if c not in allowlist_cols]
+        if drop_candidates:
+            df = df.drop(drop_candidates)
+            dropped.extend(drop_candidates)
+
+    if drop_non_allowlisted and not allowlist_cols:
+        raise ValueError("No allowlisted columns remain after applying leak guard allowlist.")
+
+    # Store adjusted banned info on the result
+    result.banned = banned
+    result.dropped = dropped
+    result.kept = [c for c in df.columns]
+    result.allowlist_kept = sorted(list(allowlist_cols)) if allowlist_cols else []
+    return df, result
+
+
+def build_schema_snapshot(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    metadata: Mapping[str, object] | None = None,
+    banned: Mapping[str, str] | None = None,
+) -> dict:
+    """Render a schema snapshot describing each column and whether it was flagged."""
+
+    banned = banned or {}
+    meta = {
+        "generated_at_utc": datetime.utcnow().isoformat(),
+        "policy_version": policy.version,
+    }
+    meta.update(metadata or {})
+
+    # Extract columns / dtypes
+    if isinstance(df, pl.DataFrame):
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+    else:  # pandas or pandas-like
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+
+    schema = {
+        "metadata": meta,
+        "columns": [],
+    }
+
+    for col, dtype in cols_and_dtypes:
+        tags: list[str] = []
+        if col in IDENTIFIER_COLUMNS:
+            tags.append("id")
+        if col in NFL_TARGET_COLUMNS:
+            tags.append("label")
+        if col.startswith("market_"):
+            tags.append("odds")
+        if col.startswith("injury_") or col.startswith("practice_"):
+            tags.append("injury")
+        if col.startswith("weather_"):
+            tags.append("weather")
+        if col.startswith("ps_"):
+            tags.append("pre_snap")
+        schema["columns"].append(
+            {
+                "name": col,
+                "dtype": dtype,
+                "banned": col in banned,
+                "tags": tags,
+            }
+        )
+    return schema
+
+
+def write_schema_snapshot(path, schema: Mapping[str, object]) -> None:
+    path.parent.mkdir(parents=True, exist_ok=True)
+    with open(path, "w") as fp:
+        json.dump(schema, fp, indent=2, sort_keys=True)
+
+
+__all__ = [
+    "DEFAULT_LEAK_POLICY",
+    "LeakPolicy",
+    "LeakCheckResult",
+    "evaluate_leak_prone_columns",
+    "enforce_leak_guard",
+    "build_schema_snapshot",
+    "write_schema_snapshot",
+]

file update:
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 5ba68e8bf1acd3a789a76a8857674e6f6433017b..0210d5b7e7ed60a8de7a126d64f5ed76326474c8
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -14,7 +14,7 @@
 
 import logging
 import os
-from datetime import date, timedelta
+from datetime import date, datetime, timedelta
 from typing import Sequence
 
 import polars as pl
@@ -37,6 +37,12 @@
     add_offense_context_features_training,
     _append_offense_context_columns,
 )
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    build_schema_snapshot,
+    enforce_leak_guard,
+    write_schema_snapshot,
+)
 from utils.feature.weather_features import (
     add_weather_forecast_features_training,
     append_weather_context_flags,
@@ -931,6 +937,32 @@
     if market_exprs:
         df_player_game_all = df_player_game_all.with_columns(market_exprs)
     
+    # Leak guard + schema snapshot before persisting
+    spec = get_label_spec(label_version)
+    allow_exact = {spec.primary, *spec.labels.keys(), *spec.aliases.keys()}
+    df_player_game_all, leak_result = enforce_leak_guard(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_exact=allow_exact,
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=True,
+    )
+
+    schema = build_schema_snapshot(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        metadata={
+            "cutoff_label": cutoff_label,
+            "label_version": spec.name,
+        },
+        banned=leak_result.banned,
+    )
+    schema_dir = FEATURE_AUDIT_DIR / "schema" / "anytime_td"
+    schema_path = schema_dir / f"{cutoff_label}_{datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')}.json"
+    write_schema_snapshot(schema_path, schema)
+    logging.info("    Schema snapshot written → %s", schema_path)
+
     # Write final feature matrix
     df_player_game_all = df_player_game_all.with_columns(
         pl.lit(current_cutoff_hours).cast(pl.Float32).alias("decision_horizon_hours")
@@ -951,7 +983,6 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    spec = get_label_spec(label_version)
     label_candidates = {spec.primary, "anytime_td"}
     for label_col in label_candidates:
         if label_col in df_player_game_all.columns:
diff --git a/pipeline/train.py b/pipeline/train.py
index fe70207dcdf25d209ee3ad55080b7ce826347c44..db24b7a473a82741febb827ac90b1cad36f1e466
--- a/pipeline/train.py
+++ b/pipeline/train.py
@@ -98,6 +98,7 @@
     fit_team_conformal_sums,
     composite_sum_interval,
 )
+from utils.feature.leak_guard import DEFAULT_LEAK_POLICY, enforce_leak_guard
 from utils.feature.targets import require_target_column
 
 # Ignore specific, noisy warnings from dependencies
diff --git a/utils/feature/leak_guard.py b/utils/feature/leak_guard.py
new file mode 100644
index 0000000000000000000000000000000000000000..9faf8cfffc436e0934b2f410aaf252e52f4f95df
--- /dev/null
+++ b/utils/feature/leak_guard.py
@@ -0,0 +1,273 @@
+"""Leak guardrails for feature matrices.
+
+This module centralizes pattern-based leak detection so both feature assembly
+and training can fail fast when post-outcome columns sneak into the data.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+from datetime import datetime
+import json
+import re
+from typing import Iterable, Mapping, Sequence
+
+import polars as pl
+
+from utils.general.constants import IDENTIFIER_COLUMNS, LEAK_PRONE_COLUMNS, NFL_TARGET_COLUMNS
+
+try:  # Optional dependency when imported from training (pandas path)
+    import pandas as pd  # type: ignore
+except Exception:  # pragma: no cover - optional dependency
+    pd = None
+
+
+@dataclass(frozen=True)
+class LeakPolicy:
+    version: str
+    banned_exact: set[str]
+    banned_prefixes: tuple[str, ...]
+    banned_suffixes: tuple[str, ...]
+    banned_regex: tuple[tuple[re.Pattern[str], str], ...]
+    description: str = ""
+
+
+@dataclass
+class LeakCheckResult:
+    policy_version: str
+    banned: dict[str, str]
+    kept: list[str]
+    dropped: list[str]
+    allowlist_kept: list[str]
+
+
+# Core policy tuned for anytime-TD style problems (can be extended per-problem).
+_BASE_BANNED_EXACT = set(LEAK_PRONE_COLUMNS) | {
+    "final_score",
+    "final_total",
+    "points_scored",
+    "actual_td_count",
+    "actual_anytime_td",
+    "postgame_anytime_td",
+    "postgame_td_count",
+}
+_BASE_BANNED_PREFIXES = (
+    "postgame_",
+    "post_game_",
+    "post_",
+    "live_",
+    "actual_",
+    "realized_",
+    "final_",
+    "postmatch_",
+)
+_BASE_BANNED_SUFFIXES = (
+    "_post",
+    "_postgame",
+    "_final",
+    "_fullgame",
+    "_actual",
+)
+_BASE_BANNED_REGEX: tuple[tuple[re.Pattern[str], str], ...] = (
+    (re.compile(r".*post.?game.*", flags=re.IGNORECASE), "postgame marker"),
+    (re.compile(r".*final_score.*", flags=re.IGNORECASE), "final score"),
+    (re.compile(r".*actual.*td.*", flags=re.IGNORECASE), "actual TD total"),
+    (re.compile(r".*anytime_td.*(post|final|actual).*", flags=re.IGNORECASE), "post-decision anytime TD"),
+    (re.compile(r".*fullgame.*", flags=re.IGNORECASE), "full game cumulative value"),
+)
+
+DEFAULT_LEAK_POLICY = LeakPolicy(
+    version="v1",
+    description="Core post-outcome leak guard for NFL anytime TD features.",
+    banned_exact=_BASE_BANNED_EXACT,
+    banned_prefixes=_BASE_BANNED_PREFIXES,
+    banned_suffixes=_BASE_BANNED_SUFFIXES,
+    banned_regex=_BASE_BANNED_REGEX,
+)
+
+
+def _ensure_sequence(value: Sequence[str] | str | None) -> tuple[str, ...]:
+    if value is None:
+        return ()
+    if isinstance(value, str):
+        return (value,)
+    return tuple(value)
+
+
+def evaluate_leak_prone_columns(
+    columns: Iterable[str],
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+) -> LeakCheckResult:
+    """Identify leak-prone columns using the configured policy."""
+
+    banned: dict[str, str] = {}
+    columns_list = list(columns)
+    for col in columns_list:
+        if col in policy.banned_exact:
+            banned[col] = "exact"
+            continue
+        for prefix in policy.banned_prefixes:
+            if col.startswith(prefix):
+                banned[col] = f"prefix:{prefix}"
+                break
+        if col in banned:
+            continue
+        for suffix in policy.banned_suffixes:
+            if col.endswith(suffix):
+                banned[col] = f"suffix:{suffix}"
+                break
+        if col in banned:
+            continue
+        for pattern, reason in policy.banned_regex:
+            if pattern.match(col):
+                banned[col] = reason
+                break
+
+    kept = [c for c in columns_list if c not in banned]
+    return LeakCheckResult(
+        policy_version=policy.version,
+        banned=banned,
+        kept=kept,
+        dropped=[],
+        allowlist_kept=[],
+    )
+
+
+def enforce_leak_guard(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    allow_prefixes: Sequence[str] | str | None = None,
+    allow_exact: Sequence[str] | str | None = None,
+    drop_banned: bool = True,
+    drop_non_allowlisted: bool = False,
+    raise_on_banned: bool = True,
+) -> tuple[pl.DataFrame | "pd.DataFrame", LeakCheckResult]:
+    """Apply leak guardrails to a feature frame.
+
+    Parameters
+    ----------
+    df : DataFrame
+        Polars or pandas DataFrame.
+    policy : LeakPolicy
+        Leak policy to apply.
+    allow_prefixes : Sequence[str] | str | None
+        Optional prefixes that define the allowed feature surface for a problem.
+    allow_exact : Sequence[str] | str | None
+        Explicitly allowed columns (e.g., identifiers).
+    drop_banned : bool
+        If True, drop any banned columns automatically.
+    drop_non_allowlisted : bool
+        If True, drop columns that are not covered by allow_prefixes/allow_exact/identifiers/targets.
+    raise_on_banned : bool
+        If True, raise when banned columns are detected (after optional drop).
+    """
+
+    result = evaluate_leak_prone_columns(df.columns, policy=policy)
+    dropped: list[str] = []
+
+    allow_prefixes = _ensure_sequence(allow_prefixes)
+    allow_exact = set(_ensure_sequence(allow_exact))
+    allow_exact.update({col for col in IDENTIFIER_COLUMNS if col in df.columns})
+    allow_exact.update({col for col in NFL_TARGET_COLUMNS if col in df.columns})
+
+    # Permit allowlisted columns even if they match a banned rule (e.g., labels)
+    banned = {col: reason for col, reason in result.banned.items() if col not in allow_exact}
+
+    if banned and drop_banned:
+        df = df.drop(list(banned.keys()))
+        dropped.extend(banned.keys())
+
+    if banned and raise_on_banned:
+        raise ValueError(f"Leak-prone columns detected: {sorted(banned.items())}")
+
+    allowlist_cols: set[str] = set()
+    if allow_prefixes:
+        allowlist_cols.update({c for c in df.columns if c.startswith(allow_prefixes)})
+    allowlist_cols.update({c for c in allow_exact if c in df.columns})
+
+    if drop_non_allowlisted and allowlist_cols:
+        drop_candidates = [c for c in df.columns if c not in allowlist_cols]
+        if drop_candidates:
+            df = df.drop(drop_candidates)
+            dropped.extend(drop_candidates)
+
+    if drop_non_allowlisted and not allowlist_cols:
+        raise ValueError("No allowlisted columns remain after applying leak guard allowlist.")
+
+    # Store adjusted banned info on the result
+    result.banned = banned
+    result.dropped = dropped
+    result.kept = [c for c in df.columns]
+    result.allowlist_kept = sorted(list(allowlist_cols)) if allowlist_cols else []
+    return df, result
+
+
+def build_schema_snapshot(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    metadata: Mapping[str, object] | None = None,
+    banned: Mapping[str, str] | None = None,
+) -> dict:
+    """Render a schema snapshot describing each column and whether it was flagged."""
+
+    banned = banned or {}
+    meta = {
+        "generated_at_utc": datetime.utcnow().isoformat(),
+        "policy_version": policy.version,
+    }
+    meta.update(metadata or {})
+
+    # Extract columns / dtypes
+    if isinstance(df, pl.DataFrame):
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+    else:  # pandas or pandas-like
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+
+    schema = {
+        "metadata": meta,
+        "columns": [],
+    }
+
+    for col, dtype in cols_and_dtypes:
+        tags: list[str] = []
+        if col in IDENTIFIER_COLUMNS:
+            tags.append("id")
+        if col in NFL_TARGET_COLUMNS:
+            tags.append("label")
+        if col.startswith("market_"):
+            tags.append("odds")
+        if col.startswith("injury_") or col.startswith("practice_"):
+            tags.append("injury")
+        if col.startswith("weather_"):
+            tags.append("weather")
+        if col.startswith("ps_"):
+            tags.append("pre_snap")
+        schema["columns"].append(
+            {
+                "name": col,
+                "dtype": dtype,
+                "banned": col in banned,
+                "tags": tags,
+            }
+        )
+    return schema
+
+
+def write_schema_snapshot(path, schema: Mapping[str, object]) -> None:
+    path.parent.mkdir(parents=True, exist_ok=True)
+    with open(path, "w") as fp:
+        json.dump(schema, fp, indent=2, sort_keys=True)
+
+
+__all__ = [
+    "DEFAULT_LEAK_POLICY",
+    "LeakPolicy",
+    "LeakCheckResult",
+    "evaluate_leak_prone_columns",
+    "enforce_leak_guard",
+    "build_schema_snapshot",
+    "write_schema_snapshot",
+]


thinking
**Planning leak guard integration**

I'm working out where to insert a leak guard during training—probably after problem-level overrides and normalization but before filtering null targets and splitting. The guard should check for banned columns without removing needed ones, raising errors if leaks are present, and allowing certain exact and prefix-based features like target and predictions. I'm considering config-driven allowances to balance safety with necessary data flow.

thinking
**Planning leak-guard enforcement patch**
file update
M /Users/jameswest/Desktop/nfl_predict/pipeline/train.py
@@ -2318,3 +2318,25 @@
                 df_problem = self._inject_composed_features(df_problem)
-            
+
+            # Leak guard on the problem-scoped frame
+            allow_prefixes = tuple(problem_copy.get('feature_prefixes_to_include') or [])
+            allow_exact = set(problem_copy.get('other_features_to_include') or [])
+            allow_exact.update(input_preds or [])
+            allow_exact.add(self.target_col)
+            df_problem, leak_info = enforce_leak_guard(
+                df_problem,
+                policy=DEFAULT_LEAK_POLICY,
+                allow_prefixes=allow_prefixes,
+                allow_exact=allow_exact,
+                drop_banned=True,
+                drop_non_allowlisted=False,
+                raise_on_banned=True,
+            )
+            if leak_info.dropped:
+                logger.info(
+                    "Dropped %d leak-prone columns for %s: %s",
+                    len(leak_info.dropped),
+                    problem_name,
+                    sorted(leak_info.dropped),
+                )
+
             self._normalize_datetime_like_columns(df_problem, problem_name)
apply_patch(auto_approved=true) exited 0 in 74ms:
Success. Updated the following files:
M pipeline/train.py
file update:
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 5ba68e8bf1acd3a789a76a8857674e6f6433017b..0210d5b7e7ed60a8de7a126d64f5ed76326474c8
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -14,7 +14,7 @@
 
 import logging
 import os
-from datetime import date, timedelta
+from datetime import date, datetime, timedelta
 from typing import Sequence
 
 import polars as pl
@@ -37,6 +37,12 @@
     add_offense_context_features_training,
     _append_offense_context_columns,
 )
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    build_schema_snapshot,
+    enforce_leak_guard,
+    write_schema_snapshot,
+)
 from utils.feature.weather_features import (
     add_weather_forecast_features_training,
     append_weather_context_flags,
@@ -931,6 +937,32 @@
     if market_exprs:
         df_player_game_all = df_player_game_all.with_columns(market_exprs)
     
+    # Leak guard + schema snapshot before persisting
+    spec = get_label_spec(label_version)
+    allow_exact = {spec.primary, *spec.labels.keys(), *spec.aliases.keys()}
+    df_player_game_all, leak_result = enforce_leak_guard(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_exact=allow_exact,
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=True,
+    )
+
+    schema = build_schema_snapshot(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        metadata={
+            "cutoff_label": cutoff_label,
+            "label_version": spec.name,
+        },
+        banned=leak_result.banned,
+    )
+    schema_dir = FEATURE_AUDIT_DIR / "schema" / "anytime_td"
+    schema_path = schema_dir / f"{cutoff_label}_{datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')}.json"
+    write_schema_snapshot(schema_path, schema)
+    logging.info("    Schema snapshot written → %s", schema_path)
+
     # Write final feature matrix
     df_player_game_all = df_player_game_all.with_columns(
         pl.lit(current_cutoff_hours).cast(pl.Float32).alias("decision_horizon_hours")
@@ -951,7 +983,6 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    spec = get_label_spec(label_version)
     label_candidates = {spec.primary, "anytime_td"}
     for label_col in label_candidates:
         if label_col in df_player_game_all.columns:
diff --git a/pipeline/train.py b/pipeline/train.py
index fe70207dcdf25d209ee3ad55080b7ce826347c44..86f60f9ad7fc0ced149a964cec33bdd637d5e060
--- a/pipeline/train.py
+++ b/pipeline/train.py
@@ -98,6 +98,7 @@
     fit_team_conformal_sums,
     composite_sum_interval,
 )
+from utils.feature.leak_guard import DEFAULT_LEAK_POLICY, enforce_leak_guard
 from utils.feature.targets import require_target_column
 
 # Ignore specific, noisy warnings from dependencies
@@ -2315,7 +2316,29 @@
                             df_problem[col] = df_problem[col].fillna(df_problem[col].mean())
 
                 df_problem = self._inject_composed_features(df_problem)
-            
+
+            # Leak guard on the problem-scoped frame
+            allow_prefixes = tuple(problem_copy.get('feature_prefixes_to_include') or [])
+            allow_exact = set(problem_copy.get('other_features_to_include') or [])
+            allow_exact.update(input_preds or [])
+            allow_exact.add(self.target_col)
+            df_problem, leak_info = enforce_leak_guard(
+                df_problem,
+                policy=DEFAULT_LEAK_POLICY,
+                allow_prefixes=allow_prefixes,
+                allow_exact=allow_exact,
+                drop_banned=True,
+                drop_non_allowlisted=False,
+                raise_on_banned=True,
+            )
+            if leak_info.dropped:
+                logger.info(
+                    "Dropped %d leak-prone columns for %s: %s",
+                    len(leak_info.dropped),
+                    problem_name,
+                    sorted(leak_info.dropped),
+                )
+
             self._normalize_datetime_like_columns(df_problem, problem_name)
             df_problem[self.time_col] = pd.to_datetime(df_problem[self.time_col])
             sort_cols = [self.time_col]
diff --git a/utils/feature/leak_guard.py b/utils/feature/leak_guard.py
new file mode 100644
index 0000000000000000000000000000000000000000..9faf8cfffc436e0934b2f410aaf252e52f4f95df
--- /dev/null
+++ b/utils/feature/leak_guard.py
@@ -0,0 +1,273 @@
+"""Leak guardrails for feature matrices.
+
+This module centralizes pattern-based leak detection so both feature assembly
+and training can fail fast when post-outcome columns sneak into the data.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+from datetime import datetime
+import json
+import re
+from typing import Iterable, Mapping, Sequence
+
+import polars as pl
+
+from utils.general.constants import IDENTIFIER_COLUMNS, LEAK_PRONE_COLUMNS, NFL_TARGET_COLUMNS
+
+try:  # Optional dependency when imported from training (pandas path)
+    import pandas as pd  # type: ignore
+except Exception:  # pragma: no cover - optional dependency
+    pd = None
+
+
+@dataclass(frozen=True)
+class LeakPolicy:
+    version: str
+    banned_exact: set[str]
+    banned_prefixes: tuple[str, ...]
+    banned_suffixes: tuple[str, ...]
+    banned_regex: tuple[tuple[re.Pattern[str], str], ...]
+    description: str = ""
+
+
+@dataclass
+class LeakCheckResult:
+    policy_version: str
+    banned: dict[str, str]
+    kept: list[str]
+    dropped: list[str]
+    allowlist_kept: list[str]
+
+
+# Core policy tuned for anytime-TD style problems (can be extended per-problem).
+_BASE_BANNED_EXACT = set(LEAK_PRONE_COLUMNS) | {
+    "final_score",
+    "final_total",
+    "points_scored",
+    "actual_td_count",
+    "actual_anytime_td",
+    "postgame_anytime_td",
+    "postgame_td_count",
+}
+_BASE_BANNED_PREFIXES = (
+    "postgame_",
+    "post_game_",
+    "post_",
+    "live_",
+    "actual_",
+    "realized_",
+    "final_",
+    "postmatch_",
+)
+_BASE_BANNED_SUFFIXES = (
+    "_post",
+    "_postgame",
+    "_final",
+    "_fullgame",
+    "_actual",
+)
+_BASE_BANNED_REGEX: tuple[tuple[re.Pattern[str], str], ...] = (
+    (re.compile(r".*post.?game.*", flags=re.IGNORECASE), "postgame marker"),
+    (re.compile(r".*final_score.*", flags=re.IGNORECASE), "final score"),
+    (re.compile(r".*actual.*td.*", flags=re.IGNORECASE), "actual TD total"),
+    (re.compile(r".*anytime_td.*(post|final|actual).*", flags=re.IGNORECASE), "post-decision anytime TD"),
+    (re.compile(r".*fullgame.*", flags=re.IGNORECASE), "full game cumulative value"),
+)
+
+DEFAULT_LEAK_POLICY = LeakPolicy(
+    version="v1",
+    description="Core post-outcome leak guard for NFL anytime TD features.",
+    banned_exact=_BASE_BANNED_EXACT,
+    banned_prefixes=_BASE_BANNED_PREFIXES,
+    banned_suffixes=_BASE_BANNED_SUFFIXES,
+    banned_regex=_BASE_BANNED_REGEX,
+)
+
+
+def _ensure_sequence(value: Sequence[str] | str | None) -> tuple[str, ...]:
+    if value is None:
+        return ()
+    if isinstance(value, str):
+        return (value,)
+    return tuple(value)
+
+
+def evaluate_leak_prone_columns(
+    columns: Iterable[str],
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+) -> LeakCheckResult:
+    """Identify leak-prone columns using the configured policy."""
+
+    banned: dict[str, str] = {}
+    columns_list = list(columns)
+    for col in columns_list:
+        if col in policy.banned_exact:
+            banned[col] = "exact"
+            continue
+        for prefix in policy.banned_prefixes:
+            if col.startswith(prefix):
+                banned[col] = f"prefix:{prefix}"
+                break
+        if col in banned:
+            continue
+        for suffix in policy.banned_suffixes:
+            if col.endswith(suffix):
+                banned[col] = f"suffix:{suffix}"
+                break
+        if col in banned:
+            continue
+        for pattern, reason in policy.banned_regex:
+            if pattern.match(col):
+                banned[col] = reason
+                break
+
+    kept = [c for c in columns_list if c not in banned]
+    return LeakCheckResult(
+        policy_version=policy.version,
+        banned=banned,
+        kept=kept,
+        dropped=[],
+        allowlist_kept=[],
+    )
+
+
+def enforce_leak_guard(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    allow_prefixes: Sequence[str] | str | None = None,
+    allow_exact: Sequence[str] | str | None = None,
+    drop_banned: bool = True,
+    drop_non_allowlisted: bool = False,
+    raise_on_banned: bool = True,
+) -> tuple[pl.DataFrame | "pd.DataFrame", LeakCheckResult]:
+    """Apply leak guardrails to a feature frame.
+
+    Parameters
+    ----------
+    df : DataFrame
+        Polars or pandas DataFrame.
+    policy : LeakPolicy
+        Leak policy to apply.
+    allow_prefixes : Sequence[str] | str | None
+        Optional prefixes that define the allowed feature surface for a problem.
+    allow_exact : Sequence[str] | str | None
+        Explicitly allowed columns (e.g., identifiers).
+    drop_banned : bool
+        If True, drop any banned columns automatically.
+    drop_non_allowlisted : bool
+        If True, drop columns that are not covered by allow_prefixes/allow_exact/identifiers/targets.
+    raise_on_banned : bool
+        If True, raise when banned columns are detected (after optional drop).
+    """
+
+    result = evaluate_leak_prone_columns(df.columns, policy=policy)
+    dropped: list[str] = []
+
+    allow_prefixes = _ensure_sequence(allow_prefixes)
+    allow_exact = set(_ensure_sequence(allow_exact))
+    allow_exact.update({col for col in IDENTIFIER_COLUMNS if col in df.columns})
+    allow_exact.update({col for col in NFL_TARGET_COLUMNS if col in df.columns})
+
+    # Permit allowlisted columns even if they match a banned rule (e.g., labels)
+    banned = {col: reason for col, reason in result.banned.items() if col not in allow_exact}
+
+    if banned and drop_banned:
+        df = df.drop(list(banned.keys()))
+        dropped.extend(banned.keys())
+
+    if banned and raise_on_banned:
+        raise ValueError(f"Leak-prone columns detected: {sorted(banned.items())}")
+
+    allowlist_cols: set[str] = set()
+    if allow_prefixes:
+        allowlist_cols.update({c for c in df.columns if c.startswith(allow_prefixes)})
+    allowlist_cols.update({c for c in allow_exact if c in df.columns})
+
+    if drop_non_allowlisted and allowlist_cols:
+        drop_candidates = [c for c in df.columns if c not in allowlist_cols]
+        if drop_candidates:
+            df = df.drop(drop_candidates)
+            dropped.extend(drop_candidates)
+
+    if drop_non_allowlisted and not allowlist_cols:
+        raise ValueError("No allowlisted columns remain after applying leak guard allowlist.")
+
+    # Store adjusted banned info on the result
+    result.banned = banned
+    result.dropped = dropped
+    result.kept = [c for c in df.columns]
+    result.allowlist_kept = sorted(list(allowlist_cols)) if allowlist_cols else []
+    return df, result
+
+
+def build_schema_snapshot(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    metadata: Mapping[str, object] | None = None,
+    banned: Mapping[str, str] | None = None,
+) -> dict:
+    """Render a schema snapshot describing each column and whether it was flagged."""
+
+    banned = banned or {}
+    meta = {
+        "generated_at_utc": datetime.utcnow().isoformat(),
+        "policy_version": policy.version,
+    }
+    meta.update(metadata or {})
+
+    # Extract columns / dtypes
+    if isinstance(df, pl.DataFrame):
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+    else:  # pandas or pandas-like
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+
+    schema = {
+        "metadata": meta,
+        "columns": [],
+    }
+
+    for col, dtype in cols_and_dtypes:
+        tags: list[str] = []
+        if col in IDENTIFIER_COLUMNS:
+            tags.append("id")
+        if col in NFL_TARGET_COLUMNS:
+            tags.append("label")
+        if col.startswith("market_"):
+            tags.append("odds")
+        if col.startswith("injury_") or col.startswith("practice_"):
+            tags.append("injury")
+        if col.startswith("weather_"):
+            tags.append("weather")
+        if col.startswith("ps_"):
+            tags.append("pre_snap")
+        schema["columns"].append(
+            {
+                "name": col,
+                "dtype": dtype,
+                "banned": col in banned,
+                "tags": tags,
+            }
+        )
+    return schema
+
+
+def write_schema_snapshot(path, schema: Mapping[str, object]) -> None:
+    path.parent.mkdir(parents=True, exist_ok=True)
+    with open(path, "w") as fp:
+        json.dump(schema, fp, indent=2, sort_keys=True)
+
+
+__all__ = [
+    "DEFAULT_LEAK_POLICY",
+    "LeakPolicy",
+    "LeakCheckResult",
+    "evaluate_leak_prone_columns",
+    "enforce_leak_guard",
+    "build_schema_snapshot",
+    "write_schema_snapshot",
+]

file update:
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 5ba68e8bf1acd3a789a76a8857674e6f6433017b..0210d5b7e7ed60a8de7a126d64f5ed76326474c8
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -14,7 +14,7 @@
 
 import logging
 import os
-from datetime import date, timedelta
+from datetime import date, datetime, timedelta
 from typing import Sequence
 
 import polars as pl
@@ -37,6 +37,12 @@
     add_offense_context_features_training,
     _append_offense_context_columns,
 )
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    build_schema_snapshot,
+    enforce_leak_guard,
+    write_schema_snapshot,
+)
 from utils.feature.weather_features import (
     add_weather_forecast_features_training,
     append_weather_context_flags,
@@ -931,6 +937,32 @@
     if market_exprs:
         df_player_game_all = df_player_game_all.with_columns(market_exprs)
     
+    # Leak guard + schema snapshot before persisting
+    spec = get_label_spec(label_version)
+    allow_exact = {spec.primary, *spec.labels.keys(), *spec.aliases.keys()}
+    df_player_game_all, leak_result = enforce_leak_guard(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_exact=allow_exact,
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=True,
+    )
+
+    schema = build_schema_snapshot(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        metadata={
+            "cutoff_label": cutoff_label,
+            "label_version": spec.name,
+        },
+        banned=leak_result.banned,
+    )
+    schema_dir = FEATURE_AUDIT_DIR / "schema" / "anytime_td"
+    schema_path = schema_dir / f"{cutoff_label}_{datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')}.json"
+    write_schema_snapshot(schema_path, schema)
+    logging.info("    Schema snapshot written → %s", schema_path)
+
     # Write final feature matrix
     df_player_game_all = df_player_game_all.with_columns(
         pl.lit(current_cutoff_hours).cast(pl.Float32).alias("decision_horizon_hours")
@@ -951,7 +983,6 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    spec = get_label_spec(label_version)
     label_candidates = {spec.primary, "anytime_td"}
     for label_col in label_candidates:
         if label_col in df_player_game_all.columns:
diff --git a/pipeline/train.py b/pipeline/train.py
index fe70207dcdf25d209ee3ad55080b7ce826347c44..86f60f9ad7fc0ced149a964cec33bdd637d5e060
--- a/pipeline/train.py
+++ b/pipeline/train.py
@@ -98,6 +98,7 @@
     fit_team_conformal_sums,
     composite_sum_interval,
 )
+from utils.feature.leak_guard import DEFAULT_LEAK_POLICY, enforce_leak_guard
 from utils.feature.targets import require_target_column
 
 # Ignore specific, noisy warnings from dependencies
@@ -2315,7 +2316,29 @@
                             df_problem[col] = df_problem[col].fillna(df_problem[col].mean())
 
                 df_problem = self._inject_composed_features(df_problem)
-            
+
+            # Leak guard on the problem-scoped frame
+            allow_prefixes = tuple(problem_copy.get('feature_prefixes_to_include') or [])
+            allow_exact = set(problem_copy.get('other_features_to_include') or [])
+            allow_exact.update(input_preds or [])
+            allow_exact.add(self.target_col)
+            df_problem, leak_info = enforce_leak_guard(
+                df_problem,
+                policy=DEFAULT_LEAK_POLICY,
+                allow_prefixes=allow_prefixes,
+                allow_exact=allow_exact,
+                drop_banned=True,
+                drop_non_allowlisted=False,
+                raise_on_banned=True,
+            )
+            if leak_info.dropped:
+                logger.info(
+                    "Dropped %d leak-prone columns for %s: %s",
+                    len(leak_info.dropped),
+                    problem_name,
+                    sorted(leak_info.dropped),
+                )
+
             self._normalize_datetime_like_columns(df_problem, problem_name)
             df_problem[self.time_col] = pd.to_datetime(df_problem[self.time_col])
             sort_cols = [self.time_col]
diff --git a/utils/feature/leak_guard.py b/utils/feature/leak_guard.py
new file mode 100644
index 0000000000000000000000000000000000000000..9faf8cfffc436e0934b2f410aaf252e52f4f95df
--- /dev/null
+++ b/utils/feature/leak_guard.py
@@ -0,0 +1,273 @@
+"""Leak guardrails for feature matrices.
+
+This module centralizes pattern-based leak detection so both feature assembly
+and training can fail fast when post-outcome columns sneak into the data.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+from datetime import datetime
+import json
+import re
+from typing import Iterable, Mapping, Sequence
+
+import polars as pl
+
+from utils.general.constants import IDENTIFIER_COLUMNS, LEAK_PRONE_COLUMNS, NFL_TARGET_COLUMNS
+
+try:  # Optional dependency when imported from training (pandas path)
+    import pandas as pd  # type: ignore
+except Exception:  # pragma: no cover - optional dependency
+    pd = None
+
+
+@dataclass(frozen=True)
+class LeakPolicy:
+    version: str
+    banned_exact: set[str]
+    banned_prefixes: tuple[str, ...]
+    banned_suffixes: tuple[str, ...]
+    banned_regex: tuple[tuple[re.Pattern[str], str], ...]
+    description: str = ""
+
+
+@dataclass
+class LeakCheckResult:
+    policy_version: str
+    banned: dict[str, str]
+    kept: list[str]
+    dropped: list[str]
+    allowlist_kept: list[str]
+
+
+# Core policy tuned for anytime-TD style problems (can be extended per-problem).
+_BASE_BANNED_EXACT = set(LEAK_PRONE_COLUMNS) | {
+    "final_score",
+    "final_total",
+    "points_scored",
+    "actual_td_count",
+    "actual_anytime_td",
+    "postgame_anytime_td",
+    "postgame_td_count",
+}
+_BASE_BANNED_PREFIXES = (
+    "postgame_",
+    "post_game_",
+    "post_",
+    "live_",
+    "actual_",
+    "realized_",
+    "final_",
+    "postmatch_",
+)
+_BASE_BANNED_SUFFIXES = (
+    "_post",
+    "_postgame",
+    "_final",
+    "_fullgame",
+    "_actual",
+)
+_BASE_BANNED_REGEX: tuple[tuple[re.Pattern[str], str], ...] = (
+    (re.compile(r".*post.?game.*", flags=re.IGNORECASE), "postgame marker"),
+    (re.compile(r".*final_score.*", flags=re.IGNORECASE), "final score"),
+    (re.compile(r".*actual.*td.*", flags=re.IGNORECASE), "actual TD total"),
+    (re.compile(r".*anytime_td.*(post|final|actual).*", flags=re.IGNORECASE), "post-decision anytime TD"),
+    (re.compile(r".*fullgame.*", flags=re.IGNORECASE), "full game cumulative value"),
+)
+
+DEFAULT_LEAK_POLICY = LeakPolicy(
+    version="v1",
+    description="Core post-outcome leak guard for NFL anytime TD features.",
+    banned_exact=_BASE_BANNED_EXACT,
+    banned_prefixes=_BASE_BANNED_PREFIXES,
+    banned_suffixes=_BASE_BANNED_SUFFIXES,
+    banned_regex=_BASE_BANNED_REGEX,
+)
+
+
+def _ensure_sequence(value: Sequence[str] | str | None) -> tuple[str, ...]:
+    if value is None:
+        return ()
+    if isinstance(value, str):
+        return (value,)
+    return tuple(value)
+
+
+def evaluate_leak_prone_columns(
+    columns: Iterable[str],
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+) -> LeakCheckResult:
+    """Identify leak-prone columns using the configured policy."""
+
+    banned: dict[str, str] = {}
+    columns_list = list(columns)
+    for col in columns_list:
+        if col in policy.banned_exact:
+            banned[col] = "exact"
+            continue
+        for prefix in policy.banned_prefixes:
+            if col.startswith(prefix):
+                banned[col] = f"prefix:{prefix}"
+                break
+        if col in banned:
+            continue
+        for suffix in policy.banned_suffixes:
+            if col.endswith(suffix):
+                banned[col] = f"suffix:{suffix}"
+                break
+        if col in banned:
+            continue
+        for pattern, reason in policy.banned_regex:
+            if pattern.match(col):
+                banned[col] = reason
+                break
+
+    kept = [c for c in columns_list if c not in banned]
+    return LeakCheckResult(
+        policy_version=policy.version,
+        banned=banned,
+        kept=kept,
+        dropped=[],
+        allowlist_kept=[],
+    )
+
+
+def enforce_leak_guard(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    allow_prefixes: Sequence[str] | str | None = None,
+    allow_exact: Sequence[str] | str | None = None,
+    drop_banned: bool = True,
+    drop_non_allowlisted: bool = False,
+    raise_on_banned: bool = True,
+) -> tuple[pl.DataFrame | "pd.DataFrame", LeakCheckResult]:
+    """Apply leak guardrails to a feature frame.
+
+    Parameters
+    ----------
+    df : DataFrame
+        Polars or pandas DataFrame.
+    policy : LeakPolicy
+        Leak policy to apply.
+    allow_prefixes : Sequence[str] | str | None
+        Optional prefixes that define the allowed feature surface for a problem.
+    allow_exact : Sequence[str] | str | None
+        Explicitly allowed columns (e.g., identifiers).
+    drop_banned : bool
+        If True, drop any banned columns automatically.
+    drop_non_allowlisted : bool
+        If True, drop columns that are not covered by allow_prefixes/allow_exact/identifiers/targets.
+    raise_on_banned : bool
+        If True, raise when banned columns are detected (after optional drop).
+    """
+
+    result = evaluate_leak_prone_columns(df.columns, policy=policy)
+    dropped: list[str] = []
+
+    allow_prefixes = _ensure_sequence(allow_prefixes)
+    allow_exact = set(_ensure_sequence(allow_exact))
+    allow_exact.update({col for col in IDENTIFIER_COLUMNS if col in df.columns})
+    allow_exact.update({col for col in NFL_TARGET_COLUMNS if col in df.columns})
+
+    # Permit allowlisted columns even if they match a banned rule (e.g., labels)
+    banned = {col: reason for col, reason in result.banned.items() if col not in allow_exact}
+
+    if banned and drop_banned:
+        df = df.drop(list(banned.keys()))
+        dropped.extend(banned.keys())
+
+    if banned and raise_on_banned:
+        raise ValueError(f"Leak-prone columns detected: {sorted(banned.items())}")
+
+    allowlist_cols: set[str] = set()
+    if allow_prefixes:
+        allowlist_cols.update({c for c in df.columns if c.startswith(allow_prefixes)})
+    allowlist_cols.update({c for c in allow_exact if c in df.columns})
+
+    if drop_non_allowlisted and allowlist_cols:
+        drop_candidates = [c for c in df.columns if c not in allowlist_cols]
+        if drop_candidates:
+            df = df.drop(drop_candidates)
+            dropped.extend(drop_candidates)
+
+    if drop_non_allowlisted and not allowlist_cols:
+        raise ValueError("No allowlisted columns remain after applying leak guard allowlist.")
+
+    # Store adjusted banned info on the result
+    result.banned = banned
+    result.dropped = dropped
+    result.kept = [c for c in df.columns]
+    result.allowlist_kept = sorted(list(allowlist_cols)) if allowlist_cols else []
+    return df, result
+
+
+def build_schema_snapshot(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    metadata: Mapping[str, object] | None = None,
+    banned: Mapping[str, str] | None = None,
+) -> dict:
+    """Render a schema snapshot describing each column and whether it was flagged."""
+
+    banned = banned or {}
+    meta = {
+        "generated_at_utc": datetime.utcnow().isoformat(),
+        "policy_version": policy.version,
+    }
+    meta.update(metadata or {})
+
+    # Extract columns / dtypes
+    if isinstance(df, pl.DataFrame):
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+    else:  # pandas or pandas-like
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+
+    schema = {
+        "metadata": meta,
+        "columns": [],
+    }
+
+    for col, dtype in cols_and_dtypes:
+        tags: list[str] = []
+        if col in IDENTIFIER_COLUMNS:
+            tags.append("id")
+        if col in NFL_TARGET_COLUMNS:
+            tags.append("label")
+        if col.startswith("market_"):
+            tags.append("odds")
+        if col.startswith("injury_") or col.startswith("practice_"):
+            tags.append("injury")
+        if col.startswith("weather_"):
+            tags.append("weather")
+        if col.startswith("ps_"):
+            tags.append("pre_snap")
+        schema["columns"].append(
+            {
+                "name": col,
+                "dtype": dtype,
+                "banned": col in banned,
+                "tags": tags,
+            }
+        )
+    return schema
+
+
+def write_schema_snapshot(path, schema: Mapping[str, object]) -> None:
+    path.parent.mkdir(parents=True, exist_ok=True)
+    with open(path, "w") as fp:
+        json.dump(schema, fp, indent=2, sort_keys=True)
+
+
+__all__ = [
+    "DEFAULT_LEAK_POLICY",
+    "LeakPolicy",
+    "LeakCheckResult",
+    "evaluate_leak_prone_columns",
+    "enforce_leak_guard",
+    "build_schema_snapshot",
+    "write_schema_snapshot",
+]


thinking
**Ensuring predicate column handling**
file update
M /Users/jameswest/Desktop/nfl_predict/pipeline/train.py
@@ -2323,3 +2323,4 @@
             allow_exact.update(input_preds or [])
-            allow_exact.add(self.target_col)
+            if self.target_col:
+                allow_exact.add(self.target_col)
             df_problem, leak_info = enforce_leak_guard(
apply_patch(auto_approved=true) exited 0 in 50ms:
Success. Updated the following files:
M pipeline/train.py
file update:
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 5ba68e8bf1acd3a789a76a8857674e6f6433017b..0210d5b7e7ed60a8de7a126d64f5ed76326474c8
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -14,7 +14,7 @@
 
 import logging
 import os
-from datetime import date, timedelta
+from datetime import date, datetime, timedelta
 from typing import Sequence
 
 import polars as pl
@@ -37,6 +37,12 @@
     add_offense_context_features_training,
     _append_offense_context_columns,
 )
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    build_schema_snapshot,
+    enforce_leak_guard,
+    write_schema_snapshot,
+)
 from utils.feature.weather_features import (
     add_weather_forecast_features_training,
     append_weather_context_flags,
@@ -931,6 +937,32 @@
     if market_exprs:
         df_player_game_all = df_player_game_all.with_columns(market_exprs)
     
+    # Leak guard + schema snapshot before persisting
+    spec = get_label_spec(label_version)
+    allow_exact = {spec.primary, *spec.labels.keys(), *spec.aliases.keys()}
+    df_player_game_all, leak_result = enforce_leak_guard(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_exact=allow_exact,
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=True,
+    )
+
+    schema = build_schema_snapshot(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        metadata={
+            "cutoff_label": cutoff_label,
+            "label_version": spec.name,
+        },
+        banned=leak_result.banned,
+    )
+    schema_dir = FEATURE_AUDIT_DIR / "schema" / "anytime_td"
+    schema_path = schema_dir / f"{cutoff_label}_{datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')}.json"
+    write_schema_snapshot(schema_path, schema)
+    logging.info("    Schema snapshot written → %s", schema_path)
+
     # Write final feature matrix
     df_player_game_all = df_player_game_all.with_columns(
         pl.lit(current_cutoff_hours).cast(pl.Float32).alias("decision_horizon_hours")
@@ -951,7 +983,6 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    spec = get_label_spec(label_version)
     label_candidates = {spec.primary, "anytime_td"}
     for label_col in label_candidates:
         if label_col in df_player_game_all.columns:
diff --git a/pipeline/train.py b/pipeline/train.py
index fe70207dcdf25d209ee3ad55080b7ce826347c44..3fab3a05b3f65e8d0e88ec1ddaa71a8857646148
--- a/pipeline/train.py
+++ b/pipeline/train.py
@@ -98,6 +98,7 @@
     fit_team_conformal_sums,
     composite_sum_interval,
 )
+from utils.feature.leak_guard import DEFAULT_LEAK_POLICY, enforce_leak_guard
 from utils.feature.targets import require_target_column
 
 # Ignore specific, noisy warnings from dependencies
@@ -2315,7 +2316,30 @@
                             df_problem[col] = df_problem[col].fillna(df_problem[col].mean())
 
                 df_problem = self._inject_composed_features(df_problem)
-            
+
+            # Leak guard on the problem-scoped frame
+            allow_prefixes = tuple(problem_copy.get('feature_prefixes_to_include') or [])
+            allow_exact = set(problem_copy.get('other_features_to_include') or [])
+            allow_exact.update(input_preds or [])
+            if self.target_col:
+                allow_exact.add(self.target_col)
+            df_problem, leak_info = enforce_leak_guard(
+                df_problem,
+                policy=DEFAULT_LEAK_POLICY,
+                allow_prefixes=allow_prefixes,
+                allow_exact=allow_exact,
+                drop_banned=True,
+                drop_non_allowlisted=False,
+                raise_on_banned=True,
+            )
+            if leak_info.dropped:
+                logger.info(
+                    "Dropped %d leak-prone columns for %s: %s",
+                    len(leak_info.dropped),
+                    problem_name,
+                    sorted(leak_info.dropped),
+                )
+
             self._normalize_datetime_like_columns(df_problem, problem_name)
             df_problem[self.time_col] = pd.to_datetime(df_problem[self.time_col])
             sort_cols = [self.time_col]
diff --git a/utils/feature/leak_guard.py b/utils/feature/leak_guard.py
new file mode 100644
index 0000000000000000000000000000000000000000..9faf8cfffc436e0934b2f410aaf252e52f4f95df
--- /dev/null
+++ b/utils/feature/leak_guard.py
@@ -0,0 +1,273 @@
+"""Leak guardrails for feature matrices.
+
+This module centralizes pattern-based leak detection so both feature assembly
+and training can fail fast when post-outcome columns sneak into the data.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+from datetime import datetime
+import json
+import re
+from typing import Iterable, Mapping, Sequence
+
+import polars as pl
+
+from utils.general.constants import IDENTIFIER_COLUMNS, LEAK_PRONE_COLUMNS, NFL_TARGET_COLUMNS
+
+try:  # Optional dependency when imported from training (pandas path)
+    import pandas as pd  # type: ignore
+except Exception:  # pragma: no cover - optional dependency
+    pd = None
+
+
+@dataclass(frozen=True)
+class LeakPolicy:
+    version: str
+    banned_exact: set[str]
+    banned_prefixes: tuple[str, ...]
+    banned_suffixes: tuple[str, ...]
+    banned_regex: tuple[tuple[re.Pattern[str], str], ...]
+    description: str = ""
+
+
+@dataclass
+class LeakCheckResult:
+    policy_version: str
+    banned: dict[str, str]
+    kept: list[str]
+    dropped: list[str]
+    allowlist_kept: list[str]
+
+
+# Core policy tuned for anytime-TD style problems (can be extended per-problem).
+_BASE_BANNED_EXACT = set(LEAK_PRONE_COLUMNS) | {
+    "final_score",
+    "final_total",
+    "points_scored",
+    "actual_td_count",
+    "actual_anytime_td",
+    "postgame_anytime_td",
+    "postgame_td_count",
+}
+_BASE_BANNED_PREFIXES = (
+    "postgame_",
+    "post_game_",
+    "post_",
+    "live_",
+    "actual_",
+    "realized_",
+    "final_",
+    "postmatch_",
+)
+_BASE_BANNED_SUFFIXES = (
+    "_post",
+    "_postgame",
+    "_final",
+    "_fullgame",
+    "_actual",
+)
+_BASE_BANNED_REGEX: tuple[tuple[re.Pattern[str], str], ...] = (
+    (re.compile(r".*post.?game.*", flags=re.IGNORECASE), "postgame marker"),
+    (re.compile(r".*final_score.*", flags=re.IGNORECASE), "final score"),
+    (re.compile(r".*actual.*td.*", flags=re.IGNORECASE), "actual TD total"),
+    (re.compile(r".*anytime_td.*(post|final|actual).*", flags=re.IGNORECASE), "post-decision anytime TD"),
+    (re.compile(r".*fullgame.*", flags=re.IGNORECASE), "full game cumulative value"),
+)
+
+DEFAULT_LEAK_POLICY = LeakPolicy(
+    version="v1",
+    description="Core post-outcome leak guard for NFL anytime TD features.",
+    banned_exact=_BASE_BANNED_EXACT,
+    banned_prefixes=_BASE_BANNED_PREFIXES,
+    banned_suffixes=_BASE_BANNED_SUFFIXES,
+    banned_regex=_BASE_BANNED_REGEX,
+)
+
+
+def _ensure_sequence(value: Sequence[str] | str | None) -> tuple[str, ...]:
+    if value is None:
+        return ()
+    if isinstance(value, str):
+        return (value,)
+    return tuple(value)
+
+
+def evaluate_leak_prone_columns(
+    columns: Iterable[str],
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+) -> LeakCheckResult:
+    """Identify leak-prone columns using the configured policy."""
+
+    banned: dict[str, str] = {}
+    columns_list = list(columns)
+    for col in columns_list:
+        if col in policy.banned_exact:
+            banned[col] = "exact"
+            continue
+        for prefix in policy.banned_prefixes:
+            if col.startswith(prefix):
+                banned[col] = f"prefix:{prefix}"
+                break
+        if col in banned:
+            continue
+        for suffix in policy.banned_suffixes:
+            if col.endswith(suffix):
+                banned[col] = f"suffix:{suffix}"
+                break
+        if col in banned:
+            continue
+        for pattern, reason in policy.banned_regex:
+            if pattern.match(col):
+                banned[col] = reason
+                break
+
+    kept = [c for c in columns_list if c not in banned]
+    return LeakCheckResult(
+        policy_version=policy.version,
+        banned=banned,
+        kept=kept,
+        dropped=[],
+        allowlist_kept=[],
+    )
+
+
+def enforce_leak_guard(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    allow_prefixes: Sequence[str] | str | None = None,
+    allow_exact: Sequence[str] | str | None = None,
+    drop_banned: bool = True,
+    drop_non_allowlisted: bool = False,
+    raise_on_banned: bool = True,
+) -> tuple[pl.DataFrame | "pd.DataFrame", LeakCheckResult]:
+    """Apply leak guardrails to a feature frame.
+
+    Parameters
+    ----------
+    df : DataFrame
+        Polars or pandas DataFrame.
+    policy : LeakPolicy
+        Leak policy to apply.
+    allow_prefixes : Sequence[str] | str | None
+        Optional prefixes that define the allowed feature surface for a problem.
+    allow_exact : Sequence[str] | str | None
+        Explicitly allowed columns (e.g., identifiers).
+    drop_banned : bool
+        If True, drop any banned columns automatically.
+    drop_non_allowlisted : bool
+        If True, drop columns that are not covered by allow_prefixes/allow_exact/identifiers/targets.
+    raise_on_banned : bool
+        If True, raise when banned columns are detected (after optional drop).
+    """
+
+    result = evaluate_leak_prone_columns(df.columns, policy=policy)
+    dropped: list[str] = []
+
+    allow_prefixes = _ensure_sequence(allow_prefixes)
+    allow_exact = set(_ensure_sequence(allow_exact))
+    allow_exact.update({col for col in IDENTIFIER_COLUMNS if col in df.columns})
+    allow_exact.update({col for col in NFL_TARGET_COLUMNS if col in df.columns})
+
+    # Permit allowlisted columns even if they match a banned rule (e.g., labels)
+    banned = {col: reason for col, reason in result.banned.items() if col not in allow_exact}
+
+    if banned and drop_banned:
+        df = df.drop(list(banned.keys()))
+        dropped.extend(banned.keys())
+
+    if banned and raise_on_banned:
+        raise ValueError(f"Leak-prone columns detected: {sorted(banned.items())}")
+
+    allowlist_cols: set[str] = set()
+    if allow_prefixes:
+        allowlist_cols.update({c for c in df.columns if c.startswith(allow_prefixes)})
+    allowlist_cols.update({c for c in allow_exact if c in df.columns})
+
+    if drop_non_allowlisted and allowlist_cols:
+        drop_candidates = [c for c in df.columns if c not in allowlist_cols]
+        if drop_candidates:
+            df = df.drop(drop_candidates)
+            dropped.extend(drop_candidates)
+
+    if drop_non_allowlisted and not allowlist_cols:
+        raise ValueError("No allowlisted columns remain after applying leak guard allowlist.")
+
+    # Store adjusted banned info on the result
+    result.banned = banned
+    result.dropped = dropped
+    result.kept = [c for c in df.columns]
+    result.allowlist_kept = sorted(list(allowlist_cols)) if allowlist_cols else []
+    return df, result
+
+
+def build_schema_snapshot(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    metadata: Mapping[str, object] | None = None,
+    banned: Mapping[str, str] | None = None,
+) -> dict:
+    """Render a schema snapshot describing each column and whether it was flagged."""
+
+    banned = banned or {}
+    meta = {
+        "generated_at_utc": datetime.utcnow().isoformat(),
+        "policy_version": policy.version,
+    }
+    meta.update(metadata or {})
+
+    # Extract columns / dtypes
+    if isinstance(df, pl.DataFrame):
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+    else:  # pandas or pandas-like
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+
+    schema = {
+        "metadata": meta,
+        "columns": [],
+    }
+
+    for col, dtype in cols_and_dtypes:
+        tags: list[str] = []
+        if col in IDENTIFIER_COLUMNS:
+            tags.append("id")
+        if col in NFL_TARGET_COLUMNS:
+            tags.append("label")
+        if col.startswith("market_"):
+            tags.append("odds")
+        if col.startswith("injury_") or col.startswith("practice_"):
+            tags.append("injury")
+        if col.startswith("weather_"):
+            tags.append("weather")
+        if col.startswith("ps_"):
+            tags.append("pre_snap")
+        schema["columns"].append(
+            {
+                "name": col,
+                "dtype": dtype,
+                "banned": col in banned,
+                "tags": tags,
+            }
+        )
+    return schema
+
+
+def write_schema_snapshot(path, schema: Mapping[str, object]) -> None:
+    path.parent.mkdir(parents=True, exist_ok=True)
+    with open(path, "w") as fp:
+        json.dump(schema, fp, indent=2, sort_keys=True)
+
+
+__all__ = [
+    "DEFAULT_LEAK_POLICY",
+    "LeakPolicy",
+    "LeakCheckResult",
+    "evaluate_leak_prone_columns",
+    "enforce_leak_guard",
+    "build_schema_snapshot",
+    "write_schema_snapshot",
+]

file update:
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 5ba68e8bf1acd3a789a76a8857674e6f6433017b..0210d5b7e7ed60a8de7a126d64f5ed76326474c8
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -14,7 +14,7 @@
 
 import logging
 import os
-from datetime import date, timedelta
+from datetime import date, datetime, timedelta
 from typing import Sequence
 
 import polars as pl
@@ -37,6 +37,12 @@
     add_offense_context_features_training,
     _append_offense_context_columns,
 )
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    build_schema_snapshot,
+    enforce_leak_guard,
+    write_schema_snapshot,
+)
 from utils.feature.weather_features import (
     add_weather_forecast_features_training,
     append_weather_context_flags,
@@ -931,6 +937,32 @@
     if market_exprs:
         df_player_game_all = df_player_game_all.with_columns(market_exprs)
     
+    # Leak guard + schema snapshot before persisting
+    spec = get_label_spec(label_version)
+    allow_exact = {spec.primary, *spec.labels.keys(), *spec.aliases.keys()}
+    df_player_game_all, leak_result = enforce_leak_guard(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_exact=allow_exact,
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=True,
+    )
+
+    schema = build_schema_snapshot(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        metadata={
+            "cutoff_label": cutoff_label,
+            "label_version": spec.name,
+        },
+        banned=leak_result.banned,
+    )
+    schema_dir = FEATURE_AUDIT_DIR / "schema" / "anytime_td"
+    schema_path = schema_dir / f"{cutoff_label}_{datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')}.json"
+    write_schema_snapshot(schema_path, schema)
+    logging.info("    Schema snapshot written → %s", schema_path)
+
     # Write final feature matrix
     df_player_game_all = df_player_game_all.with_columns(
         pl.lit(current_cutoff_hours).cast(pl.Float32).alias("decision_horizon_hours")
@@ -951,7 +983,6 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    spec = get_label_spec(label_version)
     label_candidates = {spec.primary, "anytime_td"}
     for label_col in label_candidates:
         if label_col in df_player_game_all.columns:
diff --git a/pipeline/train.py b/pipeline/train.py
index fe70207dcdf25d209ee3ad55080b7ce826347c44..3fab3a05b3f65e8d0e88ec1ddaa71a8857646148
--- a/pipeline/train.py
+++ b/pipeline/train.py
@@ -98,6 +98,7 @@
     fit_team_conformal_sums,
     composite_sum_interval,
 )
+from utils.feature.leak_guard import DEFAULT_LEAK_POLICY, enforce_leak_guard
 from utils.feature.targets import require_target_column
 
 # Ignore specific, noisy warnings from dependencies
@@ -2315,7 +2316,30 @@
                             df_problem[col] = df_problem[col].fillna(df_problem[col].mean())
 
                 df_problem = self._inject_composed_features(df_problem)
-            
+
+            # Leak guard on the problem-scoped frame
+            allow_prefixes = tuple(problem_copy.get('feature_prefixes_to_include') or [])
+            allow_exact = set(problem_copy.get('other_features_to_include') or [])
+            allow_exact.update(input_preds or [])
+            if self.target_col:
+                allow_exact.add(self.target_col)
+            df_problem, leak_info = enforce_leak_guard(
+                df_problem,
+                policy=DEFAULT_LEAK_POLICY,
+                allow_prefixes=allow_prefixes,
+                allow_exact=allow_exact,
+                drop_banned=True,
+                drop_non_allowlisted=False,
+                raise_on_banned=True,
+            )
+            if leak_info.dropped:
+                logger.info(
+                    "Dropped %d leak-prone columns for %s: %s",
+                    len(leak_info.dropped),
+                    problem_name,
+                    sorted(leak_info.dropped),
+                )
+
             self._normalize_datetime_like_columns(df_problem, problem_name)
             df_problem[self.time_col] = pd.to_datetime(df_problem[self.time_col])
             sort_cols = [self.time_col]
diff --git a/utils/feature/leak_guard.py b/utils/feature/leak_guard.py
new file mode 100644
index 0000000000000000000000000000000000000000..9faf8cfffc436e0934b2f410aaf252e52f4f95df
--- /dev/null
+++ b/utils/feature/leak_guard.py
@@ -0,0 +1,273 @@
+"""Leak guardrails for feature matrices.
+
+This module centralizes pattern-based leak detection so both feature assembly
+and training can fail fast when post-outcome columns sneak into the data.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+from datetime import datetime
+import json
+import re
+from typing import Iterable, Mapping, Sequence
+
+import polars as pl
+
+from utils.general.constants import IDENTIFIER_COLUMNS, LEAK_PRONE_COLUMNS, NFL_TARGET_COLUMNS
+
+try:  # Optional dependency when imported from training (pandas path)
+    import pandas as pd  # type: ignore
+except Exception:  # pragma: no cover - optional dependency
+    pd = None
+
+
+@dataclass(frozen=True)
+class LeakPolicy:
+    version: str
+    banned_exact: set[str]
+    banned_prefixes: tuple[str, ...]
+    banned_suffixes: tuple[str, ...]
+    banned_regex: tuple[tuple[re.Pattern[str], str], ...]
+    description: str = ""
+
+
+@dataclass
+class LeakCheckResult:
+    policy_version: str
+    banned: dict[str, str]
+    kept: list[str]
+    dropped: list[str]
+    allowlist_kept: list[str]
+
+
+# Core policy tuned for anytime-TD style problems (can be extended per-problem).
+_BASE_BANNED_EXACT = set(LEAK_PRONE_COLUMNS) | {
+    "final_score",
+    "final_total",
+    "points_scored",
+    "actual_td_count",
+    "actual_anytime_td",
+    "postgame_anytime_td",
+    "postgame_td_count",
+}
+_BASE_BANNED_PREFIXES = (
+    "postgame_",
+    "post_game_",
+    "post_",
+    "live_",
+    "actual_",
+    "realized_",
+    "final_",
+    "postmatch_",
+)
+_BASE_BANNED_SUFFIXES = (
+    "_post",
+    "_postgame",
+    "_final",
+    "_fullgame",
+    "_actual",
+)
+_BASE_BANNED_REGEX: tuple[tuple[re.Pattern[str], str], ...] = (
+    (re.compile(r".*post.?game.*", flags=re.IGNORECASE), "postgame marker"),
+    (re.compile(r".*final_score.*", flags=re.IGNORECASE), "final score"),
+    (re.compile(r".*actual.*td.*", flags=re.IGNORECASE), "actual TD total"),
+    (re.compile(r".*anytime_td.*(post|final|actual).*", flags=re.IGNORECASE), "post-decision anytime TD"),
+    (re.compile(r".*fullgame.*", flags=re.IGNORECASE), "full game cumulative value"),
+)
+
+DEFAULT_LEAK_POLICY = LeakPolicy(
+    version="v1",
+    description="Core post-outcome leak guard for NFL anytime TD features.",
+    banned_exact=_BASE_BANNED_EXACT,
+    banned_prefixes=_BASE_BANNED_PREFIXES,
+    banned_suffixes=_BASE_BANNED_SUFFIXES,
+    banned_regex=_BASE_BANNED_REGEX,
+)
+
+
+def _ensure_sequence(value: Sequence[str] | str | None) -> tuple[str, ...]:
+    if value is None:
+        return ()
+    if isinstance(value, str):
+        return (value,)
+    return tuple(value)
+
+
+def evaluate_leak_prone_columns(
+    columns: Iterable[str],
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+) -> LeakCheckResult:
+    """Identify leak-prone columns using the configured policy."""
+
+    banned: dict[str, str] = {}
+    columns_list = list(columns)
+    for col in columns_list:
+        if col in policy.banned_exact:
+            banned[col] = "exact"
+            continue
+        for prefix in policy.banned_prefixes:
+            if col.startswith(prefix):
+                banned[col] = f"prefix:{prefix}"
+                break
+        if col in banned:
+            continue
+        for suffix in policy.banned_suffixes:
+            if col.endswith(suffix):
+                banned[col] = f"suffix:{suffix}"
+                break
+        if col in banned:
+            continue
+        for pattern, reason in policy.banned_regex:
+            if pattern.match(col):
+                banned[col] = reason
+                break
+
+    kept = [c for c in columns_list if c not in banned]
+    return LeakCheckResult(
+        policy_version=policy.version,
+        banned=banned,
+        kept=kept,
+        dropped=[],
+        allowlist_kept=[],
+    )
+
+
+def enforce_leak_guard(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    allow_prefixes: Sequence[str] | str | None = None,
+    allow_exact: Sequence[str] | str | None = None,
+    drop_banned: bool = True,
+    drop_non_allowlisted: bool = False,
+    raise_on_banned: bool = True,
+) -> tuple[pl.DataFrame | "pd.DataFrame", LeakCheckResult]:
+    """Apply leak guardrails to a feature frame.
+
+    Parameters
+    ----------
+    df : DataFrame
+        Polars or pandas DataFrame.
+    policy : LeakPolicy
+        Leak policy to apply.
+    allow_prefixes : Sequence[str] | str | None
+        Optional prefixes that define the allowed feature surface for a problem.
+    allow_exact : Sequence[str] | str | None
+        Explicitly allowed columns (e.g., identifiers).
+    drop_banned : bool
+        If True, drop any banned columns automatically.
+    drop_non_allowlisted : bool
+        If True, drop columns that are not covered by allow_prefixes/allow_exact/identifiers/targets.
+    raise_on_banned : bool
+        If True, raise when banned columns are detected (after optional drop).
+    """
+
+    result = evaluate_leak_prone_columns(df.columns, policy=policy)
+    dropped: list[str] = []
+
+    allow_prefixes = _ensure_sequence(allow_prefixes)
+    allow_exact = set(_ensure_sequence(allow_exact))
+    allow_exact.update({col for col in IDENTIFIER_COLUMNS if col in df.columns})
+    allow_exact.update({col for col in NFL_TARGET_COLUMNS if col in df.columns})
+
+    # Permit allowlisted columns even if they match a banned rule (e.g., labels)
+    banned = {col: reason for col, reason in result.banned.items() if col not in allow_exact}
+
+    if banned and drop_banned:
+        df = df.drop(list(banned.keys()))
+        dropped.extend(banned.keys())
+
+    if banned and raise_on_banned:
+        raise ValueError(f"Leak-prone columns detected: {sorted(banned.items())}")
+
+    allowlist_cols: set[str] = set()
+    if allow_prefixes:
+        allowlist_cols.update({c for c in df.columns if c.startswith(allow_prefixes)})
+    allowlist_cols.update({c for c in allow_exact if c in df.columns})
+
+    if drop_non_allowlisted and allowlist_cols:
+        drop_candidates = [c for c in df.columns if c not in allowlist_cols]
+        if drop_candidates:
+            df = df.drop(drop_candidates)
+            dropped.extend(drop_candidates)
+
+    if drop_non_allowlisted and not allowlist_cols:
+        raise ValueError("No allowlisted columns remain after applying leak guard allowlist.")
+
+    # Store adjusted banned info on the result
+    result.banned = banned
+    result.dropped = dropped
+    result.kept = [c for c in df.columns]
+    result.allowlist_kept = sorted(list(allowlist_cols)) if allowlist_cols else []
+    return df, result
+
+
+def build_schema_snapshot(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    metadata: Mapping[str, object] | None = None,
+    banned: Mapping[str, str] | None = None,
+) -> dict:
+    """Render a schema snapshot describing each column and whether it was flagged."""
+
+    banned = banned or {}
+    meta = {
+        "generated_at_utc": datetime.utcnow().isoformat(),
+        "policy_version": policy.version,
+    }
+    meta.update(metadata or {})
+
+    # Extract columns / dtypes
+    if isinstance(df, pl.DataFrame):
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+    else:  # pandas or pandas-like
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+
+    schema = {
+        "metadata": meta,
+        "columns": [],
+    }
+
+    for col, dtype in cols_and_dtypes:
+        tags: list[str] = []
+        if col in IDENTIFIER_COLUMNS:
+            tags.append("id")
+        if col in NFL_TARGET_COLUMNS:
+            tags.append("label")
+        if col.startswith("market_"):
+            tags.append("odds")
+        if col.startswith("injury_") or col.startswith("practice_"):
+            tags.append("injury")
+        if col.startswith("weather_"):
+            tags.append("weather")
+        if col.startswith("ps_"):
+            tags.append("pre_snap")
+        schema["columns"].append(
+            {
+                "name": col,
+                "dtype": dtype,
+                "banned": col in banned,
+                "tags": tags,
+            }
+        )
+    return schema
+
+
+def write_schema_snapshot(path, schema: Mapping[str, object]) -> None:
+    path.parent.mkdir(parents=True, exist_ok=True)
+    with open(path, "w") as fp:
+        json.dump(schema, fp, indent=2, sort_keys=True)
+
+
+__all__ = [
+    "DEFAULT_LEAK_POLICY",
+    "LeakPolicy",
+    "LeakCheckResult",
+    "evaluate_leak_prone_columns",
+    "enforce_leak_guard",
+    "build_schema_snapshot",
+    "write_schema_snapshot",
+]


thinking
**Enhancing leak guard tests**
file update
M /Users/jameswest/Desktop/nfl_predict/tests/test_data_leak_guard.py
@@ -5,2 +5,10 @@
 
+import polars as pl
+
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    enforce_leak_guard,
+    evaluate_leak_prone_columns,
+)
+
 
@@ -50 +58,39 @@
 
+def test_leak_guard_flags_pattern_columns():
+    cols = [
+        "market_anytime_td_prob",
+        "final_score",
+        "postgame_anytime_td",
+        "actual_td_count",
+        "safe_feature",
+    ]
+    result = evaluate_leak_prone_columns(cols, policy=DEFAULT_LEAK_POLICY)
+    assert set(result.banned.keys()) == {"final_score", "postgame_anytime_td", "actual_td_count"}
+    assert "safe_feature" in result.kept
+    assert "market_anytime_td_prob" in result.kept
+
+
+def test_enforce_leak_guard_drops_banned_and_keeps_allowlisted():
+    df = pl.DataFrame(
+        {
+            "game_id": ["g1", "g2"],
+            "safe_feature": [1.0, 2.0],
+            "postgame_anytime_td": [1, 0],
+            "final_score": [30, 24],
+        }
+    )
+    cleaned, info = enforce_leak_guard(
+        df,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_prefixes=("safe_",),
+        allow_exact=("game_id",),
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=False,
+    )
+    assert "postgame_anytime_td" not in cleaned.columns
+    assert "final_score" not in cleaned.columns
+    assert "safe_feature" in cleaned.columns
+    assert "game_id" in cleaned.columns
+    assert set(info.dropped) == {"postgame_anytime_td", "final_score"}
+
apply_patch(auto_approved=true) exited 0 in 74ms:
Success. Updated the following files:
M tests/test_data_leak_guard.py
file update:
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 5ba68e8bf1acd3a789a76a8857674e6f6433017b..0210d5b7e7ed60a8de7a126d64f5ed76326474c8
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -14,7 +14,7 @@
 
 import logging
 import os
-from datetime import date, timedelta
+from datetime import date, datetime, timedelta
 from typing import Sequence
 
 import polars as pl
@@ -37,6 +37,12 @@
     add_offense_context_features_training,
     _append_offense_context_columns,
 )
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    build_schema_snapshot,
+    enforce_leak_guard,
+    write_schema_snapshot,
+)
 from utils.feature.weather_features import (
     add_weather_forecast_features_training,
     append_weather_context_flags,
@@ -931,6 +937,32 @@
     if market_exprs:
         df_player_game_all = df_player_game_all.with_columns(market_exprs)
     
+    # Leak guard + schema snapshot before persisting
+    spec = get_label_spec(label_version)
+    allow_exact = {spec.primary, *spec.labels.keys(), *spec.aliases.keys()}
+    df_player_game_all, leak_result = enforce_leak_guard(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_exact=allow_exact,
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=True,
+    )
+
+    schema = build_schema_snapshot(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        metadata={
+            "cutoff_label": cutoff_label,
+            "label_version": spec.name,
+        },
+        banned=leak_result.banned,
+    )
+    schema_dir = FEATURE_AUDIT_DIR / "schema" / "anytime_td"
+    schema_path = schema_dir / f"{cutoff_label}_{datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')}.json"
+    write_schema_snapshot(schema_path, schema)
+    logging.info("    Schema snapshot written → %s", schema_path)
+
     # Write final feature matrix
     df_player_game_all = df_player_game_all.with_columns(
         pl.lit(current_cutoff_hours).cast(pl.Float32).alias("decision_horizon_hours")
@@ -951,7 +983,6 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    spec = get_label_spec(label_version)
     label_candidates = {spec.primary, "anytime_td"}
     for label_col in label_candidates:
         if label_col in df_player_game_all.columns:
diff --git a/pipeline/train.py b/pipeline/train.py
index fe70207dcdf25d209ee3ad55080b7ce826347c44..3fab3a05b3f65e8d0e88ec1ddaa71a8857646148
--- a/pipeline/train.py
+++ b/pipeline/train.py
@@ -98,6 +98,7 @@
     fit_team_conformal_sums,
     composite_sum_interval,
 )
+from utils.feature.leak_guard import DEFAULT_LEAK_POLICY, enforce_leak_guard
 from utils.feature.targets import require_target_column
 
 # Ignore specific, noisy warnings from dependencies
@@ -2315,7 +2316,30 @@
                             df_problem[col] = df_problem[col].fillna(df_problem[col].mean())
 
                 df_problem = self._inject_composed_features(df_problem)
-            
+
+            # Leak guard on the problem-scoped frame
+            allow_prefixes = tuple(problem_copy.get('feature_prefixes_to_include') or [])
+            allow_exact = set(problem_copy.get('other_features_to_include') or [])
+            allow_exact.update(input_preds or [])
+            if self.target_col:
+                allow_exact.add(self.target_col)
+            df_problem, leak_info = enforce_leak_guard(
+                df_problem,
+                policy=DEFAULT_LEAK_POLICY,
+                allow_prefixes=allow_prefixes,
+                allow_exact=allow_exact,
+                drop_banned=True,
+                drop_non_allowlisted=False,
+                raise_on_banned=True,
+            )
+            if leak_info.dropped:
+                logger.info(
+                    "Dropped %d leak-prone columns for %s: %s",
+                    len(leak_info.dropped),
+                    problem_name,
+                    sorted(leak_info.dropped),
+                )
+
             self._normalize_datetime_like_columns(df_problem, problem_name)
             df_problem[self.time_col] = pd.to_datetime(df_problem[self.time_col])
             sort_cols = [self.time_col]
diff --git a/tests/test_data_leak_guard.py b/tests/test_data_leak_guard.py
index 8061f2760c0898aaeda29026859e1b9ff5644ba4..3e56665921db89ea523bbdb205d1bb90c21893df
--- a/tests/test_data_leak_guard.py
+++ b/tests/test_data_leak_guard.py
@@ -3,6 +3,14 @@
 import yaml
 from pathlib import Path
 
+import polars as pl
+
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    enforce_leak_guard,
+    evaluate_leak_prone_columns,
+)
+
 
 PROJECT_ROOT = Path(__file__).resolve().parents[1]
 TRAINING_CONFIG = PROJECT_ROOT / "config" / "training.yaml"
@@ -48,3 +56,41 @@
     )
 
 
+def test_leak_guard_flags_pattern_columns():
+    cols = [
+        "market_anytime_td_prob",
+        "final_score",
+        "postgame_anytime_td",
+        "actual_td_count",
+        "safe_feature",
+    ]
+    result = evaluate_leak_prone_columns(cols, policy=DEFAULT_LEAK_POLICY)
+    assert set(result.banned.keys()) == {"final_score", "postgame_anytime_td", "actual_td_count"}
+    assert "safe_feature" in result.kept
+    assert "market_anytime_td_prob" in result.kept
+
+
+def test_enforce_leak_guard_drops_banned_and_keeps_allowlisted():
+    df = pl.DataFrame(
+        {
+            "game_id": ["g1", "g2"],
+            "safe_feature": [1.0, 2.0],
+            "postgame_anytime_td": [1, 0],
+            "final_score": [30, 24],
+        }
+    )
+    cleaned, info = enforce_leak_guard(
+        df,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_prefixes=("safe_",),
+        allow_exact=("game_id",),
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=False,
+    )
+    assert "postgame_anytime_td" not in cleaned.columns
+    assert "final_score" not in cleaned.columns
+    assert "safe_feature" in cleaned.columns
+    assert "game_id" in cleaned.columns
+    assert set(info.dropped) == {"postgame_anytime_td", "final_score"}
+
diff --git a/utils/feature/leak_guard.py b/utils/feature/leak_guard.py
new file mode 100644
index 0000000000000000000000000000000000000000..9faf8cfffc436e0934b2f410aaf252e52f4f95df
--- /dev/null
+++ b/utils/feature/leak_guard.py
@@ -0,0 +1,273 @@
+"""Leak guardrails for feature matrices.
+
+This module centralizes pattern-based leak detection so both feature assembly
+and training can fail fast when post-outcome columns sneak into the data.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+from datetime import datetime
+import json
+import re
+from typing import Iterable, Mapping, Sequence
+
+import polars as pl
+
+from utils.general.constants import IDENTIFIER_COLUMNS, LEAK_PRONE_COLUMNS, NFL_TARGET_COLUMNS
+
+try:  # Optional dependency when imported from training (pandas path)
+    import pandas as pd  # type: ignore
+except Exception:  # pragma: no cover - optional dependency
+    pd = None
+
+
+@dataclass(frozen=True)
+class LeakPolicy:
+    version: str
+    banned_exact: set[str]
+    banned_prefixes: tuple[str, ...]
+    banned_suffixes: tuple[str, ...]
+    banned_regex: tuple[tuple[re.Pattern[str], str], ...]
+    description: str = ""
+
+
+@dataclass
+class LeakCheckResult:
+    policy_version: str
+    banned: dict[str, str]
+    kept: list[str]
+    dropped: list[str]
+    allowlist_kept: list[str]
+
+
+# Core policy tuned for anytime-TD style problems (can be extended per-problem).
+_BASE_BANNED_EXACT = set(LEAK_PRONE_COLUMNS) | {
+    "final_score",
+    "final_total",
+    "points_scored",
+    "actual_td_count",
+    "actual_anytime_td",
+    "postgame_anytime_td",
+    "postgame_td_count",
+}
+_BASE_BANNED_PREFIXES = (
+    "postgame_",
+    "post_game_",
+    "post_",
+    "live_",
+    "actual_",
+    "realized_",
+    "final_",
+    "postmatch_",
+)
+_BASE_BANNED_SUFFIXES = (
+    "_post",
+    "_postgame",
+    "_final",
+    "_fullgame",
+    "_actual",
+)
+_BASE_BANNED_REGEX: tuple[tuple[re.Pattern[str], str], ...] = (
+    (re.compile(r".*post.?game.*", flags=re.IGNORECASE), "postgame marker"),
+    (re.compile(r".*final_score.*", flags=re.IGNORECASE), "final score"),
+    (re.compile(r".*actual.*td.*", flags=re.IGNORECASE), "actual TD total"),
+    (re.compile(r".*anytime_td.*(post|final|actual).*", flags=re.IGNORECASE), "post-decision anytime TD"),
+    (re.compile(r".*fullgame.*", flags=re.IGNORECASE), "full game cumulative value"),
+)
+
+DEFAULT_LEAK_POLICY = LeakPolicy(
+    version="v1",
+    description="Core post-outcome leak guard for NFL anytime TD features.",
+    banned_exact=_BASE_BANNED_EXACT,
+    banned_prefixes=_BASE_BANNED_PREFIXES,
+    banned_suffixes=_BASE_BANNED_SUFFIXES,
+    banned_regex=_BASE_BANNED_REGEX,
+)
+
+
+def _ensure_sequence(value: Sequence[str] | str | None) -> tuple[str, ...]:
+    if value is None:
+        return ()
+    if isinstance(value, str):
+        return (value,)
+    return tuple(value)
+
+
+def evaluate_leak_prone_columns(
+    columns: Iterable[str],
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+) -> LeakCheckResult:
+    """Identify leak-prone columns using the configured policy."""
+
+    banned: dict[str, str] = {}
+    columns_list = list(columns)
+    for col in columns_list:
+        if col in policy.banned_exact:
+            banned[col] = "exact"
+            continue
+        for prefix in policy.banned_prefixes:
+            if col.startswith(prefix):
+                banned[col] = f"prefix:{prefix}"
+                break
+        if col in banned:
+            continue
+        for suffix in policy.banned_suffixes:
+            if col.endswith(suffix):
+                banned[col] = f"suffix:{suffix}"
+                break
+        if col in banned:
+            continue
+        for pattern, reason in policy.banned_regex:
+            if pattern.match(col):
+                banned[col] = reason
+                break
+
+    kept = [c for c in columns_list if c not in banned]
+    return LeakCheckResult(
+        policy_version=policy.version,
+        banned=banned,
+        kept=kept,
+        dropped=[],
+        allowlist_kept=[],
+    )
+
+
+def enforce_leak_guard(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    allow_prefixes: Sequence[str] | str | None = None,
+    allow_exact: Sequence[str] | str | None = None,
+    drop_banned: bool = True,
+    drop_non_allowlisted: bool = False,
+    raise_on_banned: bool = True,
+) -> tuple[pl.DataFrame | "pd.DataFrame", LeakCheckResult]:
+    """Apply leak guardrails to a feature frame.
+
+    Parameters
+    ----------
+    df : DataFrame
+        Polars or pandas DataFrame.
+    policy : LeakPolicy
+        Leak policy to apply.
+    allow_prefixes : Sequence[str] | str | None
+        Optional prefixes that define the allowed feature surface for a problem.
+    allow_exact : Sequence[str] | str | None
+        Explicitly allowed columns (e.g., identifiers).
+    drop_banned : bool
+        If True, drop any banned columns automatically.
+    drop_non_allowlisted : bool
+        If True, drop columns that are not covered by allow_prefixes/allow_exact/identifiers/targets.
+    raise_on_banned : bool
+        If True, raise when banned columns are detected (after optional drop).
+    """
+
+    result = evaluate_leak_prone_columns(df.columns, policy=policy)
+    dropped: list[str] = []
+
+    allow_prefixes = _ensure_sequence(allow_prefixes)
+    allow_exact = set(_ensure_sequence(allow_exact))
+    allow_exact.update({col for col in IDENTIFIER_COLUMNS if col in df.columns})
+    allow_exact.update({col for col in NFL_TARGET_COLUMNS if col in df.columns})
+
+    # Permit allowlisted columns even if they match a banned rule (e.g., labels)
+    banned = {col: reason for col, reason in result.banned.items() if col not in allow_exact}
+
+    if banned and drop_banned:
+        df = df.drop(list(banned.keys()))
+        dropped.extend(banned.keys())
+
+    if banned and raise_on_banned:
+        raise ValueError(f"Leak-prone columns detected: {sorted(banned.items())}")
+
+    allowlist_cols: set[str] = set()
+    if allow_prefixes:
+        allowlist_cols.update({c for c in df.columns if c.startswith(allow_prefixes)})
+    allowlist_cols.update({c for c in allow_exact if c in df.columns})
+
+    if drop_non_allowlisted and allowlist_cols:
+        drop_candidates = [c for c in df.columns if c not in allowlist_cols]
+        if drop_candidates:
+            df = df.drop(drop_candidates)
+            dropped.extend(drop_candidates)
+
+    if drop_non_allowlisted and not allowlist_cols:
+        raise ValueError("No allowlisted columns remain after applying leak guard allowlist.")
+
+    # Store adjusted banned info on the result
+    result.banned = banned
+    result.dropped = dropped
+    result.kept = [c for c in df.columns]
+    result.allowlist_kept = sorted(list(allowlist_cols)) if allowlist_cols else []
+    return df, result
+
+
+def build_schema_snapshot(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    metadata: Mapping[str, object] | None = None,
+    banned: Mapping[str, str] | None = None,
+) -> dict:
+    """Render a schema snapshot describing each column and whether it was flagged."""
+
+    banned = banned or {}
+    meta = {
+        "generated_at_utc": datetime.utcnow().isoformat(),
+        "policy_version": policy.version,
+    }
+    meta.update(metadata or {})
+
+    # Extract columns / dtypes
+    if isinstance(df, pl.DataFrame):
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+    else:  # pandas or pandas-like
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+
+    schema = {
+        "metadata": meta,
+        "columns": [],
+    }
+
+    for col, dtype in cols_and_dtypes:
+        tags: list[str] = []
+        if col in IDENTIFIER_COLUMNS:
+            tags.append("id")
+        if col in NFL_TARGET_COLUMNS:
+            tags.append("label")
+        if col.startswith("market_"):
+            tags.append("odds")
+        if col.startswith("injury_") or col.startswith("practice_"):
+            tags.append("injury")
+        if col.startswith("weather_"):
+            tags.append("weather")
+        if col.startswith("ps_"):
+            tags.append("pre_snap")
+        schema["columns"].append(
+            {
+                "name": col,
+                "dtype": dtype,
+                "banned": col in banned,
+                "tags": tags,
+            }
+        )
+    return schema
+
+
+def write_schema_snapshot(path, schema: Mapping[str, object]) -> None:
+    path.parent.mkdir(parents=True, exist_ok=True)
+    with open(path, "w") as fp:
+        json.dump(schema, fp, indent=2, sort_keys=True)
+
+
+__all__ = [
+    "DEFAULT_LEAK_POLICY",
+    "LeakPolicy",
+    "LeakCheckResult",
+    "evaluate_leak_prone_columns",
+    "enforce_leak_guard",
+    "build_schema_snapshot",
+    "write_schema_snapshot",
+]

file update:
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 5ba68e8bf1acd3a789a76a8857674e6f6433017b..0210d5b7e7ed60a8de7a126d64f5ed76326474c8
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -14,7 +14,7 @@
 
 import logging
 import os
-from datetime import date, timedelta
+from datetime import date, datetime, timedelta
 from typing import Sequence
 
 import polars as pl
@@ -37,6 +37,12 @@
     add_offense_context_features_training,
     _append_offense_context_columns,
 )
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    build_schema_snapshot,
+    enforce_leak_guard,
+    write_schema_snapshot,
+)
 from utils.feature.weather_features import (
     add_weather_forecast_features_training,
     append_weather_context_flags,
@@ -931,6 +937,32 @@
     if market_exprs:
         df_player_game_all = df_player_game_all.with_columns(market_exprs)
     
+    # Leak guard + schema snapshot before persisting
+    spec = get_label_spec(label_version)
+    allow_exact = {spec.primary, *spec.labels.keys(), *spec.aliases.keys()}
+    df_player_game_all, leak_result = enforce_leak_guard(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_exact=allow_exact,
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=True,
+    )
+
+    schema = build_schema_snapshot(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        metadata={
+            "cutoff_label": cutoff_label,
+            "label_version": spec.name,
+        },
+        banned=leak_result.banned,
+    )
+    schema_dir = FEATURE_AUDIT_DIR / "schema" / "anytime_td"
+    schema_path = schema_dir / f"{cutoff_label}_{datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')}.json"
+    write_schema_snapshot(schema_path, schema)
+    logging.info("    Schema snapshot written → %s", schema_path)
+
     # Write final feature matrix
     df_player_game_all = df_player_game_all.with_columns(
         pl.lit(current_cutoff_hours).cast(pl.Float32).alias("decision_horizon_hours")
@@ -951,7 +983,6 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    spec = get_label_spec(label_version)
     label_candidates = {spec.primary, "anytime_td"}
     for label_col in label_candidates:
         if label_col in df_player_game_all.columns:
diff --git a/pipeline/train.py b/pipeline/train.py
index fe70207dcdf25d209ee3ad55080b7ce826347c44..3fab3a05b3f65e8d0e88ec1ddaa71a8857646148
--- a/pipeline/train.py
+++ b/pipeline/train.py
@@ -98,6 +98,7 @@
     fit_team_conformal_sums,
     composite_sum_interval,
 )
+from utils.feature.leak_guard import DEFAULT_LEAK_POLICY, enforce_leak_guard
 from utils.feature.targets import require_target_column
 
 # Ignore specific, noisy warnings from dependencies
@@ -2315,7 +2316,30 @@
                             df_problem[col] = df_problem[col].fillna(df_problem[col].mean())
 
                 df_problem = self._inject_composed_features(df_problem)
-            
+
+            # Leak guard on the problem-scoped frame
+            allow_prefixes = tuple(problem_copy.get('feature_prefixes_to_include') or [])
+            allow_exact = set(problem_copy.get('other_features_to_include') or [])
+            allow_exact.update(input_preds or [])
+            if self.target_col:
+                allow_exact.add(self.target_col)
+            df_problem, leak_info = enforce_leak_guard(
+                df_problem,
+                policy=DEFAULT_LEAK_POLICY,
+                allow_prefixes=allow_prefixes,
+                allow_exact=allow_exact,
+                drop_banned=True,
+                drop_non_allowlisted=False,
+                raise_on_banned=True,
+            )
+            if leak_info.dropped:
+                logger.info(
+                    "Dropped %d leak-prone columns for %s: %s",
+                    len(leak_info.dropped),
+                    problem_name,
+                    sorted(leak_info.dropped),
+                )
+
             self._normalize_datetime_like_columns(df_problem, problem_name)
             df_problem[self.time_col] = pd.to_datetime(df_problem[self.time_col])
             sort_cols = [self.time_col]
diff --git a/tests/test_data_leak_guard.py b/tests/test_data_leak_guard.py
index 8061f2760c0898aaeda29026859e1b9ff5644ba4..3e56665921db89ea523bbdb205d1bb90c21893df
--- a/tests/test_data_leak_guard.py
+++ b/tests/test_data_leak_guard.py
@@ -3,6 +3,14 @@
 import yaml
 from pathlib import Path
 
+import polars as pl
+
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    enforce_leak_guard,
+    evaluate_leak_prone_columns,
+)
+
 
 PROJECT_ROOT = Path(__file__).resolve().parents[1]
 TRAINING_CONFIG = PROJECT_ROOT / "config" / "training.yaml"
@@ -48,3 +56,41 @@
     )
 
 
+def test_leak_guard_flags_pattern_columns():
+    cols = [
+        "market_anytime_td_prob",
+        "final_score",
+        "postgame_anytime_td",
+        "actual_td_count",
+        "safe_feature",
+    ]
+    result = evaluate_leak_prone_columns(cols, policy=DEFAULT_LEAK_POLICY)
+    assert set(result.banned.keys()) == {"final_score", "postgame_anytime_td", "actual_td_count"}
+    assert "safe_feature" in result.kept
+    assert "market_anytime_td_prob" in result.kept
+
+
+def test_enforce_leak_guard_drops_banned_and_keeps_allowlisted():
+    df = pl.DataFrame(
+        {
+            "game_id": ["g1", "g2"],
+            "safe_feature": [1.0, 2.0],
+            "postgame_anytime_td": [1, 0],
+            "final_score": [30, 24],
+        }
+    )
+    cleaned, info = enforce_leak_guard(
+        df,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_prefixes=("safe_",),
+        allow_exact=("game_id",),
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=False,
+    )
+    assert "postgame_anytime_td" not in cleaned.columns
+    assert "final_score" not in cleaned.columns
+    assert "safe_feature" in cleaned.columns
+    assert "game_id" in cleaned.columns
+    assert set(info.dropped) == {"postgame_anytime_td", "final_score"}
+
diff --git a/utils/feature/leak_guard.py b/utils/feature/leak_guard.py
new file mode 100644
index 0000000000000000000000000000000000000000..9faf8cfffc436e0934b2f410aaf252e52f4f95df
--- /dev/null
+++ b/utils/feature/leak_guard.py
@@ -0,0 +1,273 @@
+"""Leak guardrails for feature matrices.
+
+This module centralizes pattern-based leak detection so both feature assembly
+and training can fail fast when post-outcome columns sneak into the data.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+from datetime import datetime
+import json
+import re
+from typing import Iterable, Mapping, Sequence
+
+import polars as pl
+
+from utils.general.constants import IDENTIFIER_COLUMNS, LEAK_PRONE_COLUMNS, NFL_TARGET_COLUMNS
+
+try:  # Optional dependency when imported from training (pandas path)
+    import pandas as pd  # type: ignore
+except Exception:  # pragma: no cover - optional dependency
+    pd = None
+
+
+@dataclass(frozen=True)
+class LeakPolicy:
+    version: str
+    banned_exact: set[str]
+    banned_prefixes: tuple[str, ...]
+    banned_suffixes: tuple[str, ...]
+    banned_regex: tuple[tuple[re.Pattern[str], str], ...]
+    description: str = ""
+
+
+@dataclass
+class LeakCheckResult:
+    policy_version: str
+    banned: dict[str, str]
+    kept: list[str]
+    dropped: list[str]
+    allowlist_kept: list[str]
+
+
+# Core policy tuned for anytime-TD style problems (can be extended per-problem).
+_BASE_BANNED_EXACT = set(LEAK_PRONE_COLUMNS) | {
+    "final_score",
+    "final_total",
+    "points_scored",
+    "actual_td_count",
+    "actual_anytime_td",
+    "postgame_anytime_td",
+    "postgame_td_count",
+}
+_BASE_BANNED_PREFIXES = (
+    "postgame_",
+    "post_game_",
+    "post_",
+    "live_",
+    "actual_",
+    "realized_",
+    "final_",
+    "postmatch_",
+)
+_BASE_BANNED_SUFFIXES = (
+    "_post",
+    "_postgame",
+    "_final",
+    "_fullgame",
+    "_actual",
+)
+_BASE_BANNED_REGEX: tuple[tuple[re.Pattern[str], str], ...] = (
+    (re.compile(r".*post.?game.*", flags=re.IGNORECASE), "postgame marker"),
+    (re.compile(r".*final_score.*", flags=re.IGNORECASE), "final score"),
+    (re.compile(r".*actual.*td.*", flags=re.IGNORECASE), "actual TD total"),
+    (re.compile(r".*anytime_td.*(post|final|actual).*", flags=re.IGNORECASE), "post-decision anytime TD"),
+    (re.compile(r".*fullgame.*", flags=re.IGNORECASE), "full game cumulative value"),
+)
+
+DEFAULT_LEAK_POLICY = LeakPolicy(
+    version="v1",
+    description="Core post-outcome leak guard for NFL anytime TD features.",
+    banned_exact=_BASE_BANNED_EXACT,
+    banned_prefixes=_BASE_BANNED_PREFIXES,
+    banned_suffixes=_BASE_BANNED_SUFFIXES,
+    banned_regex=_BASE_BANNED_REGEX,
+)
+
+
+def _ensure_sequence(value: Sequence[str] | str | None) -> tuple[str, ...]:
+    if value is None:
+        return ()
+    if isinstance(value, str):
+        return (value,)
+    return tuple(value)
+
+
+def evaluate_leak_prone_columns(
+    columns: Iterable[str],
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+) -> LeakCheckResult:
+    """Identify leak-prone columns using the configured policy."""
+
+    banned: dict[str, str] = {}
+    columns_list = list(columns)
+    for col in columns_list:
+        if col in policy.banned_exact:
+            banned[col] = "exact"
+            continue
+        for prefix in policy.banned_prefixes:
+            if col.startswith(prefix):
+                banned[col] = f"prefix:{prefix}"
+                break
+        if col in banned:
+            continue
+        for suffix in policy.banned_suffixes:
+            if col.endswith(suffix):
+                banned[col] = f"suffix:{suffix}"
+                break
+        if col in banned:
+            continue
+        for pattern, reason in policy.banned_regex:
+            if pattern.match(col):
+                banned[col] = reason
+                break
+
+    kept = [c for c in columns_list if c not in banned]
+    return LeakCheckResult(
+        policy_version=policy.version,
+        banned=banned,
+        kept=kept,
+        dropped=[],
+        allowlist_kept=[],
+    )
+
+
+def enforce_leak_guard(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    allow_prefixes: Sequence[str] | str | None = None,
+    allow_exact: Sequence[str] | str | None = None,
+    drop_banned: bool = True,
+    drop_non_allowlisted: bool = False,
+    raise_on_banned: bool = True,
+) -> tuple[pl.DataFrame | "pd.DataFrame", LeakCheckResult]:
+    """Apply leak guardrails to a feature frame.
+
+    Parameters
+    ----------
+    df : DataFrame
+        Polars or pandas DataFrame.
+    policy : LeakPolicy
+        Leak policy to apply.
+    allow_prefixes : Sequence[str] | str | None
+        Optional prefixes that define the allowed feature surface for a problem.
+    allow_exact : Sequence[str] | str | None
+        Explicitly allowed columns (e.g., identifiers).
+    drop_banned : bool
+        If True, drop any banned columns automatically.
+    drop_non_allowlisted : bool
+        If True, drop columns that are not covered by allow_prefixes/allow_exact/identifiers/targets.
+    raise_on_banned : bool
+        If True, raise when banned columns are detected (after optional drop).
+    """
+
+    result = evaluate_leak_prone_columns(df.columns, policy=policy)
+    dropped: list[str] = []
+
+    allow_prefixes = _ensure_sequence(allow_prefixes)
+    allow_exact = set(_ensure_sequence(allow_exact))
+    allow_exact.update({col for col in IDENTIFIER_COLUMNS if col in df.columns})
+    allow_exact.update({col for col in NFL_TARGET_COLUMNS if col in df.columns})
+
+    # Permit allowlisted columns even if they match a banned rule (e.g., labels)
+    banned = {col: reason for col, reason in result.banned.items() if col not in allow_exact}
+
+    if banned and drop_banned:
+        df = df.drop(list(banned.keys()))
+        dropped.extend(banned.keys())
+
+    if banned and raise_on_banned:
+        raise ValueError(f"Leak-prone columns detected: {sorted(banned.items())}")
+
+    allowlist_cols: set[str] = set()
+    if allow_prefixes:
+        allowlist_cols.update({c for c in df.columns if c.startswith(allow_prefixes)})
+    allowlist_cols.update({c for c in allow_exact if c in df.columns})
+
+    if drop_non_allowlisted and allowlist_cols:
+        drop_candidates = [c for c in df.columns if c not in allowlist_cols]
+        if drop_candidates:
+            df = df.drop(drop_candidates)
+            dropped.extend(drop_candidates)
+
+    if drop_non_allowlisted and not allowlist_cols:
+        raise ValueError("No allowlisted columns remain after applying leak guard allowlist.")
+
+    # Store adjusted banned info on the result
+    result.banned = banned
+    result.dropped = dropped
+    result.kept = [c for c in df.columns]
+    result.allowlist_kept = sorted(list(allowlist_cols)) if allowlist_cols else []
+    return df, result
+
+
+def build_schema_snapshot(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    metadata: Mapping[str, object] | None = None,
+    banned: Mapping[str, str] | None = None,
+) -> dict:
+    """Render a schema snapshot describing each column and whether it was flagged."""
+
+    banned = banned or {}
+    meta = {
+        "generated_at_utc": datetime.utcnow().isoformat(),
+        "policy_version": policy.version,
+    }
+    meta.update(metadata or {})
+
+    # Extract columns / dtypes
+    if isinstance(df, pl.DataFrame):
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+    else:  # pandas or pandas-like
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+
+    schema = {
+        "metadata": meta,
+        "columns": [],
+    }
+
+    for col, dtype in cols_and_dtypes:
+        tags: list[str] = []
+        if col in IDENTIFIER_COLUMNS:
+            tags.append("id")
+        if col in NFL_TARGET_COLUMNS:
+            tags.append("label")
+        if col.startswith("market_"):
+            tags.append("odds")
+        if col.startswith("injury_") or col.startswith("practice_"):
+            tags.append("injury")
+        if col.startswith("weather_"):
+            tags.append("weather")
+        if col.startswith("ps_"):
+            tags.append("pre_snap")
+        schema["columns"].append(
+            {
+                "name": col,
+                "dtype": dtype,
+                "banned": col in banned,
+                "tags": tags,
+            }
+        )
+    return schema
+
+
+def write_schema_snapshot(path, schema: Mapping[str, object]) -> None:
+    path.parent.mkdir(parents=True, exist_ok=True)
+    with open(path, "w") as fp:
+        json.dump(schema, fp, indent=2, sort_keys=True)
+
+
+__all__ = [
+    "DEFAULT_LEAK_POLICY",
+    "LeakPolicy",
+    "LeakCheckResult",
+    "evaluate_leak_prone_columns",
+    "enforce_leak_guard",
+    "build_schema_snapshot",
+    "write_schema_snapshot",
+]


thinking
**Reviewing banned detection and schema artifacts**
exec
/bin/zsh -lc 'cd /Users/jameswest/Desktop/nfl_predict && rg "passing_td" config/training.yaml' in /Users/jameswest/Desktop/nfl_predict succeeded in 810ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
  - passing_td
  - passing_td
    - 'passing_td'
file update:
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 5ba68e8bf1acd3a789a76a8857674e6f6433017b..0210d5b7e7ed60a8de7a126d64f5ed76326474c8
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -14,7 +14,7 @@
 
 import logging
 import os
-from datetime import date, timedelta
+from datetime import date, datetime, timedelta
 from typing import Sequence
 
 import polars as pl
@@ -37,6 +37,12 @@
     add_offense_context_features_training,
     _append_offense_context_columns,
 )
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    build_schema_snapshot,
+    enforce_leak_guard,
+    write_schema_snapshot,
+)
 from utils.feature.weather_features import (
     add_weather_forecast_features_training,
     append_weather_context_flags,
@@ -931,6 +937,32 @@
     if market_exprs:
         df_player_game_all = df_player_game_all.with_columns(market_exprs)
     
+    # Leak guard + schema snapshot before persisting
+    spec = get_label_spec(label_version)
+    allow_exact = {spec.primary, *spec.labels.keys(), *spec.aliases.keys()}
+    df_player_game_all, leak_result = enforce_leak_guard(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_exact=allow_exact,
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=True,
+    )
+
+    schema = build_schema_snapshot(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        metadata={
+            "cutoff_label": cutoff_label,
+            "label_version": spec.name,
+        },
+        banned=leak_result.banned,
+    )
+    schema_dir = FEATURE_AUDIT_DIR / "schema" / "anytime_td"
+    schema_path = schema_dir / f"{cutoff_label}_{datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')}.json"
+    write_schema_snapshot(schema_path, schema)
+    logging.info("    Schema snapshot written → %s", schema_path)
+
     # Write final feature matrix
     df_player_game_all = df_player_game_all.with_columns(
         pl.lit(current_cutoff_hours).cast(pl.Float32).alias("decision_horizon_hours")
@@ -951,7 +983,6 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    spec = get_label_spec(label_version)
     label_candidates = {spec.primary, "anytime_td"}
     for label_col in label_candidates:
         if label_col in df_player_game_all.columns:
diff --git a/pipeline/train.py b/pipeline/train.py
index fe70207dcdf25d209ee3ad55080b7ce826347c44..3fab3a05b3f65e8d0e88ec1ddaa71a8857646148
--- a/pipeline/train.py
+++ b/pipeline/train.py
@@ -98,6 +98,7 @@
     fit_team_conformal_sums,
     composite_sum_interval,
 )
+from utils.feature.leak_guard import DEFAULT_LEAK_POLICY, enforce_leak_guard
 from utils.feature.targets import require_target_column
 
 # Ignore specific, noisy warnings from dependencies
@@ -2315,7 +2316,30 @@
                             df_problem[col] = df_problem[col].fillna(df_problem[col].mean())
 
                 df_problem = self._inject_composed_features(df_problem)
-            
+
+            # Leak guard on the problem-scoped frame
+            allow_prefixes = tuple(problem_copy.get('feature_prefixes_to_include') or [])
+            allow_exact = set(problem_copy.get('other_features_to_include') or [])
+            allow_exact.update(input_preds or [])
+            if self.target_col:
+                allow_exact.add(self.target_col)
+            df_problem, leak_info = enforce_leak_guard(
+                df_problem,
+                policy=DEFAULT_LEAK_POLICY,
+                allow_prefixes=allow_prefixes,
+                allow_exact=allow_exact,
+                drop_banned=True,
+                drop_non_allowlisted=False,
+                raise_on_banned=True,
+            )
+            if leak_info.dropped:
+                logger.info(
+                    "Dropped %d leak-prone columns for %s: %s",
+                    len(leak_info.dropped),
+                    problem_name,
+                    sorted(leak_info.dropped),
+                )
+
             self._normalize_datetime_like_columns(df_problem, problem_name)
             df_problem[self.time_col] = pd.to_datetime(df_problem[self.time_col])
             sort_cols = [self.time_col]
diff --git a/tests/test_data_leak_guard.py b/tests/test_data_leak_guard.py
index 8061f2760c0898aaeda29026859e1b9ff5644ba4..3e56665921db89ea523bbdb205d1bb90c21893df
--- a/tests/test_data_leak_guard.py
+++ b/tests/test_data_leak_guard.py
@@ -3,6 +3,14 @@
 import yaml
 from pathlib import Path
 
+import polars as pl
+
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    enforce_leak_guard,
+    evaluate_leak_prone_columns,
+)
+
 
 PROJECT_ROOT = Path(__file__).resolve().parents[1]
 TRAINING_CONFIG = PROJECT_ROOT / "config" / "training.yaml"
@@ -48,3 +56,41 @@
     )
 
 
+def test_leak_guard_flags_pattern_columns():
+    cols = [
+        "market_anytime_td_prob",
+        "final_score",
+        "postgame_anytime_td",
+        "actual_td_count",
+        "safe_feature",
+    ]
+    result = evaluate_leak_prone_columns(cols, policy=DEFAULT_LEAK_POLICY)
+    assert set(result.banned.keys()) == {"final_score", "postgame_anytime_td", "actual_td_count"}
+    assert "safe_feature" in result.kept
+    assert "market_anytime_td_prob" in result.kept
+
+
+def test_enforce_leak_guard_drops_banned_and_keeps_allowlisted():
+    df = pl.DataFrame(
+        {
+            "game_id": ["g1", "g2"],
+            "safe_feature": [1.0, 2.0],
+            "postgame_anytime_td": [1, 0],
+            "final_score": [30, 24],
+        }
+    )
+    cleaned, info = enforce_leak_guard(
+        df,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_prefixes=("safe_",),
+        allow_exact=("game_id",),
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=False,
+    )
+    assert "postgame_anytime_td" not in cleaned.columns
+    assert "final_score" not in cleaned.columns
+    assert "safe_feature" in cleaned.columns
+    assert "game_id" in cleaned.columns
+    assert set(info.dropped) == {"postgame_anytime_td", "final_score"}
+
diff --git a/utils/feature/leak_guard.py b/utils/feature/leak_guard.py
new file mode 100644
index 0000000000000000000000000000000000000000..9faf8cfffc436e0934b2f410aaf252e52f4f95df
--- /dev/null
+++ b/utils/feature/leak_guard.py
@@ -0,0 +1,273 @@
+"""Leak guardrails for feature matrices.
+
+This module centralizes pattern-based leak detection so both feature assembly
+and training can fail fast when post-outcome columns sneak into the data.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+from datetime import datetime
+import json
+import re
+from typing import Iterable, Mapping, Sequence
+
+import polars as pl
+
+from utils.general.constants import IDENTIFIER_COLUMNS, LEAK_PRONE_COLUMNS, NFL_TARGET_COLUMNS
+
+try:  # Optional dependency when imported from training (pandas path)
+    import pandas as pd  # type: ignore
+except Exception:  # pragma: no cover - optional dependency
+    pd = None
+
+
+@dataclass(frozen=True)
+class LeakPolicy:
+    version: str
+    banned_exact: set[str]
+    banned_prefixes: tuple[str, ...]
+    banned_suffixes: tuple[str, ...]
+    banned_regex: tuple[tuple[re.Pattern[str], str], ...]
+    description: str = ""
+
+
+@dataclass
+class LeakCheckResult:
+    policy_version: str
+    banned: dict[str, str]
+    kept: list[str]
+    dropped: list[str]
+    allowlist_kept: list[str]
+
+
+# Core policy tuned for anytime-TD style problems (can be extended per-problem).
+_BASE_BANNED_EXACT = set(LEAK_PRONE_COLUMNS) | {
+    "final_score",
+    "final_total",
+    "points_scored",
+    "actual_td_count",
+    "actual_anytime_td",
+    "postgame_anytime_td",
+    "postgame_td_count",
+}
+_BASE_BANNED_PREFIXES = (
+    "postgame_",
+    "post_game_",
+    "post_",
+    "live_",
+    "actual_",
+    "realized_",
+    "final_",
+    "postmatch_",
+)
+_BASE_BANNED_SUFFIXES = (
+    "_post",
+    "_postgame",
+    "_final",
+    "_fullgame",
+    "_actual",
+)
+_BASE_BANNED_REGEX: tuple[tuple[re.Pattern[str], str], ...] = (
+    (re.compile(r".*post.?game.*", flags=re.IGNORECASE), "postgame marker"),
+    (re.compile(r".*final_score.*", flags=re.IGNORECASE), "final score"),
+    (re.compile(r".*actual.*td.*", flags=re.IGNORECASE), "actual TD total"),
+    (re.compile(r".*anytime_td.*(post|final|actual).*", flags=re.IGNORECASE), "post-decision anytime TD"),
+    (re.compile(r".*fullgame.*", flags=re.IGNORECASE), "full game cumulative value"),
+)
+
+DEFAULT_LEAK_POLICY = LeakPolicy(
+    version="v1",
+    description="Core post-outcome leak guard for NFL anytime TD features.",
+    banned_exact=_BASE_BANNED_EXACT,
+    banned_prefixes=_BASE_BANNED_PREFIXES,
+    banned_suffixes=_BASE_BANNED_SUFFIXES,
+    banned_regex=_BASE_BANNED_REGEX,
+)
+
+
+def _ensure_sequence(value: Sequence[str] | str | None) -> tuple[str, ...]:
+    if value is None:
+        return ()
+    if isinstance(value, str):
+        return (value,)
+    return tuple(value)
+
+
+def evaluate_leak_prone_columns(
+    columns: Iterable[str],
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+) -> LeakCheckResult:
+    """Identify leak-prone columns using the configured policy."""
+
+    banned: dict[str, str] = {}
+    columns_list = list(columns)
+    for col in columns_list:
+        if col in policy.banned_exact:
+            banned[col] = "exact"
+            continue
+        for prefix in policy.banned_prefixes:
+            if col.startswith(prefix):
+                banned[col] = f"prefix:{prefix}"
+                break
+        if col in banned:
+            continue
+        for suffix in policy.banned_suffixes:
+            if col.endswith(suffix):
+                banned[col] = f"suffix:{suffix}"
+                break
+        if col in banned:
+            continue
+        for pattern, reason in policy.banned_regex:
+            if pattern.match(col):
+                banned[col] = reason
+                break
+
+    kept = [c for c in columns_list if c not in banned]
+    return LeakCheckResult(
+        policy_version=policy.version,
+        banned=banned,
+        kept=kept,
+        dropped=[],
+        allowlist_kept=[],
+    )
+
+
+def enforce_leak_guard(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    allow_prefixes: Sequence[str] | str | None = None,
+    allow_exact: Sequence[str] | str | None = None,
+    drop_banned: bool = True,
+    drop_non_allowlisted: bool = False,
+    raise_on_banned: bool = True,
+) -> tuple[pl.DataFrame | "pd.DataFrame", LeakCheckResult]:
+    """Apply leak guardrails to a feature frame.
+
+    Parameters
+    ----------
+    df : DataFrame
+        Polars or pandas DataFrame.
+    policy : LeakPolicy
+        Leak policy to apply.
+    allow_prefixes : Sequence[str] | str | None
+        Optional prefixes that define the allowed feature surface for a problem.
+    allow_exact : Sequence[str] | str | None
+        Explicitly allowed columns (e.g., identifiers).
+    drop_banned : bool
+        If True, drop any banned columns automatically.
+    drop_non_allowlisted : bool
+        If True, drop columns that are not covered by allow_prefixes/allow_exact/identifiers/targets.
+    raise_on_banned : bool
+        If True, raise when banned columns are detected (after optional drop).
+    """
+
+    result = evaluate_leak_prone_columns(df.columns, policy=policy)
+    dropped: list[str] = []
+
+    allow_prefixes = _ensure_sequence(allow_prefixes)
+    allow_exact = set(_ensure_sequence(allow_exact))
+    allow_exact.update({col for col in IDENTIFIER_COLUMNS if col in df.columns})
+    allow_exact.update({col for col in NFL_TARGET_COLUMNS if col in df.columns})
+
+    # Permit allowlisted columns even if they match a banned rule (e.g., labels)
+    banned = {col: reason for col, reason in result.banned.items() if col not in allow_exact}
+
+    if banned and drop_banned:
+        df = df.drop(list(banned.keys()))
+        dropped.extend(banned.keys())
+
+    if banned and raise_on_banned:
+        raise ValueError(f"Leak-prone columns detected: {sorted(banned.items())}")
+
+    allowlist_cols: set[str] = set()
+    if allow_prefixes:
+        allowlist_cols.update({c for c in df.columns if c.startswith(allow_prefixes)})
+    allowlist_cols.update({c for c in allow_exact if c in df.columns})
+
+    if drop_non_allowlisted and allowlist_cols:
+        drop_candidates = [c for c in df.columns if c not in allowlist_cols]
+        if drop_candidates:
+            df = df.drop(drop_candidates)
+            dropped.extend(drop_candidates)
+
+    if drop_non_allowlisted and not allowlist_cols:
+        raise ValueError("No allowlisted columns remain after applying leak guard allowlist.")
+
+    # Store adjusted banned info on the result
+    result.banned = banned
+    result.dropped = dropped
+    result.kept = [c for c in df.columns]
+    result.allowlist_kept = sorted(list(allowlist_cols)) if allowlist_cols else []
+    return df, result
+
+
+def build_schema_snapshot(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    metadata: Mapping[str, object] | None = None,
+    banned: Mapping[str, str] | None = None,
+) -> dict:
+    """Render a schema snapshot describing each column and whether it was flagged."""
+
+    banned = banned or {}
+    meta = {
+        "generated_at_utc": datetime.utcnow().isoformat(),
+        "policy_version": policy.version,
+    }
+    meta.update(metadata or {})
+
+    # Extract columns / dtypes
+    if isinstance(df, pl.DataFrame):
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+    else:  # pandas or pandas-like
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+
+    schema = {
+        "metadata": meta,
+        "columns": [],
+    }
+
+    for col, dtype in cols_and_dtypes:
+        tags: list[str] = []
+        if col in IDENTIFIER_COLUMNS:
+            tags.append("id")
+        if col in NFL_TARGET_COLUMNS:
+            tags.append("label")
+        if col.startswith("market_"):
+            tags.append("odds")
+        if col.startswith("injury_") or col.startswith("practice_"):
+            tags.append("injury")
+        if col.startswith("weather_"):
+            tags.append("weather")
+        if col.startswith("ps_"):
+            tags.append("pre_snap")
+        schema["columns"].append(
+            {
+                "name": col,
+                "dtype": dtype,
+                "banned": col in banned,
+                "tags": tags,
+            }
+        )
+    return schema
+
+
+def write_schema_snapshot(path, schema: Mapping[str, object]) -> None:
+    path.parent.mkdir(parents=True, exist_ok=True)
+    with open(path, "w") as fp:
+        json.dump(schema, fp, indent=2, sort_keys=True)
+
+
+__all__ = [
+    "DEFAULT_LEAK_POLICY",
+    "LeakPolicy",
+    "LeakCheckResult",
+    "evaluate_leak_prone_columns",
+    "enforce_leak_guard",
+    "build_schema_snapshot",
+    "write_schema_snapshot",
+]


thinking
**Assessing target columns and allowlist adjustments**

thinking
**Updating NFL target columns**
file update
M /Users/jameswest/Desktop/nfl_predict/utils/general/constants.py
@@ -213,3 +213,13 @@
     'anytime_td',
+    'anytime_td_offense',
+    'anytime_td_all',
+    'anytime_td_rush',
+    'anytime_td_rec',
+    'anytime_td_pass_thrown',
     'td_count',
+    'td_count_offense',
+    'td_count_all',
+    'passing_td',
+    'rushing_td_count',
+    'receiving_td_count',
     'receiving_yards',
apply_patch(auto_approved=true) exited 0 in 85ms:
Success. Updated the following files:
M utils/general/constants.py
file update:
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 5ba68e8bf1acd3a789a76a8857674e6f6433017b..0210d5b7e7ed60a8de7a126d64f5ed76326474c8
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -14,7 +14,7 @@
 
 import logging
 import os
-from datetime import date, timedelta
+from datetime import date, datetime, timedelta
 from typing import Sequence
 
 import polars as pl
@@ -37,6 +37,12 @@
     add_offense_context_features_training,
     _append_offense_context_columns,
 )
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    build_schema_snapshot,
+    enforce_leak_guard,
+    write_schema_snapshot,
+)
 from utils.feature.weather_features import (
     add_weather_forecast_features_training,
     append_weather_context_flags,
@@ -931,6 +937,32 @@
     if market_exprs:
         df_player_game_all = df_player_game_all.with_columns(market_exprs)
     
+    # Leak guard + schema snapshot before persisting
+    spec = get_label_spec(label_version)
+    allow_exact = {spec.primary, *spec.labels.keys(), *spec.aliases.keys()}
+    df_player_game_all, leak_result = enforce_leak_guard(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_exact=allow_exact,
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=True,
+    )
+
+    schema = build_schema_snapshot(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        metadata={
+            "cutoff_label": cutoff_label,
+            "label_version": spec.name,
+        },
+        banned=leak_result.banned,
+    )
+    schema_dir = FEATURE_AUDIT_DIR / "schema" / "anytime_td"
+    schema_path = schema_dir / f"{cutoff_label}_{datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')}.json"
+    write_schema_snapshot(schema_path, schema)
+    logging.info("    Schema snapshot written → %s", schema_path)
+
     # Write final feature matrix
     df_player_game_all = df_player_game_all.with_columns(
         pl.lit(current_cutoff_hours).cast(pl.Float32).alias("decision_horizon_hours")
@@ -951,7 +983,6 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    spec = get_label_spec(label_version)
     label_candidates = {spec.primary, "anytime_td"}
     for label_col in label_candidates:
         if label_col in df_player_game_all.columns:
diff --git a/pipeline/train.py b/pipeline/train.py
index fe70207dcdf25d209ee3ad55080b7ce826347c44..3fab3a05b3f65e8d0e88ec1ddaa71a8857646148
--- a/pipeline/train.py
+++ b/pipeline/train.py
@@ -98,6 +98,7 @@
     fit_team_conformal_sums,
     composite_sum_interval,
 )
+from utils.feature.leak_guard import DEFAULT_LEAK_POLICY, enforce_leak_guard
 from utils.feature.targets import require_target_column
 
 # Ignore specific, noisy warnings from dependencies
@@ -2315,7 +2316,30 @@
                             df_problem[col] = df_problem[col].fillna(df_problem[col].mean())
 
                 df_problem = self._inject_composed_features(df_problem)
-            
+
+            # Leak guard on the problem-scoped frame
+            allow_prefixes = tuple(problem_copy.get('feature_prefixes_to_include') or [])
+            allow_exact = set(problem_copy.get('other_features_to_include') or [])
+            allow_exact.update(input_preds or [])
+            if self.target_col:
+                allow_exact.add(self.target_col)
+            df_problem, leak_info = enforce_leak_guard(
+                df_problem,
+                policy=DEFAULT_LEAK_POLICY,
+                allow_prefixes=allow_prefixes,
+                allow_exact=allow_exact,
+                drop_banned=True,
+                drop_non_allowlisted=False,
+                raise_on_banned=True,
+            )
+            if leak_info.dropped:
+                logger.info(
+                    "Dropped %d leak-prone columns for %s: %s",
+                    len(leak_info.dropped),
+                    problem_name,
+                    sorted(leak_info.dropped),
+                )
+
             self._normalize_datetime_like_columns(df_problem, problem_name)
             df_problem[self.time_col] = pd.to_datetime(df_problem[self.time_col])
             sort_cols = [self.time_col]
diff --git a/tests/test_data_leak_guard.py b/tests/test_data_leak_guard.py
index 8061f2760c0898aaeda29026859e1b9ff5644ba4..3e56665921db89ea523bbdb205d1bb90c21893df
--- a/tests/test_data_leak_guard.py
+++ b/tests/test_data_leak_guard.py
@@ -3,6 +3,14 @@
 import yaml
 from pathlib import Path
 
+import polars as pl
+
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    enforce_leak_guard,
+    evaluate_leak_prone_columns,
+)
+
 
 PROJECT_ROOT = Path(__file__).resolve().parents[1]
 TRAINING_CONFIG = PROJECT_ROOT / "config" / "training.yaml"
@@ -48,3 +56,41 @@
     )
 
 
+def test_leak_guard_flags_pattern_columns():
+    cols = [
+        "market_anytime_td_prob",
+        "final_score",
+        "postgame_anytime_td",
+        "actual_td_count",
+        "safe_feature",
+    ]
+    result = evaluate_leak_prone_columns(cols, policy=DEFAULT_LEAK_POLICY)
+    assert set(result.banned.keys()) == {"final_score", "postgame_anytime_td", "actual_td_count"}
+    assert "safe_feature" in result.kept
+    assert "market_anytime_td_prob" in result.kept
+
+
+def test_enforce_leak_guard_drops_banned_and_keeps_allowlisted():
+    df = pl.DataFrame(
+        {
+            "game_id": ["g1", "g2"],
+            "safe_feature": [1.0, 2.0],
+            "postgame_anytime_td": [1, 0],
+            "final_score": [30, 24],
+        }
+    )
+    cleaned, info = enforce_leak_guard(
+        df,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_prefixes=("safe_",),
+        allow_exact=("game_id",),
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=False,
+    )
+    assert "postgame_anytime_td" not in cleaned.columns
+    assert "final_score" not in cleaned.columns
+    assert "safe_feature" in cleaned.columns
+    assert "game_id" in cleaned.columns
+    assert set(info.dropped) == {"postgame_anytime_td", "final_score"}
+
diff --git a/utils/feature/leak_guard.py b/utils/feature/leak_guard.py
new file mode 100644
index 0000000000000000000000000000000000000000..9faf8cfffc436e0934b2f410aaf252e52f4f95df
--- /dev/null
+++ b/utils/feature/leak_guard.py
@@ -0,0 +1,273 @@
+"""Leak guardrails for feature matrices.
+
+This module centralizes pattern-based leak detection so both feature assembly
+and training can fail fast when post-outcome columns sneak into the data.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+from datetime import datetime
+import json
+import re
+from typing import Iterable, Mapping, Sequence
+
+import polars as pl
+
+from utils.general.constants import IDENTIFIER_COLUMNS, LEAK_PRONE_COLUMNS, NFL_TARGET_COLUMNS
+
+try:  # Optional dependency when imported from training (pandas path)
+    import pandas as pd  # type: ignore
+except Exception:  # pragma: no cover - optional dependency
+    pd = None
+
+
+@dataclass(frozen=True)
+class LeakPolicy:
+    version: str
+    banned_exact: set[str]
+    banned_prefixes: tuple[str, ...]
+    banned_suffixes: tuple[str, ...]
+    banned_regex: tuple[tuple[re.Pattern[str], str], ...]
+    description: str = ""
+
+
+@dataclass
+class LeakCheckResult:
+    policy_version: str
+    banned: dict[str, str]
+    kept: list[str]
+    dropped: list[str]
+    allowlist_kept: list[str]
+
+
+# Core policy tuned for anytime-TD style problems (can be extended per-problem).
+_BASE_BANNED_EXACT = set(LEAK_PRONE_COLUMNS) | {
+    "final_score",
+    "final_total",
+    "points_scored",
+    "actual_td_count",
+    "actual_anytime_td",
+    "postgame_anytime_td",
+    "postgame_td_count",
+}
+_BASE_BANNED_PREFIXES = (
+    "postgame_",
+    "post_game_",
+    "post_",
+    "live_",
+    "actual_",
+    "realized_",
+    "final_",
+    "postmatch_",
+)
+_BASE_BANNED_SUFFIXES = (
+    "_post",
+    "_postgame",
+    "_final",
+    "_fullgame",
+    "_actual",
+)
+_BASE_BANNED_REGEX: tuple[tuple[re.Pattern[str], str], ...] = (
+    (re.compile(r".*post.?game.*", flags=re.IGNORECASE), "postgame marker"),
+    (re.compile(r".*final_score.*", flags=re.IGNORECASE), "final score"),
+    (re.compile(r".*actual.*td.*", flags=re.IGNORECASE), "actual TD total"),
+    (re.compile(r".*anytime_td.*(post|final|actual).*", flags=re.IGNORECASE), "post-decision anytime TD"),
+    (re.compile(r".*fullgame.*", flags=re.IGNORECASE), "full game cumulative value"),
+)
+
+DEFAULT_LEAK_POLICY = LeakPolicy(
+    version="v1",
+    description="Core post-outcome leak guard for NFL anytime TD features.",
+    banned_exact=_BASE_BANNED_EXACT,
+    banned_prefixes=_BASE_BANNED_PREFIXES,
+    banned_suffixes=_BASE_BANNED_SUFFIXES,
+    banned_regex=_BASE_BANNED_REGEX,
+)
+
+
+def _ensure_sequence(value: Sequence[str] | str | None) -> tuple[str, ...]:
+    if value is None:
+        return ()
+    if isinstance(value, str):
+        return (value,)
+    return tuple(value)
+
+
+def evaluate_leak_prone_columns(
+    columns: Iterable[str],
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+) -> LeakCheckResult:
+    """Identify leak-prone columns using the configured policy."""
+
+    banned: dict[str, str] = {}
+    columns_list = list(columns)
+    for col in columns_list:
+        if col in policy.banned_exact:
+            banned[col] = "exact"
+            continue
+        for prefix in policy.banned_prefixes:
+            if col.startswith(prefix):
+                banned[col] = f"prefix:{prefix}"
+                break
+        if col in banned:
+            continue
+        for suffix in policy.banned_suffixes:
+            if col.endswith(suffix):
+                banned[col] = f"suffix:{suffix}"
+                break
+        if col in banned:
+            continue
+        for pattern, reason in policy.banned_regex:
+            if pattern.match(col):
+                banned[col] = reason
+                break
+
+    kept = [c for c in columns_list if c not in banned]
+    return LeakCheckResult(
+        policy_version=policy.version,
+        banned=banned,
+        kept=kept,
+        dropped=[],
+        allowlist_kept=[],
+    )
+
+
+def enforce_leak_guard(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    allow_prefixes: Sequence[str] | str | None = None,
+    allow_exact: Sequence[str] | str | None = None,
+    drop_banned: bool = True,
+    drop_non_allowlisted: bool = False,
+    raise_on_banned: bool = True,
+) -> tuple[pl.DataFrame | "pd.DataFrame", LeakCheckResult]:
+    """Apply leak guardrails to a feature frame.
+
+    Parameters
+    ----------
+    df : DataFrame
+        Polars or pandas DataFrame.
+    policy : LeakPolicy
+        Leak policy to apply.
+    allow_prefixes : Sequence[str] | str | None
+        Optional prefixes that define the allowed feature surface for a problem.
+    allow_exact : Sequence[str] | str | None
+        Explicitly allowed columns (e.g., identifiers).
+    drop_banned : bool
+        If True, drop any banned columns automatically.
+    drop_non_allowlisted : bool
+        If True, drop columns that are not covered by allow_prefixes/allow_exact/identifiers/targets.
+    raise_on_banned : bool
+        If True, raise when banned columns are detected (after optional drop).
+    """
+
+    result = evaluate_leak_prone_columns(df.columns, policy=policy)
+    dropped: list[str] = []
+
+    allow_prefixes = _ensure_sequence(allow_prefixes)
+    allow_exact = set(_ensure_sequence(allow_exact))
+    allow_exact.update({col for col in IDENTIFIER_COLUMNS if col in df.columns})
+    allow_exact.update({col for col in NFL_TARGET_COLUMNS if col in df.columns})
+
+    # Permit allowlisted columns even if they match a banned rule (e.g., labels)
+    banned = {col: reason for col, reason in result.banned.items() if col not in allow_exact}
+
+    if banned and drop_banned:
+        df = df.drop(list(banned.keys()))
+        dropped.extend(banned.keys())
+
+    if banned and raise_on_banned:
+        raise ValueError(f"Leak-prone columns detected: {sorted(banned.items())}")
+
+    allowlist_cols: set[str] = set()
+    if allow_prefixes:
+        allowlist_cols.update({c for c in df.columns if c.startswith(allow_prefixes)})
+    allowlist_cols.update({c for c in allow_exact if c in df.columns})
+
+    if drop_non_allowlisted and allowlist_cols:
+        drop_candidates = [c for c in df.columns if c not in allowlist_cols]
+        if drop_candidates:
+            df = df.drop(drop_candidates)
+            dropped.extend(drop_candidates)
+
+    if drop_non_allowlisted and not allowlist_cols:
+        raise ValueError("No allowlisted columns remain after applying leak guard allowlist.")
+
+    # Store adjusted banned info on the result
+    result.banned = banned
+    result.dropped = dropped
+    result.kept = [c for c in df.columns]
+    result.allowlist_kept = sorted(list(allowlist_cols)) if allowlist_cols else []
+    return df, result
+
+
+def build_schema_snapshot(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    metadata: Mapping[str, object] | None = None,
+    banned: Mapping[str, str] | None = None,
+) -> dict:
+    """Render a schema snapshot describing each column and whether it was flagged."""
+
+    banned = banned or {}
+    meta = {
+        "generated_at_utc": datetime.utcnow().isoformat(),
+        "policy_version": policy.version,
+    }
+    meta.update(metadata or {})
+
+    # Extract columns / dtypes
+    if isinstance(df, pl.DataFrame):
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+    else:  # pandas or pandas-like
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+
+    schema = {
+        "metadata": meta,
+        "columns": [],
+    }
+
+    for col, dtype in cols_and_dtypes:
+        tags: list[str] = []
+        if col in IDENTIFIER_COLUMNS:
+            tags.append("id")
+        if col in NFL_TARGET_COLUMNS:
+            tags.append("label")
+        if col.startswith("market_"):
+            tags.append("odds")
+        if col.startswith("injury_") or col.startswith("practice_"):
+            tags.append("injury")
+        if col.startswith("weather_"):
+            tags.append("weather")
+        if col.startswith("ps_"):
+            tags.append("pre_snap")
+        schema["columns"].append(
+            {
+                "name": col,
+                "dtype": dtype,
+                "banned": col in banned,
+                "tags": tags,
+            }
+        )
+    return schema
+
+
+def write_schema_snapshot(path, schema: Mapping[str, object]) -> None:
+    path.parent.mkdir(parents=True, exist_ok=True)
+    with open(path, "w") as fp:
+        json.dump(schema, fp, indent=2, sort_keys=True)
+
+
+__all__ = [
+    "DEFAULT_LEAK_POLICY",
+    "LeakPolicy",
+    "LeakCheckResult",
+    "evaluate_leak_prone_columns",
+    "enforce_leak_guard",
+    "build_schema_snapshot",
+    "write_schema_snapshot",
+]
diff --git a/utils/general/constants.py b/utils/general/constants.py
index d94b4260ad877484da843fa99ae2caf37e8493f4..dea87caa354d94e4a08b1762d2bd8dcd4c8caa3a
--- a/utils/general/constants.py
+++ b/utils/general/constants.py
@@ -211,7 +211,17 @@
 
 NFL_TARGET_COLUMNS: Tuple[str, ...] = (
     'anytime_td',
+    'anytime_td_offense',
+    'anytime_td_all',
+    'anytime_td_rush',
+    'anytime_td_rec',
+    'anytime_td_pass_thrown',
     'td_count',
+    'td_count_offense',
+    'td_count_all',
+    'passing_td',
+    'rushing_td_count',
+    'receiving_td_count',
     'receiving_yards',
     'rushing_yards',
     'passing_yards',

file update:
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 5ba68e8bf1acd3a789a76a8857674e6f6433017b..0210d5b7e7ed60a8de7a126d64f5ed76326474c8
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -14,7 +14,7 @@
 
 import logging
 import os
-from datetime import date, timedelta
+from datetime import date, datetime, timedelta
 from typing import Sequence
 
 import polars as pl
@@ -37,6 +37,12 @@
     add_offense_context_features_training,
     _append_offense_context_columns,
 )
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    build_schema_snapshot,
+    enforce_leak_guard,
+    write_schema_snapshot,
+)
 from utils.feature.weather_features import (
     add_weather_forecast_features_training,
     append_weather_context_flags,
@@ -931,6 +937,32 @@
     if market_exprs:
         df_player_game_all = df_player_game_all.with_columns(market_exprs)
     
+    # Leak guard + schema snapshot before persisting
+    spec = get_label_spec(label_version)
+    allow_exact = {spec.primary, *spec.labels.keys(), *spec.aliases.keys()}
+    df_player_game_all, leak_result = enforce_leak_guard(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_exact=allow_exact,
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=True,
+    )
+
+    schema = build_schema_snapshot(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        metadata={
+            "cutoff_label": cutoff_label,
+            "label_version": spec.name,
+        },
+        banned=leak_result.banned,
+    )
+    schema_dir = FEATURE_AUDIT_DIR / "schema" / "anytime_td"
+    schema_path = schema_dir / f"{cutoff_label}_{datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')}.json"
+    write_schema_snapshot(schema_path, schema)
+    logging.info("    Schema snapshot written → %s", schema_path)
+
     # Write final feature matrix
     df_player_game_all = df_player_game_all.with_columns(
         pl.lit(current_cutoff_hours).cast(pl.Float32).alias("decision_horizon_hours")
@@ -951,7 +983,6 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    spec = get_label_spec(label_version)
     label_candidates = {spec.primary, "anytime_td"}
     for label_col in label_candidates:
         if label_col in df_player_game_all.columns:
diff --git a/pipeline/train.py b/pipeline/train.py
index fe70207dcdf25d209ee3ad55080b7ce826347c44..3fab3a05b3f65e8d0e88ec1ddaa71a8857646148
--- a/pipeline/train.py
+++ b/pipeline/train.py
@@ -98,6 +98,7 @@
     fit_team_conformal_sums,
     composite_sum_interval,
 )
+from utils.feature.leak_guard import DEFAULT_LEAK_POLICY, enforce_leak_guard
 from utils.feature.targets import require_target_column
 
 # Ignore specific, noisy warnings from dependencies
@@ -2315,7 +2316,30 @@
                             df_problem[col] = df_problem[col].fillna(df_problem[col].mean())
 
                 df_problem = self._inject_composed_features(df_problem)
-            
+
+            # Leak guard on the problem-scoped frame
+            allow_prefixes = tuple(problem_copy.get('feature_prefixes_to_include') or [])
+            allow_exact = set(problem_copy.get('other_features_to_include') or [])
+            allow_exact.update(input_preds or [])
+            if self.target_col:
+                allow_exact.add(self.target_col)
+            df_problem, leak_info = enforce_leak_guard(
+                df_problem,
+                policy=DEFAULT_LEAK_POLICY,
+                allow_prefixes=allow_prefixes,
+                allow_exact=allow_exact,
+                drop_banned=True,
+                drop_non_allowlisted=False,
+                raise_on_banned=True,
+            )
+            if leak_info.dropped:
+                logger.info(
+                    "Dropped %d leak-prone columns for %s: %s",
+                    len(leak_info.dropped),
+                    problem_name,
+                    sorted(leak_info.dropped),
+                )
+
             self._normalize_datetime_like_columns(df_problem, problem_name)
             df_problem[self.time_col] = pd.to_datetime(df_problem[self.time_col])
             sort_cols = [self.time_col]
diff --git a/tests/test_data_leak_guard.py b/tests/test_data_leak_guard.py
index 8061f2760c0898aaeda29026859e1b9ff5644ba4..3e56665921db89ea523bbdb205d1bb90c21893df
--- a/tests/test_data_leak_guard.py
+++ b/tests/test_data_leak_guard.py
@@ -3,6 +3,14 @@
 import yaml
 from pathlib import Path
 
+import polars as pl
+
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    enforce_leak_guard,
+    evaluate_leak_prone_columns,
+)
+
 
 PROJECT_ROOT = Path(__file__).resolve().parents[1]
 TRAINING_CONFIG = PROJECT_ROOT / "config" / "training.yaml"
@@ -48,3 +56,41 @@
     )
 
 
+def test_leak_guard_flags_pattern_columns():
+    cols = [
+        "market_anytime_td_prob",
+        "final_score",
+        "postgame_anytime_td",
+        "actual_td_count",
+        "safe_feature",
+    ]
+    result = evaluate_leak_prone_columns(cols, policy=DEFAULT_LEAK_POLICY)
+    assert set(result.banned.keys()) == {"final_score", "postgame_anytime_td", "actual_td_count"}
+    assert "safe_feature" in result.kept
+    assert "market_anytime_td_prob" in result.kept
+
+
+def test_enforce_leak_guard_drops_banned_and_keeps_allowlisted():
+    df = pl.DataFrame(
+        {
+            "game_id": ["g1", "g2"],
+            "safe_feature": [1.0, 2.0],
+            "postgame_anytime_td": [1, 0],
+            "final_score": [30, 24],
+        }
+    )
+    cleaned, info = enforce_leak_guard(
+        df,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_prefixes=("safe_",),
+        allow_exact=("game_id",),
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=False,
+    )
+    assert "postgame_anytime_td" not in cleaned.columns
+    assert "final_score" not in cleaned.columns
+    assert "safe_feature" in cleaned.columns
+    assert "game_id" in cleaned.columns
+    assert set(info.dropped) == {"postgame_anytime_td", "final_score"}
+
diff --git a/utils/feature/leak_guard.py b/utils/feature/leak_guard.py
new file mode 100644
index 0000000000000000000000000000000000000000..9faf8cfffc436e0934b2f410aaf252e52f4f95df
--- /dev/null
+++ b/utils/feature/leak_guard.py
@@ -0,0 +1,273 @@
+"""Leak guardrails for feature matrices.
+
+This module centralizes pattern-based leak detection so both feature assembly
+and training can fail fast when post-outcome columns sneak into the data.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+from datetime import datetime
+import json
+import re
+from typing import Iterable, Mapping, Sequence
+
+import polars as pl
+
+from utils.general.constants import IDENTIFIER_COLUMNS, LEAK_PRONE_COLUMNS, NFL_TARGET_COLUMNS
+
+try:  # Optional dependency when imported from training (pandas path)
+    import pandas as pd  # type: ignore
+except Exception:  # pragma: no cover - optional dependency
+    pd = None
+
+
+@dataclass(frozen=True)
+class LeakPolicy:
+    version: str
+    banned_exact: set[str]
+    banned_prefixes: tuple[str, ...]
+    banned_suffixes: tuple[str, ...]
+    banned_regex: tuple[tuple[re.Pattern[str], str], ...]
+    description: str = ""
+
+
+@dataclass
+class LeakCheckResult:
+    policy_version: str
+    banned: dict[str, str]
+    kept: list[str]
+    dropped: list[str]
+    allowlist_kept: list[str]
+
+
+# Core policy tuned for anytime-TD style problems (can be extended per-problem).
+_BASE_BANNED_EXACT = set(LEAK_PRONE_COLUMNS) | {
+    "final_score",
+    "final_total",
+    "points_scored",
+    "actual_td_count",
+    "actual_anytime_td",
+    "postgame_anytime_td",
+    "postgame_td_count",
+}
+_BASE_BANNED_PREFIXES = (
+    "postgame_",
+    "post_game_",
+    "post_",
+    "live_",
+    "actual_",
+    "realized_",
+    "final_",
+    "postmatch_",
+)
+_BASE_BANNED_SUFFIXES = (
+    "_post",
+    "_postgame",
+    "_final",
+    "_fullgame",
+    "_actual",
+)
+_BASE_BANNED_REGEX: tuple[tuple[re.Pattern[str], str], ...] = (
+    (re.compile(r".*post.?game.*", flags=re.IGNORECASE), "postgame marker"),
+    (re.compile(r".*final_score.*", flags=re.IGNORECASE), "final score"),
+    (re.compile(r".*actual.*td.*", flags=re.IGNORECASE), "actual TD total"),
+    (re.compile(r".*anytime_td.*(post|final|actual).*", flags=re.IGNORECASE), "post-decision anytime TD"),
+    (re.compile(r".*fullgame.*", flags=re.IGNORECASE), "full game cumulative value"),
+)
+
+DEFAULT_LEAK_POLICY = LeakPolicy(
+    version="v1",
+    description="Core post-outcome leak guard for NFL anytime TD features.",
+    banned_exact=_BASE_BANNED_EXACT,
+    banned_prefixes=_BASE_BANNED_PREFIXES,
+    banned_suffixes=_BASE_BANNED_SUFFIXES,
+    banned_regex=_BASE_BANNED_REGEX,
+)
+
+
+def _ensure_sequence(value: Sequence[str] | str | None) -> tuple[str, ...]:
+    if value is None:
+        return ()
+    if isinstance(value, str):
+        return (value,)
+    return tuple(value)
+
+
+def evaluate_leak_prone_columns(
+    columns: Iterable[str],
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+) -> LeakCheckResult:
+    """Identify leak-prone columns using the configured policy."""
+
+    banned: dict[str, str] = {}
+    columns_list = list(columns)
+    for col in columns_list:
+        if col in policy.banned_exact:
+            banned[col] = "exact"
+            continue
+        for prefix in policy.banned_prefixes:
+            if col.startswith(prefix):
+                banned[col] = f"prefix:{prefix}"
+                break
+        if col in banned:
+            continue
+        for suffix in policy.banned_suffixes:
+            if col.endswith(suffix):
+                banned[col] = f"suffix:{suffix}"
+                break
+        if col in banned:
+            continue
+        for pattern, reason in policy.banned_regex:
+            if pattern.match(col):
+                banned[col] = reason
+                break
+
+    kept = [c for c in columns_list if c not in banned]
+    return LeakCheckResult(
+        policy_version=policy.version,
+        banned=banned,
+        kept=kept,
+        dropped=[],
+        allowlist_kept=[],
+    )
+
+
+def enforce_leak_guard(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    allow_prefixes: Sequence[str] | str | None = None,
+    allow_exact: Sequence[str] | str | None = None,
+    drop_banned: bool = True,
+    drop_non_allowlisted: bool = False,
+    raise_on_banned: bool = True,
+) -> tuple[pl.DataFrame | "pd.DataFrame", LeakCheckResult]:
+    """Apply leak guardrails to a feature frame.
+
+    Parameters
+    ----------
+    df : DataFrame
+        Polars or pandas DataFrame.
+    policy : LeakPolicy
+        Leak policy to apply.
+    allow_prefixes : Sequence[str] | str | None
+        Optional prefixes that define the allowed feature surface for a problem.
+    allow_exact : Sequence[str] | str | None
+        Explicitly allowed columns (e.g., identifiers).
+    drop_banned : bool
+        If True, drop any banned columns automatically.
+    drop_non_allowlisted : bool
+        If True, drop columns that are not covered by allow_prefixes/allow_exact/identifiers/targets.
+    raise_on_banned : bool
+        If True, raise when banned columns are detected (after optional drop).
+    """
+
+    result = evaluate_leak_prone_columns(df.columns, policy=policy)
+    dropped: list[str] = []
+
+    allow_prefixes = _ensure_sequence(allow_prefixes)
+    allow_exact = set(_ensure_sequence(allow_exact))
+    allow_exact.update({col for col in IDENTIFIER_COLUMNS if col in df.columns})
+    allow_exact.update({col for col in NFL_TARGET_COLUMNS if col in df.columns})
+
+    # Permit allowlisted columns even if they match a banned rule (e.g., labels)
+    banned = {col: reason for col, reason in result.banned.items() if col not in allow_exact}
+
+    if banned and drop_banned:
+        df = df.drop(list(banned.keys()))
+        dropped.extend(banned.keys())
+
+    if banned and raise_on_banned:
+        raise ValueError(f"Leak-prone columns detected: {sorted(banned.items())}")
+
+    allowlist_cols: set[str] = set()
+    if allow_prefixes:
+        allowlist_cols.update({c for c in df.columns if c.startswith(allow_prefixes)})
+    allowlist_cols.update({c for c in allow_exact if c in df.columns})
+
+    if drop_non_allowlisted and allowlist_cols:
+        drop_candidates = [c for c in df.columns if c not in allowlist_cols]
+        if drop_candidates:
+            df = df.drop(drop_candidates)
+            dropped.extend(drop_candidates)
+
+    if drop_non_allowlisted and not allowlist_cols:
+        raise ValueError("No allowlisted columns remain after applying leak guard allowlist.")
+
+    # Store adjusted banned info on the result
+    result.banned = banned
+    result.dropped = dropped
+    result.kept = [c for c in df.columns]
+    result.allowlist_kept = sorted(list(allowlist_cols)) if allowlist_cols else []
+    return df, result
+
+
+def build_schema_snapshot(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    metadata: Mapping[str, object] | None = None,
+    banned: Mapping[str, str] | None = None,
+) -> dict:
+    """Render a schema snapshot describing each column and whether it was flagged."""
+
+    banned = banned or {}
+    meta = {
+        "generated_at_utc": datetime.utcnow().isoformat(),
+        "policy_version": policy.version,
+    }
+    meta.update(metadata or {})
+
+    # Extract columns / dtypes
+    if isinstance(df, pl.DataFrame):
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+    else:  # pandas or pandas-like
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+
+    schema = {
+        "metadata": meta,
+        "columns": [],
+    }
+
+    for col, dtype in cols_and_dtypes:
+        tags: list[str] = []
+        if col in IDENTIFIER_COLUMNS:
+            tags.append("id")
+        if col in NFL_TARGET_COLUMNS:
+            tags.append("label")
+        if col.startswith("market_"):
+            tags.append("odds")
+        if col.startswith("injury_") or col.startswith("practice_"):
+            tags.append("injury")
+        if col.startswith("weather_"):
+            tags.append("weather")
+        if col.startswith("ps_"):
+            tags.append("pre_snap")
+        schema["columns"].append(
+            {
+                "name": col,
+                "dtype": dtype,
+                "banned": col in banned,
+                "tags": tags,
+            }
+        )
+    return schema
+
+
+def write_schema_snapshot(path, schema: Mapping[str, object]) -> None:
+    path.parent.mkdir(parents=True, exist_ok=True)
+    with open(path, "w") as fp:
+        json.dump(schema, fp, indent=2, sort_keys=True)
+
+
+__all__ = [
+    "DEFAULT_LEAK_POLICY",
+    "LeakPolicy",
+    "LeakCheckResult",
+    "evaluate_leak_prone_columns",
+    "enforce_leak_guard",
+    "build_schema_snapshot",
+    "write_schema_snapshot",
+]
diff --git a/utils/general/constants.py b/utils/general/constants.py
index d94b4260ad877484da843fa99ae2caf37e8493f4..dea87caa354d94e4a08b1762d2bd8dcd4c8caa3a
--- a/utils/general/constants.py
+++ b/utils/general/constants.py
@@ -211,7 +211,17 @@
 
 NFL_TARGET_COLUMNS: Tuple[str, ...] = (
     'anytime_td',
+    'anytime_td_offense',
+    'anytime_td_all',
+    'anytime_td_rush',
+    'anytime_td_rec',
+    'anytime_td_pass_thrown',
     'td_count',
+    'td_count_offense',
+    'td_count_all',
+    'passing_td',
+    'rushing_td_count',
+    'receiving_td_count',
     'receiving_yards',
     'rushing_yards',
     'passing_yards',


thinking
**Reviewing feature guard and market horizon alignment**

I'm making sure label columns beyond the spec are properly allowed by the feature guard, checking the allowlist and constants related to leak-prone columns. Then, I'll focus on aligning market feature horizons by inspecting existing logic in player game level files, searching for functions and columns related to market features and their time horizons, aiming to implement filtering or adjustments near where market features are joined to datasets.
exec
/bin/zsh -lc 'cd /Users/jameswest/Desktop/nfl_predict && rg "PLAYER_MARKET_COLUMNS" -n utils/feature/player_game_level.py' in /Users/jameswest/Desktop/nfl_predict succeeded in 3.06s:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
120:PLAYER_MARKET_COLUMNS = PLAYER_MARKET_FLOAT_COLUMNS + [
file update:
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 5ba68e8bf1acd3a789a76a8857674e6f6433017b..0210d5b7e7ed60a8de7a126d64f5ed76326474c8
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -14,7 +14,7 @@
 
 import logging
 import os
-from datetime import date, timedelta
+from datetime import date, datetime, timedelta
 from typing import Sequence
 
 import polars as pl
@@ -37,6 +37,12 @@
     add_offense_context_features_training,
     _append_offense_context_columns,
 )
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    build_schema_snapshot,
+    enforce_leak_guard,
+    write_schema_snapshot,
+)
 from utils.feature.weather_features import (
     add_weather_forecast_features_training,
     append_weather_context_flags,
@@ -931,6 +937,32 @@
     if market_exprs:
         df_player_game_all = df_player_game_all.with_columns(market_exprs)
     
+    # Leak guard + schema snapshot before persisting
+    spec = get_label_spec(label_version)
+    allow_exact = {spec.primary, *spec.labels.keys(), *spec.aliases.keys()}
+    df_player_game_all, leak_result = enforce_leak_guard(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_exact=allow_exact,
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=True,
+    )
+
+    schema = build_schema_snapshot(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        metadata={
+            "cutoff_label": cutoff_label,
+            "label_version": spec.name,
+        },
+        banned=leak_result.banned,
+    )
+    schema_dir = FEATURE_AUDIT_DIR / "schema" / "anytime_td"
+    schema_path = schema_dir / f"{cutoff_label}_{datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')}.json"
+    write_schema_snapshot(schema_path, schema)
+    logging.info("    Schema snapshot written → %s", schema_path)
+
     # Write final feature matrix
     df_player_game_all = df_player_game_all.with_columns(
         pl.lit(current_cutoff_hours).cast(pl.Float32).alias("decision_horizon_hours")
@@ -951,7 +983,6 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    spec = get_label_spec(label_version)
     label_candidates = {spec.primary, "anytime_td"}
     for label_col in label_candidates:
         if label_col in df_player_game_all.columns:
diff --git a/pipeline/train.py b/pipeline/train.py
index fe70207dcdf25d209ee3ad55080b7ce826347c44..3fab3a05b3f65e8d0e88ec1ddaa71a8857646148
--- a/pipeline/train.py
+++ b/pipeline/train.py
@@ -98,6 +98,7 @@
     fit_team_conformal_sums,
     composite_sum_interval,
 )
+from utils.feature.leak_guard import DEFAULT_LEAK_POLICY, enforce_leak_guard
 from utils.feature.targets import require_target_column
 
 # Ignore specific, noisy warnings from dependencies
@@ -2315,7 +2316,30 @@
                             df_problem[col] = df_problem[col].fillna(df_problem[col].mean())
 
                 df_problem = self._inject_composed_features(df_problem)
-            
+
+            # Leak guard on the problem-scoped frame
+            allow_prefixes = tuple(problem_copy.get('feature_prefixes_to_include') or [])
+            allow_exact = set(problem_copy.get('other_features_to_include') or [])
+            allow_exact.update(input_preds or [])
+            if self.target_col:
+                allow_exact.add(self.target_col)
+            df_problem, leak_info = enforce_leak_guard(
+                df_problem,
+                policy=DEFAULT_LEAK_POLICY,
+                allow_prefixes=allow_prefixes,
+                allow_exact=allow_exact,
+                drop_banned=True,
+                drop_non_allowlisted=False,
+                raise_on_banned=True,
+            )
+            if leak_info.dropped:
+                logger.info(
+                    "Dropped %d leak-prone columns for %s: %s",
+                    len(leak_info.dropped),
+                    problem_name,
+                    sorted(leak_info.dropped),
+                )
+
             self._normalize_datetime_like_columns(df_problem, problem_name)
             df_problem[self.time_col] = pd.to_datetime(df_problem[self.time_col])
             sort_cols = [self.time_col]
diff --git a/tests/test_data_leak_guard.py b/tests/test_data_leak_guard.py
index 8061f2760c0898aaeda29026859e1b9ff5644ba4..3e56665921db89ea523bbdb205d1bb90c21893df
--- a/tests/test_data_leak_guard.py
+++ b/tests/test_data_leak_guard.py
@@ -3,6 +3,14 @@
 import yaml
 from pathlib import Path
 
+import polars as pl
+
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    enforce_leak_guard,
+    evaluate_leak_prone_columns,
+)
+
 
 PROJECT_ROOT = Path(__file__).resolve().parents[1]
 TRAINING_CONFIG = PROJECT_ROOT / "config" / "training.yaml"
@@ -48,3 +56,41 @@
     )
 
 
+def test_leak_guard_flags_pattern_columns():
+    cols = [
+        "market_anytime_td_prob",
+        "final_score",
+        "postgame_anytime_td",
+        "actual_td_count",
+        "safe_feature",
+    ]
+    result = evaluate_leak_prone_columns(cols, policy=DEFAULT_LEAK_POLICY)
+    assert set(result.banned.keys()) == {"final_score", "postgame_anytime_td", "actual_td_count"}
+    assert "safe_feature" in result.kept
+    assert "market_anytime_td_prob" in result.kept
+
+
+def test_enforce_leak_guard_drops_banned_and_keeps_allowlisted():
+    df = pl.DataFrame(
+        {
+            "game_id": ["g1", "g2"],
+            "safe_feature": [1.0, 2.0],
+            "postgame_anytime_td": [1, 0],
+            "final_score": [30, 24],
+        }
+    )
+    cleaned, info = enforce_leak_guard(
+        df,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_prefixes=("safe_",),
+        allow_exact=("game_id",),
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=False,
+    )
+    assert "postgame_anytime_td" not in cleaned.columns
+    assert "final_score" not in cleaned.columns
+    assert "safe_feature" in cleaned.columns
+    assert "game_id" in cleaned.columns
+    assert set(info.dropped) == {"postgame_anytime_td", "final_score"}
+
diff --git a/utils/feature/leak_guard.py b/utils/feature/leak_guard.py
new file mode 100644
index 0000000000000000000000000000000000000000..9faf8cfffc436e0934b2f410aaf252e52f4f95df
--- /dev/null
+++ b/utils/feature/leak_guard.py
@@ -0,0 +1,273 @@
+"""Leak guardrails for feature matrices.
+
+This module centralizes pattern-based leak detection so both feature assembly
+and training can fail fast when post-outcome columns sneak into the data.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+from datetime import datetime
+import json
+import re
+from typing import Iterable, Mapping, Sequence
+
+import polars as pl
+
+from utils.general.constants import IDENTIFIER_COLUMNS, LEAK_PRONE_COLUMNS, NFL_TARGET_COLUMNS
+
+try:  # Optional dependency when imported from training (pandas path)
+    import pandas as pd  # type: ignore
+except Exception:  # pragma: no cover - optional dependency
+    pd = None
+
+
+@dataclass(frozen=True)
+class LeakPolicy:
+    version: str
+    banned_exact: set[str]
+    banned_prefixes: tuple[str, ...]
+    banned_suffixes: tuple[str, ...]
+    banned_regex: tuple[tuple[re.Pattern[str], str], ...]
+    description: str = ""
+
+
+@dataclass
+class LeakCheckResult:
+    policy_version: str
+    banned: dict[str, str]
+    kept: list[str]
+    dropped: list[str]
+    allowlist_kept: list[str]
+
+
+# Core policy tuned for anytime-TD style problems (can be extended per-problem).
+_BASE_BANNED_EXACT = set(LEAK_PRONE_COLUMNS) | {
+    "final_score",
+    "final_total",
+    "points_scored",
+    "actual_td_count",
+    "actual_anytime_td",
+    "postgame_anytime_td",
+    "postgame_td_count",
+}
+_BASE_BANNED_PREFIXES = (
+    "postgame_",
+    "post_game_",
+    "post_",
+    "live_",
+    "actual_",
+    "realized_",
+    "final_",
+    "postmatch_",
+)
+_BASE_BANNED_SUFFIXES = (
+    "_post",
+    "_postgame",
+    "_final",
+    "_fullgame",
+    "_actual",
+)
+_BASE_BANNED_REGEX: tuple[tuple[re.Pattern[str], str], ...] = (
+    (re.compile(r".*post.?game.*", flags=re.IGNORECASE), "postgame marker"),
+    (re.compile(r".*final_score.*", flags=re.IGNORECASE), "final score"),
+    (re.compile(r".*actual.*td.*", flags=re.IGNORECASE), "actual TD total"),
+    (re.compile(r".*anytime_td.*(post|final|actual).*", flags=re.IGNORECASE), "post-decision anytime TD"),
+    (re.compile(r".*fullgame.*", flags=re.IGNORECASE), "full game cumulative value"),
+)
+
+DEFAULT_LEAK_POLICY = LeakPolicy(
+    version="v1",
+    description="Core post-outcome leak guard for NFL anytime TD features.",
+    banned_exact=_BASE_BANNED_EXACT,
+    banned_prefixes=_BASE_BANNED_PREFIXES,
+    banned_suffixes=_BASE_BANNED_SUFFIXES,
+    banned_regex=_BASE_BANNED_REGEX,
+)
+
+
+def _ensure_sequence(value: Sequence[str] | str | None) -> tuple[str, ...]:
+    if value is None:
+        return ()
+    if isinstance(value, str):
+        return (value,)
+    return tuple(value)
+
+
+def evaluate_leak_prone_columns(
+    columns: Iterable[str],
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+) -> LeakCheckResult:
+    """Identify leak-prone columns using the configured policy."""
+
+    banned: dict[str, str] = {}
+    columns_list = list(columns)
+    for col in columns_list:
+        if col in policy.banned_exact:
+            banned[col] = "exact"
+            continue
+        for prefix in policy.banned_prefixes:
+            if col.startswith(prefix):
+                banned[col] = f"prefix:{prefix}"
+                break
+        if col in banned:
+            continue
+        for suffix in policy.banned_suffixes:
+            if col.endswith(suffix):
+                banned[col] = f"suffix:{suffix}"
+                break
+        if col in banned:
+            continue
+        for pattern, reason in policy.banned_regex:
+            if pattern.match(col):
+                banned[col] = reason
+                break
+
+    kept = [c for c in columns_list if c not in banned]
+    return LeakCheckResult(
+        policy_version=policy.version,
+        banned=banned,
+        kept=kept,
+        dropped=[],
+        allowlist_kept=[],
+    )
+
+
+def enforce_leak_guard(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    allow_prefixes: Sequence[str] | str | None = None,
+    allow_exact: Sequence[str] | str | None = None,
+    drop_banned: bool = True,
+    drop_non_allowlisted: bool = False,
+    raise_on_banned: bool = True,
+) -> tuple[pl.DataFrame | "pd.DataFrame", LeakCheckResult]:
+    """Apply leak guardrails to a feature frame.
+
+    Parameters
+    ----------
+    df : DataFrame
+        Polars or pandas DataFrame.
+    policy : LeakPolicy
+        Leak policy to apply.
+    allow_prefixes : Sequence[str] | str | None
+        Optional prefixes that define the allowed feature surface for a problem.
+    allow_exact : Sequence[str] | str | None
+        Explicitly allowed columns (e.g., identifiers).
+    drop_banned : bool
+        If True, drop any banned columns automatically.
+    drop_non_allowlisted : bool
+        If True, drop columns that are not covered by allow_prefixes/allow_exact/identifiers/targets.
+    raise_on_banned : bool
+        If True, raise when banned columns are detected (after optional drop).
+    """
+
+    result = evaluate_leak_prone_columns(df.columns, policy=policy)
+    dropped: list[str] = []
+
+    allow_prefixes = _ensure_sequence(allow_prefixes)
+    allow_exact = set(_ensure_sequence(allow_exact))
+    allow_exact.update({col for col in IDENTIFIER_COLUMNS if col in df.columns})
+    allow_exact.update({col for col in NFL_TARGET_COLUMNS if col in df.columns})
+
+    # Permit allowlisted columns even if they match a banned rule (e.g., labels)
+    banned = {col: reason for col, reason in result.banned.items() if col not in allow_exact}
+
+    if banned and drop_banned:
+        df = df.drop(list(banned.keys()))
+        dropped.extend(banned.keys())
+
+    if banned and raise_on_banned:
+        raise ValueError(f"Leak-prone columns detected: {sorted(banned.items())}")
+
+    allowlist_cols: set[str] = set()
+    if allow_prefixes:
+        allowlist_cols.update({c for c in df.columns if c.startswith(allow_prefixes)})
+    allowlist_cols.update({c for c in allow_exact if c in df.columns})
+
+    if drop_non_allowlisted and allowlist_cols:
+        drop_candidates = [c for c in df.columns if c not in allowlist_cols]
+        if drop_candidates:
+            df = df.drop(drop_candidates)
+            dropped.extend(drop_candidates)
+
+    if drop_non_allowlisted and not allowlist_cols:
+        raise ValueError("No allowlisted columns remain after applying leak guard allowlist.")
+
+    # Store adjusted banned info on the result
+    result.banned = banned
+    result.dropped = dropped
+    result.kept = [c for c in df.columns]
+    result.allowlist_kept = sorted(list(allowlist_cols)) if allowlist_cols else []
+    return df, result
+
+
+def build_schema_snapshot(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    metadata: Mapping[str, object] | None = None,
+    banned: Mapping[str, str] | None = None,
+) -> dict:
+    """Render a schema snapshot describing each column and whether it was flagged."""
+
+    banned = banned or {}
+    meta = {
+        "generated_at_utc": datetime.utcnow().isoformat(),
+        "policy_version": policy.version,
+    }
+    meta.update(metadata or {})
+
+    # Extract columns / dtypes
+    if isinstance(df, pl.DataFrame):
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+    else:  # pandas or pandas-like
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+
+    schema = {
+        "metadata": meta,
+        "columns": [],
+    }
+
+    for col, dtype in cols_and_dtypes:
+        tags: list[str] = []
+        if col in IDENTIFIER_COLUMNS:
+            tags.append("id")
+        if col in NFL_TARGET_COLUMNS:
+            tags.append("label")
+        if col.startswith("market_"):
+            tags.append("odds")
+        if col.startswith("injury_") or col.startswith("practice_"):
+            tags.append("injury")
+        if col.startswith("weather_"):
+            tags.append("weather")
+        if col.startswith("ps_"):
+            tags.append("pre_snap")
+        schema["columns"].append(
+            {
+                "name": col,
+                "dtype": dtype,
+                "banned": col in banned,
+                "tags": tags,
+            }
+        )
+    return schema
+
+
+def write_schema_snapshot(path, schema: Mapping[str, object]) -> None:
+    path.parent.mkdir(parents=True, exist_ok=True)
+    with open(path, "w") as fp:
+        json.dump(schema, fp, indent=2, sort_keys=True)
+
+
+__all__ = [
+    "DEFAULT_LEAK_POLICY",
+    "LeakPolicy",
+    "LeakCheckResult",
+    "evaluate_leak_prone_columns",
+    "enforce_leak_guard",
+    "build_schema_snapshot",
+    "write_schema_snapshot",
+]
diff --git a/utils/general/constants.py b/utils/general/constants.py
index d94b4260ad877484da843fa99ae2caf37e8493f4..dea87caa354d94e4a08b1762d2bd8dcd4c8caa3a
--- a/utils/general/constants.py
+++ b/utils/general/constants.py
@@ -211,7 +211,17 @@
 
 NFL_TARGET_COLUMNS: Tuple[str, ...] = (
     'anytime_td',
+    'anytime_td_offense',
+    'anytime_td_all',
+    'anytime_td_rush',
+    'anytime_td_rec',
+    'anytime_td_pass_thrown',
     'td_count',
+    'td_count_offense',
+    'td_count_all',
+    'passing_td',
+    'rushing_td_count',
+    'receiving_td_count',
     'receiving_yards',
     'rushing_yards',
     'passing_yards',


thinking
**Searching for column usage**
exec
/bin/zsh -lc 'cd /Users/jameswest/Desktop/nfl_predict && rg "market_player" utils/feature/player_game_level.py' in /Users/jameswest/Desktop/nfl_predict succeeded in 1.97s:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
    "market_player_tds_line",
    "market_player_tds_prob_over",
    "market_player_tds_consensus_over",
file update:
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 5ba68e8bf1acd3a789a76a8857674e6f6433017b..0210d5b7e7ed60a8de7a126d64f5ed76326474c8
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -14,7 +14,7 @@
 
 import logging
 import os
-from datetime import date, timedelta
+from datetime import date, datetime, timedelta
 from typing import Sequence
 
 import polars as pl
@@ -37,6 +37,12 @@
     add_offense_context_features_training,
     _append_offense_context_columns,
 )
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    build_schema_snapshot,
+    enforce_leak_guard,
+    write_schema_snapshot,
+)
 from utils.feature.weather_features import (
     add_weather_forecast_features_training,
     append_weather_context_flags,
@@ -931,6 +937,32 @@
     if market_exprs:
         df_player_game_all = df_player_game_all.with_columns(market_exprs)
     
+    # Leak guard + schema snapshot before persisting
+    spec = get_label_spec(label_version)
+    allow_exact = {spec.primary, *spec.labels.keys(), *spec.aliases.keys()}
+    df_player_game_all, leak_result = enforce_leak_guard(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_exact=allow_exact,
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=True,
+    )
+
+    schema = build_schema_snapshot(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        metadata={
+            "cutoff_label": cutoff_label,
+            "label_version": spec.name,
+        },
+        banned=leak_result.banned,
+    )
+    schema_dir = FEATURE_AUDIT_DIR / "schema" / "anytime_td"
+    schema_path = schema_dir / f"{cutoff_label}_{datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')}.json"
+    write_schema_snapshot(schema_path, schema)
+    logging.info("    Schema snapshot written → %s", schema_path)
+
     # Write final feature matrix
     df_player_game_all = df_player_game_all.with_columns(
         pl.lit(current_cutoff_hours).cast(pl.Float32).alias("decision_horizon_hours")
@@ -951,7 +983,6 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    spec = get_label_spec(label_version)
     label_candidates = {spec.primary, "anytime_td"}
     for label_col in label_candidates:
         if label_col in df_player_game_all.columns:
diff --git a/pipeline/train.py b/pipeline/train.py
index fe70207dcdf25d209ee3ad55080b7ce826347c44..3fab3a05b3f65e8d0e88ec1ddaa71a8857646148
--- a/pipeline/train.py
+++ b/pipeline/train.py
@@ -98,6 +98,7 @@
     fit_team_conformal_sums,
     composite_sum_interval,
 )
+from utils.feature.leak_guard import DEFAULT_LEAK_POLICY, enforce_leak_guard
 from utils.feature.targets import require_target_column
 
 # Ignore specific, noisy warnings from dependencies
@@ -2315,7 +2316,30 @@
                             df_problem[col] = df_problem[col].fillna(df_problem[col].mean())
 
                 df_problem = self._inject_composed_features(df_problem)
-            
+
+            # Leak guard on the problem-scoped frame
+            allow_prefixes = tuple(problem_copy.get('feature_prefixes_to_include') or [])
+            allow_exact = set(problem_copy.get('other_features_to_include') or [])
+            allow_exact.update(input_preds or [])
+            if self.target_col:
+                allow_exact.add(self.target_col)
+            df_problem, leak_info = enforce_leak_guard(
+                df_problem,
+                policy=DEFAULT_LEAK_POLICY,
+                allow_prefixes=allow_prefixes,
+                allow_exact=allow_exact,
+                drop_banned=True,
+                drop_non_allowlisted=False,
+                raise_on_banned=True,
+            )
+            if leak_info.dropped:
+                logger.info(
+                    "Dropped %d leak-prone columns for %s: %s",
+                    len(leak_info.dropped),
+                    problem_name,
+                    sorted(leak_info.dropped),
+                )
+
             self._normalize_datetime_like_columns(df_problem, problem_name)
             df_problem[self.time_col] = pd.to_datetime(df_problem[self.time_col])
             sort_cols = [self.time_col]
diff --git a/tests/test_data_leak_guard.py b/tests/test_data_leak_guard.py
index 8061f2760c0898aaeda29026859e1b9ff5644ba4..3e56665921db89ea523bbdb205d1bb90c21893df
--- a/tests/test_data_leak_guard.py
+++ b/tests/test_data_leak_guard.py
@@ -3,6 +3,14 @@
 import yaml
 from pathlib import Path
 
+import polars as pl
+
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    enforce_leak_guard,
+    evaluate_leak_prone_columns,
+)
+
 
 PROJECT_ROOT = Path(__file__).resolve().parents[1]
 TRAINING_CONFIG = PROJECT_ROOT / "config" / "training.yaml"
@@ -48,3 +56,41 @@
     )
 
 
+def test_leak_guard_flags_pattern_columns():
+    cols = [
+        "market_anytime_td_prob",
+        "final_score",
+        "postgame_anytime_td",
+        "actual_td_count",
+        "safe_feature",
+    ]
+    result = evaluate_leak_prone_columns(cols, policy=DEFAULT_LEAK_POLICY)
+    assert set(result.banned.keys()) == {"final_score", "postgame_anytime_td", "actual_td_count"}
+    assert "safe_feature" in result.kept
+    assert "market_anytime_td_prob" in result.kept
+
+
+def test_enforce_leak_guard_drops_banned_and_keeps_allowlisted():
+    df = pl.DataFrame(
+        {
+            "game_id": ["g1", "g2"],
+            "safe_feature": [1.0, 2.0],
+            "postgame_anytime_td": [1, 0],
+            "final_score": [30, 24],
+        }
+    )
+    cleaned, info = enforce_leak_guard(
+        df,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_prefixes=("safe_",),
+        allow_exact=("game_id",),
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=False,
+    )
+    assert "postgame_anytime_td" not in cleaned.columns
+    assert "final_score" not in cleaned.columns
+    assert "safe_feature" in cleaned.columns
+    assert "game_id" in cleaned.columns
+    assert set(info.dropped) == {"postgame_anytime_td", "final_score"}
+
diff --git a/utils/feature/leak_guard.py b/utils/feature/leak_guard.py
new file mode 100644
index 0000000000000000000000000000000000000000..9faf8cfffc436e0934b2f410aaf252e52f4f95df
--- /dev/null
+++ b/utils/feature/leak_guard.py
@@ -0,0 +1,273 @@
+"""Leak guardrails for feature matrices.
+
+This module centralizes pattern-based leak detection so both feature assembly
+and training can fail fast when post-outcome columns sneak into the data.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+from datetime import datetime
+import json
+import re
+from typing import Iterable, Mapping, Sequence
+
+import polars as pl
+
+from utils.general.constants import IDENTIFIER_COLUMNS, LEAK_PRONE_COLUMNS, NFL_TARGET_COLUMNS
+
+try:  # Optional dependency when imported from training (pandas path)
+    import pandas as pd  # type: ignore
+except Exception:  # pragma: no cover - optional dependency
+    pd = None
+
+
+@dataclass(frozen=True)
+class LeakPolicy:
+    version: str
+    banned_exact: set[str]
+    banned_prefixes: tuple[str, ...]
+    banned_suffixes: tuple[str, ...]
+    banned_regex: tuple[tuple[re.Pattern[str], str], ...]
+    description: str = ""
+
+
+@dataclass
+class LeakCheckResult:
+    policy_version: str
+    banned: dict[str, str]
+    kept: list[str]
+    dropped: list[str]
+    allowlist_kept: list[str]
+
+
+# Core policy tuned for anytime-TD style problems (can be extended per-problem).
+_BASE_BANNED_EXACT = set(LEAK_PRONE_COLUMNS) | {
+    "final_score",
+    "final_total",
+    "points_scored",
+    "actual_td_count",
+    "actual_anytime_td",
+    "postgame_anytime_td",
+    "postgame_td_count",
+}
+_BASE_BANNED_PREFIXES = (
+    "postgame_",
+    "post_game_",
+    "post_",
+    "live_",
+    "actual_",
+    "realized_",
+    "final_",
+    "postmatch_",
+)
+_BASE_BANNED_SUFFIXES = (
+    "_post",
+    "_postgame",
+    "_final",
+    "_fullgame",
+    "_actual",
+)
+_BASE_BANNED_REGEX: tuple[tuple[re.Pattern[str], str], ...] = (
+    (re.compile(r".*post.?game.*", flags=re.IGNORECASE), "postgame marker"),
+    (re.compile(r".*final_score.*", flags=re.IGNORECASE), "final score"),
+    (re.compile(r".*actual.*td.*", flags=re.IGNORECASE), "actual TD total"),
+    (re.compile(r".*anytime_td.*(post|final|actual).*", flags=re.IGNORECASE), "post-decision anytime TD"),
+    (re.compile(r".*fullgame.*", flags=re.IGNORECASE), "full game cumulative value"),
+)
+
+DEFAULT_LEAK_POLICY = LeakPolicy(
+    version="v1",
+    description="Core post-outcome leak guard for NFL anytime TD features.",
+    banned_exact=_BASE_BANNED_EXACT,
+    banned_prefixes=_BASE_BANNED_PREFIXES,
+    banned_suffixes=_BASE_BANNED_SUFFIXES,
+    banned_regex=_BASE_BANNED_REGEX,
+)
+
+
+def _ensure_sequence(value: Sequence[str] | str | None) -> tuple[str, ...]:
+    if value is None:
+        return ()
+    if isinstance(value, str):
+        return (value,)
+    return tuple(value)
+
+
+def evaluate_leak_prone_columns(
+    columns: Iterable[str],
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+) -> LeakCheckResult:
+    """Identify leak-prone columns using the configured policy."""
+
+    banned: dict[str, str] = {}
+    columns_list = list(columns)
+    for col in columns_list:
+        if col in policy.banned_exact:
+            banned[col] = "exact"
+            continue
+        for prefix in policy.banned_prefixes:
+            if col.startswith(prefix):
+                banned[col] = f"prefix:{prefix}"
+                break
+        if col in banned:
+            continue
+        for suffix in policy.banned_suffixes:
+            if col.endswith(suffix):
+                banned[col] = f"suffix:{suffix}"
+                break
+        if col in banned:
+            continue
+        for pattern, reason in policy.banned_regex:
+            if pattern.match(col):
+                banned[col] = reason
+                break
+
+    kept = [c for c in columns_list if c not in banned]
+    return LeakCheckResult(
+        policy_version=policy.version,
+        banned=banned,
+        kept=kept,
+        dropped=[],
+        allowlist_kept=[],
+    )
+
+
+def enforce_leak_guard(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    allow_prefixes: Sequence[str] | str | None = None,
+    allow_exact: Sequence[str] | str | None = None,
+    drop_banned: bool = True,
+    drop_non_allowlisted: bool = False,
+    raise_on_banned: bool = True,
+) -> tuple[pl.DataFrame | "pd.DataFrame", LeakCheckResult]:
+    """Apply leak guardrails to a feature frame.
+
+    Parameters
+    ----------
+    df : DataFrame
+        Polars or pandas DataFrame.
+    policy : LeakPolicy
+        Leak policy to apply.
+    allow_prefixes : Sequence[str] | str | None
+        Optional prefixes that define the allowed feature surface for a problem.
+    allow_exact : Sequence[str] | str | None
+        Explicitly allowed columns (e.g., identifiers).
+    drop_banned : bool
+        If True, drop any banned columns automatically.
+    drop_non_allowlisted : bool
+        If True, drop columns that are not covered by allow_prefixes/allow_exact/identifiers/targets.
+    raise_on_banned : bool
+        If True, raise when banned columns are detected (after optional drop).
+    """
+
+    result = evaluate_leak_prone_columns(df.columns, policy=policy)
+    dropped: list[str] = []
+
+    allow_prefixes = _ensure_sequence(allow_prefixes)
+    allow_exact = set(_ensure_sequence(allow_exact))
+    allow_exact.update({col for col in IDENTIFIER_COLUMNS if col in df.columns})
+    allow_exact.update({col for col in NFL_TARGET_COLUMNS if col in df.columns})
+
+    # Permit allowlisted columns even if they match a banned rule (e.g., labels)
+    banned = {col: reason for col, reason in result.banned.items() if col not in allow_exact}
+
+    if banned and drop_banned:
+        df = df.drop(list(banned.keys()))
+        dropped.extend(banned.keys())
+
+    if banned and raise_on_banned:
+        raise ValueError(f"Leak-prone columns detected: {sorted(banned.items())}")
+
+    allowlist_cols: set[str] = set()
+    if allow_prefixes:
+        allowlist_cols.update({c for c in df.columns if c.startswith(allow_prefixes)})
+    allowlist_cols.update({c for c in allow_exact if c in df.columns})
+
+    if drop_non_allowlisted and allowlist_cols:
+        drop_candidates = [c for c in df.columns if c not in allowlist_cols]
+        if drop_candidates:
+            df = df.drop(drop_candidates)
+            dropped.extend(drop_candidates)
+
+    if drop_non_allowlisted and not allowlist_cols:
+        raise ValueError("No allowlisted columns remain after applying leak guard allowlist.")
+
+    # Store adjusted banned info on the result
+    result.banned = banned
+    result.dropped = dropped
+    result.kept = [c for c in df.columns]
+    result.allowlist_kept = sorted(list(allowlist_cols)) if allowlist_cols else []
+    return df, result
+
+
+def build_schema_snapshot(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    metadata: Mapping[str, object] | None = None,
+    banned: Mapping[str, str] | None = None,
+) -> dict:
+    """Render a schema snapshot describing each column and whether it was flagged."""
+
+    banned = banned or {}
+    meta = {
+        "generated_at_utc": datetime.utcnow().isoformat(),
+        "policy_version": policy.version,
+    }
+    meta.update(metadata or {})
+
+    # Extract columns / dtypes
+    if isinstance(df, pl.DataFrame):
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+    else:  # pandas or pandas-like
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+
+    schema = {
+        "metadata": meta,
+        "columns": [],
+    }
+
+    for col, dtype in cols_and_dtypes:
+        tags: list[str] = []
+        if col in IDENTIFIER_COLUMNS:
+            tags.append("id")
+        if col in NFL_TARGET_COLUMNS:
+            tags.append("label")
+        if col.startswith("market_"):
+            tags.append("odds")
+        if col.startswith("injury_") or col.startswith("practice_"):
+            tags.append("injury")
+        if col.startswith("weather_"):
+            tags.append("weather")
+        if col.startswith("ps_"):
+            tags.append("pre_snap")
+        schema["columns"].append(
+            {
+                "name": col,
+                "dtype": dtype,
+                "banned": col in banned,
+                "tags": tags,
+            }
+        )
+    return schema
+
+
+def write_schema_snapshot(path, schema: Mapping[str, object]) -> None:
+    path.parent.mkdir(parents=True, exist_ok=True)
+    with open(path, "w") as fp:
+        json.dump(schema, fp, indent=2, sort_keys=True)
+
+
+__all__ = [
+    "DEFAULT_LEAK_POLICY",
+    "LeakPolicy",
+    "LeakCheckResult",
+    "evaluate_leak_prone_columns",
+    "enforce_leak_guard",
+    "build_schema_snapshot",
+    "write_schema_snapshot",
+]
diff --git a/utils/general/constants.py b/utils/general/constants.py
index d94b4260ad877484da843fa99ae2caf37e8493f4..dea87caa354d94e4a08b1762d2bd8dcd4c8caa3a
--- a/utils/general/constants.py
+++ b/utils/general/constants.py
@@ -211,7 +211,17 @@
 
 NFL_TARGET_COLUMNS: Tuple[str, ...] = (
     'anytime_td',
+    'anytime_td_offense',
+    'anytime_td_all',
+    'anytime_td_rush',
+    'anytime_td_rec',
+    'anytime_td_pass_thrown',
     'td_count',
+    'td_count_offense',
+    'td_count_all',
+    'passing_td',
+    'rushing_td_count',
+    'receiving_td_count',
     'receiving_yards',
     'rushing_yards',
     'passing_yards',


thinking
**Searching for odds loading function**
exec
/bin/zsh -lc 'cd /Users/jameswest/Desktop/nfl_predict && rg "market" utils/feature/player_game_level.py | head' in /Users/jameswest/Desktop/nfl_predict succeeded in 3.03s:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
    "market_anytime_td_prob",
    "market_anytime_td_consensus",
    "market_anytime_td_spread",
    "market_anytime_td_book_count",
    "market_anytime_td_prob_2h",
    "market_anytime_td_consensus_2h",
    "market_anytime_td_spread_2h",
    "market_anytime_td_book_count_2h",
    "market_anytime_td_prob_6h",
    "market_anytime_td_consensus_6h",
file update:
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 5ba68e8bf1acd3a789a76a8857674e6f6433017b..0210d5b7e7ed60a8de7a126d64f5ed76326474c8
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -14,7 +14,7 @@
 
 import logging
 import os
-from datetime import date, timedelta
+from datetime import date, datetime, timedelta
 from typing import Sequence
 
 import polars as pl
@@ -37,6 +37,12 @@
     add_offense_context_features_training,
     _append_offense_context_columns,
 )
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    build_schema_snapshot,
+    enforce_leak_guard,
+    write_schema_snapshot,
+)
 from utils.feature.weather_features import (
     add_weather_forecast_features_training,
     append_weather_context_flags,
@@ -931,6 +937,32 @@
     if market_exprs:
         df_player_game_all = df_player_game_all.with_columns(market_exprs)
     
+    # Leak guard + schema snapshot before persisting
+    spec = get_label_spec(label_version)
+    allow_exact = {spec.primary, *spec.labels.keys(), *spec.aliases.keys()}
+    df_player_game_all, leak_result = enforce_leak_guard(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_exact=allow_exact,
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=True,
+    )
+
+    schema = build_schema_snapshot(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        metadata={
+            "cutoff_label": cutoff_label,
+            "label_version": spec.name,
+        },
+        banned=leak_result.banned,
+    )
+    schema_dir = FEATURE_AUDIT_DIR / "schema" / "anytime_td"
+    schema_path = schema_dir / f"{cutoff_label}_{datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')}.json"
+    write_schema_snapshot(schema_path, schema)
+    logging.info("    Schema snapshot written → %s", schema_path)
+
     # Write final feature matrix
     df_player_game_all = df_player_game_all.with_columns(
         pl.lit(current_cutoff_hours).cast(pl.Float32).alias("decision_horizon_hours")
@@ -951,7 +983,6 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    spec = get_label_spec(label_version)
     label_candidates = {spec.primary, "anytime_td"}
     for label_col in label_candidates:
         if label_col in df_player_game_all.columns:
diff --git a/pipeline/train.py b/pipeline/train.py
index fe70207dcdf25d209ee3ad55080b7ce826347c44..3fab3a05b3f65e8d0e88ec1ddaa71a8857646148
--- a/pipeline/train.py
+++ b/pipeline/train.py
@@ -98,6 +98,7 @@
     fit_team_conformal_sums,
     composite_sum_interval,
 )
+from utils.feature.leak_guard import DEFAULT_LEAK_POLICY, enforce_leak_guard
 from utils.feature.targets import require_target_column
 
 # Ignore specific, noisy warnings from dependencies
@@ -2315,7 +2316,30 @@
                             df_problem[col] = df_problem[col].fillna(df_problem[col].mean())
 
                 df_problem = self._inject_composed_features(df_problem)
-            
+
+            # Leak guard on the problem-scoped frame
+            allow_prefixes = tuple(problem_copy.get('feature_prefixes_to_include') or [])
+            allow_exact = set(problem_copy.get('other_features_to_include') or [])
+            allow_exact.update(input_preds or [])
+            if self.target_col:
+                allow_exact.add(self.target_col)
+            df_problem, leak_info = enforce_leak_guard(
+                df_problem,
+                policy=DEFAULT_LEAK_POLICY,
+                allow_prefixes=allow_prefixes,
+                allow_exact=allow_exact,
+                drop_banned=True,
+                drop_non_allowlisted=False,
+                raise_on_banned=True,
+            )
+            if leak_info.dropped:
+                logger.info(
+                    "Dropped %d leak-prone columns for %s: %s",
+                    len(leak_info.dropped),
+                    problem_name,
+                    sorted(leak_info.dropped),
+                )
+
             self._normalize_datetime_like_columns(df_problem, problem_name)
             df_problem[self.time_col] = pd.to_datetime(df_problem[self.time_col])
             sort_cols = [self.time_col]
diff --git a/tests/test_data_leak_guard.py b/tests/test_data_leak_guard.py
index 8061f2760c0898aaeda29026859e1b9ff5644ba4..3e56665921db89ea523bbdb205d1bb90c21893df
--- a/tests/test_data_leak_guard.py
+++ b/tests/test_data_leak_guard.py
@@ -3,6 +3,14 @@
 import yaml
 from pathlib import Path
 
+import polars as pl
+
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    enforce_leak_guard,
+    evaluate_leak_prone_columns,
+)
+
 
 PROJECT_ROOT = Path(__file__).resolve().parents[1]
 TRAINING_CONFIG = PROJECT_ROOT / "config" / "training.yaml"
@@ -48,3 +56,41 @@
     )
 
 
+def test_leak_guard_flags_pattern_columns():
+    cols = [
+        "market_anytime_td_prob",
+        "final_score",
+        "postgame_anytime_td",
+        "actual_td_count",
+        "safe_feature",
+    ]
+    result = evaluate_leak_prone_columns(cols, policy=DEFAULT_LEAK_POLICY)
+    assert set(result.banned.keys()) == {"final_score", "postgame_anytime_td", "actual_td_count"}
+    assert "safe_feature" in result.kept
+    assert "market_anytime_td_prob" in result.kept
+
+
+def test_enforce_leak_guard_drops_banned_and_keeps_allowlisted():
+    df = pl.DataFrame(
+        {
+            "game_id": ["g1", "g2"],
+            "safe_feature": [1.0, 2.0],
+            "postgame_anytime_td": [1, 0],
+            "final_score": [30, 24],
+        }
+    )
+    cleaned, info = enforce_leak_guard(
+        df,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_prefixes=("safe_",),
+        allow_exact=("game_id",),
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=False,
+    )
+    assert "postgame_anytime_td" not in cleaned.columns
+    assert "final_score" not in cleaned.columns
+    assert "safe_feature" in cleaned.columns
+    assert "game_id" in cleaned.columns
+    assert set(info.dropped) == {"postgame_anytime_td", "final_score"}
+
diff --git a/utils/feature/leak_guard.py b/utils/feature/leak_guard.py
new file mode 100644
index 0000000000000000000000000000000000000000..9faf8cfffc436e0934b2f410aaf252e52f4f95df
--- /dev/null
+++ b/utils/feature/leak_guard.py
@@ -0,0 +1,273 @@
+"""Leak guardrails for feature matrices.
+
+This module centralizes pattern-based leak detection so both feature assembly
+and training can fail fast when post-outcome columns sneak into the data.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+from datetime import datetime
+import json
+import re
+from typing import Iterable, Mapping, Sequence
+
+import polars as pl
+
+from utils.general.constants import IDENTIFIER_COLUMNS, LEAK_PRONE_COLUMNS, NFL_TARGET_COLUMNS
+
+try:  # Optional dependency when imported from training (pandas path)
+    import pandas as pd  # type: ignore
+except Exception:  # pragma: no cover - optional dependency
+    pd = None
+
+
+@dataclass(frozen=True)
+class LeakPolicy:
+    version: str
+    banned_exact: set[str]
+    banned_prefixes: tuple[str, ...]
+    banned_suffixes: tuple[str, ...]
+    banned_regex: tuple[tuple[re.Pattern[str], str], ...]
+    description: str = ""
+
+
+@dataclass
+class LeakCheckResult:
+    policy_version: str
+    banned: dict[str, str]
+    kept: list[str]
+    dropped: list[str]
+    allowlist_kept: list[str]
+
+
+# Core policy tuned for anytime-TD style problems (can be extended per-problem).
+_BASE_BANNED_EXACT = set(LEAK_PRONE_COLUMNS) | {
+    "final_score",
+    "final_total",
+    "points_scored",
+    "actual_td_count",
+    "actual_anytime_td",
+    "postgame_anytime_td",
+    "postgame_td_count",
+}
+_BASE_BANNED_PREFIXES = (
+    "postgame_",
+    "post_game_",
+    "post_",
+    "live_",
+    "actual_",
+    "realized_",
+    "final_",
+    "postmatch_",
+)
+_BASE_BANNED_SUFFIXES = (
+    "_post",
+    "_postgame",
+    "_final",
+    "_fullgame",
+    "_actual",
+)
+_BASE_BANNED_REGEX: tuple[tuple[re.Pattern[str], str], ...] = (
+    (re.compile(r".*post.?game.*", flags=re.IGNORECASE), "postgame marker"),
+    (re.compile(r".*final_score.*", flags=re.IGNORECASE), "final score"),
+    (re.compile(r".*actual.*td.*", flags=re.IGNORECASE), "actual TD total"),
+    (re.compile(r".*anytime_td.*(post|final|actual).*", flags=re.IGNORECASE), "post-decision anytime TD"),
+    (re.compile(r".*fullgame.*", flags=re.IGNORECASE), "full game cumulative value"),
+)
+
+DEFAULT_LEAK_POLICY = LeakPolicy(
+    version="v1",
+    description="Core post-outcome leak guard for NFL anytime TD features.",
+    banned_exact=_BASE_BANNED_EXACT,
+    banned_prefixes=_BASE_BANNED_PREFIXES,
+    banned_suffixes=_BASE_BANNED_SUFFIXES,
+    banned_regex=_BASE_BANNED_REGEX,
+)
+
+
+def _ensure_sequence(value: Sequence[str] | str | None) -> tuple[str, ...]:
+    if value is None:
+        return ()
+    if isinstance(value, str):
+        return (value,)
+    return tuple(value)
+
+
+def evaluate_leak_prone_columns(
+    columns: Iterable[str],
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+) -> LeakCheckResult:
+    """Identify leak-prone columns using the configured policy."""
+
+    banned: dict[str, str] = {}
+    columns_list = list(columns)
+    for col in columns_list:
+        if col in policy.banned_exact:
+            banned[col] = "exact"
+            continue
+        for prefix in policy.banned_prefixes:
+            if col.startswith(prefix):
+                banned[col] = f"prefix:{prefix}"
+                break
+        if col in banned:
+            continue
+        for suffix in policy.banned_suffixes:
+            if col.endswith(suffix):
+                banned[col] = f"suffix:{suffix}"
+                break
+        if col in banned:
+            continue
+        for pattern, reason in policy.banned_regex:
+            if pattern.match(col):
+                banned[col] = reason
+                break
+
+    kept = [c for c in columns_list if c not in banned]
+    return LeakCheckResult(
+        policy_version=policy.version,
+        banned=banned,
+        kept=kept,
+        dropped=[],
+        allowlist_kept=[],
+    )
+
+
+def enforce_leak_guard(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    allow_prefixes: Sequence[str] | str | None = None,
+    allow_exact: Sequence[str] | str | None = None,
+    drop_banned: bool = True,
+    drop_non_allowlisted: bool = False,
+    raise_on_banned: bool = True,
+) -> tuple[pl.DataFrame | "pd.DataFrame", LeakCheckResult]:
+    """Apply leak guardrails to a feature frame.
+
+    Parameters
+    ----------
+    df : DataFrame
+        Polars or pandas DataFrame.
+    policy : LeakPolicy
+        Leak policy to apply.
+    allow_prefixes : Sequence[str] | str | None
+        Optional prefixes that define the allowed feature surface for a problem.
+    allow_exact : Sequence[str] | str | None
+        Explicitly allowed columns (e.g., identifiers).
+    drop_banned : bool
+        If True, drop any banned columns automatically.
+    drop_non_allowlisted : bool
+        If True, drop columns that are not covered by allow_prefixes/allow_exact/identifiers/targets.
+    raise_on_banned : bool
+        If True, raise when banned columns are detected (after optional drop).
+    """
+
+    result = evaluate_leak_prone_columns(df.columns, policy=policy)
+    dropped: list[str] = []
+
+    allow_prefixes = _ensure_sequence(allow_prefixes)
+    allow_exact = set(_ensure_sequence(allow_exact))
+    allow_exact.update({col for col in IDENTIFIER_COLUMNS if col in df.columns})
+    allow_exact.update({col for col in NFL_TARGET_COLUMNS if col in df.columns})
+
+    # Permit allowlisted columns even if they match a banned rule (e.g., labels)
+    banned = {col: reason for col, reason in result.banned.items() if col not in allow_exact}
+
+    if banned and drop_banned:
+        df = df.drop(list(banned.keys()))
+        dropped.extend(banned.keys())
+
+    if banned and raise_on_banned:
+        raise ValueError(f"Leak-prone columns detected: {sorted(banned.items())}")
+
+    allowlist_cols: set[str] = set()
+    if allow_prefixes:
+        allowlist_cols.update({c for c in df.columns if c.startswith(allow_prefixes)})
+    allowlist_cols.update({c for c in allow_exact if c in df.columns})
+
+    if drop_non_allowlisted and allowlist_cols:
+        drop_candidates = [c for c in df.columns if c not in allowlist_cols]
+        if drop_candidates:
+            df = df.drop(drop_candidates)
+            dropped.extend(drop_candidates)
+
+    if drop_non_allowlisted and not allowlist_cols:
+        raise ValueError("No allowlisted columns remain after applying leak guard allowlist.")
+
+    # Store adjusted banned info on the result
+    result.banned = banned
+    result.dropped = dropped
+    result.kept = [c for c in df.columns]
+    result.allowlist_kept = sorted(list(allowlist_cols)) if allowlist_cols else []
+    return df, result
+
+
+def build_schema_snapshot(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    metadata: Mapping[str, object] | None = None,
+    banned: Mapping[str, str] | None = None,
+) -> dict:
+    """Render a schema snapshot describing each column and whether it was flagged."""
+
+    banned = banned or {}
+    meta = {
+        "generated_at_utc": datetime.utcnow().isoformat(),
+        "policy_version": policy.version,
+    }
+    meta.update(metadata or {})
+
+    # Extract columns / dtypes
+    if isinstance(df, pl.DataFrame):
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+    else:  # pandas or pandas-like
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+
+    schema = {
+        "metadata": meta,
+        "columns": [],
+    }
+
+    for col, dtype in cols_and_dtypes:
+        tags: list[str] = []
+        if col in IDENTIFIER_COLUMNS:
+            tags.append("id")
+        if col in NFL_TARGET_COLUMNS:
+            tags.append("label")
+        if col.startswith("market_"):
+            tags.append("odds")
+        if col.startswith("injury_") or col.startswith("practice_"):
+            tags.append("injury")
+        if col.startswith("weather_"):
+            tags.append("weather")
+        if col.startswith("ps_"):
+            tags.append("pre_snap")
+        schema["columns"].append(
+            {
+                "name": col,
+                "dtype": dtype,
+                "banned": col in banned,
+                "tags": tags,
+            }
+        )
+    return schema
+
+
+def write_schema_snapshot(path, schema: Mapping[str, object]) -> None:
+    path.parent.mkdir(parents=True, exist_ok=True)
+    with open(path, "w") as fp:
+        json.dump(schema, fp, indent=2, sort_keys=True)
+
+
+__all__ = [
+    "DEFAULT_LEAK_POLICY",
+    "LeakPolicy",
+    "LeakCheckResult",
+    "evaluate_leak_prone_columns",
+    "enforce_leak_guard",
+    "build_schema_snapshot",
+    "write_schema_snapshot",
+]
diff --git a/utils/general/constants.py b/utils/general/constants.py
index d94b4260ad877484da843fa99ae2caf37e8493f4..dea87caa354d94e4a08b1762d2bd8dcd4c8caa3a
--- a/utils/general/constants.py
+++ b/utils/general/constants.py
@@ -211,7 +211,17 @@
 
 NFL_TARGET_COLUMNS: Tuple[str, ...] = (
     'anytime_td',
+    'anytime_td_offense',
+    'anytime_td_all',
+    'anytime_td_rush',
+    'anytime_td_rec',
+    'anytime_td_pass_thrown',
     'td_count',
+    'td_count_offense',
+    'td_count_all',
+    'passing_td',
+    'rushing_td_count',
+    'receiving_td_count',
     'receiving_yards',
     'rushing_yards',
     'passing_yards',


thinking
**Searching for code segments with market_anytime_td_prob**
exec
/bin/zsh -lc 'cd /Users/jameswest/Desktop/nfl_predict && rg "market_anytime_td_prob" -n utils/feature/player_game_level.py | head' in /Users/jameswest/Desktop/nfl_predict succeeded in 1.57s:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
90:    "market_anytime_td_prob",
94:    "market_anytime_td_prob_2h",
98:    "market_anytime_td_prob_6h",
102:    "market_anytime_td_prob_24h",
106:    "market_anytime_td_prob_open",
118:    "market_anytime_td_prob_l3",
2998:    if {"market_anytime_td_prob", "injury_inactive_probability"} <= set(df_merged.columns):
3001:                pl.col("market_anytime_td_prob") - pl.col("injury_inactive_probability")
3006:    if {"player_id", "game_date", "market_anytime_td_prob"} <= set(df_merged.columns):
3009:            pl.col("market_anytime_td_prob")
file update:
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 5ba68e8bf1acd3a789a76a8857674e6f6433017b..0210d5b7e7ed60a8de7a126d64f5ed76326474c8
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -14,7 +14,7 @@
 
 import logging
 import os
-from datetime import date, timedelta
+from datetime import date, datetime, timedelta
 from typing import Sequence
 
 import polars as pl
@@ -37,6 +37,12 @@
     add_offense_context_features_training,
     _append_offense_context_columns,
 )
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    build_schema_snapshot,
+    enforce_leak_guard,
+    write_schema_snapshot,
+)
 from utils.feature.weather_features import (
     add_weather_forecast_features_training,
     append_weather_context_flags,
@@ -931,6 +937,32 @@
     if market_exprs:
         df_player_game_all = df_player_game_all.with_columns(market_exprs)
     
+    # Leak guard + schema snapshot before persisting
+    spec = get_label_spec(label_version)
+    allow_exact = {spec.primary, *spec.labels.keys(), *spec.aliases.keys()}
+    df_player_game_all, leak_result = enforce_leak_guard(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_exact=allow_exact,
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=True,
+    )
+
+    schema = build_schema_snapshot(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        metadata={
+            "cutoff_label": cutoff_label,
+            "label_version": spec.name,
+        },
+        banned=leak_result.banned,
+    )
+    schema_dir = FEATURE_AUDIT_DIR / "schema" / "anytime_td"
+    schema_path = schema_dir / f"{cutoff_label}_{datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')}.json"
+    write_schema_snapshot(schema_path, schema)
+    logging.info("    Schema snapshot written → %s", schema_path)
+
     # Write final feature matrix
     df_player_game_all = df_player_game_all.with_columns(
         pl.lit(current_cutoff_hours).cast(pl.Float32).alias("decision_horizon_hours")
@@ -951,7 +983,6 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    spec = get_label_spec(label_version)
     label_candidates = {spec.primary, "anytime_td"}
     for label_col in label_candidates:
         if label_col in df_player_game_all.columns:
diff --git a/pipeline/train.py b/pipeline/train.py
index fe70207dcdf25d209ee3ad55080b7ce826347c44..3fab3a05b3f65e8d0e88ec1ddaa71a8857646148
--- a/pipeline/train.py
+++ b/pipeline/train.py
@@ -98,6 +98,7 @@
     fit_team_conformal_sums,
     composite_sum_interval,
 )
+from utils.feature.leak_guard import DEFAULT_LEAK_POLICY, enforce_leak_guard
 from utils.feature.targets import require_target_column
 
 # Ignore specific, noisy warnings from dependencies
@@ -2315,7 +2316,30 @@
                             df_problem[col] = df_problem[col].fillna(df_problem[col].mean())
 
                 df_problem = self._inject_composed_features(df_problem)
-            
+
+            # Leak guard on the problem-scoped frame
+            allow_prefixes = tuple(problem_copy.get('feature_prefixes_to_include') or [])
+            allow_exact = set(problem_copy.get('other_features_to_include') or [])
+            allow_exact.update(input_preds or [])
+            if self.target_col:
+                allow_exact.add(self.target_col)
+            df_problem, leak_info = enforce_leak_guard(
+                df_problem,
+                policy=DEFAULT_LEAK_POLICY,
+                allow_prefixes=allow_prefixes,
+                allow_exact=allow_exact,
+                drop_banned=True,
+                drop_non_allowlisted=False,
+                raise_on_banned=True,
+            )
+            if leak_info.dropped:
+                logger.info(
+                    "Dropped %d leak-prone columns for %s: %s",
+                    len(leak_info.dropped),
+                    problem_name,
+                    sorted(leak_info.dropped),
+                )
+
             self._normalize_datetime_like_columns(df_problem, problem_name)
             df_problem[self.time_col] = pd.to_datetime(df_problem[self.time_col])
             sort_cols = [self.time_col]
diff --git a/tests/test_data_leak_guard.py b/tests/test_data_leak_guard.py
index 8061f2760c0898aaeda29026859e1b9ff5644ba4..3e56665921db89ea523bbdb205d1bb90c21893df
--- a/tests/test_data_leak_guard.py
+++ b/tests/test_data_leak_guard.py
@@ -3,6 +3,14 @@
 import yaml
 from pathlib import Path
 
+import polars as pl
+
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    enforce_leak_guard,
+    evaluate_leak_prone_columns,
+)
+
 
 PROJECT_ROOT = Path(__file__).resolve().parents[1]
 TRAINING_CONFIG = PROJECT_ROOT / "config" / "training.yaml"
@@ -48,3 +56,41 @@
     )
 
 
+def test_leak_guard_flags_pattern_columns():
+    cols = [
+        "market_anytime_td_prob",
+        "final_score",
+        "postgame_anytime_td",
+        "actual_td_count",
+        "safe_feature",
+    ]
+    result = evaluate_leak_prone_columns(cols, policy=DEFAULT_LEAK_POLICY)
+    assert set(result.banned.keys()) == {"final_score", "postgame_anytime_td", "actual_td_count"}
+    assert "safe_feature" in result.kept
+    assert "market_anytime_td_prob" in result.kept
+
+
+def test_enforce_leak_guard_drops_banned_and_keeps_allowlisted():
+    df = pl.DataFrame(
+        {
+            "game_id": ["g1", "g2"],
+            "safe_feature": [1.0, 2.0],
+            "postgame_anytime_td": [1, 0],
+            "final_score": [30, 24],
+        }
+    )
+    cleaned, info = enforce_leak_guard(
+        df,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_prefixes=("safe_",),
+        allow_exact=("game_id",),
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=False,
+    )
+    assert "postgame_anytime_td" not in cleaned.columns
+    assert "final_score" not in cleaned.columns
+    assert "safe_feature" in cleaned.columns
+    assert "game_id" in cleaned.columns
+    assert set(info.dropped) == {"postgame_anytime_td", "final_score"}
+
diff --git a/utils/feature/leak_guard.py b/utils/feature/leak_guard.py
new file mode 100644
index 0000000000000000000000000000000000000000..9faf8cfffc436e0934b2f410aaf252e52f4f95df
--- /dev/null
+++ b/utils/feature/leak_guard.py
@@ -0,0 +1,273 @@
+"""Leak guardrails for feature matrices.
+
+This module centralizes pattern-based leak detection so both feature assembly
+and training can fail fast when post-outcome columns sneak into the data.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+from datetime import datetime
+import json
+import re
+from typing import Iterable, Mapping, Sequence
+
+import polars as pl
+
+from utils.general.constants import IDENTIFIER_COLUMNS, LEAK_PRONE_COLUMNS, NFL_TARGET_COLUMNS
+
+try:  # Optional dependency when imported from training (pandas path)
+    import pandas as pd  # type: ignore
+except Exception:  # pragma: no cover - optional dependency
+    pd = None
+
+
+@dataclass(frozen=True)
+class LeakPolicy:
+    version: str
+    banned_exact: set[str]
+    banned_prefixes: tuple[str, ...]
+    banned_suffixes: tuple[str, ...]
+    banned_regex: tuple[tuple[re.Pattern[str], str], ...]
+    description: str = ""
+
+
+@dataclass
+class LeakCheckResult:
+    policy_version: str
+    banned: dict[str, str]
+    kept: list[str]
+    dropped: list[str]
+    allowlist_kept: list[str]
+
+
+# Core policy tuned for anytime-TD style problems (can be extended per-problem).
+_BASE_BANNED_EXACT = set(LEAK_PRONE_COLUMNS) | {
+    "final_score",
+    "final_total",
+    "points_scored",
+    "actual_td_count",
+    "actual_anytime_td",
+    "postgame_anytime_td",
+    "postgame_td_count",
+}
+_BASE_BANNED_PREFIXES = (
+    "postgame_",
+    "post_game_",
+    "post_",
+    "live_",
+    "actual_",
+    "realized_",
+    "final_",
+    "postmatch_",
+)
+_BASE_BANNED_SUFFIXES = (
+    "_post",
+    "_postgame",
+    "_final",
+    "_fullgame",
+    "_actual",
+)
+_BASE_BANNED_REGEX: tuple[tuple[re.Pattern[str], str], ...] = (
+    (re.compile(r".*post.?game.*", flags=re.IGNORECASE), "postgame marker"),
+    (re.compile(r".*final_score.*", flags=re.IGNORECASE), "final score"),
+    (re.compile(r".*actual.*td.*", flags=re.IGNORECASE), "actual TD total"),
+    (re.compile(r".*anytime_td.*(post|final|actual).*", flags=re.IGNORECASE), "post-decision anytime TD"),
+    (re.compile(r".*fullgame.*", flags=re.IGNORECASE), "full game cumulative value"),
+)
+
+DEFAULT_LEAK_POLICY = LeakPolicy(
+    version="v1",
+    description="Core post-outcome leak guard for NFL anytime TD features.",
+    banned_exact=_BASE_BANNED_EXACT,
+    banned_prefixes=_BASE_BANNED_PREFIXES,
+    banned_suffixes=_BASE_BANNED_SUFFIXES,
+    banned_regex=_BASE_BANNED_REGEX,
+)
+
+
+def _ensure_sequence(value: Sequence[str] | str | None) -> tuple[str, ...]:
+    if value is None:
+        return ()
+    if isinstance(value, str):
+        return (value,)
+    return tuple(value)
+
+
+def evaluate_leak_prone_columns(
+    columns: Iterable[str],
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+) -> LeakCheckResult:
+    """Identify leak-prone columns using the configured policy."""
+
+    banned: dict[str, str] = {}
+    columns_list = list(columns)
+    for col in columns_list:
+        if col in policy.banned_exact:
+            banned[col] = "exact"
+            continue
+        for prefix in policy.banned_prefixes:
+            if col.startswith(prefix):
+                banned[col] = f"prefix:{prefix}"
+                break
+        if col in banned:
+            continue
+        for suffix in policy.banned_suffixes:
+            if col.endswith(suffix):
+                banned[col] = f"suffix:{suffix}"
+                break
+        if col in banned:
+            continue
+        for pattern, reason in policy.banned_regex:
+            if pattern.match(col):
+                banned[col] = reason
+                break
+
+    kept = [c for c in columns_list if c not in banned]
+    return LeakCheckResult(
+        policy_version=policy.version,
+        banned=banned,
+        kept=kept,
+        dropped=[],
+        allowlist_kept=[],
+    )
+
+
+def enforce_leak_guard(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    allow_prefixes: Sequence[str] | str | None = None,
+    allow_exact: Sequence[str] | str | None = None,
+    drop_banned: bool = True,
+    drop_non_allowlisted: bool = False,
+    raise_on_banned: bool = True,
+) -> tuple[pl.DataFrame | "pd.DataFrame", LeakCheckResult]:
+    """Apply leak guardrails to a feature frame.
+
+    Parameters
+    ----------
+    df : DataFrame
+        Polars or pandas DataFrame.
+    policy : LeakPolicy
+        Leak policy to apply.
+    allow_prefixes : Sequence[str] | str | None
+        Optional prefixes that define the allowed feature surface for a problem.
+    allow_exact : Sequence[str] | str | None
+        Explicitly allowed columns (e.g., identifiers).
+    drop_banned : bool
+        If True, drop any banned columns automatically.
+    drop_non_allowlisted : bool
+        If True, drop columns that are not covered by allow_prefixes/allow_exact/identifiers/targets.
+    raise_on_banned : bool
+        If True, raise when banned columns are detected (after optional drop).
+    """
+
+    result = evaluate_leak_prone_columns(df.columns, policy=policy)
+    dropped: list[str] = []
+
+    allow_prefixes = _ensure_sequence(allow_prefixes)
+    allow_exact = set(_ensure_sequence(allow_exact))
+    allow_exact.update({col for col in IDENTIFIER_COLUMNS if col in df.columns})
+    allow_exact.update({col for col in NFL_TARGET_COLUMNS if col in df.columns})
+
+    # Permit allowlisted columns even if they match a banned rule (e.g., labels)
+    banned = {col: reason for col, reason in result.banned.items() if col not in allow_exact}
+
+    if banned and drop_banned:
+        df = df.drop(list(banned.keys()))
+        dropped.extend(banned.keys())
+
+    if banned and raise_on_banned:
+        raise ValueError(f"Leak-prone columns detected: {sorted(banned.items())}")
+
+    allowlist_cols: set[str] = set()
+    if allow_prefixes:
+        allowlist_cols.update({c for c in df.columns if c.startswith(allow_prefixes)})
+    allowlist_cols.update({c for c in allow_exact if c in df.columns})
+
+    if drop_non_allowlisted and allowlist_cols:
+        drop_candidates = [c for c in df.columns if c not in allowlist_cols]
+        if drop_candidates:
+            df = df.drop(drop_candidates)
+            dropped.extend(drop_candidates)
+
+    if drop_non_allowlisted and not allowlist_cols:
+        raise ValueError("No allowlisted columns remain after applying leak guard allowlist.")
+
+    # Store adjusted banned info on the result
+    result.banned = banned
+    result.dropped = dropped
+    result.kept = [c for c in df.columns]
+    result.allowlist_kept = sorted(list(allowlist_cols)) if allowlist_cols else []
+    return df, result
+
+
+def build_schema_snapshot(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    metadata: Mapping[str, object] | None = None,
+    banned: Mapping[str, str] | None = None,
+) -> dict:
+    """Render a schema snapshot describing each column and whether it was flagged."""
+
+    banned = banned or {}
+    meta = {
+        "generated_at_utc": datetime.utcnow().isoformat(),
+        "policy_version": policy.version,
+    }
+    meta.update(metadata or {})
+
+    # Extract columns / dtypes
+    if isinstance(df, pl.DataFrame):
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+    else:  # pandas or pandas-like
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+
+    schema = {
+        "metadata": meta,
+        "columns": [],
+    }
+
+    for col, dtype in cols_and_dtypes:
+        tags: list[str] = []
+        if col in IDENTIFIER_COLUMNS:
+            tags.append("id")
+        if col in NFL_TARGET_COLUMNS:
+            tags.append("label")
+        if col.startswith("market_"):
+            tags.append("odds")
+        if col.startswith("injury_") or col.startswith("practice_"):
+            tags.append("injury")
+        if col.startswith("weather_"):
+            tags.append("weather")
+        if col.startswith("ps_"):
+            tags.append("pre_snap")
+        schema["columns"].append(
+            {
+                "name": col,
+                "dtype": dtype,
+                "banned": col in banned,
+                "tags": tags,
+            }
+        )
+    return schema
+
+
+def write_schema_snapshot(path, schema: Mapping[str, object]) -> None:
+    path.parent.mkdir(parents=True, exist_ok=True)
+    with open(path, "w") as fp:
+        json.dump(schema, fp, indent=2, sort_keys=True)
+
+
+__all__ = [
+    "DEFAULT_LEAK_POLICY",
+    "LeakPolicy",
+    "LeakCheckResult",
+    "evaluate_leak_prone_columns",
+    "enforce_leak_guard",
+    "build_schema_snapshot",
+    "write_schema_snapshot",
+]
diff --git a/utils/general/constants.py b/utils/general/constants.py
index d94b4260ad877484da843fa99ae2caf37e8493f4..dea87caa354d94e4a08b1762d2bd8dcd4c8caa3a
--- a/utils/general/constants.py
+++ b/utils/general/constants.py
@@ -211,7 +211,17 @@
 
 NFL_TARGET_COLUMNS: Tuple[str, ...] = (
     'anytime_td',
+    'anytime_td_offense',
+    'anytime_td_all',
+    'anytime_td_rush',
+    'anytime_td_rec',
+    'anytime_td_pass_thrown',
     'td_count',
+    'td_count_offense',
+    'td_count_all',
+    'passing_td',
+    'rushing_td_count',
+    'receiving_td_count',
     'receiving_yards',
     'rushing_yards',
     'passing_yards',


thinking
**Examining code around line 2800**
exec
/bin/zsh -lc "cd /Users/jameswest/Desktop/nfl_predict && sed -n '2800,3060p' utils/feature/player_game_level.py" in /Users/jameswest/Desktop/nfl_predict succeeded in 2.78s:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
                ]
                existing_injury_cols = [col for col in injury_cols_override if col in df_merged.columns]
                if existing_injury_cols:
                    df_merged = df_merged.drop(existing_injury_cols)
                df_merged = df_merged.join(
                    injury_features,
                    on=post_join_keys,
                    how="left",
                )
                logger.debug(
                    "Injury join delivered %d rows (sample: %s)",
                    len(df_merged),
                    df_merged.select(
                        ["season", "week", "player_id", "injury_report_status"]
                    ).head(5),
                )

        tx_seasons = (
            df_merged.select(pl.col("season").drop_nulls().unique())
file update:
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 5ba68e8bf1acd3a789a76a8857674e6f6433017b..0210d5b7e7ed60a8de7a126d64f5ed76326474c8
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -14,7 +14,7 @@
 
 import logging
 import os
-from datetime import date, timedelta
+from datetime import date, datetime, timedelta
 from typing import Sequence
 
 import polars as pl
@@ -37,6 +37,12 @@
     add_offense_context_features_training,
     _append_offense_context_columns,
 )
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    build_schema_snapshot,
+    enforce_leak_guard,
+    write_schema_snapshot,
+)
 from utils.feature.weather_features import (
     add_weather_forecast_features_training,
     append_weather_context_flags,
@@ -931,6 +937,32 @@
     if market_exprs:
         df_player_game_all = df_player_game_all.with_columns(market_exprs)
     
+    # Leak guard + schema snapshot before persisting
+    spec = get_label_spec(label_version)
+    allow_exact = {spec.primary, *spec.labels.keys(), *spec.aliases.keys()}
+    df_player_game_all, leak_result = enforce_leak_guard(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_exact=allow_exact,
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=True,
+    )
+
+    schema = build_schema_snapshot(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        metadata={
+            "cutoff_label": cutoff_label,
+            "label_version": spec.name,
+        },
+        banned=leak_result.banned,
+    )
+    schema_dir = FEATURE_AUDIT_DIR / "schema" / "anytime_td"
+    schema_path = schema_dir / f"{cutoff_label}_{datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')}.json"
+    write_schema_snapshot(schema_path, schema)
+    logging.info("    Schema snapshot written → %s", schema_path)
+
     # Write final feature matrix
     df_player_game_all = df_player_game_all.with_columns(
         pl.lit(current_cutoff_hours).cast(pl.Float32).alias("decision_horizon_hours")
@@ -951,7 +983,6 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    spec = get_label_spec(label_version)
     label_candidates = {spec.primary, "anytime_td"}
     for label_col in label_candidates:
         if label_col in df_player_game_all.columns:
diff --git a/pipeline/train.py b/pipeline/train.py
index fe70207dcdf25d209ee3ad55080b7ce826347c44..3fab3a05b3f65e8d0e88ec1ddaa71a8857646148
--- a/pipeline/train.py
+++ b/pipeline/train.py
@@ -98,6 +98,7 @@
     fit_team_conformal_sums,
     composite_sum_interval,
 )
+from utils.feature.leak_guard import DEFAULT_LEAK_POLICY, enforce_leak_guard
 from utils.feature.targets import require_target_column
 
 # Ignore specific, noisy warnings from dependencies
@@ -2315,7 +2316,30 @@
                             df_problem[col] = df_problem[col].fillna(df_problem[col].mean())
 
                 df_problem = self._inject_composed_features(df_problem)
-            
+
+            # Leak guard on the problem-scoped frame
+            allow_prefixes = tuple(problem_copy.get('feature_prefixes_to_include') or [])
+            allow_exact = set(problem_copy.get('other_features_to_include') or [])
+            allow_exact.update(input_preds or [])
+            if self.target_col:
+                allow_exact.add(self.target_col)
+            df_problem, leak_info = enforce_leak_guard(
+                df_problem,
+                policy=DEFAULT_LEAK_POLICY,
+                allow_prefixes=allow_prefixes,
+                allow_exact=allow_exact,
+                drop_banned=True,
+                drop_non_allowlisted=False,
+                raise_on_banned=True,
+            )
+            if leak_info.dropped:
+                logger.info(
+                    "Dropped %d leak-prone columns for %s: %s",
+                    len(leak_info.dropped),
+                    problem_name,
+                    sorted(leak_info.dropped),
+                )
+
             self._normalize_datetime_like_columns(df_problem, problem_name)
             df_problem[self.time_col] = pd.to_datetime(df_problem[self.time_col])
             sort_cols = [self.time_col]
diff --git a/tests/test_data_leak_guard.py b/tests/test_data_leak_guard.py
index 8061f2760c0898aaeda29026859e1b9ff5644ba4..3e56665921db89ea523bbdb205d1bb90c21893df
--- a/tests/test_data_leak_guard.py
+++ b/tests/test_data_leak_guard.py
@@ -3,6 +3,14 @@
 import yaml
 from pathlib import Path
 
+import polars as pl
+
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    enforce_leak_guard,
+    evaluate_leak_prone_columns,
+)
+
 
 PROJECT_ROOT = Path(__file__).resolve().parents[1]
 TRAINING_CONFIG = PROJECT_ROOT / "config" / "training.yaml"
@@ -48,3 +56,41 @@
     )
 
 
+def test_leak_guard_flags_pattern_columns():
+    cols = [
+        "market_anytime_td_prob",
+        "final_score",
+        "postgame_anytime_td",
+        "actual_td_count",
+        "safe_feature",
+    ]
+    result = evaluate_leak_prone_columns(cols, policy=DEFAULT_LEAK_POLICY)
+    assert set(result.banned.keys()) == {"final_score", "postgame_anytime_td", "actual_td_count"}
+    assert "safe_feature" in result.kept
+    assert "market_anytime_td_prob" in result.kept
+
+
+def test_enforce_leak_guard_drops_banned_and_keeps_allowlisted():
+    df = pl.DataFrame(
+        {
+            "game_id": ["g1", "g2"],
+            "safe_feature": [1.0, 2.0],
+            "postgame_anytime_td": [1, 0],
+            "final_score": [30, 24],
+        }
+    )
+    cleaned, info = enforce_leak_guard(
+        df,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_prefixes=("safe_",),
+        allow_exact=("game_id",),
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=False,
+    )
+    assert "postgame_anytime_td" not in cleaned.columns
+    assert "final_score" not in cleaned.columns
+    assert "safe_feature" in cleaned.columns
+    assert "game_id" in cleaned.columns
+    assert set(info.dropped) == {"postgame_anytime_td", "final_score"}
+
diff --git a/utils/feature/leak_guard.py b/utils/feature/leak_guard.py
new file mode 100644
index 0000000000000000000000000000000000000000..9faf8cfffc436e0934b2f410aaf252e52f4f95df
--- /dev/null
+++ b/utils/feature/leak_guard.py
@@ -0,0 +1,273 @@
+"""Leak guardrails for feature matrices.
+
+This module centralizes pattern-based leak detection so both feature assembly
+and training can fail fast when post-outcome columns sneak into the data.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+from datetime import datetime
+import json
+import re
+from typing import Iterable, Mapping, Sequence
+
+import polars as pl
+
+from utils.general.constants import IDENTIFIER_COLUMNS, LEAK_PRONE_COLUMNS, NFL_TARGET_COLUMNS
+
+try:  # Optional dependency when imported from training (pandas path)
+    import pandas as pd  # type: ignore
+except Exception:  # pragma: no cover - optional dependency
+    pd = None
+
+
+@dataclass(frozen=True)
+class LeakPolicy:
+    version: str
+    banned_exact: set[str]
+    banned_prefixes: tuple[str, ...]
+    banned_suffixes: tuple[str, ...]
+    banned_regex: tuple[tuple[re.Pattern[str], str], ...]
+    description: str = ""
+
+
+@dataclass
+class LeakCheckResult:
+    policy_version: str
+    banned: dict[str, str]
+    kept: list[str]
+    dropped: list[str]
+    allowlist_kept: list[str]
+
+
+# Core policy tuned for anytime-TD style problems (can be extended per-problem).
+_BASE_BANNED_EXACT = set(LEAK_PRONE_COLUMNS) | {
+    "final_score",
+    "final_total",
+    "points_scored",
+    "actual_td_count",
+    "actual_anytime_td",
+    "postgame_anytime_td",
+    "postgame_td_count",
+}
+_BASE_BANNED_PREFIXES = (
+    "postgame_",
+    "post_game_",
+    "post_",
+    "live_",
+    "actual_",
+    "realized_",
+    "final_",
+    "postmatch_",
+)
+_BASE_BANNED_SUFFIXES = (
+    "_post",
+    "_postgame",
+    "_final",
+    "_fullgame",
+    "_actual",
+)
+_BASE_BANNED_REGEX: tuple[tuple[re.Pattern[str], str], ...] = (
+    (re.compile(r".*post.?game.*", flags=re.IGNORECASE), "postgame marker"),
+    (re.compile(r".*final_score.*", flags=re.IGNORECASE), "final score"),
+    (re.compile(r".*actual.*td.*", flags=re.IGNORECASE), "actual TD total"),
+    (re.compile(r".*anytime_td.*(post|final|actual).*", flags=re.IGNORECASE), "post-decision anytime TD"),
+    (re.compile(r".*fullgame.*", flags=re.IGNORECASE), "full game cumulative value"),
+)
+
+DEFAULT_LEAK_POLICY = LeakPolicy(
+    version="v1",
+    description="Core post-outcome leak guard for NFL anytime TD features.",
+    banned_exact=_BASE_BANNED_EXACT,
+    banned_prefixes=_BASE_BANNED_PREFIXES,
+    banned_suffixes=_BASE_BANNED_SUFFIXES,
+    banned_regex=_BASE_BANNED_REGEX,
+)
+
+
+def _ensure_sequence(value: Sequence[str] | str | None) -> tuple[str, ...]:
+    if value is None:
+        return ()
+    if isinstance(value, str):
+        return (value,)
+    return tuple(value)
+
+
+def evaluate_leak_prone_columns(
+    columns: Iterable[str],
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+) -> LeakCheckResult:
+    """Identify leak-prone columns using the configured policy."""
+
+    banned: dict[str, str] = {}
+    columns_list = list(columns)
+    for col in columns_list:
+        if col in policy.banned_exact:
+            banned[col] = "exact"
+            continue
+        for prefix in policy.banned_prefixes:
+            if col.startswith(prefix):
+                banned[col] = f"prefix:{prefix}"
+                break
+        if col in banned:
+            continue
+        for suffix in policy.banned_suffixes:
+            if col.endswith(suffix):
+                banned[col] = f"suffix:{suffix}"
+                break
+        if col in banned:
+            continue
+        for pattern, reason in policy.banned_regex:
+            if pattern.match(col):
+                banned[col] = reason
+                break
+
+    kept = [c for c in columns_list if c not in banned]
+    return LeakCheckResult(
+        policy_version=policy.version,
+        banned=banned,
+        kept=kept,
+        dropped=[],
+        allowlist_kept=[],
+    )
+
+
+def enforce_leak_guard(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    allow_prefixes: Sequence[str] | str | None = None,
+    allow_exact: Sequence[str] | str | None = None,
+    drop_banned: bool = True,
+    drop_non_allowlisted: bool = False,
+    raise_on_banned: bool = True,
+) -> tuple[pl.DataFrame | "pd.DataFrame", LeakCheckResult]:
+    """Apply leak guardrails to a feature frame.
+
+    Parameters
+    ----------
+    df : DataFrame
+        Polars or pandas DataFrame.
+    policy : LeakPolicy
+        Leak policy to apply.
+    allow_prefixes : Sequence[str] | str | None
+        Optional prefixes that define the allowed feature surface for a problem.
+    allow_exact : Sequence[str] | str | None
+        Explicitly allowed columns (e.g., identifiers).
+    drop_banned : bool
+        If True, drop any banned columns automatically.
+    drop_non_allowlisted : bool
+        If True, drop columns that are not covered by allow_prefixes/allow_exact/identifiers/targets.
+    raise_on_banned : bool
+        If True, raise when banned columns are detected (after optional drop).
+    """
+
+    result = evaluate_leak_prone_columns(df.columns, policy=policy)
+    dropped: list[str] = []
+
+    allow_prefixes = _ensure_sequence(allow_prefixes)
+    allow_exact = set(_ensure_sequence(allow_exact))
+    allow_exact.update({col for col in IDENTIFIER_COLUMNS if col in df.columns})
+    allow_exact.update({col for col in NFL_TARGET_COLUMNS if col in df.columns})
+
+    # Permit allowlisted columns even if they match a banned rule (e.g., labels)
+    banned = {col: reason for col, reason in result.banned.items() if col not in allow_exact}
+
+    if banned and drop_banned:
+        df = df.drop(list(banned.keys()))
+        dropped.extend(banned.keys())
+
+    if banned and raise_on_banned:
+        raise ValueError(f"Leak-prone columns detected: {sorted(banned.items())}")
+
+    allowlist_cols: set[str] = set()
+    if allow_prefixes:
+        allowlist_cols.update({c for c in df.columns if c.startswith(allow_prefixes)})
+    allowlist_cols.update({c for c in allow_exact if c in df.columns})
+
+    if drop_non_allowlisted and allowlist_cols:
+        drop_candidates = [c for c in df.columns if c not in allowlist_cols]
+        if drop_candidates:
+            df = df.drop(drop_candidates)
+            dropped.extend(drop_candidates)
+
+    if drop_non_allowlisted and not allowlist_cols:
+        raise ValueError("No allowlisted columns remain after applying leak guard allowlist.")
+
+    # Store adjusted banned info on the result
+    result.banned = banned
+    result.dropped = dropped
+    result.kept = [c for c in df.columns]
+    result.allowlist_kept = sorted(list(allowlist_cols)) if allowlist_cols else []
+    return df, result
+
+
+def build_schema_snapshot(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    metadata: Mapping[str, object] | None = None,
+    banned: Mapping[str, str] | None = None,
+) -> dict:
+    """Render a schema snapshot describing each column and whether it was flagged."""
+
+    banned = banned or {}
+    meta = {
+        "generated_at_utc": datetime.utcnow().isoformat(),
+        "policy_version": policy.version,
+    }
+    meta.update(metadata or {})
+
+    # Extract columns / dtypes
+    if isinstance(df, pl.DataFrame):
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+    else:  # pandas or pandas-like
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+
+    schema = {
+        "metadata": meta,
+        "columns": [],
+    }
+
+    for col, dtype in cols_and_dtypes:
+        tags: list[str] = []
+        if col in IDENTIFIER_COLUMNS:
+            tags.append("id")
+        if col in NFL_TARGET_COLUMNS:
+            tags.append("label")
+        if col.startswith("market_"):
+            tags.append("odds")
+        if col.startswith("injury_") or col.startswith("practice_"):
+            tags.append("injury")
+        if col.startswith("weather_"):
+            tags.append("weather")
+        if col.startswith("ps_"):
+            tags.append("pre_snap")
+        schema["columns"].append(
+            {
+                "name": col,
+                "dtype": dtype,
+                "banned": col in banned,
+                "tags": tags,
+            }
+        )
+    return schema
+
+
+def write_schema_snapshot(path, schema: Mapping[str, object]) -> None:
+    path.parent.mkdir(parents=True, exist_ok=True)
+    with open(path, "w") as fp:
+        json.dump(schema, fp, indent=2, sort_keys=True)
+
+
+__all__ = [
+    "DEFAULT_LEAK_POLICY",
+    "LeakPolicy",
+    "LeakCheckResult",
+    "evaluate_leak_prone_columns",
+    "enforce_leak_guard",
+    "build_schema_snapshot",
+    "write_schema_snapshot",
+]
diff --git a/utils/general/constants.py b/utils/general/constants.py
index d94b4260ad877484da843fa99ae2caf37e8493f4..dea87caa354d94e4a08b1762d2bd8dcd4c8caa3a
--- a/utils/general/constants.py
+++ b/utils/general/constants.py
@@ -211,7 +211,17 @@
 
 NFL_TARGET_COLUMNS: Tuple[str, ...] = (
     'anytime_td',
+    'anytime_td_offense',
+    'anytime_td_all',
+    'anytime_td_rush',
+    'anytime_td_rec',
+    'anytime_td_pass_thrown',
     'td_count',
+    'td_count_offense',
+    'td_count_all',
+    'passing_td',
+    'rushing_td_count',
+    'receiving_td_count',
     'receiving_yards',
     'rushing_yards',
     'passing_yards',


thinking
**Searching for player market features loader**
exec
/bin/zsh -lc 'cd /Users/jameswest/Desktop/nfl_predict && rg "def _load_player_market_features" -n utils/feature/player_game_level.py' in /Users/jameswest/Desktop/nfl_predict succeeded in 947ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
1380:def _load_player_market_features(seasons: list[int]) -> pl.DataFrame:
file update:
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 5ba68e8bf1acd3a789a76a8857674e6f6433017b..0210d5b7e7ed60a8de7a126d64f5ed76326474c8
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -14,7 +14,7 @@
 
 import logging
 import os
-from datetime import date, timedelta
+from datetime import date, datetime, timedelta
 from typing import Sequence
 
 import polars as pl
@@ -37,6 +37,12 @@
     add_offense_context_features_training,
     _append_offense_context_columns,
 )
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    build_schema_snapshot,
+    enforce_leak_guard,
+    write_schema_snapshot,
+)
 from utils.feature.weather_features import (
     add_weather_forecast_features_training,
     append_weather_context_flags,
@@ -931,6 +937,32 @@
     if market_exprs:
         df_player_game_all = df_player_game_all.with_columns(market_exprs)
     
+    # Leak guard + schema snapshot before persisting
+    spec = get_label_spec(label_version)
+    allow_exact = {spec.primary, *spec.labels.keys(), *spec.aliases.keys()}
+    df_player_game_all, leak_result = enforce_leak_guard(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_exact=allow_exact,
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=True,
+    )
+
+    schema = build_schema_snapshot(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        metadata={
+            "cutoff_label": cutoff_label,
+            "label_version": spec.name,
+        },
+        banned=leak_result.banned,
+    )
+    schema_dir = FEATURE_AUDIT_DIR / "schema" / "anytime_td"
+    schema_path = schema_dir / f"{cutoff_label}_{datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')}.json"
+    write_schema_snapshot(schema_path, schema)
+    logging.info("    Schema snapshot written → %s", schema_path)
+
     # Write final feature matrix
     df_player_game_all = df_player_game_all.with_columns(
         pl.lit(current_cutoff_hours).cast(pl.Float32).alias("decision_horizon_hours")
@@ -951,7 +983,6 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    spec = get_label_spec(label_version)
     label_candidates = {spec.primary, "anytime_td"}
     for label_col in label_candidates:
         if label_col in df_player_game_all.columns:
diff --git a/pipeline/train.py b/pipeline/train.py
index fe70207dcdf25d209ee3ad55080b7ce826347c44..3fab3a05b3f65e8d0e88ec1ddaa71a8857646148
--- a/pipeline/train.py
+++ b/pipeline/train.py
@@ -98,6 +98,7 @@
     fit_team_conformal_sums,
     composite_sum_interval,
 )
+from utils.feature.leak_guard import DEFAULT_LEAK_POLICY, enforce_leak_guard
 from utils.feature.targets import require_target_column
 
 # Ignore specific, noisy warnings from dependencies
@@ -2315,7 +2316,30 @@
                             df_problem[col] = df_problem[col].fillna(df_problem[col].mean())
 
                 df_problem = self._inject_composed_features(df_problem)
-            
+
+            # Leak guard on the problem-scoped frame
+            allow_prefixes = tuple(problem_copy.get('feature_prefixes_to_include') or [])
+            allow_exact = set(problem_copy.get('other_features_to_include') or [])
+            allow_exact.update(input_preds or [])
+            if self.target_col:
+                allow_exact.add(self.target_col)
+            df_problem, leak_info = enforce_leak_guard(
+                df_problem,
+                policy=DEFAULT_LEAK_POLICY,
+                allow_prefixes=allow_prefixes,
+                allow_exact=allow_exact,
+                drop_banned=True,
+                drop_non_allowlisted=False,
+                raise_on_banned=True,
+            )
+            if leak_info.dropped:
+                logger.info(
+                    "Dropped %d leak-prone columns for %s: %s",
+                    len(leak_info.dropped),
+                    problem_name,
+                    sorted(leak_info.dropped),
+                )
+
             self._normalize_datetime_like_columns(df_problem, problem_name)
             df_problem[self.time_col] = pd.to_datetime(df_problem[self.time_col])
             sort_cols = [self.time_col]
diff --git a/tests/test_data_leak_guard.py b/tests/test_data_leak_guard.py
index 8061f2760c0898aaeda29026859e1b9ff5644ba4..3e56665921db89ea523bbdb205d1bb90c21893df
--- a/tests/test_data_leak_guard.py
+++ b/tests/test_data_leak_guard.py
@@ -3,6 +3,14 @@
 import yaml
 from pathlib import Path
 
+import polars as pl
+
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    enforce_leak_guard,
+    evaluate_leak_prone_columns,
+)
+
 
 PROJECT_ROOT = Path(__file__).resolve().parents[1]
 TRAINING_CONFIG = PROJECT_ROOT / "config" / "training.yaml"
@@ -48,3 +56,41 @@
     )
 
 
+def test_leak_guard_flags_pattern_columns():
+    cols = [
+        "market_anytime_td_prob",
+        "final_score",
+        "postgame_anytime_td",
+        "actual_td_count",
+        "safe_feature",
+    ]
+    result = evaluate_leak_prone_columns(cols, policy=DEFAULT_LEAK_POLICY)
+    assert set(result.banned.keys()) == {"final_score", "postgame_anytime_td", "actual_td_count"}
+    assert "safe_feature" in result.kept
+    assert "market_anytime_td_prob" in result.kept
+
+
+def test_enforce_leak_guard_drops_banned_and_keeps_allowlisted():
+    df = pl.DataFrame(
+        {
+            "game_id": ["g1", "g2"],
+            "safe_feature": [1.0, 2.0],
+            "postgame_anytime_td": [1, 0],
+            "final_score": [30, 24],
+        }
+    )
+    cleaned, info = enforce_leak_guard(
+        df,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_prefixes=("safe_",),
+        allow_exact=("game_id",),
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=False,
+    )
+    assert "postgame_anytime_td" not in cleaned.columns
+    assert "final_score" not in cleaned.columns
+    assert "safe_feature" in cleaned.columns
+    assert "game_id" in cleaned.columns
+    assert set(info.dropped) == {"postgame_anytime_td", "final_score"}
+
diff --git a/utils/feature/leak_guard.py b/utils/feature/leak_guard.py
new file mode 100644
index 0000000000000000000000000000000000000000..9faf8cfffc436e0934b2f410aaf252e52f4f95df
--- /dev/null
+++ b/utils/feature/leak_guard.py
@@ -0,0 +1,273 @@
+"""Leak guardrails for feature matrices.
+
+This module centralizes pattern-based leak detection so both feature assembly
+and training can fail fast when post-outcome columns sneak into the data.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+from datetime import datetime
+import json
+import re
+from typing import Iterable, Mapping, Sequence
+
+import polars as pl
+
+from utils.general.constants import IDENTIFIER_COLUMNS, LEAK_PRONE_COLUMNS, NFL_TARGET_COLUMNS
+
+try:  # Optional dependency when imported from training (pandas path)
+    import pandas as pd  # type: ignore
+except Exception:  # pragma: no cover - optional dependency
+    pd = None
+
+
+@dataclass(frozen=True)
+class LeakPolicy:
+    version: str
+    banned_exact: set[str]
+    banned_prefixes: tuple[str, ...]
+    banned_suffixes: tuple[str, ...]
+    banned_regex: tuple[tuple[re.Pattern[str], str], ...]
+    description: str = ""
+
+
+@dataclass
+class LeakCheckResult:
+    policy_version: str
+    banned: dict[str, str]
+    kept: list[str]
+    dropped: list[str]
+    allowlist_kept: list[str]
+
+
+# Core policy tuned for anytime-TD style problems (can be extended per-problem).
+_BASE_BANNED_EXACT = set(LEAK_PRONE_COLUMNS) | {
+    "final_score",
+    "final_total",
+    "points_scored",
+    "actual_td_count",
+    "actual_anytime_td",
+    "postgame_anytime_td",
+    "postgame_td_count",
+}
+_BASE_BANNED_PREFIXES = (
+    "postgame_",
+    "post_game_",
+    "post_",
+    "live_",
+    "actual_",
+    "realized_",
+    "final_",
+    "postmatch_",
+)
+_BASE_BANNED_SUFFIXES = (
+    "_post",
+    "_postgame",
+    "_final",
+    "_fullgame",
+    "_actual",
+)
+_BASE_BANNED_REGEX: tuple[tuple[re.Pattern[str], str], ...] = (
+    (re.compile(r".*post.?game.*", flags=re.IGNORECASE), "postgame marker"),
+    (re.compile(r".*final_score.*", flags=re.IGNORECASE), "final score"),
+    (re.compile(r".*actual.*td.*", flags=re.IGNORECASE), "actual TD total"),
+    (re.compile(r".*anytime_td.*(post|final|actual).*", flags=re.IGNORECASE), "post-decision anytime TD"),
+    (re.compile(r".*fullgame.*", flags=re.IGNORECASE), "full game cumulative value"),
+)
+
+DEFAULT_LEAK_POLICY = LeakPolicy(
+    version="v1",
+    description="Core post-outcome leak guard for NFL anytime TD features.",
+    banned_exact=_BASE_BANNED_EXACT,
+    banned_prefixes=_BASE_BANNED_PREFIXES,
+    banned_suffixes=_BASE_BANNED_SUFFIXES,
+    banned_regex=_BASE_BANNED_REGEX,
+)
+
+
+def _ensure_sequence(value: Sequence[str] | str | None) -> tuple[str, ...]:
+    if value is None:
+        return ()
+    if isinstance(value, str):
+        return (value,)
+    return tuple(value)
+
+
+def evaluate_leak_prone_columns(
+    columns: Iterable[str],
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+) -> LeakCheckResult:
+    """Identify leak-prone columns using the configured policy."""
+
+    banned: dict[str, str] = {}
+    columns_list = list(columns)
+    for col in columns_list:
+        if col in policy.banned_exact:
+            banned[col] = "exact"
+            continue
+        for prefix in policy.banned_prefixes:
+            if col.startswith(prefix):
+                banned[col] = f"prefix:{prefix}"
+                break
+        if col in banned:
+            continue
+        for suffix in policy.banned_suffixes:
+            if col.endswith(suffix):
+                banned[col] = f"suffix:{suffix}"
+                break
+        if col in banned:
+            continue
+        for pattern, reason in policy.banned_regex:
+            if pattern.match(col):
+                banned[col] = reason
+                break
+
+    kept = [c for c in columns_list if c not in banned]
+    return LeakCheckResult(
+        policy_version=policy.version,
+        banned=banned,
+        kept=kept,
+        dropped=[],
+        allowlist_kept=[],
+    )
+
+
+def enforce_leak_guard(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    allow_prefixes: Sequence[str] | str | None = None,
+    allow_exact: Sequence[str] | str | None = None,
+    drop_banned: bool = True,
+    drop_non_allowlisted: bool = False,
+    raise_on_banned: bool = True,
+) -> tuple[pl.DataFrame | "pd.DataFrame", LeakCheckResult]:
+    """Apply leak guardrails to a feature frame.
+
+    Parameters
+    ----------
+    df : DataFrame
+        Polars or pandas DataFrame.
+    policy : LeakPolicy
+        Leak policy to apply.
+    allow_prefixes : Sequence[str] | str | None
+        Optional prefixes that define the allowed feature surface for a problem.
+    allow_exact : Sequence[str] | str | None
+        Explicitly allowed columns (e.g., identifiers).
+    drop_banned : bool
+        If True, drop any banned columns automatically.
+    drop_non_allowlisted : bool
+        If True, drop columns that are not covered by allow_prefixes/allow_exact/identifiers/targets.
+    raise_on_banned : bool
+        If True, raise when banned columns are detected (after optional drop).
+    """
+
+    result = evaluate_leak_prone_columns(df.columns, policy=policy)
+    dropped: list[str] = []
+
+    allow_prefixes = _ensure_sequence(allow_prefixes)
+    allow_exact = set(_ensure_sequence(allow_exact))
+    allow_exact.update({col for col in IDENTIFIER_COLUMNS if col in df.columns})
+    allow_exact.update({col for col in NFL_TARGET_COLUMNS if col in df.columns})
+
+    # Permit allowlisted columns even if they match a banned rule (e.g., labels)
+    banned = {col: reason for col, reason in result.banned.items() if col not in allow_exact}
+
+    if banned and drop_banned:
+        df = df.drop(list(banned.keys()))
+        dropped.extend(banned.keys())
+
+    if banned and raise_on_banned:
+        raise ValueError(f"Leak-prone columns detected: {sorted(banned.items())}")
+
+    allowlist_cols: set[str] = set()
+    if allow_prefixes:
+        allowlist_cols.update({c for c in df.columns if c.startswith(allow_prefixes)})
+    allowlist_cols.update({c for c in allow_exact if c in df.columns})
+
+    if drop_non_allowlisted and allowlist_cols:
+        drop_candidates = [c for c in df.columns if c not in allowlist_cols]
+        if drop_candidates:
+            df = df.drop(drop_candidates)
+            dropped.extend(drop_candidates)
+
+    if drop_non_allowlisted and not allowlist_cols:
+        raise ValueError("No allowlisted columns remain after applying leak guard allowlist.")
+
+    # Store adjusted banned info on the result
+    result.banned = banned
+    result.dropped = dropped
+    result.kept = [c for c in df.columns]
+    result.allowlist_kept = sorted(list(allowlist_cols)) if allowlist_cols else []
+    return df, result
+
+
+def build_schema_snapshot(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    metadata: Mapping[str, object] | None = None,
+    banned: Mapping[str, str] | None = None,
+) -> dict:
+    """Render a schema snapshot describing each column and whether it was flagged."""
+
+    banned = banned or {}
+    meta = {
+        "generated_at_utc": datetime.utcnow().isoformat(),
+        "policy_version": policy.version,
+    }
+    meta.update(metadata or {})
+
+    # Extract columns / dtypes
+    if isinstance(df, pl.DataFrame):
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+    else:  # pandas or pandas-like
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+
+    schema = {
+        "metadata": meta,
+        "columns": [],
+    }
+
+    for col, dtype in cols_and_dtypes:
+        tags: list[str] = []
+        if col in IDENTIFIER_COLUMNS:
+            tags.append("id")
+        if col in NFL_TARGET_COLUMNS:
+            tags.append("label")
+        if col.startswith("market_"):
+            tags.append("odds")
+        if col.startswith("injury_") or col.startswith("practice_"):
+            tags.append("injury")
+        if col.startswith("weather_"):
+            tags.append("weather")
+        if col.startswith("ps_"):
+            tags.append("pre_snap")
+        schema["columns"].append(
+            {
+                "name": col,
+                "dtype": dtype,
+                "banned": col in banned,
+                "tags": tags,
+            }
+        )
+    return schema
+
+
+def write_schema_snapshot(path, schema: Mapping[str, object]) -> None:
+    path.parent.mkdir(parents=True, exist_ok=True)
+    with open(path, "w") as fp:
+        json.dump(schema, fp, indent=2, sort_keys=True)
+
+
+__all__ = [
+    "DEFAULT_LEAK_POLICY",
+    "LeakPolicy",
+    "LeakCheckResult",
+    "evaluate_leak_prone_columns",
+    "enforce_leak_guard",
+    "build_schema_snapshot",
+    "write_schema_snapshot",
+]
diff --git a/utils/general/constants.py b/utils/general/constants.py
index d94b4260ad877484da843fa99ae2caf37e8493f4..dea87caa354d94e4a08b1762d2bd8dcd4c8caa3a
--- a/utils/general/constants.py
+++ b/utils/general/constants.py
@@ -211,7 +211,17 @@
 
 NFL_TARGET_COLUMNS: Tuple[str, ...] = (
     'anytime_td',
+    'anytime_td_offense',
+    'anytime_td_all',
+    'anytime_td_rush',
+    'anytime_td_rec',
+    'anytime_td_pass_thrown',
     'td_count',
+    'td_count_offense',
+    'td_count_all',
+    'passing_td',
+    'rushing_td_count',
+    'receiving_td_count',
     'receiving_yards',
     'rushing_yards',
     'passing_yards',

exec
/bin/zsh -lc "cd /Users/jameswest/Desktop/nfl_predict && sed -n '1380,1500p' utils/feature/player_game_level.py" in /Users/jameswest/Desktop/nfl_predict succeeded in 808ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
def _load_player_market_features(seasons: list[int]) -> pl.DataFrame:
    """Load processed player market priors for the given seasons."""
    if not seasons:
        return pl.DataFrame()

    frames: list[pl.DataFrame] = []
    for season in sorted({int(s) for s in seasons}):
        base_dir = PLAYER_MARKET_PROCESSED_DIR / f"season={season}"
        if not base_dir.exists():
            continue
        week_dirs = sorted(base_dir.glob("week=*"))
        for week_dir in week_dirs:
            part_path = week_dir / "part.parquet"
            if not part_path.exists():
                continue
            try:
                frame = pl.read_parquet(part_path)
            except Exception as exc:  # pragma: no cover - defensive
                logger.warning("Failed to load player market features from %s: %s", part_path, exc)
file update:
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 5ba68e8bf1acd3a789a76a8857674e6f6433017b..0210d5b7e7ed60a8de7a126d64f5ed76326474c8
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -14,7 +14,7 @@
 
 import logging
 import os
-from datetime import date, timedelta
+from datetime import date, datetime, timedelta
 from typing import Sequence
 
 import polars as pl
@@ -37,6 +37,12 @@
     add_offense_context_features_training,
     _append_offense_context_columns,
 )
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    build_schema_snapshot,
+    enforce_leak_guard,
+    write_schema_snapshot,
+)
 from utils.feature.weather_features import (
     add_weather_forecast_features_training,
     append_weather_context_flags,
@@ -931,6 +937,32 @@
     if market_exprs:
         df_player_game_all = df_player_game_all.with_columns(market_exprs)
     
+    # Leak guard + schema snapshot before persisting
+    spec = get_label_spec(label_version)
+    allow_exact = {spec.primary, *spec.labels.keys(), *spec.aliases.keys()}
+    df_player_game_all, leak_result = enforce_leak_guard(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_exact=allow_exact,
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=True,
+    )
+
+    schema = build_schema_snapshot(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        metadata={
+            "cutoff_label": cutoff_label,
+            "label_version": spec.name,
+        },
+        banned=leak_result.banned,
+    )
+    schema_dir = FEATURE_AUDIT_DIR / "schema" / "anytime_td"
+    schema_path = schema_dir / f"{cutoff_label}_{datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')}.json"
+    write_schema_snapshot(schema_path, schema)
+    logging.info("    Schema snapshot written → %s", schema_path)
+
     # Write final feature matrix
     df_player_game_all = df_player_game_all.with_columns(
         pl.lit(current_cutoff_hours).cast(pl.Float32).alias("decision_horizon_hours")
@@ -951,7 +983,6 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    spec = get_label_spec(label_version)
     label_candidates = {spec.primary, "anytime_td"}
     for label_col in label_candidates:
         if label_col in df_player_game_all.columns:
diff --git a/pipeline/train.py b/pipeline/train.py
index fe70207dcdf25d209ee3ad55080b7ce826347c44..3fab3a05b3f65e8d0e88ec1ddaa71a8857646148
--- a/pipeline/train.py
+++ b/pipeline/train.py
@@ -98,6 +98,7 @@
     fit_team_conformal_sums,
     composite_sum_interval,
 )
+from utils.feature.leak_guard import DEFAULT_LEAK_POLICY, enforce_leak_guard
 from utils.feature.targets import require_target_column
 
 # Ignore specific, noisy warnings from dependencies
@@ -2315,7 +2316,30 @@
                             df_problem[col] = df_problem[col].fillna(df_problem[col].mean())
 
                 df_problem = self._inject_composed_features(df_problem)
-            
+
+            # Leak guard on the problem-scoped frame
+            allow_prefixes = tuple(problem_copy.get('feature_prefixes_to_include') or [])
+            allow_exact = set(problem_copy.get('other_features_to_include') or [])
+            allow_exact.update(input_preds or [])
+            if self.target_col:
+                allow_exact.add(self.target_col)
+            df_problem, leak_info = enforce_leak_guard(
+                df_problem,
+                policy=DEFAULT_LEAK_POLICY,
+                allow_prefixes=allow_prefixes,
+                allow_exact=allow_exact,
+                drop_banned=True,
+                drop_non_allowlisted=False,
+                raise_on_banned=True,
+            )
+            if leak_info.dropped:
+                logger.info(
+                    "Dropped %d leak-prone columns for %s: %s",
+                    len(leak_info.dropped),
+                    problem_name,
+                    sorted(leak_info.dropped),
+                )
+
             self._normalize_datetime_like_columns(df_problem, problem_name)
             df_problem[self.time_col] = pd.to_datetime(df_problem[self.time_col])
             sort_cols = [self.time_col]
diff --git a/tests/test_data_leak_guard.py b/tests/test_data_leak_guard.py
index 8061f2760c0898aaeda29026859e1b9ff5644ba4..3e56665921db89ea523bbdb205d1bb90c21893df
--- a/tests/test_data_leak_guard.py
+++ b/tests/test_data_leak_guard.py
@@ -3,6 +3,14 @@
 import yaml
 from pathlib import Path
 
+import polars as pl
+
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    enforce_leak_guard,
+    evaluate_leak_prone_columns,
+)
+
 
 PROJECT_ROOT = Path(__file__).resolve().parents[1]
 TRAINING_CONFIG = PROJECT_ROOT / "config" / "training.yaml"
@@ -48,3 +56,41 @@
     )
 
 
+def test_leak_guard_flags_pattern_columns():
+    cols = [
+        "market_anytime_td_prob",
+        "final_score",
+        "postgame_anytime_td",
+        "actual_td_count",
+        "safe_feature",
+    ]
+    result = evaluate_leak_prone_columns(cols, policy=DEFAULT_LEAK_POLICY)
+    assert set(result.banned.keys()) == {"final_score", "postgame_anytime_td", "actual_td_count"}
+    assert "safe_feature" in result.kept
+    assert "market_anytime_td_prob" in result.kept
+
+
+def test_enforce_leak_guard_drops_banned_and_keeps_allowlisted():
+    df = pl.DataFrame(
+        {
+            "game_id": ["g1", "g2"],
+            "safe_feature": [1.0, 2.0],
+            "postgame_anytime_td": [1, 0],
+            "final_score": [30, 24],
+        }
+    )
+    cleaned, info = enforce_leak_guard(
+        df,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_prefixes=("safe_",),
+        allow_exact=("game_id",),
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=False,
+    )
+    assert "postgame_anytime_td" not in cleaned.columns
+    assert "final_score" not in cleaned.columns
+    assert "safe_feature" in cleaned.columns
+    assert "game_id" in cleaned.columns
+    assert set(info.dropped) == {"postgame_anytime_td", "final_score"}
+
diff --git a/utils/feature/leak_guard.py b/utils/feature/leak_guard.py
new file mode 100644
index 0000000000000000000000000000000000000000..9faf8cfffc436e0934b2f410aaf252e52f4f95df
--- /dev/null
+++ b/utils/feature/leak_guard.py
@@ -0,0 +1,273 @@
+"""Leak guardrails for feature matrices.
+
+This module centralizes pattern-based leak detection so both feature assembly
+and training can fail fast when post-outcome columns sneak into the data.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+from datetime import datetime
+import json
+import re
+from typing import Iterable, Mapping, Sequence
+
+import polars as pl
+
+from utils.general.constants import IDENTIFIER_COLUMNS, LEAK_PRONE_COLUMNS, NFL_TARGET_COLUMNS
+
+try:  # Optional dependency when imported from training (pandas path)
+    import pandas as pd  # type: ignore
+except Exception:  # pragma: no cover - optional dependency
+    pd = None
+
+
+@dataclass(frozen=True)
+class LeakPolicy:
+    version: str
+    banned_exact: set[str]
+    banned_prefixes: tuple[str, ...]
+    banned_suffixes: tuple[str, ...]
+    banned_regex: tuple[tuple[re.Pattern[str], str], ...]
+    description: str = ""
+
+
+@dataclass
+class LeakCheckResult:
+    policy_version: str
+    banned: dict[str, str]
+    kept: list[str]
+    dropped: list[str]
+    allowlist_kept: list[str]
+
+
+# Core policy tuned for anytime-TD style problems (can be extended per-problem).
+_BASE_BANNED_EXACT = set(LEAK_PRONE_COLUMNS) | {
+    "final_score",
+    "final_total",
+    "points_scored",
+    "actual_td_count",
+    "actual_anytime_td",
+    "postgame_anytime_td",
+    "postgame_td_count",
+}
+_BASE_BANNED_PREFIXES = (
+    "postgame_",
+    "post_game_",
+    "post_",
+    "live_",
+    "actual_",
+    "realized_",
+    "final_",
+    "postmatch_",
+)
+_BASE_BANNED_SUFFIXES = (
+    "_post",
+    "_postgame",
+    "_final",
+    "_fullgame",
+    "_actual",
+)
+_BASE_BANNED_REGEX: tuple[tuple[re.Pattern[str], str], ...] = (
+    (re.compile(r".*post.?game.*", flags=re.IGNORECASE), "postgame marker"),
+    (re.compile(r".*final_score.*", flags=re.IGNORECASE), "final score"),
+    (re.compile(r".*actual.*td.*", flags=re.IGNORECASE), "actual TD total"),
+    (re.compile(r".*anytime_td.*(post|final|actual).*", flags=re.IGNORECASE), "post-decision anytime TD"),
+    (re.compile(r".*fullgame.*", flags=re.IGNORECASE), "full game cumulative value"),
+)
+
+DEFAULT_LEAK_POLICY = LeakPolicy(
+    version="v1",
+    description="Core post-outcome leak guard for NFL anytime TD features.",
+    banned_exact=_BASE_BANNED_EXACT,
+    banned_prefixes=_BASE_BANNED_PREFIXES,
+    banned_suffixes=_BASE_BANNED_SUFFIXES,
+    banned_regex=_BASE_BANNED_REGEX,
+)
+
+
+def _ensure_sequence(value: Sequence[str] | str | None) -> tuple[str, ...]:
+    if value is None:
+        return ()
+    if isinstance(value, str):
+        return (value,)
+    return tuple(value)
+
+
+def evaluate_leak_prone_columns(
+    columns: Iterable[str],
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+) -> LeakCheckResult:
+    """Identify leak-prone columns using the configured policy."""
+
+    banned: dict[str, str] = {}
+    columns_list = list(columns)
+    for col in columns_list:
+        if col in policy.banned_exact:
+            banned[col] = "exact"
+            continue
+        for prefix in policy.banned_prefixes:
+            if col.startswith(prefix):
+                banned[col] = f"prefix:{prefix}"
+                break
+        if col in banned:
+            continue
+        for suffix in policy.banned_suffixes:
+            if col.endswith(suffix):
+                banned[col] = f"suffix:{suffix}"
+                break
+        if col in banned:
+            continue
+        for pattern, reason in policy.banned_regex:
+            if pattern.match(col):
+                banned[col] = reason
+                break
+
+    kept = [c for c in columns_list if c not in banned]
+    return LeakCheckResult(
+        policy_version=policy.version,
+        banned=banned,
+        kept=kept,
+        dropped=[],
+        allowlist_kept=[],
+    )
+
+
+def enforce_leak_guard(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    allow_prefixes: Sequence[str] | str | None = None,
+    allow_exact: Sequence[str] | str | None = None,
+    drop_banned: bool = True,
+    drop_non_allowlisted: bool = False,
+    raise_on_banned: bool = True,
+) -> tuple[pl.DataFrame | "pd.DataFrame", LeakCheckResult]:
+    """Apply leak guardrails to a feature frame.
+
+    Parameters
+    ----------
+    df : DataFrame
+        Polars or pandas DataFrame.
+    policy : LeakPolicy
+        Leak policy to apply.
+    allow_prefixes : Sequence[str] | str | None
+        Optional prefixes that define the allowed feature surface for a problem.
+    allow_exact : Sequence[str] | str | None
+        Explicitly allowed columns (e.g., identifiers).
+    drop_banned : bool
+        If True, drop any banned columns automatically.
+    drop_non_allowlisted : bool
+        If True, drop columns that are not covered by allow_prefixes/allow_exact/identifiers/targets.
+    raise_on_banned : bool
+        If True, raise when banned columns are detected (after optional drop).
+    """
+
+    result = evaluate_leak_prone_columns(df.columns, policy=policy)
+    dropped: list[str] = []
+
+    allow_prefixes = _ensure_sequence(allow_prefixes)
+    allow_exact = set(_ensure_sequence(allow_exact))
+    allow_exact.update({col for col in IDENTIFIER_COLUMNS if col in df.columns})
+    allow_exact.update({col for col in NFL_TARGET_COLUMNS if col in df.columns})
+
+    # Permit allowlisted columns even if they match a banned rule (e.g., labels)
+    banned = {col: reason for col, reason in result.banned.items() if col not in allow_exact}
+
+    if banned and drop_banned:
+        df = df.drop(list(banned.keys()))
+        dropped.extend(banned.keys())
+
+    if banned and raise_on_banned:
+        raise ValueError(f"Leak-prone columns detected: {sorted(banned.items())}")
+
+    allowlist_cols: set[str] = set()
+    if allow_prefixes:
+        allowlist_cols.update({c for c in df.columns if c.startswith(allow_prefixes)})
+    allowlist_cols.update({c for c in allow_exact if c in df.columns})
+
+    if drop_non_allowlisted and allowlist_cols:
+        drop_candidates = [c for c in df.columns if c not in allowlist_cols]
+        if drop_candidates:
+            df = df.drop(drop_candidates)
+            dropped.extend(drop_candidates)
+
+    if drop_non_allowlisted and not allowlist_cols:
+        raise ValueError("No allowlisted columns remain after applying leak guard allowlist.")
+
+    # Store adjusted banned info on the result
+    result.banned = banned
+    result.dropped = dropped
+    result.kept = [c for c in df.columns]
+    result.allowlist_kept = sorted(list(allowlist_cols)) if allowlist_cols else []
+    return df, result
+
+
+def build_schema_snapshot(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    metadata: Mapping[str, object] | None = None,
+    banned: Mapping[str, str] | None = None,
+) -> dict:
+    """Render a schema snapshot describing each column and whether it was flagged."""
+
+    banned = banned or {}
+    meta = {
+        "generated_at_utc": datetime.utcnow().isoformat(),
+        "policy_version": policy.version,
+    }
+    meta.update(metadata or {})
+
+    # Extract columns / dtypes
+    if isinstance(df, pl.DataFrame):
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+    else:  # pandas or pandas-like
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+
+    schema = {
+        "metadata": meta,
+        "columns": [],
+    }
+
+    for col, dtype in cols_and_dtypes:
+        tags: list[str] = []
+        if col in IDENTIFIER_COLUMNS:
+            tags.append("id")
+        if col in NFL_TARGET_COLUMNS:
+            tags.append("label")
+        if col.startswith("market_"):
+            tags.append("odds")
+        if col.startswith("injury_") or col.startswith("practice_"):
+            tags.append("injury")
+        if col.startswith("weather_"):
+            tags.append("weather")
+        if col.startswith("ps_"):
+            tags.append("pre_snap")
+        schema["columns"].append(
+            {
+                "name": col,
+                "dtype": dtype,
+                "banned": col in banned,
+                "tags": tags,
+            }
+        )
+    return schema
+
+
+def write_schema_snapshot(path, schema: Mapping[str, object]) -> None:
+    path.parent.mkdir(parents=True, exist_ok=True)
+    with open(path, "w") as fp:
+        json.dump(schema, fp, indent=2, sort_keys=True)
+
+
+__all__ = [
+    "DEFAULT_LEAK_POLICY",
+    "LeakPolicy",
+    "LeakCheckResult",
+    "evaluate_leak_prone_columns",
+    "enforce_leak_guard",
+    "build_schema_snapshot",
+    "write_schema_snapshot",
+]
diff --git a/utils/general/constants.py b/utils/general/constants.py
index d94b4260ad877484da843fa99ae2caf37e8493f4..dea87caa354d94e4a08b1762d2bd8dcd4c8caa3a
--- a/utils/general/constants.py
+++ b/utils/general/constants.py
@@ -211,7 +211,17 @@
 
 NFL_TARGET_COLUMNS: Tuple[str, ...] = (
     'anytime_td',
+    'anytime_td_offense',
+    'anytime_td_all',
+    'anytime_td_rush',
+    'anytime_td_rec',
+    'anytime_td_pass_thrown',
     'td_count',
+    'td_count_offense',
+    'td_count_all',
+    'passing_td',
+    'rushing_td_count',
+    'receiving_td_count',
     'receiving_yards',
     'rushing_yards',
     'passing_yards',


thinking
**Reviewing feature horizon alignment**
exec
/bin/zsh -lc 'cd /Users/jameswest/Desktop/nfl_predict && cat config/config.yaml' in /Users/jameswest/Desktop/nfl_predict succeeded in 733ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
version: "1.0"

odds_api_key: "1ee3ae64f6008dd1316fbbd02a5f1f6c"

# NFL Pipeline Configuration  
pipeline:
  # Debug flags - set to true to skip specific pipeline stages
  # Useful for development and testing individual stages
  debug:
    skip_data_collection: false
    skip_data_cleaning: false
    skip_feature_engineering: false
    skip_model_training: false
    skip_prediction: true  # Prediction step not yet fully implemented for NFL
  start_date: "2021-09-09"  # NFL 2021 season start (4+ years of reliable data)
  end_date: null             # null = today
  seasons: [2025, 2024, 2023, 2022, 2021]  # 4+ years of training data (nfl_data_py library limitation for older data)

paths:
file update:
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 5ba68e8bf1acd3a789a76a8857674e6f6433017b..0210d5b7e7ed60a8de7a126d64f5ed76326474c8
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -14,7 +14,7 @@
 
 import logging
 import os
-from datetime import date, timedelta
+from datetime import date, datetime, timedelta
 from typing import Sequence
 
 import polars as pl
@@ -37,6 +37,12 @@
     add_offense_context_features_training,
     _append_offense_context_columns,
 )
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    build_schema_snapshot,
+    enforce_leak_guard,
+    write_schema_snapshot,
+)
 from utils.feature.weather_features import (
     add_weather_forecast_features_training,
     append_weather_context_flags,
@@ -931,6 +937,32 @@
     if market_exprs:
         df_player_game_all = df_player_game_all.with_columns(market_exprs)
     
+    # Leak guard + schema snapshot before persisting
+    spec = get_label_spec(label_version)
+    allow_exact = {spec.primary, *spec.labels.keys(), *spec.aliases.keys()}
+    df_player_game_all, leak_result = enforce_leak_guard(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_exact=allow_exact,
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=True,
+    )
+
+    schema = build_schema_snapshot(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        metadata={
+            "cutoff_label": cutoff_label,
+            "label_version": spec.name,
+        },
+        banned=leak_result.banned,
+    )
+    schema_dir = FEATURE_AUDIT_DIR / "schema" / "anytime_td"
+    schema_path = schema_dir / f"{cutoff_label}_{datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')}.json"
+    write_schema_snapshot(schema_path, schema)
+    logging.info("    Schema snapshot written → %s", schema_path)
+
     # Write final feature matrix
     df_player_game_all = df_player_game_all.with_columns(
         pl.lit(current_cutoff_hours).cast(pl.Float32).alias("decision_horizon_hours")
@@ -951,7 +983,6 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    spec = get_label_spec(label_version)
     label_candidates = {spec.primary, "anytime_td"}
     for label_col in label_candidates:
         if label_col in df_player_game_all.columns:
diff --git a/pipeline/train.py b/pipeline/train.py
index fe70207dcdf25d209ee3ad55080b7ce826347c44..3fab3a05b3f65e8d0e88ec1ddaa71a8857646148
--- a/pipeline/train.py
+++ b/pipeline/train.py
@@ -98,6 +98,7 @@
     fit_team_conformal_sums,
     composite_sum_interval,
 )
+from utils.feature.leak_guard import DEFAULT_LEAK_POLICY, enforce_leak_guard
 from utils.feature.targets import require_target_column
 
 # Ignore specific, noisy warnings from dependencies
@@ -2315,7 +2316,30 @@
                             df_problem[col] = df_problem[col].fillna(df_problem[col].mean())
 
                 df_problem = self._inject_composed_features(df_problem)
-            
+
+            # Leak guard on the problem-scoped frame
+            allow_prefixes = tuple(problem_copy.get('feature_prefixes_to_include') or [])
+            allow_exact = set(problem_copy.get('other_features_to_include') or [])
+            allow_exact.update(input_preds or [])
+            if self.target_col:
+                allow_exact.add(self.target_col)
+            df_problem, leak_info = enforce_leak_guard(
+                df_problem,
+                policy=DEFAULT_LEAK_POLICY,
+                allow_prefixes=allow_prefixes,
+                allow_exact=allow_exact,
+                drop_banned=True,
+                drop_non_allowlisted=False,
+                raise_on_banned=True,
+            )
+            if leak_info.dropped:
+                logger.info(
+                    "Dropped %d leak-prone columns for %s: %s",
+                    len(leak_info.dropped),
+                    problem_name,
+                    sorted(leak_info.dropped),
+                )
+
             self._normalize_datetime_like_columns(df_problem, problem_name)
             df_problem[self.time_col] = pd.to_datetime(df_problem[self.time_col])
             sort_cols = [self.time_col]
diff --git a/tests/test_data_leak_guard.py b/tests/test_data_leak_guard.py
index 8061f2760c0898aaeda29026859e1b9ff5644ba4..3e56665921db89ea523bbdb205d1bb90c21893df
--- a/tests/test_data_leak_guard.py
+++ b/tests/test_data_leak_guard.py
@@ -3,6 +3,14 @@
 import yaml
 from pathlib import Path
 
+import polars as pl
+
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    enforce_leak_guard,
+    evaluate_leak_prone_columns,
+)
+
 
 PROJECT_ROOT = Path(__file__).resolve().parents[1]
 TRAINING_CONFIG = PROJECT_ROOT / "config" / "training.yaml"
@@ -48,3 +56,41 @@
     )
 
 
+def test_leak_guard_flags_pattern_columns():
+    cols = [
+        "market_anytime_td_prob",
+        "final_score",
+        "postgame_anytime_td",
+        "actual_td_count",
+        "safe_feature",
+    ]
+    result = evaluate_leak_prone_columns(cols, policy=DEFAULT_LEAK_POLICY)
+    assert set(result.banned.keys()) == {"final_score", "postgame_anytime_td", "actual_td_count"}
+    assert "safe_feature" in result.kept
+    assert "market_anytime_td_prob" in result.kept
+
+
+def test_enforce_leak_guard_drops_banned_and_keeps_allowlisted():
+    df = pl.DataFrame(
+        {
+            "game_id": ["g1", "g2"],
+            "safe_feature": [1.0, 2.0],
+            "postgame_anytime_td": [1, 0],
+            "final_score": [30, 24],
+        }
+    )
+    cleaned, info = enforce_leak_guard(
+        df,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_prefixes=("safe_",),
+        allow_exact=("game_id",),
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=False,
+    )
+    assert "postgame_anytime_td" not in cleaned.columns
+    assert "final_score" not in cleaned.columns
+    assert "safe_feature" in cleaned.columns
+    assert "game_id" in cleaned.columns
+    assert set(info.dropped) == {"postgame_anytime_td", "final_score"}
+
diff --git a/utils/feature/leak_guard.py b/utils/feature/leak_guard.py
new file mode 100644
index 0000000000000000000000000000000000000000..9faf8cfffc436e0934b2f410aaf252e52f4f95df
--- /dev/null
+++ b/utils/feature/leak_guard.py
@@ -0,0 +1,273 @@
+"""Leak guardrails for feature matrices.
+
+This module centralizes pattern-based leak detection so both feature assembly
+and training can fail fast when post-outcome columns sneak into the data.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+from datetime import datetime
+import json
+import re
+from typing import Iterable, Mapping, Sequence
+
+import polars as pl
+
+from utils.general.constants import IDENTIFIER_COLUMNS, LEAK_PRONE_COLUMNS, NFL_TARGET_COLUMNS
+
+try:  # Optional dependency when imported from training (pandas path)
+    import pandas as pd  # type: ignore
+except Exception:  # pragma: no cover - optional dependency
+    pd = None
+
+
+@dataclass(frozen=True)
+class LeakPolicy:
+    version: str
+    banned_exact: set[str]
+    banned_prefixes: tuple[str, ...]
+    banned_suffixes: tuple[str, ...]
+    banned_regex: tuple[tuple[re.Pattern[str], str], ...]
+    description: str = ""
+
+
+@dataclass
+class LeakCheckResult:
+    policy_version: str
+    banned: dict[str, str]
+    kept: list[str]
+    dropped: list[str]
+    allowlist_kept: list[str]
+
+
+# Core policy tuned for anytime-TD style problems (can be extended per-problem).
+_BASE_BANNED_EXACT = set(LEAK_PRONE_COLUMNS) | {
+    "final_score",
+    "final_total",
+    "points_scored",
+    "actual_td_count",
+    "actual_anytime_td",
+    "postgame_anytime_td",
+    "postgame_td_count",
+}
+_BASE_BANNED_PREFIXES = (
+    "postgame_",
+    "post_game_",
+    "post_",
+    "live_",
+    "actual_",
+    "realized_",
+    "final_",
+    "postmatch_",
+)
+_BASE_BANNED_SUFFIXES = (
+    "_post",
+    "_postgame",
+    "_final",
+    "_fullgame",
+    "_actual",
+)
+_BASE_BANNED_REGEX: tuple[tuple[re.Pattern[str], str], ...] = (
+    (re.compile(r".*post.?game.*", flags=re.IGNORECASE), "postgame marker"),
+    (re.compile(r".*final_score.*", flags=re.IGNORECASE), "final score"),
+    (re.compile(r".*actual.*td.*", flags=re.IGNORECASE), "actual TD total"),
+    (re.compile(r".*anytime_td.*(post|final|actual).*", flags=re.IGNORECASE), "post-decision anytime TD"),
+    (re.compile(r".*fullgame.*", flags=re.IGNORECASE), "full game cumulative value"),
+)
+
+DEFAULT_LEAK_POLICY = LeakPolicy(
+    version="v1",
+    description="Core post-outcome leak guard for NFL anytime TD features.",
+    banned_exact=_BASE_BANNED_EXACT,
+    banned_prefixes=_BASE_BANNED_PREFIXES,
+    banned_suffixes=_BASE_BANNED_SUFFIXES,
+    banned_regex=_BASE_BANNED_REGEX,
+)
+
+
+def _ensure_sequence(value: Sequence[str] | str | None) -> tuple[str, ...]:
+    if value is None:
+        return ()
+    if isinstance(value, str):
+        return (value,)
+    return tuple(value)
+
+
+def evaluate_leak_prone_columns(
+    columns: Iterable[str],
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+) -> LeakCheckResult:
+    """Identify leak-prone columns using the configured policy."""
+
+    banned: dict[str, str] = {}
+    columns_list = list(columns)
+    for col in columns_list:
+        if col in policy.banned_exact:
+            banned[col] = "exact"
+            continue
+        for prefix in policy.banned_prefixes:
+            if col.startswith(prefix):
+                banned[col] = f"prefix:{prefix}"
+                break
+        if col in banned:
+            continue
+        for suffix in policy.banned_suffixes:
+            if col.endswith(suffix):
+                banned[col] = f"suffix:{suffix}"
+                break
+        if col in banned:
+            continue
+        for pattern, reason in policy.banned_regex:
+            if pattern.match(col):
+                banned[col] = reason
+                break
+
+    kept = [c for c in columns_list if c not in banned]
+    return LeakCheckResult(
+        policy_version=policy.version,
+        banned=banned,
+        kept=kept,
+        dropped=[],
+        allowlist_kept=[],
+    )
+
+
+def enforce_leak_guard(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    allow_prefixes: Sequence[str] | str | None = None,
+    allow_exact: Sequence[str] | str | None = None,
+    drop_banned: bool = True,
+    drop_non_allowlisted: bool = False,
+    raise_on_banned: bool = True,
+) -> tuple[pl.DataFrame | "pd.DataFrame", LeakCheckResult]:
+    """Apply leak guardrails to a feature frame.
+
+    Parameters
+    ----------
+    df : DataFrame
+        Polars or pandas DataFrame.
+    policy : LeakPolicy
+        Leak policy to apply.
+    allow_prefixes : Sequence[str] | str | None
+        Optional prefixes that define the allowed feature surface for a problem.
+    allow_exact : Sequence[str] | str | None
+        Explicitly allowed columns (e.g., identifiers).
+    drop_banned : bool
+        If True, drop any banned columns automatically.
+    drop_non_allowlisted : bool
+        If True, drop columns that are not covered by allow_prefixes/allow_exact/identifiers/targets.
+    raise_on_banned : bool
+        If True, raise when banned columns are detected (after optional drop).
+    """
+
+    result = evaluate_leak_prone_columns(df.columns, policy=policy)
+    dropped: list[str] = []
+
+    allow_prefixes = _ensure_sequence(allow_prefixes)
+    allow_exact = set(_ensure_sequence(allow_exact))
+    allow_exact.update({col for col in IDENTIFIER_COLUMNS if col in df.columns})
+    allow_exact.update({col for col in NFL_TARGET_COLUMNS if col in df.columns})
+
+    # Permit allowlisted columns even if they match a banned rule (e.g., labels)
+    banned = {col: reason for col, reason in result.banned.items() if col not in allow_exact}
+
+    if banned and drop_banned:
+        df = df.drop(list(banned.keys()))
+        dropped.extend(banned.keys())
+
+    if banned and raise_on_banned:
+        raise ValueError(f"Leak-prone columns detected: {sorted(banned.items())}")
+
+    allowlist_cols: set[str] = set()
+    if allow_prefixes:
+        allowlist_cols.update({c for c in df.columns if c.startswith(allow_prefixes)})
+    allowlist_cols.update({c for c in allow_exact if c in df.columns})
+
+    if drop_non_allowlisted and allowlist_cols:
+        drop_candidates = [c for c in df.columns if c not in allowlist_cols]
+        if drop_candidates:
+            df = df.drop(drop_candidates)
+            dropped.extend(drop_candidates)
+
+    if drop_non_allowlisted and not allowlist_cols:
+        raise ValueError("No allowlisted columns remain after applying leak guard allowlist.")
+
+    # Store adjusted banned info on the result
+    result.banned = banned
+    result.dropped = dropped
+    result.kept = [c for c in df.columns]
+    result.allowlist_kept = sorted(list(allowlist_cols)) if allowlist_cols else []
+    return df, result
+
+
+def build_schema_snapshot(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    metadata: Mapping[str, object] | None = None,
+    banned: Mapping[str, str] | None = None,
+) -> dict:
+    """Render a schema snapshot describing each column and whether it was flagged."""
+
+    banned = banned or {}
+    meta = {
+        "generated_at_utc": datetime.utcnow().isoformat(),
+        "policy_version": policy.version,
+    }
+    meta.update(metadata or {})
+
+    # Extract columns / dtypes
+    if isinstance(df, pl.DataFrame):
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+    else:  # pandas or pandas-like
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+
+    schema = {
+        "metadata": meta,
+        "columns": [],
+    }
+
+    for col, dtype in cols_and_dtypes:
+        tags: list[str] = []
+        if col in IDENTIFIER_COLUMNS:
+            tags.append("id")
+        if col in NFL_TARGET_COLUMNS:
+            tags.append("label")
+        if col.startswith("market_"):
+            tags.append("odds")
+        if col.startswith("injury_") or col.startswith("practice_"):
+            tags.append("injury")
+        if col.startswith("weather_"):
+            tags.append("weather")
+        if col.startswith("ps_"):
+            tags.append("pre_snap")
+        schema["columns"].append(
+            {
+                "name": col,
+                "dtype": dtype,
+                "banned": col in banned,
+                "tags": tags,
+            }
+        )
+    return schema
+
+
+def write_schema_snapshot(path, schema: Mapping[str, object]) -> None:
+    path.parent.mkdir(parents=True, exist_ok=True)
+    with open(path, "w") as fp:
+        json.dump(schema, fp, indent=2, sort_keys=True)
+
+
+__all__ = [
+    "DEFAULT_LEAK_POLICY",
+    "LeakPolicy",
+    "LeakCheckResult",
+    "evaluate_leak_prone_columns",
+    "enforce_leak_guard",
+    "build_schema_snapshot",
+    "write_schema_snapshot",
+]
diff --git a/utils/general/constants.py b/utils/general/constants.py
index d94b4260ad877484da843fa99ae2caf37e8493f4..dea87caa354d94e4a08b1762d2bd8dcd4c8caa3a
--- a/utils/general/constants.py
+++ b/utils/general/constants.py
@@ -211,7 +211,17 @@
 
 NFL_TARGET_COLUMNS: Tuple[str, ...] = (
     'anytime_td',
+    'anytime_td_offense',
+    'anytime_td_all',
+    'anytime_td_rush',
+    'anytime_td_rec',
+    'anytime_td_pass_thrown',
     'td_count',
+    'td_count_offense',
+    'td_count_all',
+    'passing_td',
+    'rushing_td_count',
+    'receiving_td_count',
     'receiving_yards',
     'rushing_yards',
     'passing_yards',


thinking
**Investigating odds_snapshot_mode usage**
exec
/bin/zsh -lc 'cd /Users/jameswest/Desktop/nfl_predict && rg "odds_snapshot_mode" -n' in /Users/jameswest/Desktop/nfl_predict succeeded in 724ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
utils/general/config.py:90:        "mode": cutoff_cfg.get("odds_snapshot_mode", "cutoff"),
file update:
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 5ba68e8bf1acd3a789a76a8857674e6f6433017b..0210d5b7e7ed60a8de7a126d64f5ed76326474c8
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -14,7 +14,7 @@
 
 import logging
 import os
-from datetime import date, timedelta
+from datetime import date, datetime, timedelta
 from typing import Sequence
 
 import polars as pl
@@ -37,6 +37,12 @@
     add_offense_context_features_training,
     _append_offense_context_columns,
 )
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    build_schema_snapshot,
+    enforce_leak_guard,
+    write_schema_snapshot,
+)
 from utils.feature.weather_features import (
     add_weather_forecast_features_training,
     append_weather_context_flags,
@@ -931,6 +937,32 @@
     if market_exprs:
         df_player_game_all = df_player_game_all.with_columns(market_exprs)
     
+    # Leak guard + schema snapshot before persisting
+    spec = get_label_spec(label_version)
+    allow_exact = {spec.primary, *spec.labels.keys(), *spec.aliases.keys()}
+    df_player_game_all, leak_result = enforce_leak_guard(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_exact=allow_exact,
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=True,
+    )
+
+    schema = build_schema_snapshot(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        metadata={
+            "cutoff_label": cutoff_label,
+            "label_version": spec.name,
+        },
+        banned=leak_result.banned,
+    )
+    schema_dir = FEATURE_AUDIT_DIR / "schema" / "anytime_td"
+    schema_path = schema_dir / f"{cutoff_label}_{datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')}.json"
+    write_schema_snapshot(schema_path, schema)
+    logging.info("    Schema snapshot written → %s", schema_path)
+
     # Write final feature matrix
     df_player_game_all = df_player_game_all.with_columns(
         pl.lit(current_cutoff_hours).cast(pl.Float32).alias("decision_horizon_hours")
@@ -951,7 +983,6 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    spec = get_label_spec(label_version)
     label_candidates = {spec.primary, "anytime_td"}
     for label_col in label_candidates:
         if label_col in df_player_game_all.columns:
diff --git a/pipeline/train.py b/pipeline/train.py
index fe70207dcdf25d209ee3ad55080b7ce826347c44..3fab3a05b3f65e8d0e88ec1ddaa71a8857646148
--- a/pipeline/train.py
+++ b/pipeline/train.py
@@ -98,6 +98,7 @@
     fit_team_conformal_sums,
     composite_sum_interval,
 )
+from utils.feature.leak_guard import DEFAULT_LEAK_POLICY, enforce_leak_guard
 from utils.feature.targets import require_target_column
 
 # Ignore specific, noisy warnings from dependencies
@@ -2315,7 +2316,30 @@
                             df_problem[col] = df_problem[col].fillna(df_problem[col].mean())
 
                 df_problem = self._inject_composed_features(df_problem)
-            
+
+            # Leak guard on the problem-scoped frame
+            allow_prefixes = tuple(problem_copy.get('feature_prefixes_to_include') or [])
+            allow_exact = set(problem_copy.get('other_features_to_include') or [])
+            allow_exact.update(input_preds or [])
+            if self.target_col:
+                allow_exact.add(self.target_col)
+            df_problem, leak_info = enforce_leak_guard(
+                df_problem,
+                policy=DEFAULT_LEAK_POLICY,
+                allow_prefixes=allow_prefixes,
+                allow_exact=allow_exact,
+                drop_banned=True,
+                drop_non_allowlisted=False,
+                raise_on_banned=True,
+            )
+            if leak_info.dropped:
+                logger.info(
+                    "Dropped %d leak-prone columns for %s: %s",
+                    len(leak_info.dropped),
+                    problem_name,
+                    sorted(leak_info.dropped),
+                )
+
             self._normalize_datetime_like_columns(df_problem, problem_name)
             df_problem[self.time_col] = pd.to_datetime(df_problem[self.time_col])
             sort_cols = [self.time_col]
diff --git a/tests/test_data_leak_guard.py b/tests/test_data_leak_guard.py
index 8061f2760c0898aaeda29026859e1b9ff5644ba4..3e56665921db89ea523bbdb205d1bb90c21893df
--- a/tests/test_data_leak_guard.py
+++ b/tests/test_data_leak_guard.py
@@ -3,6 +3,14 @@
 import yaml
 from pathlib import Path
 
+import polars as pl
+
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    enforce_leak_guard,
+    evaluate_leak_prone_columns,
+)
+
 
 PROJECT_ROOT = Path(__file__).resolve().parents[1]
 TRAINING_CONFIG = PROJECT_ROOT / "config" / "training.yaml"
@@ -48,3 +56,41 @@
     )
 
 
+def test_leak_guard_flags_pattern_columns():
+    cols = [
+        "market_anytime_td_prob",
+        "final_score",
+        "postgame_anytime_td",
+        "actual_td_count",
+        "safe_feature",
+    ]
+    result = evaluate_leak_prone_columns(cols, policy=DEFAULT_LEAK_POLICY)
+    assert set(result.banned.keys()) == {"final_score", "postgame_anytime_td", "actual_td_count"}
+    assert "safe_feature" in result.kept
+    assert "market_anytime_td_prob" in result.kept
+
+
+def test_enforce_leak_guard_drops_banned_and_keeps_allowlisted():
+    df = pl.DataFrame(
+        {
+            "game_id": ["g1", "g2"],
+            "safe_feature": [1.0, 2.0],
+            "postgame_anytime_td": [1, 0],
+            "final_score": [30, 24],
+        }
+    )
+    cleaned, info = enforce_leak_guard(
+        df,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_prefixes=("safe_",),
+        allow_exact=("game_id",),
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=False,
+    )
+    assert "postgame_anytime_td" not in cleaned.columns
+    assert "final_score" not in cleaned.columns
+    assert "safe_feature" in cleaned.columns
+    assert "game_id" in cleaned.columns
+    assert set(info.dropped) == {"postgame_anytime_td", "final_score"}
+
diff --git a/utils/feature/leak_guard.py b/utils/feature/leak_guard.py
new file mode 100644
index 0000000000000000000000000000000000000000..9faf8cfffc436e0934b2f410aaf252e52f4f95df
--- /dev/null
+++ b/utils/feature/leak_guard.py
@@ -0,0 +1,273 @@
+"""Leak guardrails for feature matrices.
+
+This module centralizes pattern-based leak detection so both feature assembly
+and training can fail fast when post-outcome columns sneak into the data.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+from datetime import datetime
+import json
+import re
+from typing import Iterable, Mapping, Sequence
+
+import polars as pl
+
+from utils.general.constants import IDENTIFIER_COLUMNS, LEAK_PRONE_COLUMNS, NFL_TARGET_COLUMNS
+
+try:  # Optional dependency when imported from training (pandas path)
+    import pandas as pd  # type: ignore
+except Exception:  # pragma: no cover - optional dependency
+    pd = None
+
+
+@dataclass(frozen=True)
+class LeakPolicy:
+    version: str
+    banned_exact: set[str]
+    banned_prefixes: tuple[str, ...]
+    banned_suffixes: tuple[str, ...]
+    banned_regex: tuple[tuple[re.Pattern[str], str], ...]
+    description: str = ""
+
+
+@dataclass
+class LeakCheckResult:
+    policy_version: str
+    banned: dict[str, str]
+    kept: list[str]
+    dropped: list[str]
+    allowlist_kept: list[str]
+
+
+# Core policy tuned for anytime-TD style problems (can be extended per-problem).
+_BASE_BANNED_EXACT = set(LEAK_PRONE_COLUMNS) | {
+    "final_score",
+    "final_total",
+    "points_scored",
+    "actual_td_count",
+    "actual_anytime_td",
+    "postgame_anytime_td",
+    "postgame_td_count",
+}
+_BASE_BANNED_PREFIXES = (
+    "postgame_",
+    "post_game_",
+    "post_",
+    "live_",
+    "actual_",
+    "realized_",
+    "final_",
+    "postmatch_",
+)
+_BASE_BANNED_SUFFIXES = (
+    "_post",
+    "_postgame",
+    "_final",
+    "_fullgame",
+    "_actual",
+)
+_BASE_BANNED_REGEX: tuple[tuple[re.Pattern[str], str], ...] = (
+    (re.compile(r".*post.?game.*", flags=re.IGNORECASE), "postgame marker"),
+    (re.compile(r".*final_score.*", flags=re.IGNORECASE), "final score"),
+    (re.compile(r".*actual.*td.*", flags=re.IGNORECASE), "actual TD total"),
+    (re.compile(r".*anytime_td.*(post|final|actual).*", flags=re.IGNORECASE), "post-decision anytime TD"),
+    (re.compile(r".*fullgame.*", flags=re.IGNORECASE), "full game cumulative value"),
+)
+
+DEFAULT_LEAK_POLICY = LeakPolicy(
+    version="v1",
+    description="Core post-outcome leak guard for NFL anytime TD features.",
+    banned_exact=_BASE_BANNED_EXACT,
+    banned_prefixes=_BASE_BANNED_PREFIXES,
+    banned_suffixes=_BASE_BANNED_SUFFIXES,
+    banned_regex=_BASE_BANNED_REGEX,
+)
+
+
+def _ensure_sequence(value: Sequence[str] | str | None) -> tuple[str, ...]:
+    if value is None:
+        return ()
+    if isinstance(value, str):
+        return (value,)
+    return tuple(value)
+
+
+def evaluate_leak_prone_columns(
+    columns: Iterable[str],
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+) -> LeakCheckResult:
+    """Identify leak-prone columns using the configured policy."""
+
+    banned: dict[str, str] = {}
+    columns_list = list(columns)
+    for col in columns_list:
+        if col in policy.banned_exact:
+            banned[col] = "exact"
+            continue
+        for prefix in policy.banned_prefixes:
+            if col.startswith(prefix):
+                banned[col] = f"prefix:{prefix}"
+                break
+        if col in banned:
+            continue
+        for suffix in policy.banned_suffixes:
+            if col.endswith(suffix):
+                banned[col] = f"suffix:{suffix}"
+                break
+        if col in banned:
+            continue
+        for pattern, reason in policy.banned_regex:
+            if pattern.match(col):
+                banned[col] = reason
+                break
+
+    kept = [c for c in columns_list if c not in banned]
+    return LeakCheckResult(
+        policy_version=policy.version,
+        banned=banned,
+        kept=kept,
+        dropped=[],
+        allowlist_kept=[],
+    )
+
+
+def enforce_leak_guard(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    allow_prefixes: Sequence[str] | str | None = None,
+    allow_exact: Sequence[str] | str | None = None,
+    drop_banned: bool = True,
+    drop_non_allowlisted: bool = False,
+    raise_on_banned: bool = True,
+) -> tuple[pl.DataFrame | "pd.DataFrame", LeakCheckResult]:
+    """Apply leak guardrails to a feature frame.
+
+    Parameters
+    ----------
+    df : DataFrame
+        Polars or pandas DataFrame.
+    policy : LeakPolicy
+        Leak policy to apply.
+    allow_prefixes : Sequence[str] | str | None
+        Optional prefixes that define the allowed feature surface for a problem.
+    allow_exact : Sequence[str] | str | None
+        Explicitly allowed columns (e.g., identifiers).
+    drop_banned : bool
+        If True, drop any banned columns automatically.
+    drop_non_allowlisted : bool
+        If True, drop columns that are not covered by allow_prefixes/allow_exact/identifiers/targets.
+    raise_on_banned : bool
+        If True, raise when banned columns are detected (after optional drop).
+    """
+
+    result = evaluate_leak_prone_columns(df.columns, policy=policy)
+    dropped: list[str] = []
+
+    allow_prefixes = _ensure_sequence(allow_prefixes)
+    allow_exact = set(_ensure_sequence(allow_exact))
+    allow_exact.update({col for col in IDENTIFIER_COLUMNS if col in df.columns})
+    allow_exact.update({col for col in NFL_TARGET_COLUMNS if col in df.columns})
+
+    # Permit allowlisted columns even if they match a banned rule (e.g., labels)
+    banned = {col: reason for col, reason in result.banned.items() if col not in allow_exact}
+
+    if banned and drop_banned:
+        df = df.drop(list(banned.keys()))
+        dropped.extend(banned.keys())
+
+    if banned and raise_on_banned:
+        raise ValueError(f"Leak-prone columns detected: {sorted(banned.items())}")
+
+    allowlist_cols: set[str] = set()
+    if allow_prefixes:
+        allowlist_cols.update({c for c in df.columns if c.startswith(allow_prefixes)})
+    allowlist_cols.update({c for c in allow_exact if c in df.columns})
+
+    if drop_non_allowlisted and allowlist_cols:
+        drop_candidates = [c for c in df.columns if c not in allowlist_cols]
+        if drop_candidates:
+            df = df.drop(drop_candidates)
+            dropped.extend(drop_candidates)
+
+    if drop_non_allowlisted and not allowlist_cols:
+        raise ValueError("No allowlisted columns remain after applying leak guard allowlist.")
+
+    # Store adjusted banned info on the result
+    result.banned = banned
+    result.dropped = dropped
+    result.kept = [c for c in df.columns]
+    result.allowlist_kept = sorted(list(allowlist_cols)) if allowlist_cols else []
+    return df, result
+
+
+def build_schema_snapshot(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    metadata: Mapping[str, object] | None = None,
+    banned: Mapping[str, str] | None = None,
+) -> dict:
+    """Render a schema snapshot describing each column and whether it was flagged."""
+
+    banned = banned or {}
+    meta = {
+        "generated_at_utc": datetime.utcnow().isoformat(),
+        "policy_version": policy.version,
+    }
+    meta.update(metadata or {})
+
+    # Extract columns / dtypes
+    if isinstance(df, pl.DataFrame):
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+    else:  # pandas or pandas-like
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+
+    schema = {
+        "metadata": meta,
+        "columns": [],
+    }
+
+    for col, dtype in cols_and_dtypes:
+        tags: list[str] = []
+        if col in IDENTIFIER_COLUMNS:
+            tags.append("id")
+        if col in NFL_TARGET_COLUMNS:
+            tags.append("label")
+        if col.startswith("market_"):
+            tags.append("odds")
+        if col.startswith("injury_") or col.startswith("practice_"):
+            tags.append("injury")
+        if col.startswith("weather_"):
+            tags.append("weather")
+        if col.startswith("ps_"):
+            tags.append("pre_snap")
+        schema["columns"].append(
+            {
+                "name": col,
+                "dtype": dtype,
+                "banned": col in banned,
+                "tags": tags,
+            }
+        )
+    return schema
+
+
+def write_schema_snapshot(path, schema: Mapping[str, object]) -> None:
+    path.parent.mkdir(parents=True, exist_ok=True)
+    with open(path, "w") as fp:
+        json.dump(schema, fp, indent=2, sort_keys=True)
+
+
+__all__ = [
+    "DEFAULT_LEAK_POLICY",
+    "LeakPolicy",
+    "LeakCheckResult",
+    "evaluate_leak_prone_columns",
+    "enforce_leak_guard",
+    "build_schema_snapshot",
+    "write_schema_snapshot",
+]
diff --git a/utils/general/constants.py b/utils/general/constants.py
index d94b4260ad877484da843fa99ae2caf37e8493f4..dea87caa354d94e4a08b1762d2bd8dcd4c8caa3a
--- a/utils/general/constants.py
+++ b/utils/general/constants.py
@@ -211,7 +211,17 @@
 
 NFL_TARGET_COLUMNS: Tuple[str, ...] = (
     'anytime_td',
+    'anytime_td_offense',
+    'anytime_td_all',
+    'anytime_td_rush',
+    'anytime_td_rec',
+    'anytime_td_pass_thrown',
     'td_count',
+    'td_count_offense',
+    'td_count_all',
+    'passing_td',
+    'rushing_td_count',
+    'receiving_td_count',
     'receiving_yards',
     'rushing_yards',
     'passing_yards',

exec
/bin/zsh -lc "cd /Users/jameswest/Desktop/nfl_predict && sed -n '60,140p' utils/general/config.py" in /Users/jameswest/Desktop/nfl_predict succeeded in 705ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted

def get_weather_api_key() -> str | None:
    """Get the weather API key from configuration."""
    config = load_config()
    weather_cfg = config.get("weather", {})
    return weather_cfg.get("api_key")


def get_pipeline_config() -> Mapping[str, Any]:
    """Get the pipeline section of the main config."""
    config = load_config()
    return config.get("pipeline", {})


def get_collect_params() -> Mapping[str, Any]:
    """Get the collect_params section of the main config."""
    config = load_config()
    return config.get("collect_params", {})

file update:
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 5ba68e8bf1acd3a789a76a8857674e6f6433017b..0210d5b7e7ed60a8de7a126d64f5ed76326474c8
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -14,7 +14,7 @@
 
 import logging
 import os
-from datetime import date, timedelta
+from datetime import date, datetime, timedelta
 from typing import Sequence
 
 import polars as pl
@@ -37,6 +37,12 @@
     add_offense_context_features_training,
     _append_offense_context_columns,
 )
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    build_schema_snapshot,
+    enforce_leak_guard,
+    write_schema_snapshot,
+)
 from utils.feature.weather_features import (
     add_weather_forecast_features_training,
     append_weather_context_flags,
@@ -931,6 +937,32 @@
     if market_exprs:
         df_player_game_all = df_player_game_all.with_columns(market_exprs)
     
+    # Leak guard + schema snapshot before persisting
+    spec = get_label_spec(label_version)
+    allow_exact = {spec.primary, *spec.labels.keys(), *spec.aliases.keys()}
+    df_player_game_all, leak_result = enforce_leak_guard(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_exact=allow_exact,
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=True,
+    )
+
+    schema = build_schema_snapshot(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        metadata={
+            "cutoff_label": cutoff_label,
+            "label_version": spec.name,
+        },
+        banned=leak_result.banned,
+    )
+    schema_dir = FEATURE_AUDIT_DIR / "schema" / "anytime_td"
+    schema_path = schema_dir / f"{cutoff_label}_{datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')}.json"
+    write_schema_snapshot(schema_path, schema)
+    logging.info("    Schema snapshot written → %s", schema_path)
+
     # Write final feature matrix
     df_player_game_all = df_player_game_all.with_columns(
         pl.lit(current_cutoff_hours).cast(pl.Float32).alias("decision_horizon_hours")
@@ -951,7 +983,6 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    spec = get_label_spec(label_version)
     label_candidates = {spec.primary, "anytime_td"}
     for label_col in label_candidates:
         if label_col in df_player_game_all.columns:
diff --git a/pipeline/train.py b/pipeline/train.py
index fe70207dcdf25d209ee3ad55080b7ce826347c44..3fab3a05b3f65e8d0e88ec1ddaa71a8857646148
--- a/pipeline/train.py
+++ b/pipeline/train.py
@@ -98,6 +98,7 @@
     fit_team_conformal_sums,
     composite_sum_interval,
 )
+from utils.feature.leak_guard import DEFAULT_LEAK_POLICY, enforce_leak_guard
 from utils.feature.targets import require_target_column
 
 # Ignore specific, noisy warnings from dependencies
@@ -2315,7 +2316,30 @@
                             df_problem[col] = df_problem[col].fillna(df_problem[col].mean())
 
                 df_problem = self._inject_composed_features(df_problem)
-            
+
+            # Leak guard on the problem-scoped frame
+            allow_prefixes = tuple(problem_copy.get('feature_prefixes_to_include') or [])
+            allow_exact = set(problem_copy.get('other_features_to_include') or [])
+            allow_exact.update(input_preds or [])
+            if self.target_col:
+                allow_exact.add(self.target_col)
+            df_problem, leak_info = enforce_leak_guard(
+                df_problem,
+                policy=DEFAULT_LEAK_POLICY,
+                allow_prefixes=allow_prefixes,
+                allow_exact=allow_exact,
+                drop_banned=True,
+                drop_non_allowlisted=False,
+                raise_on_banned=True,
+            )
+            if leak_info.dropped:
+                logger.info(
+                    "Dropped %d leak-prone columns for %s: %s",
+                    len(leak_info.dropped),
+                    problem_name,
+                    sorted(leak_info.dropped),
+                )
+
             self._normalize_datetime_like_columns(df_problem, problem_name)
             df_problem[self.time_col] = pd.to_datetime(df_problem[self.time_col])
             sort_cols = [self.time_col]
diff --git a/tests/test_data_leak_guard.py b/tests/test_data_leak_guard.py
index 8061f2760c0898aaeda29026859e1b9ff5644ba4..3e56665921db89ea523bbdb205d1bb90c21893df
--- a/tests/test_data_leak_guard.py
+++ b/tests/test_data_leak_guard.py
@@ -3,6 +3,14 @@
 import yaml
 from pathlib import Path
 
+import polars as pl
+
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    enforce_leak_guard,
+    evaluate_leak_prone_columns,
+)
+
 
 PROJECT_ROOT = Path(__file__).resolve().parents[1]
 TRAINING_CONFIG = PROJECT_ROOT / "config" / "training.yaml"
@@ -48,3 +56,41 @@
     )
 
 
+def test_leak_guard_flags_pattern_columns():
+    cols = [
+        "market_anytime_td_prob",
+        "final_score",
+        "postgame_anytime_td",
+        "actual_td_count",
+        "safe_feature",
+    ]
+    result = evaluate_leak_prone_columns(cols, policy=DEFAULT_LEAK_POLICY)
+    assert set(result.banned.keys()) == {"final_score", "postgame_anytime_td", "actual_td_count"}
+    assert "safe_feature" in result.kept
+    assert "market_anytime_td_prob" in result.kept
+
+
+def test_enforce_leak_guard_drops_banned_and_keeps_allowlisted():
+    df = pl.DataFrame(
+        {
+            "game_id": ["g1", "g2"],
+            "safe_feature": [1.0, 2.0],
+            "postgame_anytime_td": [1, 0],
+            "final_score": [30, 24],
+        }
+    )
+    cleaned, info = enforce_leak_guard(
+        df,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_prefixes=("safe_",),
+        allow_exact=("game_id",),
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=False,
+    )
+    assert "postgame_anytime_td" not in cleaned.columns
+    assert "final_score" not in cleaned.columns
+    assert "safe_feature" in cleaned.columns
+    assert "game_id" in cleaned.columns
+    assert set(info.dropped) == {"postgame_anytime_td", "final_score"}
+
diff --git a/utils/feature/leak_guard.py b/utils/feature/leak_guard.py
new file mode 100644
index 0000000000000000000000000000000000000000..9faf8cfffc436e0934b2f410aaf252e52f4f95df
--- /dev/null
+++ b/utils/feature/leak_guard.py
@@ -0,0 +1,273 @@
+"""Leak guardrails for feature matrices.
+
+This module centralizes pattern-based leak detection so both feature assembly
+and training can fail fast when post-outcome columns sneak into the data.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+from datetime import datetime
+import json
+import re
+from typing import Iterable, Mapping, Sequence
+
+import polars as pl
+
+from utils.general.constants import IDENTIFIER_COLUMNS, LEAK_PRONE_COLUMNS, NFL_TARGET_COLUMNS
+
+try:  # Optional dependency when imported from training (pandas path)
+    import pandas as pd  # type: ignore
+except Exception:  # pragma: no cover - optional dependency
+    pd = None
+
+
+@dataclass(frozen=True)
+class LeakPolicy:
+    version: str
+    banned_exact: set[str]
+    banned_prefixes: tuple[str, ...]
+    banned_suffixes: tuple[str, ...]
+    banned_regex: tuple[tuple[re.Pattern[str], str], ...]
+    description: str = ""
+
+
+@dataclass
+class LeakCheckResult:
+    policy_version: str
+    banned: dict[str, str]
+    kept: list[str]
+    dropped: list[str]
+    allowlist_kept: list[str]
+
+
+# Core policy tuned for anytime-TD style problems (can be extended per-problem).
+_BASE_BANNED_EXACT = set(LEAK_PRONE_COLUMNS) | {
+    "final_score",
+    "final_total",
+    "points_scored",
+    "actual_td_count",
+    "actual_anytime_td",
+    "postgame_anytime_td",
+    "postgame_td_count",
+}
+_BASE_BANNED_PREFIXES = (
+    "postgame_",
+    "post_game_",
+    "post_",
+    "live_",
+    "actual_",
+    "realized_",
+    "final_",
+    "postmatch_",
+)
+_BASE_BANNED_SUFFIXES = (
+    "_post",
+    "_postgame",
+    "_final",
+    "_fullgame",
+    "_actual",
+)
+_BASE_BANNED_REGEX: tuple[tuple[re.Pattern[str], str], ...] = (
+    (re.compile(r".*post.?game.*", flags=re.IGNORECASE), "postgame marker"),
+    (re.compile(r".*final_score.*", flags=re.IGNORECASE), "final score"),
+    (re.compile(r".*actual.*td.*", flags=re.IGNORECASE), "actual TD total"),
+    (re.compile(r".*anytime_td.*(post|final|actual).*", flags=re.IGNORECASE), "post-decision anytime TD"),
+    (re.compile(r".*fullgame.*", flags=re.IGNORECASE), "full game cumulative value"),
+)
+
+DEFAULT_LEAK_POLICY = LeakPolicy(
+    version="v1",
+    description="Core post-outcome leak guard for NFL anytime TD features.",
+    banned_exact=_BASE_BANNED_EXACT,
+    banned_prefixes=_BASE_BANNED_PREFIXES,
+    banned_suffixes=_BASE_BANNED_SUFFIXES,
+    banned_regex=_BASE_BANNED_REGEX,
+)
+
+
+def _ensure_sequence(value: Sequence[str] | str | None) -> tuple[str, ...]:
+    if value is None:
+        return ()
+    if isinstance(value, str):
+        return (value,)
+    return tuple(value)
+
+
+def evaluate_leak_prone_columns(
+    columns: Iterable[str],
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+) -> LeakCheckResult:
+    """Identify leak-prone columns using the configured policy."""
+
+    banned: dict[str, str] = {}
+    columns_list = list(columns)
+    for col in columns_list:
+        if col in policy.banned_exact:
+            banned[col] = "exact"
+            continue
+        for prefix in policy.banned_prefixes:
+            if col.startswith(prefix):
+                banned[col] = f"prefix:{prefix}"
+                break
+        if col in banned:
+            continue
+        for suffix in policy.banned_suffixes:
+            if col.endswith(suffix):
+                banned[col] = f"suffix:{suffix}"
+                break
+        if col in banned:
+            continue
+        for pattern, reason in policy.banned_regex:
+            if pattern.match(col):
+                banned[col] = reason
+                break
+
+    kept = [c for c in columns_list if c not in banned]
+    return LeakCheckResult(
+        policy_version=policy.version,
+        banned=banned,
+        kept=kept,
+        dropped=[],
+        allowlist_kept=[],
+    )
+
+
+def enforce_leak_guard(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    allow_prefixes: Sequence[str] | str | None = None,
+    allow_exact: Sequence[str] | str | None = None,
+    drop_banned: bool = True,
+    drop_non_allowlisted: bool = False,
+    raise_on_banned: bool = True,
+) -> tuple[pl.DataFrame | "pd.DataFrame", LeakCheckResult]:
+    """Apply leak guardrails to a feature frame.
+
+    Parameters
+    ----------
+    df : DataFrame
+        Polars or pandas DataFrame.
+    policy : LeakPolicy
+        Leak policy to apply.
+    allow_prefixes : Sequence[str] | str | None
+        Optional prefixes that define the allowed feature surface for a problem.
+    allow_exact : Sequence[str] | str | None
+        Explicitly allowed columns (e.g., identifiers).
+    drop_banned : bool
+        If True, drop any banned columns automatically.
+    drop_non_allowlisted : bool
+        If True, drop columns that are not covered by allow_prefixes/allow_exact/identifiers/targets.
+    raise_on_banned : bool
+        If True, raise when banned columns are detected (after optional drop).
+    """
+
+    result = evaluate_leak_prone_columns(df.columns, policy=policy)
+    dropped: list[str] = []
+
+    allow_prefixes = _ensure_sequence(allow_prefixes)
+    allow_exact = set(_ensure_sequence(allow_exact))
+    allow_exact.update({col for col in IDENTIFIER_COLUMNS if col in df.columns})
+    allow_exact.update({col for col in NFL_TARGET_COLUMNS if col in df.columns})
+
+    # Permit allowlisted columns even if they match a banned rule (e.g., labels)
+    banned = {col: reason for col, reason in result.banned.items() if col not in allow_exact}
+
+    if banned and drop_banned:
+        df = df.drop(list(banned.keys()))
+        dropped.extend(banned.keys())
+
+    if banned and raise_on_banned:
+        raise ValueError(f"Leak-prone columns detected: {sorted(banned.items())}")
+
+    allowlist_cols: set[str] = set()
+    if allow_prefixes:
+        allowlist_cols.update({c for c in df.columns if c.startswith(allow_prefixes)})
+    allowlist_cols.update({c for c in allow_exact if c in df.columns})
+
+    if drop_non_allowlisted and allowlist_cols:
+        drop_candidates = [c for c in df.columns if c not in allowlist_cols]
+        if drop_candidates:
+            df = df.drop(drop_candidates)
+            dropped.extend(drop_candidates)
+
+    if drop_non_allowlisted and not allowlist_cols:
+        raise ValueError("No allowlisted columns remain after applying leak guard allowlist.")
+
+    # Store adjusted banned info on the result
+    result.banned = banned
+    result.dropped = dropped
+    result.kept = [c for c in df.columns]
+    result.allowlist_kept = sorted(list(allowlist_cols)) if allowlist_cols else []
+    return df, result
+
+
+def build_schema_snapshot(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    metadata: Mapping[str, object] | None = None,
+    banned: Mapping[str, str] | None = None,
+) -> dict:
+    """Render a schema snapshot describing each column and whether it was flagged."""
+
+    banned = banned or {}
+    meta = {
+        "generated_at_utc": datetime.utcnow().isoformat(),
+        "policy_version": policy.version,
+    }
+    meta.update(metadata or {})
+
+    # Extract columns / dtypes
+    if isinstance(df, pl.DataFrame):
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+    else:  # pandas or pandas-like
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+
+    schema = {
+        "metadata": meta,
+        "columns": [],
+    }
+
+    for col, dtype in cols_and_dtypes:
+        tags: list[str] = []
+        if col in IDENTIFIER_COLUMNS:
+            tags.append("id")
+        if col in NFL_TARGET_COLUMNS:
+            tags.append("label")
+        if col.startswith("market_"):
+            tags.append("odds")
+        if col.startswith("injury_") or col.startswith("practice_"):
+            tags.append("injury")
+        if col.startswith("weather_"):
+            tags.append("weather")
+        if col.startswith("ps_"):
+            tags.append("pre_snap")
+        schema["columns"].append(
+            {
+                "name": col,
+                "dtype": dtype,
+                "banned": col in banned,
+                "tags": tags,
+            }
+        )
+    return schema
+
+
+def write_schema_snapshot(path, schema: Mapping[str, object]) -> None:
+    path.parent.mkdir(parents=True, exist_ok=True)
+    with open(path, "w") as fp:
+        json.dump(schema, fp, indent=2, sort_keys=True)
+
+
+__all__ = [
+    "DEFAULT_LEAK_POLICY",
+    "LeakPolicy",
+    "LeakCheckResult",
+    "evaluate_leak_prone_columns",
+    "enforce_leak_guard",
+    "build_schema_snapshot",
+    "write_schema_snapshot",
+]
diff --git a/utils/general/constants.py b/utils/general/constants.py
index d94b4260ad877484da843fa99ae2caf37e8493f4..dea87caa354d94e4a08b1762d2bd8dcd4c8caa3a
--- a/utils/general/constants.py
+++ b/utils/general/constants.py
@@ -211,7 +211,17 @@
 
 NFL_TARGET_COLUMNS: Tuple[str, ...] = (
     'anytime_td',
+    'anytime_td_offense',
+    'anytime_td_all',
+    'anytime_td_rush',
+    'anytime_td_rec',
+    'anytime_td_pass_thrown',
     'td_count',
+    'td_count_offense',
+    'td_count_all',
+    'passing_td',
+    'rushing_td_count',
+    'receiving_td_count',
     'receiving_yards',
     'rushing_yards',
     'passing_yards',


thinking
**Searching for odds snapshot config usage**
exec
/bin/zsh -lc 'cd /Users/jameswest/Desktop/nfl_predict && rg "get_odds_snapshot_config" -n' in /Users/jameswest/Desktop/nfl_predict succeeded in 749ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
utils/feature/odds.py:39:from utils.general.config import get_odds_api_key, get_odds_snapshot_config
utils/feature/odds.py:50:_ODDS_SNAPSHOT_CFG = get_odds_snapshot_config() or {}
utils/general/config.py:86:def get_odds_snapshot_config() -> Mapping[str, Any]:
utils/general/config.py:113:    "get_odds_snapshot_config",
file update:
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 5ba68e8bf1acd3a789a76a8857674e6f6433017b..0210d5b7e7ed60a8de7a126d64f5ed76326474c8
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -14,7 +14,7 @@
 
 import logging
 import os
-from datetime import date, timedelta
+from datetime import date, datetime, timedelta
 from typing import Sequence
 
 import polars as pl
@@ -37,6 +37,12 @@
     add_offense_context_features_training,
     _append_offense_context_columns,
 )
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    build_schema_snapshot,
+    enforce_leak_guard,
+    write_schema_snapshot,
+)
 from utils.feature.weather_features import (
     add_weather_forecast_features_training,
     append_weather_context_flags,
@@ -931,6 +937,32 @@
     if market_exprs:
         df_player_game_all = df_player_game_all.with_columns(market_exprs)
     
+    # Leak guard + schema snapshot before persisting
+    spec = get_label_spec(label_version)
+    allow_exact = {spec.primary, *spec.labels.keys(), *spec.aliases.keys()}
+    df_player_game_all, leak_result = enforce_leak_guard(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_exact=allow_exact,
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=True,
+    )
+
+    schema = build_schema_snapshot(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        metadata={
+            "cutoff_label": cutoff_label,
+            "label_version": spec.name,
+        },
+        banned=leak_result.banned,
+    )
+    schema_dir = FEATURE_AUDIT_DIR / "schema" / "anytime_td"
+    schema_path = schema_dir / f"{cutoff_label}_{datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')}.json"
+    write_schema_snapshot(schema_path, schema)
+    logging.info("    Schema snapshot written → %s", schema_path)
+
     # Write final feature matrix
     df_player_game_all = df_player_game_all.with_columns(
         pl.lit(current_cutoff_hours).cast(pl.Float32).alias("decision_horizon_hours")
@@ -951,7 +983,6 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    spec = get_label_spec(label_version)
     label_candidates = {spec.primary, "anytime_td"}
     for label_col in label_candidates:
         if label_col in df_player_game_all.columns:
diff --git a/pipeline/train.py b/pipeline/train.py
index fe70207dcdf25d209ee3ad55080b7ce826347c44..3fab3a05b3f65e8d0e88ec1ddaa71a8857646148
--- a/pipeline/train.py
+++ b/pipeline/train.py
@@ -98,6 +98,7 @@
     fit_team_conformal_sums,
     composite_sum_interval,
 )
+from utils.feature.leak_guard import DEFAULT_LEAK_POLICY, enforce_leak_guard
 from utils.feature.targets import require_target_column
 
 # Ignore specific, noisy warnings from dependencies
@@ -2315,7 +2316,30 @@
                             df_problem[col] = df_problem[col].fillna(df_problem[col].mean())
 
                 df_problem = self._inject_composed_features(df_problem)
-            
+
+            # Leak guard on the problem-scoped frame
+            allow_prefixes = tuple(problem_copy.get('feature_prefixes_to_include') or [])
+            allow_exact = set(problem_copy.get('other_features_to_include') or [])
+            allow_exact.update(input_preds or [])
+            if self.target_col:
+                allow_exact.add(self.target_col)
+            df_problem, leak_info = enforce_leak_guard(
+                df_problem,
+                policy=DEFAULT_LEAK_POLICY,
+                allow_prefixes=allow_prefixes,
+                allow_exact=allow_exact,
+                drop_banned=True,
+                drop_non_allowlisted=False,
+                raise_on_banned=True,
+            )
+            if leak_info.dropped:
+                logger.info(
+                    "Dropped %d leak-prone columns for %s: %s",
+                    len(leak_info.dropped),
+                    problem_name,
+                    sorted(leak_info.dropped),
+                )
+
             self._normalize_datetime_like_columns(df_problem, problem_name)
             df_problem[self.time_col] = pd.to_datetime(df_problem[self.time_col])
             sort_cols = [self.time_col]
diff --git a/tests/test_data_leak_guard.py b/tests/test_data_leak_guard.py
index 8061f2760c0898aaeda29026859e1b9ff5644ba4..3e56665921db89ea523bbdb205d1bb90c21893df
--- a/tests/test_data_leak_guard.py
+++ b/tests/test_data_leak_guard.py
@@ -3,6 +3,14 @@
 import yaml
 from pathlib import Path
 
+import polars as pl
+
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    enforce_leak_guard,
+    evaluate_leak_prone_columns,
+)
+
 
 PROJECT_ROOT = Path(__file__).resolve().parents[1]
 TRAINING_CONFIG = PROJECT_ROOT / "config" / "training.yaml"
@@ -48,3 +56,41 @@
     )
 
 
+def test_leak_guard_flags_pattern_columns():
+    cols = [
+        "market_anytime_td_prob",
+        "final_score",
+        "postgame_anytime_td",
+        "actual_td_count",
+        "safe_feature",
+    ]
+    result = evaluate_leak_prone_columns(cols, policy=DEFAULT_LEAK_POLICY)
+    assert set(result.banned.keys()) == {"final_score", "postgame_anytime_td", "actual_td_count"}
+    assert "safe_feature" in result.kept
+    assert "market_anytime_td_prob" in result.kept
+
+
+def test_enforce_leak_guard_drops_banned_and_keeps_allowlisted():
+    df = pl.DataFrame(
+        {
+            "game_id": ["g1", "g2"],
+            "safe_feature": [1.0, 2.0],
+            "postgame_anytime_td": [1, 0],
+            "final_score": [30, 24],
+        }
+    )
+    cleaned, info = enforce_leak_guard(
+        df,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_prefixes=("safe_",),
+        allow_exact=("game_id",),
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=False,
+    )
+    assert "postgame_anytime_td" not in cleaned.columns
+    assert "final_score" not in cleaned.columns
+    assert "safe_feature" in cleaned.columns
+    assert "game_id" in cleaned.columns
+    assert set(info.dropped) == {"postgame_anytime_td", "final_score"}
+
diff --git a/utils/feature/leak_guard.py b/utils/feature/leak_guard.py
new file mode 100644
index 0000000000000000000000000000000000000000..9faf8cfffc436e0934b2f410aaf252e52f4f95df
--- /dev/null
+++ b/utils/feature/leak_guard.py
@@ -0,0 +1,273 @@
+"""Leak guardrails for feature matrices.
+
+This module centralizes pattern-based leak detection so both feature assembly
+and training can fail fast when post-outcome columns sneak into the data.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+from datetime import datetime
+import json
+import re
+from typing import Iterable, Mapping, Sequence
+
+import polars as pl
+
+from utils.general.constants import IDENTIFIER_COLUMNS, LEAK_PRONE_COLUMNS, NFL_TARGET_COLUMNS
+
+try:  # Optional dependency when imported from training (pandas path)
+    import pandas as pd  # type: ignore
+except Exception:  # pragma: no cover - optional dependency
+    pd = None
+
+
+@dataclass(frozen=True)
+class LeakPolicy:
+    version: str
+    banned_exact: set[str]
+    banned_prefixes: tuple[str, ...]
+    banned_suffixes: tuple[str, ...]
+    banned_regex: tuple[tuple[re.Pattern[str], str], ...]
+    description: str = ""
+
+
+@dataclass
+class LeakCheckResult:
+    policy_version: str
+    banned: dict[str, str]
+    kept: list[str]
+    dropped: list[str]
+    allowlist_kept: list[str]
+
+
+# Core policy tuned for anytime-TD style problems (can be extended per-problem).
+_BASE_BANNED_EXACT = set(LEAK_PRONE_COLUMNS) | {
+    "final_score",
+    "final_total",
+    "points_scored",
+    "actual_td_count",
+    "actual_anytime_td",
+    "postgame_anytime_td",
+    "postgame_td_count",
+}
+_BASE_BANNED_PREFIXES = (
+    "postgame_",
+    "post_game_",
+    "post_",
+    "live_",
+    "actual_",
+    "realized_",
+    "final_",
+    "postmatch_",
+)
+_BASE_BANNED_SUFFIXES = (
+    "_post",
+    "_postgame",
+    "_final",
+    "_fullgame",
+    "_actual",
+)
+_BASE_BANNED_REGEX: tuple[tuple[re.Pattern[str], str], ...] = (
+    (re.compile(r".*post.?game.*", flags=re.IGNORECASE), "postgame marker"),
+    (re.compile(r".*final_score.*", flags=re.IGNORECASE), "final score"),
+    (re.compile(r".*actual.*td.*", flags=re.IGNORECASE), "actual TD total"),
+    (re.compile(r".*anytime_td.*(post|final|actual).*", flags=re.IGNORECASE), "post-decision anytime TD"),
+    (re.compile(r".*fullgame.*", flags=re.IGNORECASE), "full game cumulative value"),
+)
+
+DEFAULT_LEAK_POLICY = LeakPolicy(
+    version="v1",
+    description="Core post-outcome leak guard for NFL anytime TD features.",
+    banned_exact=_BASE_BANNED_EXACT,
+    banned_prefixes=_BASE_BANNED_PREFIXES,
+    banned_suffixes=_BASE_BANNED_SUFFIXES,
+    banned_regex=_BASE_BANNED_REGEX,
+)
+
+
+def _ensure_sequence(value: Sequence[str] | str | None) -> tuple[str, ...]:
+    if value is None:
+        return ()
+    if isinstance(value, str):
+        return (value,)
+    return tuple(value)
+
+
+def evaluate_leak_prone_columns(
+    columns: Iterable[str],
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+) -> LeakCheckResult:
+    """Identify leak-prone columns using the configured policy."""
+
+    banned: dict[str, str] = {}
+    columns_list = list(columns)
+    for col in columns_list:
+        if col in policy.banned_exact:
+            banned[col] = "exact"
+            continue
+        for prefix in policy.banned_prefixes:
+            if col.startswith(prefix):
+                banned[col] = f"prefix:{prefix}"
+                break
+        if col in banned:
+            continue
+        for suffix in policy.banned_suffixes:
+            if col.endswith(suffix):
+                banned[col] = f"suffix:{suffix}"
+                break
+        if col in banned:
+            continue
+        for pattern, reason in policy.banned_regex:
+            if pattern.match(col):
+                banned[col] = reason
+                break
+
+    kept = [c for c in columns_list if c not in banned]
+    return LeakCheckResult(
+        policy_version=policy.version,
+        banned=banned,
+        kept=kept,
+        dropped=[],
+        allowlist_kept=[],
+    )
+
+
+def enforce_leak_guard(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    allow_prefixes: Sequence[str] | str | None = None,
+    allow_exact: Sequence[str] | str | None = None,
+    drop_banned: bool = True,
+    drop_non_allowlisted: bool = False,
+    raise_on_banned: bool = True,
+) -> tuple[pl.DataFrame | "pd.DataFrame", LeakCheckResult]:
+    """Apply leak guardrails to a feature frame.
+
+    Parameters
+    ----------
+    df : DataFrame
+        Polars or pandas DataFrame.
+    policy : LeakPolicy
+        Leak policy to apply.
+    allow_prefixes : Sequence[str] | str | None
+        Optional prefixes that define the allowed feature surface for a problem.
+    allow_exact : Sequence[str] | str | None
+        Explicitly allowed columns (e.g., identifiers).
+    drop_banned : bool
+        If True, drop any banned columns automatically.
+    drop_non_allowlisted : bool
+        If True, drop columns that are not covered by allow_prefixes/allow_exact/identifiers/targets.
+    raise_on_banned : bool
+        If True, raise when banned columns are detected (after optional drop).
+    """
+
+    result = evaluate_leak_prone_columns(df.columns, policy=policy)
+    dropped: list[str] = []
+
+    allow_prefixes = _ensure_sequence(allow_prefixes)
+    allow_exact = set(_ensure_sequence(allow_exact))
+    allow_exact.update({col for col in IDENTIFIER_COLUMNS if col in df.columns})
+    allow_exact.update({col for col in NFL_TARGET_COLUMNS if col in df.columns})
+
+    # Permit allowlisted columns even if they match a banned rule (e.g., labels)
+    banned = {col: reason for col, reason in result.banned.items() if col not in allow_exact}
+
+    if banned and drop_banned:
+        df = df.drop(list(banned.keys()))
+        dropped.extend(banned.keys())
+
+    if banned and raise_on_banned:
+        raise ValueError(f"Leak-prone columns detected: {sorted(banned.items())}")
+
+    allowlist_cols: set[str] = set()
+    if allow_prefixes:
+        allowlist_cols.update({c for c in df.columns if c.startswith(allow_prefixes)})
+    allowlist_cols.update({c for c in allow_exact if c in df.columns})
+
+    if drop_non_allowlisted and allowlist_cols:
+        drop_candidates = [c for c in df.columns if c not in allowlist_cols]
+        if drop_candidates:
+            df = df.drop(drop_candidates)
+            dropped.extend(drop_candidates)
+
+    if drop_non_allowlisted and not allowlist_cols:
+        raise ValueError("No allowlisted columns remain after applying leak guard allowlist.")
+
+    # Store adjusted banned info on the result
+    result.banned = banned
+    result.dropped = dropped
+    result.kept = [c for c in df.columns]
+    result.allowlist_kept = sorted(list(allowlist_cols)) if allowlist_cols else []
+    return df, result
+
+
+def build_schema_snapshot(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    metadata: Mapping[str, object] | None = None,
+    banned: Mapping[str, str] | None = None,
+) -> dict:
+    """Render a schema snapshot describing each column and whether it was flagged."""
+
+    banned = banned or {}
+    meta = {
+        "generated_at_utc": datetime.utcnow().isoformat(),
+        "policy_version": policy.version,
+    }
+    meta.update(metadata or {})
+
+    # Extract columns / dtypes
+    if isinstance(df, pl.DataFrame):
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+    else:  # pandas or pandas-like
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+
+    schema = {
+        "metadata": meta,
+        "columns": [],
+    }
+
+    for col, dtype in cols_and_dtypes:
+        tags: list[str] = []
+        if col in IDENTIFIER_COLUMNS:
+            tags.append("id")
+        if col in NFL_TARGET_COLUMNS:
+            tags.append("label")
+        if col.startswith("market_"):
+            tags.append("odds")
+        if col.startswith("injury_") or col.startswith("practice_"):
+            tags.append("injury")
+        if col.startswith("weather_"):
+            tags.append("weather")
+        if col.startswith("ps_"):
+            tags.append("pre_snap")
+        schema["columns"].append(
+            {
+                "name": col,
+                "dtype": dtype,
+                "banned": col in banned,
+                "tags": tags,
+            }
+        )
+    return schema
+
+
+def write_schema_snapshot(path, schema: Mapping[str, object]) -> None:
+    path.parent.mkdir(parents=True, exist_ok=True)
+    with open(path, "w") as fp:
+        json.dump(schema, fp, indent=2, sort_keys=True)
+
+
+__all__ = [
+    "DEFAULT_LEAK_POLICY",
+    "LeakPolicy",
+    "LeakCheckResult",
+    "evaluate_leak_prone_columns",
+    "enforce_leak_guard",
+    "build_schema_snapshot",
+    "write_schema_snapshot",
+]
diff --git a/utils/general/constants.py b/utils/general/constants.py
index d94b4260ad877484da843fa99ae2caf37e8493f4..dea87caa354d94e4a08b1762d2bd8dcd4c8caa3a
--- a/utils/general/constants.py
+++ b/utils/general/constants.py
@@ -211,7 +211,17 @@
 
 NFL_TARGET_COLUMNS: Tuple[str, ...] = (
     'anytime_td',
+    'anytime_td_offense',
+    'anytime_td_all',
+    'anytime_td_rush',
+    'anytime_td_rec',
+    'anytime_td_pass_thrown',
     'td_count',
+    'td_count_offense',
+    'td_count_all',
+    'passing_td',
+    'rushing_td_count',
+    'receiving_td_count',
     'receiving_yards',
     'rushing_yards',
     'passing_yards',

exec
/bin/zsh -lc "cd /Users/jameswest/Desktop/nfl_predict && sed -n '1,240p' utils/feature/odds.py" in /Users/jameswest/Desktop/nfl_predict succeeded in 734ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
"""
Consolidated NFL Odds Module
============================

This module provides all odds-related functionality for the NFL prediction pipeline:

1. OddsAPIClient - HTTP client for The Odds API with caching and retry logic
2. Game-level odds features (moneyline, spread, totals) from nfl_odds.py
3. Player-level odds features (anytime TD props) from odds_features.py
4. Odds snapshot collection and persistence from odds_snapshots.py

All odds logic is consolidated here to prevent drift and ensure consistency.
"""

from __future__ import annotations

import datetime as dt
import hashlib
import json
file update:
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 5ba68e8bf1acd3a789a76a8857674e6f6433017b..0210d5b7e7ed60a8de7a126d64f5ed76326474c8
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -14,7 +14,7 @@
 
 import logging
 import os
-from datetime import date, timedelta
+from datetime import date, datetime, timedelta
 from typing import Sequence
 
 import polars as pl
@@ -37,6 +37,12 @@
     add_offense_context_features_training,
     _append_offense_context_columns,
 )
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    build_schema_snapshot,
+    enforce_leak_guard,
+    write_schema_snapshot,
+)
 from utils.feature.weather_features import (
     add_weather_forecast_features_training,
     append_weather_context_flags,
@@ -931,6 +937,32 @@
     if market_exprs:
         df_player_game_all = df_player_game_all.with_columns(market_exprs)
     
+    # Leak guard + schema snapshot before persisting
+    spec = get_label_spec(label_version)
+    allow_exact = {spec.primary, *spec.labels.keys(), *spec.aliases.keys()}
+    df_player_game_all, leak_result = enforce_leak_guard(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_exact=allow_exact,
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=True,
+    )
+
+    schema = build_schema_snapshot(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        metadata={
+            "cutoff_label": cutoff_label,
+            "label_version": spec.name,
+        },
+        banned=leak_result.banned,
+    )
+    schema_dir = FEATURE_AUDIT_DIR / "schema" / "anytime_td"
+    schema_path = schema_dir / f"{cutoff_label}_{datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')}.json"
+    write_schema_snapshot(schema_path, schema)
+    logging.info("    Schema snapshot written → %s", schema_path)
+
     # Write final feature matrix
     df_player_game_all = df_player_game_all.with_columns(
         pl.lit(current_cutoff_hours).cast(pl.Float32).alias("decision_horizon_hours")
@@ -951,7 +983,6 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    spec = get_label_spec(label_version)
     label_candidates = {spec.primary, "anytime_td"}
     for label_col in label_candidates:
         if label_col in df_player_game_all.columns:
diff --git a/pipeline/train.py b/pipeline/train.py
index fe70207dcdf25d209ee3ad55080b7ce826347c44..3fab3a05b3f65e8d0e88ec1ddaa71a8857646148
--- a/pipeline/train.py
+++ b/pipeline/train.py
@@ -98,6 +98,7 @@
     fit_team_conformal_sums,
     composite_sum_interval,
 )
+from utils.feature.leak_guard import DEFAULT_LEAK_POLICY, enforce_leak_guard
 from utils.feature.targets import require_target_column
 
 # Ignore specific, noisy warnings from dependencies
@@ -2315,7 +2316,30 @@
                             df_problem[col] = df_problem[col].fillna(df_problem[col].mean())
 
                 df_problem = self._inject_composed_features(df_problem)
-            
+
+            # Leak guard on the problem-scoped frame
+            allow_prefixes = tuple(problem_copy.get('feature_prefixes_to_include') or [])
+            allow_exact = set(problem_copy.get('other_features_to_include') or [])
+            allow_exact.update(input_preds or [])
+            if self.target_col:
+                allow_exact.add(self.target_col)
+            df_problem, leak_info = enforce_leak_guard(
+                df_problem,
+                policy=DEFAULT_LEAK_POLICY,
+                allow_prefixes=allow_prefixes,
+                allow_exact=allow_exact,
+                drop_banned=True,
+                drop_non_allowlisted=False,
+                raise_on_banned=True,
+            )
+            if leak_info.dropped:
+                logger.info(
+                    "Dropped %d leak-prone columns for %s: %s",
+                    len(leak_info.dropped),
+                    problem_name,
+                    sorted(leak_info.dropped),
+                )
+
             self._normalize_datetime_like_columns(df_problem, problem_name)
             df_problem[self.time_col] = pd.to_datetime(df_problem[self.time_col])
             sort_cols = [self.time_col]
diff --git a/tests/test_data_leak_guard.py b/tests/test_data_leak_guard.py
index 8061f2760c0898aaeda29026859e1b9ff5644ba4..3e56665921db89ea523bbdb205d1bb90c21893df
--- a/tests/test_data_leak_guard.py
+++ b/tests/test_data_leak_guard.py
@@ -3,6 +3,14 @@
 import yaml
 from pathlib import Path
 
+import polars as pl
+
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    enforce_leak_guard,
+    evaluate_leak_prone_columns,
+)
+
 
 PROJECT_ROOT = Path(__file__).resolve().parents[1]
 TRAINING_CONFIG = PROJECT_ROOT / "config" / "training.yaml"
@@ -48,3 +56,41 @@
     )
 
 
+def test_leak_guard_flags_pattern_columns():
+    cols = [
+        "market_anytime_td_prob",
+        "final_score",
+        "postgame_anytime_td",
+        "actual_td_count",
+        "safe_feature",
+    ]
+    result = evaluate_leak_prone_columns(cols, policy=DEFAULT_LEAK_POLICY)
+    assert set(result.banned.keys()) == {"final_score", "postgame_anytime_td", "actual_td_count"}
+    assert "safe_feature" in result.kept
+    assert "market_anytime_td_prob" in result.kept
+
+
+def test_enforce_leak_guard_drops_banned_and_keeps_allowlisted():
+    df = pl.DataFrame(
+        {
+            "game_id": ["g1", "g2"],
+            "safe_feature": [1.0, 2.0],
+            "postgame_anytime_td": [1, 0],
+            "final_score": [30, 24],
+        }
+    )
+    cleaned, info = enforce_leak_guard(
+        df,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_prefixes=("safe_",),
+        allow_exact=("game_id",),
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=False,
+    )
+    assert "postgame_anytime_td" not in cleaned.columns
+    assert "final_score" not in cleaned.columns
+    assert "safe_feature" in cleaned.columns
+    assert "game_id" in cleaned.columns
+    assert set(info.dropped) == {"postgame_anytime_td", "final_score"}
+
diff --git a/utils/feature/leak_guard.py b/utils/feature/leak_guard.py
new file mode 100644
index 0000000000000000000000000000000000000000..9faf8cfffc436e0934b2f410aaf252e52f4f95df
--- /dev/null
+++ b/utils/feature/leak_guard.py
@@ -0,0 +1,273 @@
+"""Leak guardrails for feature matrices.
+
+This module centralizes pattern-based leak detection so both feature assembly
+and training can fail fast when post-outcome columns sneak into the data.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+from datetime import datetime
+import json
+import re
+from typing import Iterable, Mapping, Sequence
+
+import polars as pl
+
+from utils.general.constants import IDENTIFIER_COLUMNS, LEAK_PRONE_COLUMNS, NFL_TARGET_COLUMNS
+
+try:  # Optional dependency when imported from training (pandas path)
+    import pandas as pd  # type: ignore
+except Exception:  # pragma: no cover - optional dependency
+    pd = None
+
+
+@dataclass(frozen=True)
+class LeakPolicy:
+    version: str
+    banned_exact: set[str]
+    banned_prefixes: tuple[str, ...]
+    banned_suffixes: tuple[str, ...]
+    banned_regex: tuple[tuple[re.Pattern[str], str], ...]
+    description: str = ""
+
+
+@dataclass
+class LeakCheckResult:
+    policy_version: str
+    banned: dict[str, str]
+    kept: list[str]
+    dropped: list[str]
+    allowlist_kept: list[str]
+
+
+# Core policy tuned for anytime-TD style problems (can be extended per-problem).
+_BASE_BANNED_EXACT = set(LEAK_PRONE_COLUMNS) | {
+    "final_score",
+    "final_total",
+    "points_scored",
+    "actual_td_count",
+    "actual_anytime_td",
+    "postgame_anytime_td",
+    "postgame_td_count",
+}
+_BASE_BANNED_PREFIXES = (
+    "postgame_",
+    "post_game_",
+    "post_",
+    "live_",
+    "actual_",
+    "realized_",
+    "final_",
+    "postmatch_",
+)
+_BASE_BANNED_SUFFIXES = (
+    "_post",
+    "_postgame",
+    "_final",
+    "_fullgame",
+    "_actual",
+)
+_BASE_BANNED_REGEX: tuple[tuple[re.Pattern[str], str], ...] = (
+    (re.compile(r".*post.?game.*", flags=re.IGNORECASE), "postgame marker"),
+    (re.compile(r".*final_score.*", flags=re.IGNORECASE), "final score"),
+    (re.compile(r".*actual.*td.*", flags=re.IGNORECASE), "actual TD total"),
+    (re.compile(r".*anytime_td.*(post|final|actual).*", flags=re.IGNORECASE), "post-decision anytime TD"),
+    (re.compile(r".*fullgame.*", flags=re.IGNORECASE), "full game cumulative value"),
+)
+
+DEFAULT_LEAK_POLICY = LeakPolicy(
+    version="v1",
+    description="Core post-outcome leak guard for NFL anytime TD features.",
+    banned_exact=_BASE_BANNED_EXACT,
+    banned_prefixes=_BASE_BANNED_PREFIXES,
+    banned_suffixes=_BASE_BANNED_SUFFIXES,
+    banned_regex=_BASE_BANNED_REGEX,
+)
+
+
+def _ensure_sequence(value: Sequence[str] | str | None) -> tuple[str, ...]:
+    if value is None:
+        return ()
+    if isinstance(value, str):
+        return (value,)
+    return tuple(value)
+
+
+def evaluate_leak_prone_columns(
+    columns: Iterable[str],
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+) -> LeakCheckResult:
+    """Identify leak-prone columns using the configured policy."""
+
+    banned: dict[str, str] = {}
+    columns_list = list(columns)
+    for col in columns_list:
+        if col in policy.banned_exact:
+            banned[col] = "exact"
+            continue
+        for prefix in policy.banned_prefixes:
+            if col.startswith(prefix):
+                banned[col] = f"prefix:{prefix}"
+                break
+        if col in banned:
+            continue
+        for suffix in policy.banned_suffixes:
+            if col.endswith(suffix):
+                banned[col] = f"suffix:{suffix}"
+                break
+        if col in banned:
+            continue
+        for pattern, reason in policy.banned_regex:
+            if pattern.match(col):
+                banned[col] = reason
+                break
+
+    kept = [c for c in columns_list if c not in banned]
+    return LeakCheckResult(
+        policy_version=policy.version,
+        banned=banned,
+        kept=kept,
+        dropped=[],
+        allowlist_kept=[],
+    )
+
+
+def enforce_leak_guard(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    allow_prefixes: Sequence[str] | str | None = None,
+    allow_exact: Sequence[str] | str | None = None,
+    drop_banned: bool = True,
+    drop_non_allowlisted: bool = False,
+    raise_on_banned: bool = True,
+) -> tuple[pl.DataFrame | "pd.DataFrame", LeakCheckResult]:
+    """Apply leak guardrails to a feature frame.
+
+    Parameters
+    ----------
+    df : DataFrame
+        Polars or pandas DataFrame.
+    policy : LeakPolicy
+        Leak policy to apply.
+    allow_prefixes : Sequence[str] | str | None
+        Optional prefixes that define the allowed feature surface for a problem.
+    allow_exact : Sequence[str] | str | None
+        Explicitly allowed columns (e.g., identifiers).
+    drop_banned : bool
+        If True, drop any banned columns automatically.
+    drop_non_allowlisted : bool
+        If True, drop columns that are not covered by allow_prefixes/allow_exact/identifiers/targets.
+    raise_on_banned : bool
+        If True, raise when banned columns are detected (after optional drop).
+    """
+
+    result = evaluate_leak_prone_columns(df.columns, policy=policy)
+    dropped: list[str] = []
+
+    allow_prefixes = _ensure_sequence(allow_prefixes)
+    allow_exact = set(_ensure_sequence(allow_exact))
+    allow_exact.update({col for col in IDENTIFIER_COLUMNS if col in df.columns})
+    allow_exact.update({col for col in NFL_TARGET_COLUMNS if col in df.columns})
+
+    # Permit allowlisted columns even if they match a banned rule (e.g., labels)
+    banned = {col: reason for col, reason in result.banned.items() if col not in allow_exact}
+
+    if banned and drop_banned:
+        df = df.drop(list(banned.keys()))
+        dropped.extend(banned.keys())
+
+    if banned and raise_on_banned:
+        raise ValueError(f"Leak-prone columns detected: {sorted(banned.items())}")
+
+    allowlist_cols: set[str] = set()
+    if allow_prefixes:
+        allowlist_cols.update({c for c in df.columns if c.startswith(allow_prefixes)})
+    allowlist_cols.update({c for c in allow_exact if c in df.columns})
+
+    if drop_non_allowlisted and allowlist_cols:
+        drop_candidates = [c for c in df.columns if c not in allowlist_cols]
+        if drop_candidates:
+            df = df.drop(drop_candidates)
+            dropped.extend(drop_candidates)
+
+    if drop_non_allowlisted and not allowlist_cols:
+        raise ValueError("No allowlisted columns remain after applying leak guard allowlist.")
+
+    # Store adjusted banned info on the result
+    result.banned = banned
+    result.dropped = dropped
+    result.kept = [c for c in df.columns]
+    result.allowlist_kept = sorted(list(allowlist_cols)) if allowlist_cols else []
+    return df, result
+
+
+def build_schema_snapshot(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    metadata: Mapping[str, object] | None = None,
+    banned: Mapping[str, str] | None = None,
+) -> dict:
+    """Render a schema snapshot describing each column and whether it was flagged."""
+
+    banned = banned or {}
+    meta = {
+        "generated_at_utc": datetime.utcnow().isoformat(),
+        "policy_version": policy.version,
+    }
+    meta.update(metadata or {})
+
+    # Extract columns / dtypes
+    if isinstance(df, pl.DataFrame):
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+    else:  # pandas or pandas-like
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+
+    schema = {
+        "metadata": meta,
+        "columns": [],
+    }
+
+    for col, dtype in cols_and_dtypes:
+        tags: list[str] = []
+        if col in IDENTIFIER_COLUMNS:
+            tags.append("id")
+        if col in NFL_TARGET_COLUMNS:
+            tags.append("label")
+        if col.startswith("market_"):
+            tags.append("odds")
+        if col.startswith("injury_") or col.startswith("practice_"):
+            tags.append("injury")
+        if col.startswith("weather_"):
+            tags.append("weather")
+        if col.startswith("ps_"):
+            tags.append("pre_snap")
+        schema["columns"].append(
+            {
+                "name": col,
+                "dtype": dtype,
+                "banned": col in banned,
+                "tags": tags,
+            }
+        )
+    return schema
+
+
+def write_schema_snapshot(path, schema: Mapping[str, object]) -> None:
+    path.parent.mkdir(parents=True, exist_ok=True)
+    with open(path, "w") as fp:
+        json.dump(schema, fp, indent=2, sort_keys=True)
+
+
+__all__ = [
+    "DEFAULT_LEAK_POLICY",
+    "LeakPolicy",
+    "LeakCheckResult",
+    "evaluate_leak_prone_columns",
+    "enforce_leak_guard",
+    "build_schema_snapshot",
+    "write_schema_snapshot",
+]
diff --git a/utils/general/constants.py b/utils/general/constants.py
index d94b4260ad877484da843fa99ae2caf37e8493f4..dea87caa354d94e4a08b1762d2bd8dcd4c8caa3a
--- a/utils/general/constants.py
+++ b/utils/general/constants.py
@@ -211,7 +211,17 @@
 
 NFL_TARGET_COLUMNS: Tuple[str, ...] = (
     'anytime_td',
+    'anytime_td_offense',
+    'anytime_td_all',
+    'anytime_td_rush',
+    'anytime_td_rec',
+    'anytime_td_pass_thrown',
     'td_count',
+    'td_count_offense',
+    'td_count_all',
+    'passing_td',
+    'rushing_td_count',
+    'receiving_td_count',
     'receiving_yards',
     'rushing_yards',
     'passing_yards',


thinking
**Evaluating horizon filtering strategies**

thinking
**Planning odds horizon filtering**

thinking
**Designing horizon-based odds filtering**

thinking
**Designing horizon filtering for odds columns**

I’m thinking about how to handle filtering columns by horizon suffix for training data, aiming to keep only columns matching a configured horizon like "cutoff" while dropping others (_2h, _6h, etc.) to avoid data leakage. I’ll implement a method that inspects columns with certain prefixes and retains those with the desired horizon suffix or no suffix, considering how to handle base columns alongside horizon-specific ones.

thinking
**Designing horizon-based column filtering**

thinking
**Planning column filtering integration**

I'm verifying that the regex module needs importing for the new column-dropping method, deciding to add the call just after merges but before the leak guard to prevent detecting dropped columns as leaks, and figuring out the best place to insert the new `_filter_odds_snapshot_columns` method near existing helper functions like `_normalize_datetime_like_columns` inside the ModelTrainer class.
exec
/bin/zsh -lc 'cd /Users/jameswest/Desktop/nfl_predict && rg "_normalize_datetime_like_columns" -n pipeline/train.py' in /Users/jameswest/Desktop/nfl_predict succeeded in 803ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
493:    def _normalize_datetime_like_columns(self, df: pd.DataFrame, problem_name: str) -> None:
2343:            self._normalize_datetime_like_columns(df_problem, problem_name)
file update:
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 5ba68e8bf1acd3a789a76a8857674e6f6433017b..0210d5b7e7ed60a8de7a126d64f5ed76326474c8
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -14,7 +14,7 @@
 
 import logging
 import os
-from datetime import date, timedelta
+from datetime import date, datetime, timedelta
 from typing import Sequence
 
 import polars as pl
@@ -37,6 +37,12 @@
     add_offense_context_features_training,
     _append_offense_context_columns,
 )
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    build_schema_snapshot,
+    enforce_leak_guard,
+    write_schema_snapshot,
+)
 from utils.feature.weather_features import (
     add_weather_forecast_features_training,
     append_weather_context_flags,
@@ -931,6 +937,32 @@
     if market_exprs:
         df_player_game_all = df_player_game_all.with_columns(market_exprs)
     
+    # Leak guard + schema snapshot before persisting
+    spec = get_label_spec(label_version)
+    allow_exact = {spec.primary, *spec.labels.keys(), *spec.aliases.keys()}
+    df_player_game_all, leak_result = enforce_leak_guard(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_exact=allow_exact,
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=True,
+    )
+
+    schema = build_schema_snapshot(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        metadata={
+            "cutoff_label": cutoff_label,
+            "label_version": spec.name,
+        },
+        banned=leak_result.banned,
+    )
+    schema_dir = FEATURE_AUDIT_DIR / "schema" / "anytime_td"
+    schema_path = schema_dir / f"{cutoff_label}_{datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')}.json"
+    write_schema_snapshot(schema_path, schema)
+    logging.info("    Schema snapshot written → %s", schema_path)
+
     # Write final feature matrix
     df_player_game_all = df_player_game_all.with_columns(
         pl.lit(current_cutoff_hours).cast(pl.Float32).alias("decision_horizon_hours")
@@ -951,7 +983,6 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    spec = get_label_spec(label_version)
     label_candidates = {spec.primary, "anytime_td"}
     for label_col in label_candidates:
         if label_col in df_player_game_all.columns:
diff --git a/pipeline/train.py b/pipeline/train.py
index fe70207dcdf25d209ee3ad55080b7ce826347c44..3fab3a05b3f65e8d0e88ec1ddaa71a8857646148
--- a/pipeline/train.py
+++ b/pipeline/train.py
@@ -98,6 +98,7 @@
     fit_team_conformal_sums,
     composite_sum_interval,
 )
+from utils.feature.leak_guard import DEFAULT_LEAK_POLICY, enforce_leak_guard
 from utils.feature.targets import require_target_column
 
 # Ignore specific, noisy warnings from dependencies
@@ -2315,7 +2316,30 @@
                             df_problem[col] = df_problem[col].fillna(df_problem[col].mean())
 
                 df_problem = self._inject_composed_features(df_problem)
-            
+
+            # Leak guard on the problem-scoped frame
+            allow_prefixes = tuple(problem_copy.get('feature_prefixes_to_include') or [])
+            allow_exact = set(problem_copy.get('other_features_to_include') or [])
+            allow_exact.update(input_preds or [])
+            if self.target_col:
+                allow_exact.add(self.target_col)
+            df_problem, leak_info = enforce_leak_guard(
+                df_problem,
+                policy=DEFAULT_LEAK_POLICY,
+                allow_prefixes=allow_prefixes,
+                allow_exact=allow_exact,
+                drop_banned=True,
+                drop_non_allowlisted=False,
+                raise_on_banned=True,
+            )
+            if leak_info.dropped:
+                logger.info(
+                    "Dropped %d leak-prone columns for %s: %s",
+                    len(leak_info.dropped),
+                    problem_name,
+                    sorted(leak_info.dropped),
+                )
+
             self._normalize_datetime_like_columns(df_problem, problem_name)
             df_problem[self.time_col] = pd.to_datetime(df_problem[self.time_col])
             sort_cols = [self.time_col]
diff --git a/tests/test_data_leak_guard.py b/tests/test_data_leak_guard.py
index 8061f2760c0898aaeda29026859e1b9ff5644ba4..3e56665921db89ea523bbdb205d1bb90c21893df
--- a/tests/test_data_leak_guard.py
+++ b/tests/test_data_leak_guard.py
@@ -3,6 +3,14 @@
 import yaml
 from pathlib import Path
 
+import polars as pl
+
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    enforce_leak_guard,
+    evaluate_leak_prone_columns,
+)
+
 
 PROJECT_ROOT = Path(__file__).resolve().parents[1]
 TRAINING_CONFIG = PROJECT_ROOT / "config" / "training.yaml"
@@ -48,3 +56,41 @@
     )
 
 
+def test_leak_guard_flags_pattern_columns():
+    cols = [
+        "market_anytime_td_prob",
+        "final_score",
+        "postgame_anytime_td",
+        "actual_td_count",
+        "safe_feature",
+    ]
+    result = evaluate_leak_prone_columns(cols, policy=DEFAULT_LEAK_POLICY)
+    assert set(result.banned.keys()) == {"final_score", "postgame_anytime_td", "actual_td_count"}
+    assert "safe_feature" in result.kept
+    assert "market_anytime_td_prob" in result.kept
+
+
+def test_enforce_leak_guard_drops_banned_and_keeps_allowlisted():
+    df = pl.DataFrame(
+        {
+            "game_id": ["g1", "g2"],
+            "safe_feature": [1.0, 2.0],
+            "postgame_anytime_td": [1, 0],
+            "final_score": [30, 24],
+        }
+    )
+    cleaned, info = enforce_leak_guard(
+        df,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_prefixes=("safe_",),
+        allow_exact=("game_id",),
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=False,
+    )
+    assert "postgame_anytime_td" not in cleaned.columns
+    assert "final_score" not in cleaned.columns
+    assert "safe_feature" in cleaned.columns
+    assert "game_id" in cleaned.columns
+    assert set(info.dropped) == {"postgame_anytime_td", "final_score"}
+
diff --git a/utils/feature/leak_guard.py b/utils/feature/leak_guard.py
new file mode 100644
index 0000000000000000000000000000000000000000..9faf8cfffc436e0934b2f410aaf252e52f4f95df
--- /dev/null
+++ b/utils/feature/leak_guard.py
@@ -0,0 +1,273 @@
+"""Leak guardrails for feature matrices.
+
+This module centralizes pattern-based leak detection so both feature assembly
+and training can fail fast when post-outcome columns sneak into the data.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+from datetime import datetime
+import json
+import re
+from typing import Iterable, Mapping, Sequence
+
+import polars as pl
+
+from utils.general.constants import IDENTIFIER_COLUMNS, LEAK_PRONE_COLUMNS, NFL_TARGET_COLUMNS
+
+try:  # Optional dependency when imported from training (pandas path)
+    import pandas as pd  # type: ignore
+except Exception:  # pragma: no cover - optional dependency
+    pd = None
+
+
+@dataclass(frozen=True)
+class LeakPolicy:
+    version: str
+    banned_exact: set[str]
+    banned_prefixes: tuple[str, ...]
+    banned_suffixes: tuple[str, ...]
+    banned_regex: tuple[tuple[re.Pattern[str], str], ...]
+    description: str = ""
+
+
+@dataclass
+class LeakCheckResult:
+    policy_version: str
+    banned: dict[str, str]
+    kept: list[str]
+    dropped: list[str]
+    allowlist_kept: list[str]
+
+
+# Core policy tuned for anytime-TD style problems (can be extended per-problem).
+_BASE_BANNED_EXACT = set(LEAK_PRONE_COLUMNS) | {
+    "final_score",
+    "final_total",
+    "points_scored",
+    "actual_td_count",
+    "actual_anytime_td",
+    "postgame_anytime_td",
+    "postgame_td_count",
+}
+_BASE_BANNED_PREFIXES = (
+    "postgame_",
+    "post_game_",
+    "post_",
+    "live_",
+    "actual_",
+    "realized_",
+    "final_",
+    "postmatch_",
+)
+_BASE_BANNED_SUFFIXES = (
+    "_post",
+    "_postgame",
+    "_final",
+    "_fullgame",
+    "_actual",
+)
+_BASE_BANNED_REGEX: tuple[tuple[re.Pattern[str], str], ...] = (
+    (re.compile(r".*post.?game.*", flags=re.IGNORECASE), "postgame marker"),
+    (re.compile(r".*final_score.*", flags=re.IGNORECASE), "final score"),
+    (re.compile(r".*actual.*td.*", flags=re.IGNORECASE), "actual TD total"),
+    (re.compile(r".*anytime_td.*(post|final|actual).*", flags=re.IGNORECASE), "post-decision anytime TD"),
+    (re.compile(r".*fullgame.*", flags=re.IGNORECASE), "full game cumulative value"),
+)
+
+DEFAULT_LEAK_POLICY = LeakPolicy(
+    version="v1",
+    description="Core post-outcome leak guard for NFL anytime TD features.",
+    banned_exact=_BASE_BANNED_EXACT,
+    banned_prefixes=_BASE_BANNED_PREFIXES,
+    banned_suffixes=_BASE_BANNED_SUFFIXES,
+    banned_regex=_BASE_BANNED_REGEX,
+)
+
+
+def _ensure_sequence(value: Sequence[str] | str | None) -> tuple[str, ...]:
+    if value is None:
+        return ()
+    if isinstance(value, str):
+        return (value,)
+    return tuple(value)
+
+
+def evaluate_leak_prone_columns(
+    columns: Iterable[str],
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+) -> LeakCheckResult:
+    """Identify leak-prone columns using the configured policy."""
+
+    banned: dict[str, str] = {}
+    columns_list = list(columns)
+    for col in columns_list:
+        if col in policy.banned_exact:
+            banned[col] = "exact"
+            continue
+        for prefix in policy.banned_prefixes:
+            if col.startswith(prefix):
+                banned[col] = f"prefix:{prefix}"
+                break
+        if col in banned:
+            continue
+        for suffix in policy.banned_suffixes:
+            if col.endswith(suffix):
+                banned[col] = f"suffix:{suffix}"
+                break
+        if col in banned:
+            continue
+        for pattern, reason in policy.banned_regex:
+            if pattern.match(col):
+                banned[col] = reason
+                break
+
+    kept = [c for c in columns_list if c not in banned]
+    return LeakCheckResult(
+        policy_version=policy.version,
+        banned=banned,
+        kept=kept,
+        dropped=[],
+        allowlist_kept=[],
+    )
+
+
+def enforce_leak_guard(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    allow_prefixes: Sequence[str] | str | None = None,
+    allow_exact: Sequence[str] | str | None = None,
+    drop_banned: bool = True,
+    drop_non_allowlisted: bool = False,
+    raise_on_banned: bool = True,
+) -> tuple[pl.DataFrame | "pd.DataFrame", LeakCheckResult]:
+    """Apply leak guardrails to a feature frame.
+
+    Parameters
+    ----------
+    df : DataFrame
+        Polars or pandas DataFrame.
+    policy : LeakPolicy
+        Leak policy to apply.
+    allow_prefixes : Sequence[str] | str | None
+        Optional prefixes that define the allowed feature surface for a problem.
+    allow_exact : Sequence[str] | str | None
+        Explicitly allowed columns (e.g., identifiers).
+    drop_banned : bool
+        If True, drop any banned columns automatically.
+    drop_non_allowlisted : bool
+        If True, drop columns that are not covered by allow_prefixes/allow_exact/identifiers/targets.
+    raise_on_banned : bool
+        If True, raise when banned columns are detected (after optional drop).
+    """
+
+    result = evaluate_leak_prone_columns(df.columns, policy=policy)
+    dropped: list[str] = []
+
+    allow_prefixes = _ensure_sequence(allow_prefixes)
+    allow_exact = set(_ensure_sequence(allow_exact))
+    allow_exact.update({col for col in IDENTIFIER_COLUMNS if col in df.columns})
+    allow_exact.update({col for col in NFL_TARGET_COLUMNS if col in df.columns})
+
+    # Permit allowlisted columns even if they match a banned rule (e.g., labels)
+    banned = {col: reason for col, reason in result.banned.items() if col not in allow_exact}
+
+    if banned and drop_banned:
+        df = df.drop(list(banned.keys()))
+        dropped.extend(banned.keys())
+
+    if banned and raise_on_banned:
+        raise ValueError(f"Leak-prone columns detected: {sorted(banned.items())}")
+
+    allowlist_cols: set[str] = set()
+    if allow_prefixes:
+        allowlist_cols.update({c for c in df.columns if c.startswith(allow_prefixes)})
+    allowlist_cols.update({c for c in allow_exact if c in df.columns})
+
+    if drop_non_allowlisted and allowlist_cols:
+        drop_candidates = [c for c in df.columns if c not in allowlist_cols]
+        if drop_candidates:
+            df = df.drop(drop_candidates)
+            dropped.extend(drop_candidates)
+
+    if drop_non_allowlisted and not allowlist_cols:
+        raise ValueError("No allowlisted columns remain after applying leak guard allowlist.")
+
+    # Store adjusted banned info on the result
+    result.banned = banned
+    result.dropped = dropped
+    result.kept = [c for c in df.columns]
+    result.allowlist_kept = sorted(list(allowlist_cols)) if allowlist_cols else []
+    return df, result
+
+
+def build_schema_snapshot(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    metadata: Mapping[str, object] | None = None,
+    banned: Mapping[str, str] | None = None,
+) -> dict:
+    """Render a schema snapshot describing each column and whether it was flagged."""
+
+    banned = banned or {}
+    meta = {
+        "generated_at_utc": datetime.utcnow().isoformat(),
+        "policy_version": policy.version,
+    }
+    meta.update(metadata or {})
+
+    # Extract columns / dtypes
+    if isinstance(df, pl.DataFrame):
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+    else:  # pandas or pandas-like
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+
+    schema = {
+        "metadata": meta,
+        "columns": [],
+    }
+
+    for col, dtype in cols_and_dtypes:
+        tags: list[str] = []
+        if col in IDENTIFIER_COLUMNS:
+            tags.append("id")
+        if col in NFL_TARGET_COLUMNS:
+            tags.append("label")
+        if col.startswith("market_"):
+            tags.append("odds")
+        if col.startswith("injury_") or col.startswith("practice_"):
+            tags.append("injury")
+        if col.startswith("weather_"):
+            tags.append("weather")
+        if col.startswith("ps_"):
+            tags.append("pre_snap")
+        schema["columns"].append(
+            {
+                "name": col,
+                "dtype": dtype,
+                "banned": col in banned,
+                "tags": tags,
+            }
+        )
+    return schema
+
+
+def write_schema_snapshot(path, schema: Mapping[str, object]) -> None:
+    path.parent.mkdir(parents=True, exist_ok=True)
+    with open(path, "w") as fp:
+        json.dump(schema, fp, indent=2, sort_keys=True)
+
+
+__all__ = [
+    "DEFAULT_LEAK_POLICY",
+    "LeakPolicy",
+    "LeakCheckResult",
+    "evaluate_leak_prone_columns",
+    "enforce_leak_guard",
+    "build_schema_snapshot",
+    "write_schema_snapshot",
+]
diff --git a/utils/general/constants.py b/utils/general/constants.py
index d94b4260ad877484da843fa99ae2caf37e8493f4..dea87caa354d94e4a08b1762d2bd8dcd4c8caa3a
--- a/utils/general/constants.py
+++ b/utils/general/constants.py
@@ -211,7 +211,17 @@
 
 NFL_TARGET_COLUMNS: Tuple[str, ...] = (
     'anytime_td',
+    'anytime_td_offense',
+    'anytime_td_all',
+    'anytime_td_rush',
+    'anytime_td_rec',
+    'anytime_td_pass_thrown',
     'td_count',
+    'td_count_offense',
+    'td_count_all',
+    'passing_td',
+    'rushing_td_count',
+    'receiving_td_count',
     'receiving_yards',
     'rushing_yards',
     'passing_yards',


thinking
**Locating method insertion point**
exec
/bin/zsh -lc "cd /Users/jameswest/Desktop/nfl_predict && sed -n '420,520p' pipeline/train.py" in /Users/jameswest/Desktop/nfl_predict succeeded in 696ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
                prefix: {
                    "weight": float(
                        sum(abs(w) for feat, w in importance_dict.items() if feat.startswith(prefix))
                    ),
                }
                for prefix in prefix_targets
            }
            for prefix, payload in prefix_summary.items():
                payload["share"] = float(payload["weight"] / total_weight)

            data = {
                "timestamp": datetime.utcnow().isoformat(),
                "problem": problem_name,
                "model": model_name,
                "top_features": [
                    {"feature": feat, "importance": float(weight)}
                    for feat, weight in top_items
                ],
                "prefix_summary": prefix_summary,
file update:
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 5ba68e8bf1acd3a789a76a8857674e6f6433017b..0210d5b7e7ed60a8de7a126d64f5ed76326474c8
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -14,7 +14,7 @@
 
 import logging
 import os
-from datetime import date, timedelta
+from datetime import date, datetime, timedelta
 from typing import Sequence
 
 import polars as pl
@@ -37,6 +37,12 @@
     add_offense_context_features_training,
     _append_offense_context_columns,
 )
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    build_schema_snapshot,
+    enforce_leak_guard,
+    write_schema_snapshot,
+)
 from utils.feature.weather_features import (
     add_weather_forecast_features_training,
     append_weather_context_flags,
@@ -931,6 +937,32 @@
     if market_exprs:
         df_player_game_all = df_player_game_all.with_columns(market_exprs)
     
+    # Leak guard + schema snapshot before persisting
+    spec = get_label_spec(label_version)
+    allow_exact = {spec.primary, *spec.labels.keys(), *spec.aliases.keys()}
+    df_player_game_all, leak_result = enforce_leak_guard(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_exact=allow_exact,
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=True,
+    )
+
+    schema = build_schema_snapshot(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        metadata={
+            "cutoff_label": cutoff_label,
+            "label_version": spec.name,
+        },
+        banned=leak_result.banned,
+    )
+    schema_dir = FEATURE_AUDIT_DIR / "schema" / "anytime_td"
+    schema_path = schema_dir / f"{cutoff_label}_{datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')}.json"
+    write_schema_snapshot(schema_path, schema)
+    logging.info("    Schema snapshot written → %s", schema_path)
+
     # Write final feature matrix
     df_player_game_all = df_player_game_all.with_columns(
         pl.lit(current_cutoff_hours).cast(pl.Float32).alias("decision_horizon_hours")
@@ -951,7 +983,6 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    spec = get_label_spec(label_version)
     label_candidates = {spec.primary, "anytime_td"}
     for label_col in label_candidates:
         if label_col in df_player_game_all.columns:
diff --git a/pipeline/train.py b/pipeline/train.py
index fe70207dcdf25d209ee3ad55080b7ce826347c44..3fab3a05b3f65e8d0e88ec1ddaa71a8857646148
--- a/pipeline/train.py
+++ b/pipeline/train.py
@@ -98,6 +98,7 @@
     fit_team_conformal_sums,
     composite_sum_interval,
 )
+from utils.feature.leak_guard import DEFAULT_LEAK_POLICY, enforce_leak_guard
 from utils.feature.targets import require_target_column
 
 # Ignore specific, noisy warnings from dependencies
@@ -2315,7 +2316,30 @@
                             df_problem[col] = df_problem[col].fillna(df_problem[col].mean())
 
                 df_problem = self._inject_composed_features(df_problem)
-            
+
+            # Leak guard on the problem-scoped frame
+            allow_prefixes = tuple(problem_copy.get('feature_prefixes_to_include') or [])
+            allow_exact = set(problem_copy.get('other_features_to_include') or [])
+            allow_exact.update(input_preds or [])
+            if self.target_col:
+                allow_exact.add(self.target_col)
+            df_problem, leak_info = enforce_leak_guard(
+                df_problem,
+                policy=DEFAULT_LEAK_POLICY,
+                allow_prefixes=allow_prefixes,
+                allow_exact=allow_exact,
+                drop_banned=True,
+                drop_non_allowlisted=False,
+                raise_on_banned=True,
+            )
+            if leak_info.dropped:
+                logger.info(
+                    "Dropped %d leak-prone columns for %s: %s",
+                    len(leak_info.dropped),
+                    problem_name,
+                    sorted(leak_info.dropped),
+                )
+
             self._normalize_datetime_like_columns(df_problem, problem_name)
             df_problem[self.time_col] = pd.to_datetime(df_problem[self.time_col])
             sort_cols = [self.time_col]
diff --git a/tests/test_data_leak_guard.py b/tests/test_data_leak_guard.py
index 8061f2760c0898aaeda29026859e1b9ff5644ba4..3e56665921db89ea523bbdb205d1bb90c21893df
--- a/tests/test_data_leak_guard.py
+++ b/tests/test_data_leak_guard.py
@@ -3,6 +3,14 @@
 import yaml
 from pathlib import Path
 
+import polars as pl
+
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    enforce_leak_guard,
+    evaluate_leak_prone_columns,
+)
+
 
 PROJECT_ROOT = Path(__file__).resolve().parents[1]
 TRAINING_CONFIG = PROJECT_ROOT / "config" / "training.yaml"
@@ -48,3 +56,41 @@
     )
 
 
+def test_leak_guard_flags_pattern_columns():
+    cols = [
+        "market_anytime_td_prob",
+        "final_score",
+        "postgame_anytime_td",
+        "actual_td_count",
+        "safe_feature",
+    ]
+    result = evaluate_leak_prone_columns(cols, policy=DEFAULT_LEAK_POLICY)
+    assert set(result.banned.keys()) == {"final_score", "postgame_anytime_td", "actual_td_count"}
+    assert "safe_feature" in result.kept
+    assert "market_anytime_td_prob" in result.kept
+
+
+def test_enforce_leak_guard_drops_banned_and_keeps_allowlisted():
+    df = pl.DataFrame(
+        {
+            "game_id": ["g1", "g2"],
+            "safe_feature": [1.0, 2.0],
+            "postgame_anytime_td": [1, 0],
+            "final_score": [30, 24],
+        }
+    )
+    cleaned, info = enforce_leak_guard(
+        df,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_prefixes=("safe_",),
+        allow_exact=("game_id",),
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=False,
+    )
+    assert "postgame_anytime_td" not in cleaned.columns
+    assert "final_score" not in cleaned.columns
+    assert "safe_feature" in cleaned.columns
+    assert "game_id" in cleaned.columns
+    assert set(info.dropped) == {"postgame_anytime_td", "final_score"}
+
diff --git a/utils/feature/leak_guard.py b/utils/feature/leak_guard.py
new file mode 100644
index 0000000000000000000000000000000000000000..9faf8cfffc436e0934b2f410aaf252e52f4f95df
--- /dev/null
+++ b/utils/feature/leak_guard.py
@@ -0,0 +1,273 @@
+"""Leak guardrails for feature matrices.
+
+This module centralizes pattern-based leak detection so both feature assembly
+and training can fail fast when post-outcome columns sneak into the data.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+from datetime import datetime
+import json
+import re
+from typing import Iterable, Mapping, Sequence
+
+import polars as pl
+
+from utils.general.constants import IDENTIFIER_COLUMNS, LEAK_PRONE_COLUMNS, NFL_TARGET_COLUMNS
+
+try:  # Optional dependency when imported from training (pandas path)
+    import pandas as pd  # type: ignore
+except Exception:  # pragma: no cover - optional dependency
+    pd = None
+
+
+@dataclass(frozen=True)
+class LeakPolicy:
+    version: str
+    banned_exact: set[str]
+    banned_prefixes: tuple[str, ...]
+    banned_suffixes: tuple[str, ...]
+    banned_regex: tuple[tuple[re.Pattern[str], str], ...]
+    description: str = ""
+
+
+@dataclass
+class LeakCheckResult:
+    policy_version: str
+    banned: dict[str, str]
+    kept: list[str]
+    dropped: list[str]
+    allowlist_kept: list[str]
+
+
+# Core policy tuned for anytime-TD style problems (can be extended per-problem).
+_BASE_BANNED_EXACT = set(LEAK_PRONE_COLUMNS) | {
+    "final_score",
+    "final_total",
+    "points_scored",
+    "actual_td_count",
+    "actual_anytime_td",
+    "postgame_anytime_td",
+    "postgame_td_count",
+}
+_BASE_BANNED_PREFIXES = (
+    "postgame_",
+    "post_game_",
+    "post_",
+    "live_",
+    "actual_",
+    "realized_",
+    "final_",
+    "postmatch_",
+)
+_BASE_BANNED_SUFFIXES = (
+    "_post",
+    "_postgame",
+    "_final",
+    "_fullgame",
+    "_actual",
+)
+_BASE_BANNED_REGEX: tuple[tuple[re.Pattern[str], str], ...] = (
+    (re.compile(r".*post.?game.*", flags=re.IGNORECASE), "postgame marker"),
+    (re.compile(r".*final_score.*", flags=re.IGNORECASE), "final score"),
+    (re.compile(r".*actual.*td.*", flags=re.IGNORECASE), "actual TD total"),
+    (re.compile(r".*anytime_td.*(post|final|actual).*", flags=re.IGNORECASE), "post-decision anytime TD"),
+    (re.compile(r".*fullgame.*", flags=re.IGNORECASE), "full game cumulative value"),
+)
+
+DEFAULT_LEAK_POLICY = LeakPolicy(
+    version="v1",
+    description="Core post-outcome leak guard for NFL anytime TD features.",
+    banned_exact=_BASE_BANNED_EXACT,
+    banned_prefixes=_BASE_BANNED_PREFIXES,
+    banned_suffixes=_BASE_BANNED_SUFFIXES,
+    banned_regex=_BASE_BANNED_REGEX,
+)
+
+
+def _ensure_sequence(value: Sequence[str] | str | None) -> tuple[str, ...]:
+    if value is None:
+        return ()
+    if isinstance(value, str):
+        return (value,)
+    return tuple(value)
+
+
+def evaluate_leak_prone_columns(
+    columns: Iterable[str],
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+) -> LeakCheckResult:
+    """Identify leak-prone columns using the configured policy."""
+
+    banned: dict[str, str] = {}
+    columns_list = list(columns)
+    for col in columns_list:
+        if col in policy.banned_exact:
+            banned[col] = "exact"
+            continue
+        for prefix in policy.banned_prefixes:
+            if col.startswith(prefix):
+                banned[col] = f"prefix:{prefix}"
+                break
+        if col in banned:
+            continue
+        for suffix in policy.banned_suffixes:
+            if col.endswith(suffix):
+                banned[col] = f"suffix:{suffix}"
+                break
+        if col in banned:
+            continue
+        for pattern, reason in policy.banned_regex:
+            if pattern.match(col):
+                banned[col] = reason
+                break
+
+    kept = [c for c in columns_list if c not in banned]
+    return LeakCheckResult(
+        policy_version=policy.version,
+        banned=banned,
+        kept=kept,
+        dropped=[],
+        allowlist_kept=[],
+    )
+
+
+def enforce_leak_guard(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    allow_prefixes: Sequence[str] | str | None = None,
+    allow_exact: Sequence[str] | str | None = None,
+    drop_banned: bool = True,
+    drop_non_allowlisted: bool = False,
+    raise_on_banned: bool = True,
+) -> tuple[pl.DataFrame | "pd.DataFrame", LeakCheckResult]:
+    """Apply leak guardrails to a feature frame.
+
+    Parameters
+    ----------
+    df : DataFrame
+        Polars or pandas DataFrame.
+    policy : LeakPolicy
+        Leak policy to apply.
+    allow_prefixes : Sequence[str] | str | None
+        Optional prefixes that define the allowed feature surface for a problem.
+    allow_exact : Sequence[str] | str | None
+        Explicitly allowed columns (e.g., identifiers).
+    drop_banned : bool
+        If True, drop any banned columns automatically.
+    drop_non_allowlisted : bool
+        If True, drop columns that are not covered by allow_prefixes/allow_exact/identifiers/targets.
+    raise_on_banned : bool
+        If True, raise when banned columns are detected (after optional drop).
+    """
+
+    result = evaluate_leak_prone_columns(df.columns, policy=policy)
+    dropped: list[str] = []
+
+    allow_prefixes = _ensure_sequence(allow_prefixes)
+    allow_exact = set(_ensure_sequence(allow_exact))
+    allow_exact.update({col for col in IDENTIFIER_COLUMNS if col in df.columns})
+    allow_exact.update({col for col in NFL_TARGET_COLUMNS if col in df.columns})
+
+    # Permit allowlisted columns even if they match a banned rule (e.g., labels)
+    banned = {col: reason for col, reason in result.banned.items() if col not in allow_exact}
+
+    if banned and drop_banned:
+        df = df.drop(list(banned.keys()))
+        dropped.extend(banned.keys())
+
+    if banned and raise_on_banned:
+        raise ValueError(f"Leak-prone columns detected: {sorted(banned.items())}")
+
+    allowlist_cols: set[str] = set()
+    if allow_prefixes:
+        allowlist_cols.update({c for c in df.columns if c.startswith(allow_prefixes)})
+    allowlist_cols.update({c for c in allow_exact if c in df.columns})
+
+    if drop_non_allowlisted and allowlist_cols:
+        drop_candidates = [c for c in df.columns if c not in allowlist_cols]
+        if drop_candidates:
+            df = df.drop(drop_candidates)
+            dropped.extend(drop_candidates)
+
+    if drop_non_allowlisted and not allowlist_cols:
+        raise ValueError("No allowlisted columns remain after applying leak guard allowlist.")
+
+    # Store adjusted banned info on the result
+    result.banned = banned
+    result.dropped = dropped
+    result.kept = [c for c in df.columns]
+    result.allowlist_kept = sorted(list(allowlist_cols)) if allowlist_cols else []
+    return df, result
+
+
+def build_schema_snapshot(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    metadata: Mapping[str, object] | None = None,
+    banned: Mapping[str, str] | None = None,
+) -> dict:
+    """Render a schema snapshot describing each column and whether it was flagged."""
+
+    banned = banned or {}
+    meta = {
+        "generated_at_utc": datetime.utcnow().isoformat(),
+        "policy_version": policy.version,
+    }
+    meta.update(metadata or {})
+
+    # Extract columns / dtypes
+    if isinstance(df, pl.DataFrame):
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+    else:  # pandas or pandas-like
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+
+    schema = {
+        "metadata": meta,
+        "columns": [],
+    }
+
+    for col, dtype in cols_and_dtypes:
+        tags: list[str] = []
+        if col in IDENTIFIER_COLUMNS:
+            tags.append("id")
+        if col in NFL_TARGET_COLUMNS:
+            tags.append("label")
+        if col.startswith("market_"):
+            tags.append("odds")
+        if col.startswith("injury_") or col.startswith("practice_"):
+            tags.append("injury")
+        if col.startswith("weather_"):
+            tags.append("weather")
+        if col.startswith("ps_"):
+            tags.append("pre_snap")
+        schema["columns"].append(
+            {
+                "name": col,
+                "dtype": dtype,
+                "banned": col in banned,
+                "tags": tags,
+            }
+        )
+    return schema
+
+
+def write_schema_snapshot(path, schema: Mapping[str, object]) -> None:
+    path.parent.mkdir(parents=True, exist_ok=True)
+    with open(path, "w") as fp:
+        json.dump(schema, fp, indent=2, sort_keys=True)
+
+
+__all__ = [
+    "DEFAULT_LEAK_POLICY",
+    "LeakPolicy",
+    "LeakCheckResult",
+    "evaluate_leak_prone_columns",
+    "enforce_leak_guard",
+    "build_schema_snapshot",
+    "write_schema_snapshot",
+]
diff --git a/utils/general/constants.py b/utils/general/constants.py
index d94b4260ad877484da843fa99ae2caf37e8493f4..dea87caa354d94e4a08b1762d2bd8dcd4c8caa3a
--- a/utils/general/constants.py
+++ b/utils/general/constants.py
@@ -211,7 +211,17 @@
 
 NFL_TARGET_COLUMNS: Tuple[str, ...] = (
     'anytime_td',
+    'anytime_td_offense',
+    'anytime_td_all',
+    'anytime_td_rush',
+    'anytime_td_rec',
+    'anytime_td_pass_thrown',
     'td_count',
+    'td_count_offense',
+    'td_count_all',
+    'passing_td',
+    'rushing_td_count',
+    'receiving_td_count',
     'receiving_yards',
     'rushing_yards',
     'passing_yards',


thinking
**Adding method and import for filtering odds**
file update
M /Users/jameswest/Desktop/nfl_predict/pipeline/train.py
@@ -6,2 +6,3 @@
 import math
+import re
 
apply_patch(auto_approved=true) exited 0 in 73ms:
Success. Updated the following files:
M pipeline/train.py
file update:
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 5ba68e8bf1acd3a789a76a8857674e6f6433017b..0210d5b7e7ed60a8de7a126d64f5ed76326474c8
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -14,7 +14,7 @@
 
 import logging
 import os
-from datetime import date, timedelta
+from datetime import date, datetime, timedelta
 from typing import Sequence
 
 import polars as pl
@@ -37,6 +37,12 @@
     add_offense_context_features_training,
     _append_offense_context_columns,
 )
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    build_schema_snapshot,
+    enforce_leak_guard,
+    write_schema_snapshot,
+)
 from utils.feature.weather_features import (
     add_weather_forecast_features_training,
     append_weather_context_flags,
@@ -931,6 +937,32 @@
     if market_exprs:
         df_player_game_all = df_player_game_all.with_columns(market_exprs)
     
+    # Leak guard + schema snapshot before persisting
+    spec = get_label_spec(label_version)
+    allow_exact = {spec.primary, *spec.labels.keys(), *spec.aliases.keys()}
+    df_player_game_all, leak_result = enforce_leak_guard(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_exact=allow_exact,
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=True,
+    )
+
+    schema = build_schema_snapshot(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        metadata={
+            "cutoff_label": cutoff_label,
+            "label_version": spec.name,
+        },
+        banned=leak_result.banned,
+    )
+    schema_dir = FEATURE_AUDIT_DIR / "schema" / "anytime_td"
+    schema_path = schema_dir / f"{cutoff_label}_{datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')}.json"
+    write_schema_snapshot(schema_path, schema)
+    logging.info("    Schema snapshot written → %s", schema_path)
+
     # Write final feature matrix
     df_player_game_all = df_player_game_all.with_columns(
         pl.lit(current_cutoff_hours).cast(pl.Float32).alias("decision_horizon_hours")
@@ -951,7 +983,6 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    spec = get_label_spec(label_version)
     label_candidates = {spec.primary, "anytime_td"}
     for label_col in label_candidates:
         if label_col in df_player_game_all.columns:
diff --git a/pipeline/train.py b/pipeline/train.py
index fe70207dcdf25d209ee3ad55080b7ce826347c44..d441717695a21ed0a286a5721d248a60c73c68e4
--- a/pipeline/train.py
+++ b/pipeline/train.py
@@ -4,6 +4,7 @@
 import sys
 import logging
 import math
+import re
 
 
 # Move logging to top and remove global thread pinning
@@ -98,6 +99,7 @@
     fit_team_conformal_sums,
     composite_sum_interval,
 )
+from utils.feature.leak_guard import DEFAULT_LEAK_POLICY, enforce_leak_guard
 from utils.feature.targets import require_target_column
 
 # Ignore specific, noisy warnings from dependencies
@@ -2315,7 +2317,30 @@
                             df_problem[col] = df_problem[col].fillna(df_problem[col].mean())
 
                 df_problem = self._inject_composed_features(df_problem)
-            
+
+            # Leak guard on the problem-scoped frame
+            allow_prefixes = tuple(problem_copy.get('feature_prefixes_to_include') or [])
+            allow_exact = set(problem_copy.get('other_features_to_include') or [])
+            allow_exact.update(input_preds or [])
+            if self.target_col:
+                allow_exact.add(self.target_col)
+            df_problem, leak_info = enforce_leak_guard(
+                df_problem,
+                policy=DEFAULT_LEAK_POLICY,
+                allow_prefixes=allow_prefixes,
+                allow_exact=allow_exact,
+                drop_banned=True,
+                drop_non_allowlisted=False,
+                raise_on_banned=True,
+            )
+            if leak_info.dropped:
+                logger.info(
+                    "Dropped %d leak-prone columns for %s: %s",
+                    len(leak_info.dropped),
+                    problem_name,
+                    sorted(leak_info.dropped),
+                )
+
             self._normalize_datetime_like_columns(df_problem, problem_name)
             df_problem[self.time_col] = pd.to_datetime(df_problem[self.time_col])
             sort_cols = [self.time_col]
diff --git a/tests/test_data_leak_guard.py b/tests/test_data_leak_guard.py
index 8061f2760c0898aaeda29026859e1b9ff5644ba4..3e56665921db89ea523bbdb205d1bb90c21893df
--- a/tests/test_data_leak_guard.py
+++ b/tests/test_data_leak_guard.py
@@ -3,6 +3,14 @@
 import yaml
 from pathlib import Path
 
+import polars as pl
+
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    enforce_leak_guard,
+    evaluate_leak_prone_columns,
+)
+
 
 PROJECT_ROOT = Path(__file__).resolve().parents[1]
 TRAINING_CONFIG = PROJECT_ROOT / "config" / "training.yaml"
@@ -48,3 +56,41 @@
     )
 
 
+def test_leak_guard_flags_pattern_columns():
+    cols = [
+        "market_anytime_td_prob",
+        "final_score",
+        "postgame_anytime_td",
+        "actual_td_count",
+        "safe_feature",
+    ]
+    result = evaluate_leak_prone_columns(cols, policy=DEFAULT_LEAK_POLICY)
+    assert set(result.banned.keys()) == {"final_score", "postgame_anytime_td", "actual_td_count"}
+    assert "safe_feature" in result.kept
+    assert "market_anytime_td_prob" in result.kept
+
+
+def test_enforce_leak_guard_drops_banned_and_keeps_allowlisted():
+    df = pl.DataFrame(
+        {
+            "game_id": ["g1", "g2"],
+            "safe_feature": [1.0, 2.0],
+            "postgame_anytime_td": [1, 0],
+            "final_score": [30, 24],
+        }
+    )
+    cleaned, info = enforce_leak_guard(
+        df,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_prefixes=("safe_",),
+        allow_exact=("game_id",),
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=False,
+    )
+    assert "postgame_anytime_td" not in cleaned.columns
+    assert "final_score" not in cleaned.columns
+    assert "safe_feature" in cleaned.columns
+    assert "game_id" in cleaned.columns
+    assert set(info.dropped) == {"postgame_anytime_td", "final_score"}
+
diff --git a/utils/feature/leak_guard.py b/utils/feature/leak_guard.py
new file mode 100644
index 0000000000000000000000000000000000000000..9faf8cfffc436e0934b2f410aaf252e52f4f95df
--- /dev/null
+++ b/utils/feature/leak_guard.py
@@ -0,0 +1,273 @@
+"""Leak guardrails for feature matrices.
+
+This module centralizes pattern-based leak detection so both feature assembly
+and training can fail fast when post-outcome columns sneak into the data.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+from datetime import datetime
+import json
+import re
+from typing import Iterable, Mapping, Sequence
+
+import polars as pl
+
+from utils.general.constants import IDENTIFIER_COLUMNS, LEAK_PRONE_COLUMNS, NFL_TARGET_COLUMNS
+
+try:  # Optional dependency when imported from training (pandas path)
+    import pandas as pd  # type: ignore
+except Exception:  # pragma: no cover - optional dependency
+    pd = None
+
+
+@dataclass(frozen=True)
+class LeakPolicy:
+    version: str
+    banned_exact: set[str]
+    banned_prefixes: tuple[str, ...]
+    banned_suffixes: tuple[str, ...]
+    banned_regex: tuple[tuple[re.Pattern[str], str], ...]
+    description: str = ""
+
+
+@dataclass
+class LeakCheckResult:
+    policy_version: str
+    banned: dict[str, str]
+    kept: list[str]
+    dropped: list[str]
+    allowlist_kept: list[str]
+
+
+# Core policy tuned for anytime-TD style problems (can be extended per-problem).
+_BASE_BANNED_EXACT = set(LEAK_PRONE_COLUMNS) | {
+    "final_score",
+    "final_total",
+    "points_scored",
+    "actual_td_count",
+    "actual_anytime_td",
+    "postgame_anytime_td",
+    "postgame_td_count",
+}
+_BASE_BANNED_PREFIXES = (
+    "postgame_",
+    "post_game_",
+    "post_",
+    "live_",
+    "actual_",
+    "realized_",
+    "final_",
+    "postmatch_",
+)
+_BASE_BANNED_SUFFIXES = (
+    "_post",
+    "_postgame",
+    "_final",
+    "_fullgame",
+    "_actual",
+)
+_BASE_BANNED_REGEX: tuple[tuple[re.Pattern[str], str], ...] = (
+    (re.compile(r".*post.?game.*", flags=re.IGNORECASE), "postgame marker"),
+    (re.compile(r".*final_score.*", flags=re.IGNORECASE), "final score"),
+    (re.compile(r".*actual.*td.*", flags=re.IGNORECASE), "actual TD total"),
+    (re.compile(r".*anytime_td.*(post|final|actual).*", flags=re.IGNORECASE), "post-decision anytime TD"),
+    (re.compile(r".*fullgame.*", flags=re.IGNORECASE), "full game cumulative value"),
+)
+
+DEFAULT_LEAK_POLICY = LeakPolicy(
+    version="v1",
+    description="Core post-outcome leak guard for NFL anytime TD features.",
+    banned_exact=_BASE_BANNED_EXACT,
+    banned_prefixes=_BASE_BANNED_PREFIXES,
+    banned_suffixes=_BASE_BANNED_SUFFIXES,
+    banned_regex=_BASE_BANNED_REGEX,
+)
+
+
+def _ensure_sequence(value: Sequence[str] | str | None) -> tuple[str, ...]:
+    if value is None:
+        return ()
+    if isinstance(value, str):
+        return (value,)
+    return tuple(value)
+
+
+def evaluate_leak_prone_columns(
+    columns: Iterable[str],
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+) -> LeakCheckResult:
+    """Identify leak-prone columns using the configured policy."""
+
+    banned: dict[str, str] = {}
+    columns_list = list(columns)
+    for col in columns_list:
+        if col in policy.banned_exact:
+            banned[col] = "exact"
+            continue
+        for prefix in policy.banned_prefixes:
+            if col.startswith(prefix):
+                banned[col] = f"prefix:{prefix}"
+                break
+        if col in banned:
+            continue
+        for suffix in policy.banned_suffixes:
+            if col.endswith(suffix):
+                banned[col] = f"suffix:{suffix}"
+                break
+        if col in banned:
+            continue
+        for pattern, reason in policy.banned_regex:
+            if pattern.match(col):
+                banned[col] = reason
+                break
+
+    kept = [c for c in columns_list if c not in banned]
+    return LeakCheckResult(
+        policy_version=policy.version,
+        banned=banned,
+        kept=kept,
+        dropped=[],
+        allowlist_kept=[],
+    )
+
+
+def enforce_leak_guard(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    allow_prefixes: Sequence[str] | str | None = None,
+    allow_exact: Sequence[str] | str | None = None,
+    drop_banned: bool = True,
+    drop_non_allowlisted: bool = False,
+    raise_on_banned: bool = True,
+) -> tuple[pl.DataFrame | "pd.DataFrame", LeakCheckResult]:
+    """Apply leak guardrails to a feature frame.
+
+    Parameters
+    ----------
+    df : DataFrame
+        Polars or pandas DataFrame.
+    policy : LeakPolicy
+        Leak policy to apply.
+    allow_prefixes : Sequence[str] | str | None
+        Optional prefixes that define the allowed feature surface for a problem.
+    allow_exact : Sequence[str] | str | None
+        Explicitly allowed columns (e.g., identifiers).
+    drop_banned : bool
+        If True, drop any banned columns automatically.
+    drop_non_allowlisted : bool
+        If True, drop columns that are not covered by allow_prefixes/allow_exact/identifiers/targets.
+    raise_on_banned : bool
+        If True, raise when banned columns are detected (after optional drop).
+    """
+
+    result = evaluate_leak_prone_columns(df.columns, policy=policy)
+    dropped: list[str] = []
+
+    allow_prefixes = _ensure_sequence(allow_prefixes)
+    allow_exact = set(_ensure_sequence(allow_exact))
+    allow_exact.update({col for col in IDENTIFIER_COLUMNS if col in df.columns})
+    allow_exact.update({col for col in NFL_TARGET_COLUMNS if col in df.columns})
+
+    # Permit allowlisted columns even if they match a banned rule (e.g., labels)
+    banned = {col: reason for col, reason in result.banned.items() if col not in allow_exact}
+
+    if banned and drop_banned:
+        df = df.drop(list(banned.keys()))
+        dropped.extend(banned.keys())
+
+    if banned and raise_on_banned:
+        raise ValueError(f"Leak-prone columns detected: {sorted(banned.items())}")
+
+    allowlist_cols: set[str] = set()
+    if allow_prefixes:
+        allowlist_cols.update({c for c in df.columns if c.startswith(allow_prefixes)})
+    allowlist_cols.update({c for c in allow_exact if c in df.columns})
+
+    if drop_non_allowlisted and allowlist_cols:
+        drop_candidates = [c for c in df.columns if c not in allowlist_cols]
+        if drop_candidates:
+            df = df.drop(drop_candidates)
+            dropped.extend(drop_candidates)
+
+    if drop_non_allowlisted and not allowlist_cols:
+        raise ValueError("No allowlisted columns remain after applying leak guard allowlist.")
+
+    # Store adjusted banned info on the result
+    result.banned = banned
+    result.dropped = dropped
+    result.kept = [c for c in df.columns]
+    result.allowlist_kept = sorted(list(allowlist_cols)) if allowlist_cols else []
+    return df, result
+
+
+def build_schema_snapshot(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    metadata: Mapping[str, object] | None = None,
+    banned: Mapping[str, str] | None = None,
+) -> dict:
+    """Render a schema snapshot describing each column and whether it was flagged."""
+
+    banned = banned or {}
+    meta = {
+        "generated_at_utc": datetime.utcnow().isoformat(),
+        "policy_version": policy.version,
+    }
+    meta.update(metadata or {})
+
+    # Extract columns / dtypes
+    if isinstance(df, pl.DataFrame):
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+    else:  # pandas or pandas-like
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+
+    schema = {
+        "metadata": meta,
+        "columns": [],
+    }
+
+    for col, dtype in cols_and_dtypes:
+        tags: list[str] = []
+        if col in IDENTIFIER_COLUMNS:
+            tags.append("id")
+        if col in NFL_TARGET_COLUMNS:
+            tags.append("label")
+        if col.startswith("market_"):
+            tags.append("odds")
+        if col.startswith("injury_") or col.startswith("practice_"):
+            tags.append("injury")
+        if col.startswith("weather_"):
+            tags.append("weather")
+        if col.startswith("ps_"):
+            tags.append("pre_snap")
+        schema["columns"].append(
+            {
+                "name": col,
+                "dtype": dtype,
+                "banned": col in banned,
+                "tags": tags,
+            }
+        )
+    return schema
+
+
+def write_schema_snapshot(path, schema: Mapping[str, object]) -> None:
+    path.parent.mkdir(parents=True, exist_ok=True)
+    with open(path, "w") as fp:
+        json.dump(schema, fp, indent=2, sort_keys=True)
+
+
+__all__ = [
+    "DEFAULT_LEAK_POLICY",
+    "LeakPolicy",
+    "LeakCheckResult",
+    "evaluate_leak_prone_columns",
+    "enforce_leak_guard",
+    "build_schema_snapshot",
+    "write_schema_snapshot",
+]
diff --git a/utils/general/constants.py b/utils/general/constants.py
index d94b4260ad877484da843fa99ae2caf37e8493f4..dea87caa354d94e4a08b1762d2bd8dcd4c8caa3a
--- a/utils/general/constants.py
+++ b/utils/general/constants.py
@@ -211,7 +211,17 @@
 
 NFL_TARGET_COLUMNS: Tuple[str, ...] = (
     'anytime_td',
+    'anytime_td_offense',
+    'anytime_td_all',
+    'anytime_td_rush',
+    'anytime_td_rec',
+    'anytime_td_pass_thrown',
     'td_count',
+    'td_count_offense',
+    'td_count_all',
+    'passing_td',
+    'rushing_td_count',
+    'receiving_td_count',
     'receiving_yards',
     'rushing_yards',
     'passing_yards',

file update:
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 5ba68e8bf1acd3a789a76a8857674e6f6433017b..0210d5b7e7ed60a8de7a126d64f5ed76326474c8
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -14,7 +14,7 @@
 
 import logging
 import os
-from datetime import date, timedelta
+from datetime import date, datetime, timedelta
 from typing import Sequence
 
 import polars as pl
@@ -37,6 +37,12 @@
     add_offense_context_features_training,
     _append_offense_context_columns,
 )
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    build_schema_snapshot,
+    enforce_leak_guard,
+    write_schema_snapshot,
+)
 from utils.feature.weather_features import (
     add_weather_forecast_features_training,
     append_weather_context_flags,
@@ -931,6 +937,32 @@
     if market_exprs:
         df_player_game_all = df_player_game_all.with_columns(market_exprs)
     
+    # Leak guard + schema snapshot before persisting
+    spec = get_label_spec(label_version)
+    allow_exact = {spec.primary, *spec.labels.keys(), *spec.aliases.keys()}
+    df_player_game_all, leak_result = enforce_leak_guard(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_exact=allow_exact,
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=True,
+    )
+
+    schema = build_schema_snapshot(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        metadata={
+            "cutoff_label": cutoff_label,
+            "label_version": spec.name,
+        },
+        banned=leak_result.banned,
+    )
+    schema_dir = FEATURE_AUDIT_DIR / "schema" / "anytime_td"
+    schema_path = schema_dir / f"{cutoff_label}_{datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')}.json"
+    write_schema_snapshot(schema_path, schema)
+    logging.info("    Schema snapshot written → %s", schema_path)
+
     # Write final feature matrix
     df_player_game_all = df_player_game_all.with_columns(
         pl.lit(current_cutoff_hours).cast(pl.Float32).alias("decision_horizon_hours")
@@ -951,7 +983,6 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    spec = get_label_spec(label_version)
     label_candidates = {spec.primary, "anytime_td"}
     for label_col in label_candidates:
         if label_col in df_player_game_all.columns:
diff --git a/pipeline/train.py b/pipeline/train.py
index fe70207dcdf25d209ee3ad55080b7ce826347c44..d441717695a21ed0a286a5721d248a60c73c68e4
--- a/pipeline/train.py
+++ b/pipeline/train.py
@@ -4,6 +4,7 @@
 import sys
 import logging
 import math
+import re
 
 
 # Move logging to top and remove global thread pinning
@@ -98,6 +99,7 @@
     fit_team_conformal_sums,
     composite_sum_interval,
 )
+from utils.feature.leak_guard import DEFAULT_LEAK_POLICY, enforce_leak_guard
 from utils.feature.targets import require_target_column
 
 # Ignore specific, noisy warnings from dependencies
@@ -2315,7 +2317,30 @@
                             df_problem[col] = df_problem[col].fillna(df_problem[col].mean())
 
                 df_problem = self._inject_composed_features(df_problem)
-            
+
+            # Leak guard on the problem-scoped frame
+            allow_prefixes = tuple(problem_copy.get('feature_prefixes_to_include') or [])
+            allow_exact = set(problem_copy.get('other_features_to_include') or [])
+            allow_exact.update(input_preds or [])
+            if self.target_col:
+                allow_exact.add(self.target_col)
+            df_problem, leak_info = enforce_leak_guard(
+                df_problem,
+                policy=DEFAULT_LEAK_POLICY,
+                allow_prefixes=allow_prefixes,
+                allow_exact=allow_exact,
+                drop_banned=True,
+                drop_non_allowlisted=False,
+                raise_on_banned=True,
+            )
+            if leak_info.dropped:
+                logger.info(
+                    "Dropped %d leak-prone columns for %s: %s",
+                    len(leak_info.dropped),
+                    problem_name,
+                    sorted(leak_info.dropped),
+                )
+
             self._normalize_datetime_like_columns(df_problem, problem_name)
             df_problem[self.time_col] = pd.to_datetime(df_problem[self.time_col])
             sort_cols = [self.time_col]
diff --git a/tests/test_data_leak_guard.py b/tests/test_data_leak_guard.py
index 8061f2760c0898aaeda29026859e1b9ff5644ba4..3e56665921db89ea523bbdb205d1bb90c21893df
--- a/tests/test_data_leak_guard.py
+++ b/tests/test_data_leak_guard.py
@@ -3,6 +3,14 @@
 import yaml
 from pathlib import Path
 
+import polars as pl
+
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    enforce_leak_guard,
+    evaluate_leak_prone_columns,
+)
+
 
 PROJECT_ROOT = Path(__file__).resolve().parents[1]
 TRAINING_CONFIG = PROJECT_ROOT / "config" / "training.yaml"
@@ -48,3 +56,41 @@
     )
 
 
+def test_leak_guard_flags_pattern_columns():
+    cols = [
+        "market_anytime_td_prob",
+        "final_score",
+        "postgame_anytime_td",
+        "actual_td_count",
+        "safe_feature",
+    ]
+    result = evaluate_leak_prone_columns(cols, policy=DEFAULT_LEAK_POLICY)
+    assert set(result.banned.keys()) == {"final_score", "postgame_anytime_td", "actual_td_count"}
+    assert "safe_feature" in result.kept
+    assert "market_anytime_td_prob" in result.kept
+
+
+def test_enforce_leak_guard_drops_banned_and_keeps_allowlisted():
+    df = pl.DataFrame(
+        {
+            "game_id": ["g1", "g2"],
+            "safe_feature": [1.0, 2.0],
+            "postgame_anytime_td": [1, 0],
+            "final_score": [30, 24],
+        }
+    )
+    cleaned, info = enforce_leak_guard(
+        df,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_prefixes=("safe_",),
+        allow_exact=("game_id",),
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=False,
+    )
+    assert "postgame_anytime_td" not in cleaned.columns
+    assert "final_score" not in cleaned.columns
+    assert "safe_feature" in cleaned.columns
+    assert "game_id" in cleaned.columns
+    assert set(info.dropped) == {"postgame_anytime_td", "final_score"}
+
diff --git a/utils/feature/leak_guard.py b/utils/feature/leak_guard.py
new file mode 100644
index 0000000000000000000000000000000000000000..9faf8cfffc436e0934b2f410aaf252e52f4f95df
--- /dev/null
+++ b/utils/feature/leak_guard.py
@@ -0,0 +1,273 @@
+"""Leak guardrails for feature matrices.
+
+This module centralizes pattern-based leak detection so both feature assembly
+and training can fail fast when post-outcome columns sneak into the data.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+from datetime import datetime
+import json
+import re
+from typing import Iterable, Mapping, Sequence
+
+import polars as pl
+
+from utils.general.constants import IDENTIFIER_COLUMNS, LEAK_PRONE_COLUMNS, NFL_TARGET_COLUMNS
+
+try:  # Optional dependency when imported from training (pandas path)
+    import pandas as pd  # type: ignore
+except Exception:  # pragma: no cover - optional dependency
+    pd = None
+
+
+@dataclass(frozen=True)
+class LeakPolicy:
+    version: str
+    banned_exact: set[str]
+    banned_prefixes: tuple[str, ...]
+    banned_suffixes: tuple[str, ...]
+    banned_regex: tuple[tuple[re.Pattern[str], str], ...]
+    description: str = ""
+
+
+@dataclass
+class LeakCheckResult:
+    policy_version: str
+    banned: dict[str, str]
+    kept: list[str]
+    dropped: list[str]
+    allowlist_kept: list[str]
+
+
+# Core policy tuned for anytime-TD style problems (can be extended per-problem).
+_BASE_BANNED_EXACT = set(LEAK_PRONE_COLUMNS) | {
+    "final_score",
+    "final_total",
+    "points_scored",
+    "actual_td_count",
+    "actual_anytime_td",
+    "postgame_anytime_td",
+    "postgame_td_count",
+}
+_BASE_BANNED_PREFIXES = (
+    "postgame_",
+    "post_game_",
+    "post_",
+    "live_",
+    "actual_",
+    "realized_",
+    "final_",
+    "postmatch_",
+)
+_BASE_BANNED_SUFFIXES = (
+    "_post",
+    "_postgame",
+    "_final",
+    "_fullgame",
+    "_actual",
+)
+_BASE_BANNED_REGEX: tuple[tuple[re.Pattern[str], str], ...] = (
+    (re.compile(r".*post.?game.*", flags=re.IGNORECASE), "postgame marker"),
+    (re.compile(r".*final_score.*", flags=re.IGNORECASE), "final score"),
+    (re.compile(r".*actual.*td.*", flags=re.IGNORECASE), "actual TD total"),
+    (re.compile(r".*anytime_td.*(post|final|actual).*", flags=re.IGNORECASE), "post-decision anytime TD"),
+    (re.compile(r".*fullgame.*", flags=re.IGNORECASE), "full game cumulative value"),
+)
+
+DEFAULT_LEAK_POLICY = LeakPolicy(
+    version="v1",
+    description="Core post-outcome leak guard for NFL anytime TD features.",
+    banned_exact=_BASE_BANNED_EXACT,
+    banned_prefixes=_BASE_BANNED_PREFIXES,
+    banned_suffixes=_BASE_BANNED_SUFFIXES,
+    banned_regex=_BASE_BANNED_REGEX,
+)
+
+
+def _ensure_sequence(value: Sequence[str] | str | None) -> tuple[str, ...]:
+    if value is None:
+        return ()
+    if isinstance(value, str):
+        return (value,)
+    return tuple(value)
+
+
+def evaluate_leak_prone_columns(
+    columns: Iterable[str],
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+) -> LeakCheckResult:
+    """Identify leak-prone columns using the configured policy."""
+
+    banned: dict[str, str] = {}
+    columns_list = list(columns)
+    for col in columns_list:
+        if col in policy.banned_exact:
+            banned[col] = "exact"
+            continue
+        for prefix in policy.banned_prefixes:
+            if col.startswith(prefix):
+                banned[col] = f"prefix:{prefix}"
+                break
+        if col in banned:
+            continue
+        for suffix in policy.banned_suffixes:
+            if col.endswith(suffix):
+                banned[col] = f"suffix:{suffix}"
+                break
+        if col in banned:
+            continue
+        for pattern, reason in policy.banned_regex:
+            if pattern.match(col):
+                banned[col] = reason
+                break
+
+    kept = [c for c in columns_list if c not in banned]
+    return LeakCheckResult(
+        policy_version=policy.version,
+        banned=banned,
+        kept=kept,
+        dropped=[],
+        allowlist_kept=[],
+    )
+
+
+def enforce_leak_guard(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    allow_prefixes: Sequence[str] | str | None = None,
+    allow_exact: Sequence[str] | str | None = None,
+    drop_banned: bool = True,
+    drop_non_allowlisted: bool = False,
+    raise_on_banned: bool = True,
+) -> tuple[pl.DataFrame | "pd.DataFrame", LeakCheckResult]:
+    """Apply leak guardrails to a feature frame.
+
+    Parameters
+    ----------
+    df : DataFrame
+        Polars or pandas DataFrame.
+    policy : LeakPolicy
+        Leak policy to apply.
+    allow_prefixes : Sequence[str] | str | None
+        Optional prefixes that define the allowed feature surface for a problem.
+    allow_exact : Sequence[str] | str | None
+        Explicitly allowed columns (e.g., identifiers).
+    drop_banned : bool
+        If True, drop any banned columns automatically.
+    drop_non_allowlisted : bool
+        If True, drop columns that are not covered by allow_prefixes/allow_exact/identifiers/targets.
+    raise_on_banned : bool
+        If True, raise when banned columns are detected (after optional drop).
+    """
+
+    result = evaluate_leak_prone_columns(df.columns, policy=policy)
+    dropped: list[str] = []
+
+    allow_prefixes = _ensure_sequence(allow_prefixes)
+    allow_exact = set(_ensure_sequence(allow_exact))
+    allow_exact.update({col for col in IDENTIFIER_COLUMNS if col in df.columns})
+    allow_exact.update({col for col in NFL_TARGET_COLUMNS if col in df.columns})
+
+    # Permit allowlisted columns even if they match a banned rule (e.g., labels)
+    banned = {col: reason for col, reason in result.banned.items() if col not in allow_exact}
+
+    if banned and drop_banned:
+        df = df.drop(list(banned.keys()))
+        dropped.extend(banned.keys())
+
+    if banned and raise_on_banned:
+        raise ValueError(f"Leak-prone columns detected: {sorted(banned.items())}")
+
+    allowlist_cols: set[str] = set()
+    if allow_prefixes:
+        allowlist_cols.update({c for c in df.columns if c.startswith(allow_prefixes)})
+    allowlist_cols.update({c for c in allow_exact if c in df.columns})
+
+    if drop_non_allowlisted and allowlist_cols:
+        drop_candidates = [c for c in df.columns if c not in allowlist_cols]
+        if drop_candidates:
+            df = df.drop(drop_candidates)
+            dropped.extend(drop_candidates)
+
+    if drop_non_allowlisted and not allowlist_cols:
+        raise ValueError("No allowlisted columns remain after applying leak guard allowlist.")
+
+    # Store adjusted banned info on the result
+    result.banned = banned
+    result.dropped = dropped
+    result.kept = [c for c in df.columns]
+    result.allowlist_kept = sorted(list(allowlist_cols)) if allowlist_cols else []
+    return df, result
+
+
+def build_schema_snapshot(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    metadata: Mapping[str, object] | None = None,
+    banned: Mapping[str, str] | None = None,
+) -> dict:
+    """Render a schema snapshot describing each column and whether it was flagged."""
+
+    banned = banned or {}
+    meta = {
+        "generated_at_utc": datetime.utcnow().isoformat(),
+        "policy_version": policy.version,
+    }
+    meta.update(metadata or {})
+
+    # Extract columns / dtypes
+    if isinstance(df, pl.DataFrame):
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+    else:  # pandas or pandas-like
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+
+    schema = {
+        "metadata": meta,
+        "columns": [],
+    }
+
+    for col, dtype in cols_and_dtypes:
+        tags: list[str] = []
+        if col in IDENTIFIER_COLUMNS:
+            tags.append("id")
+        if col in NFL_TARGET_COLUMNS:
+            tags.append("label")
+        if col.startswith("market_"):
+            tags.append("odds")
+        if col.startswith("injury_") or col.startswith("practice_"):
+            tags.append("injury")
+        if col.startswith("weather_"):
+            tags.append("weather")
+        if col.startswith("ps_"):
+            tags.append("pre_snap")
+        schema["columns"].append(
+            {
+                "name": col,
+                "dtype": dtype,
+                "banned": col in banned,
+                "tags": tags,
+            }
+        )
+    return schema
+
+
+def write_schema_snapshot(path, schema: Mapping[str, object]) -> None:
+    path.parent.mkdir(parents=True, exist_ok=True)
+    with open(path, "w") as fp:
+        json.dump(schema, fp, indent=2, sort_keys=True)
+
+
+__all__ = [
+    "DEFAULT_LEAK_POLICY",
+    "LeakPolicy",
+    "LeakCheckResult",
+    "evaluate_leak_prone_columns",
+    "enforce_leak_guard",
+    "build_schema_snapshot",
+    "write_schema_snapshot",
+]
diff --git a/utils/general/constants.py b/utils/general/constants.py
index d94b4260ad877484da843fa99ae2caf37e8493f4..dea87caa354d94e4a08b1762d2bd8dcd4c8caa3a
--- a/utils/general/constants.py
+++ b/utils/general/constants.py
@@ -211,7 +211,17 @@
 
 NFL_TARGET_COLUMNS: Tuple[str, ...] = (
     'anytime_td',
+    'anytime_td_offense',
+    'anytime_td_all',
+    'anytime_td_rush',
+    'anytime_td_rec',
+    'anytime_td_pass_thrown',
     'td_count',
+    'td_count_offense',
+    'td_count_all',
+    'passing_td',
+    'rushing_td_count',
+    'receiving_td_count',
     'receiving_yards',
     'rushing_yards',
     'passing_yards',


thinking
**Deciding method insertion point**
exec
/bin/zsh -lc "cd /Users/jameswest/Desktop/nfl_predict && sed -n '520,680p' pipeline/train.py" in /Users/jameswest/Desktop/nfl_predict succeeded in 801ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
        Derive reality-aligned features (expected targets/carries/opportunities)
        from specialist predictions so downstream models learn the causal chain
        instead of raw, disjoint signals.
        """
        if df is None or df.empty:
            return df

        def _ensure_availability_composites(frame: pd.DataFrame) -> None:
            if (
                "pred_availability" in frame.columns
                and "pred_availability_raw" in frame.columns
            ):
                return
            has_active = "pred_availability_active" in frame.columns
            has_share = "pred_availability_snapshare" in frame.columns
            if not (has_active and has_share):
                return
            active = pd.to_numeric(frame["pred_availability_active"], errors="coerce").fillna(0.0).clip(0.0, 1.0)
            share = pd.to_numeric(frame["pred_availability_snapshare"], errors="coerce").fillna(0.0).clip(0.0, 1.0)
file update:
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 5ba68e8bf1acd3a789a76a8857674e6f6433017b..0210d5b7e7ed60a8de7a126d64f5ed76326474c8
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -14,7 +14,7 @@
 
 import logging
 import os
-from datetime import date, timedelta
+from datetime import date, datetime, timedelta
 from typing import Sequence
 
 import polars as pl
@@ -37,6 +37,12 @@
     add_offense_context_features_training,
     _append_offense_context_columns,
 )
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    build_schema_snapshot,
+    enforce_leak_guard,
+    write_schema_snapshot,
+)
 from utils.feature.weather_features import (
     add_weather_forecast_features_training,
     append_weather_context_flags,
@@ -931,6 +937,32 @@
     if market_exprs:
         df_player_game_all = df_player_game_all.with_columns(market_exprs)
     
+    # Leak guard + schema snapshot before persisting
+    spec = get_label_spec(label_version)
+    allow_exact = {spec.primary, *spec.labels.keys(), *spec.aliases.keys()}
+    df_player_game_all, leak_result = enforce_leak_guard(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_exact=allow_exact,
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=True,
+    )
+
+    schema = build_schema_snapshot(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        metadata={
+            "cutoff_label": cutoff_label,
+            "label_version": spec.name,
+        },
+        banned=leak_result.banned,
+    )
+    schema_dir = FEATURE_AUDIT_DIR / "schema" / "anytime_td"
+    schema_path = schema_dir / f"{cutoff_label}_{datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')}.json"
+    write_schema_snapshot(schema_path, schema)
+    logging.info("    Schema snapshot written → %s", schema_path)
+
     # Write final feature matrix
     df_player_game_all = df_player_game_all.with_columns(
         pl.lit(current_cutoff_hours).cast(pl.Float32).alias("decision_horizon_hours")
@@ -951,7 +983,6 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    spec = get_label_spec(label_version)
     label_candidates = {spec.primary, "anytime_td"}
     for label_col in label_candidates:
         if label_col in df_player_game_all.columns:
diff --git a/pipeline/train.py b/pipeline/train.py
index fe70207dcdf25d209ee3ad55080b7ce826347c44..d441717695a21ed0a286a5721d248a60c73c68e4
--- a/pipeline/train.py
+++ b/pipeline/train.py
@@ -4,6 +4,7 @@
 import sys
 import logging
 import math
+import re
 
 
 # Move logging to top and remove global thread pinning
@@ -98,6 +99,7 @@
     fit_team_conformal_sums,
     composite_sum_interval,
 )
+from utils.feature.leak_guard import DEFAULT_LEAK_POLICY, enforce_leak_guard
 from utils.feature.targets import require_target_column
 
 # Ignore specific, noisy warnings from dependencies
@@ -2315,7 +2317,30 @@
                             df_problem[col] = df_problem[col].fillna(df_problem[col].mean())
 
                 df_problem = self._inject_composed_features(df_problem)
-            
+
+            # Leak guard on the problem-scoped frame
+            allow_prefixes = tuple(problem_copy.get('feature_prefixes_to_include') or [])
+            allow_exact = set(problem_copy.get('other_features_to_include') or [])
+            allow_exact.update(input_preds or [])
+            if self.target_col:
+                allow_exact.add(self.target_col)
+            df_problem, leak_info = enforce_leak_guard(
+                df_problem,
+                policy=DEFAULT_LEAK_POLICY,
+                allow_prefixes=allow_prefixes,
+                allow_exact=allow_exact,
+                drop_banned=True,
+                drop_non_allowlisted=False,
+                raise_on_banned=True,
+            )
+            if leak_info.dropped:
+                logger.info(
+                    "Dropped %d leak-prone columns for %s: %s",
+                    len(leak_info.dropped),
+                    problem_name,
+                    sorted(leak_info.dropped),
+                )
+
             self._normalize_datetime_like_columns(df_problem, problem_name)
             df_problem[self.time_col] = pd.to_datetime(df_problem[self.time_col])
             sort_cols = [self.time_col]
diff --git a/tests/test_data_leak_guard.py b/tests/test_data_leak_guard.py
index 8061f2760c0898aaeda29026859e1b9ff5644ba4..3e56665921db89ea523bbdb205d1bb90c21893df
--- a/tests/test_data_leak_guard.py
+++ b/tests/test_data_leak_guard.py
@@ -3,6 +3,14 @@
 import yaml
 from pathlib import Path
 
+import polars as pl
+
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    enforce_leak_guard,
+    evaluate_leak_prone_columns,
+)
+
 
 PROJECT_ROOT = Path(__file__).resolve().parents[1]
 TRAINING_CONFIG = PROJECT_ROOT / "config" / "training.yaml"
@@ -48,3 +56,41 @@
     )
 
 
+def test_leak_guard_flags_pattern_columns():
+    cols = [
+        "market_anytime_td_prob",
+        "final_score",
+        "postgame_anytime_td",
+        "actual_td_count",
+        "safe_feature",
+    ]
+    result = evaluate_leak_prone_columns(cols, policy=DEFAULT_LEAK_POLICY)
+    assert set(result.banned.keys()) == {"final_score", "postgame_anytime_td", "actual_td_count"}
+    assert "safe_feature" in result.kept
+    assert "market_anytime_td_prob" in result.kept
+
+
+def test_enforce_leak_guard_drops_banned_and_keeps_allowlisted():
+    df = pl.DataFrame(
+        {
+            "game_id": ["g1", "g2"],
+            "safe_feature": [1.0, 2.0],
+            "postgame_anytime_td": [1, 0],
+            "final_score": [30, 24],
+        }
+    )
+    cleaned, info = enforce_leak_guard(
+        df,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_prefixes=("safe_",),
+        allow_exact=("game_id",),
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=False,
+    )
+    assert "postgame_anytime_td" not in cleaned.columns
+    assert "final_score" not in cleaned.columns
+    assert "safe_feature" in cleaned.columns
+    assert "game_id" in cleaned.columns
+    assert set(info.dropped) == {"postgame_anytime_td", "final_score"}
+
diff --git a/utils/feature/leak_guard.py b/utils/feature/leak_guard.py
new file mode 100644
index 0000000000000000000000000000000000000000..9faf8cfffc436e0934b2f410aaf252e52f4f95df
--- /dev/null
+++ b/utils/feature/leak_guard.py
@@ -0,0 +1,273 @@
+"""Leak guardrails for feature matrices.
+
+This module centralizes pattern-based leak detection so both feature assembly
+and training can fail fast when post-outcome columns sneak into the data.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+from datetime import datetime
+import json
+import re
+from typing import Iterable, Mapping, Sequence
+
+import polars as pl
+
+from utils.general.constants import IDENTIFIER_COLUMNS, LEAK_PRONE_COLUMNS, NFL_TARGET_COLUMNS
+
+try:  # Optional dependency when imported from training (pandas path)
+    import pandas as pd  # type: ignore
+except Exception:  # pragma: no cover - optional dependency
+    pd = None
+
+
+@dataclass(frozen=True)
+class LeakPolicy:
+    version: str
+    banned_exact: set[str]
+    banned_prefixes: tuple[str, ...]
+    banned_suffixes: tuple[str, ...]
+    banned_regex: tuple[tuple[re.Pattern[str], str], ...]
+    description: str = ""
+
+
+@dataclass
+class LeakCheckResult:
+    policy_version: str
+    banned: dict[str, str]
+    kept: list[str]
+    dropped: list[str]
+    allowlist_kept: list[str]
+
+
+# Core policy tuned for anytime-TD style problems (can be extended per-problem).
+_BASE_BANNED_EXACT = set(LEAK_PRONE_COLUMNS) | {
+    "final_score",
+    "final_total",
+    "points_scored",
+    "actual_td_count",
+    "actual_anytime_td",
+    "postgame_anytime_td",
+    "postgame_td_count",
+}
+_BASE_BANNED_PREFIXES = (
+    "postgame_",
+    "post_game_",
+    "post_",
+    "live_",
+    "actual_",
+    "realized_",
+    "final_",
+    "postmatch_",
+)
+_BASE_BANNED_SUFFIXES = (
+    "_post",
+    "_postgame",
+    "_final",
+    "_fullgame",
+    "_actual",
+)
+_BASE_BANNED_REGEX: tuple[tuple[re.Pattern[str], str], ...] = (
+    (re.compile(r".*post.?game.*", flags=re.IGNORECASE), "postgame marker"),
+    (re.compile(r".*final_score.*", flags=re.IGNORECASE), "final score"),
+    (re.compile(r".*actual.*td.*", flags=re.IGNORECASE), "actual TD total"),
+    (re.compile(r".*anytime_td.*(post|final|actual).*", flags=re.IGNORECASE), "post-decision anytime TD"),
+    (re.compile(r".*fullgame.*", flags=re.IGNORECASE), "full game cumulative value"),
+)
+
+DEFAULT_LEAK_POLICY = LeakPolicy(
+    version="v1",
+    description="Core post-outcome leak guard for NFL anytime TD features.",
+    banned_exact=_BASE_BANNED_EXACT,
+    banned_prefixes=_BASE_BANNED_PREFIXES,
+    banned_suffixes=_BASE_BANNED_SUFFIXES,
+    banned_regex=_BASE_BANNED_REGEX,
+)
+
+
+def _ensure_sequence(value: Sequence[str] | str | None) -> tuple[str, ...]:
+    if value is None:
+        return ()
+    if isinstance(value, str):
+        return (value,)
+    return tuple(value)
+
+
+def evaluate_leak_prone_columns(
+    columns: Iterable[str],
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+) -> LeakCheckResult:
+    """Identify leak-prone columns using the configured policy."""
+
+    banned: dict[str, str] = {}
+    columns_list = list(columns)
+    for col in columns_list:
+        if col in policy.banned_exact:
+            banned[col] = "exact"
+            continue
+        for prefix in policy.banned_prefixes:
+            if col.startswith(prefix):
+                banned[col] = f"prefix:{prefix}"
+                break
+        if col in banned:
+            continue
+        for suffix in policy.banned_suffixes:
+            if col.endswith(suffix):
+                banned[col] = f"suffix:{suffix}"
+                break
+        if col in banned:
+            continue
+        for pattern, reason in policy.banned_regex:
+            if pattern.match(col):
+                banned[col] = reason
+                break
+
+    kept = [c for c in columns_list if c not in banned]
+    return LeakCheckResult(
+        policy_version=policy.version,
+        banned=banned,
+        kept=kept,
+        dropped=[],
+        allowlist_kept=[],
+    )
+
+
+def enforce_leak_guard(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    allow_prefixes: Sequence[str] | str | None = None,
+    allow_exact: Sequence[str] | str | None = None,
+    drop_banned: bool = True,
+    drop_non_allowlisted: bool = False,
+    raise_on_banned: bool = True,
+) -> tuple[pl.DataFrame | "pd.DataFrame", LeakCheckResult]:
+    """Apply leak guardrails to a feature frame.
+
+    Parameters
+    ----------
+    df : DataFrame
+        Polars or pandas DataFrame.
+    policy : LeakPolicy
+        Leak policy to apply.
+    allow_prefixes : Sequence[str] | str | None
+        Optional prefixes that define the allowed feature surface for a problem.
+    allow_exact : Sequence[str] | str | None
+        Explicitly allowed columns (e.g., identifiers).
+    drop_banned : bool
+        If True, drop any banned columns automatically.
+    drop_non_allowlisted : bool
+        If True, drop columns that are not covered by allow_prefixes/allow_exact/identifiers/targets.
+    raise_on_banned : bool
+        If True, raise when banned columns are detected (after optional drop).
+    """
+
+    result = evaluate_leak_prone_columns(df.columns, policy=policy)
+    dropped: list[str] = []
+
+    allow_prefixes = _ensure_sequence(allow_prefixes)
+    allow_exact = set(_ensure_sequence(allow_exact))
+    allow_exact.update({col for col in IDENTIFIER_COLUMNS if col in df.columns})
+    allow_exact.update({col for col in NFL_TARGET_COLUMNS if col in df.columns})
+
+    # Permit allowlisted columns even if they match a banned rule (e.g., labels)
+    banned = {col: reason for col, reason in result.banned.items() if col not in allow_exact}
+
+    if banned and drop_banned:
+        df = df.drop(list(banned.keys()))
+        dropped.extend(banned.keys())
+
+    if banned and raise_on_banned:
+        raise ValueError(f"Leak-prone columns detected: {sorted(banned.items())}")
+
+    allowlist_cols: set[str] = set()
+    if allow_prefixes:
+        allowlist_cols.update({c for c in df.columns if c.startswith(allow_prefixes)})
+    allowlist_cols.update({c for c in allow_exact if c in df.columns})
+
+    if drop_non_allowlisted and allowlist_cols:
+        drop_candidates = [c for c in df.columns if c not in allowlist_cols]
+        if drop_candidates:
+            df = df.drop(drop_candidates)
+            dropped.extend(drop_candidates)
+
+    if drop_non_allowlisted and not allowlist_cols:
+        raise ValueError("No allowlisted columns remain after applying leak guard allowlist.")
+
+    # Store adjusted banned info on the result
+    result.banned = banned
+    result.dropped = dropped
+    result.kept = [c for c in df.columns]
+    result.allowlist_kept = sorted(list(allowlist_cols)) if allowlist_cols else []
+    return df, result
+
+
+def build_schema_snapshot(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    metadata: Mapping[str, object] | None = None,
+    banned: Mapping[str, str] | None = None,
+) -> dict:
+    """Render a schema snapshot describing each column and whether it was flagged."""
+
+    banned = banned or {}
+    meta = {
+        "generated_at_utc": datetime.utcnow().isoformat(),
+        "policy_version": policy.version,
+    }
+    meta.update(metadata or {})
+
+    # Extract columns / dtypes
+    if isinstance(df, pl.DataFrame):
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+    else:  # pandas or pandas-like
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+
+    schema = {
+        "metadata": meta,
+        "columns": [],
+    }
+
+    for col, dtype in cols_and_dtypes:
+        tags: list[str] = []
+        if col in IDENTIFIER_COLUMNS:
+            tags.append("id")
+        if col in NFL_TARGET_COLUMNS:
+            tags.append("label")
+        if col.startswith("market_"):
+            tags.append("odds")
+        if col.startswith("injury_") or col.startswith("practice_"):
+            tags.append("injury")
+        if col.startswith("weather_"):
+            tags.append("weather")
+        if col.startswith("ps_"):
+            tags.append("pre_snap")
+        schema["columns"].append(
+            {
+                "name": col,
+                "dtype": dtype,
+                "banned": col in banned,
+                "tags": tags,
+            }
+        )
+    return schema
+
+
+def write_schema_snapshot(path, schema: Mapping[str, object]) -> None:
+    path.parent.mkdir(parents=True, exist_ok=True)
+    with open(path, "w") as fp:
+        json.dump(schema, fp, indent=2, sort_keys=True)
+
+
+__all__ = [
+    "DEFAULT_LEAK_POLICY",
+    "LeakPolicy",
+    "LeakCheckResult",
+    "evaluate_leak_prone_columns",
+    "enforce_leak_guard",
+    "build_schema_snapshot",
+    "write_schema_snapshot",
+]
diff --git a/utils/general/constants.py b/utils/general/constants.py
index d94b4260ad877484da843fa99ae2caf37e8493f4..dea87caa354d94e4a08b1762d2bd8dcd4c8caa3a
--- a/utils/general/constants.py
+++ b/utils/general/constants.py
@@ -211,7 +211,17 @@
 
 NFL_TARGET_COLUMNS: Tuple[str, ...] = (
     'anytime_td',
+    'anytime_td_offense',
+    'anytime_td_all',
+    'anytime_td_rush',
+    'anytime_td_rec',
+    'anytime_td_pass_thrown',
     'td_count',
+    'td_count_offense',
+    'td_count_all',
+    'passing_td',
+    'rushing_td_count',
+    'receiving_td_count',
     'receiving_yards',
     'rushing_yards',
     'passing_yards',


thinking
**Locating method end for patching**
exec
/bin/zsh -lc 'cd /Users/jameswest/Desktop/nfl_predict && rg "def _inject_composed_features" -n pipeline/train.py' in /Users/jameswest/Desktop/nfl_predict succeeded in 850ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
518:    def _inject_composed_features(self, df: pd.DataFrame) -> pd.DataFrame:
file update:
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 5ba68e8bf1acd3a789a76a8857674e6f6433017b..0210d5b7e7ed60a8de7a126d64f5ed76326474c8
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -14,7 +14,7 @@
 
 import logging
 import os
-from datetime import date, timedelta
+from datetime import date, datetime, timedelta
 from typing import Sequence
 
 import polars as pl
@@ -37,6 +37,12 @@
     add_offense_context_features_training,
     _append_offense_context_columns,
 )
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    build_schema_snapshot,
+    enforce_leak_guard,
+    write_schema_snapshot,
+)
 from utils.feature.weather_features import (
     add_weather_forecast_features_training,
     append_weather_context_flags,
@@ -931,6 +937,32 @@
     if market_exprs:
         df_player_game_all = df_player_game_all.with_columns(market_exprs)
     
+    # Leak guard + schema snapshot before persisting
+    spec = get_label_spec(label_version)
+    allow_exact = {spec.primary, *spec.labels.keys(), *spec.aliases.keys()}
+    df_player_game_all, leak_result = enforce_leak_guard(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_exact=allow_exact,
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=True,
+    )
+
+    schema = build_schema_snapshot(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        metadata={
+            "cutoff_label": cutoff_label,
+            "label_version": spec.name,
+        },
+        banned=leak_result.banned,
+    )
+    schema_dir = FEATURE_AUDIT_DIR / "schema" / "anytime_td"
+    schema_path = schema_dir / f"{cutoff_label}_{datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')}.json"
+    write_schema_snapshot(schema_path, schema)
+    logging.info("    Schema snapshot written → %s", schema_path)
+
     # Write final feature matrix
     df_player_game_all = df_player_game_all.with_columns(
         pl.lit(current_cutoff_hours).cast(pl.Float32).alias("decision_horizon_hours")
@@ -951,7 +983,6 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    spec = get_label_spec(label_version)
     label_candidates = {spec.primary, "anytime_td"}
     for label_col in label_candidates:
         if label_col in df_player_game_all.columns:
diff --git a/pipeline/train.py b/pipeline/train.py
index fe70207dcdf25d209ee3ad55080b7ce826347c44..d441717695a21ed0a286a5721d248a60c73c68e4
--- a/pipeline/train.py
+++ b/pipeline/train.py
@@ -4,6 +4,7 @@
 import sys
 import logging
 import math
+import re
 
 
 # Move logging to top and remove global thread pinning
@@ -98,6 +99,7 @@
     fit_team_conformal_sums,
     composite_sum_interval,
 )
+from utils.feature.leak_guard import DEFAULT_LEAK_POLICY, enforce_leak_guard
 from utils.feature.targets import require_target_column
 
 # Ignore specific, noisy warnings from dependencies
@@ -2315,7 +2317,30 @@
                             df_problem[col] = df_problem[col].fillna(df_problem[col].mean())
 
                 df_problem = self._inject_composed_features(df_problem)
-            
+
+            # Leak guard on the problem-scoped frame
+            allow_prefixes = tuple(problem_copy.get('feature_prefixes_to_include') or [])
+            allow_exact = set(problem_copy.get('other_features_to_include') or [])
+            allow_exact.update(input_preds or [])
+            if self.target_col:
+                allow_exact.add(self.target_col)
+            df_problem, leak_info = enforce_leak_guard(
+                df_problem,
+                policy=DEFAULT_LEAK_POLICY,
+                allow_prefixes=allow_prefixes,
+                allow_exact=allow_exact,
+                drop_banned=True,
+                drop_non_allowlisted=False,
+                raise_on_banned=True,
+            )
+            if leak_info.dropped:
+                logger.info(
+                    "Dropped %d leak-prone columns for %s: %s",
+                    len(leak_info.dropped),
+                    problem_name,
+                    sorted(leak_info.dropped),
+                )
+
             self._normalize_datetime_like_columns(df_problem, problem_name)
             df_problem[self.time_col] = pd.to_datetime(df_problem[self.time_col])
             sort_cols = [self.time_col]
diff --git a/tests/test_data_leak_guard.py b/tests/test_data_leak_guard.py
index 8061f2760c0898aaeda29026859e1b9ff5644ba4..3e56665921db89ea523bbdb205d1bb90c21893df
--- a/tests/test_data_leak_guard.py
+++ b/tests/test_data_leak_guard.py
@@ -3,6 +3,14 @@
 import yaml
 from pathlib import Path
 
+import polars as pl
+
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    enforce_leak_guard,
+    evaluate_leak_prone_columns,
+)
+
 
 PROJECT_ROOT = Path(__file__).resolve().parents[1]
 TRAINING_CONFIG = PROJECT_ROOT / "config" / "training.yaml"
@@ -48,3 +56,41 @@
     )
 
 
+def test_leak_guard_flags_pattern_columns():
+    cols = [
+        "market_anytime_td_prob",
+        "final_score",
+        "postgame_anytime_td",
+        "actual_td_count",
+        "safe_feature",
+    ]
+    result = evaluate_leak_prone_columns(cols, policy=DEFAULT_LEAK_POLICY)
+    assert set(result.banned.keys()) == {"final_score", "postgame_anytime_td", "actual_td_count"}
+    assert "safe_feature" in result.kept
+    assert "market_anytime_td_prob" in result.kept
+
+
+def test_enforce_leak_guard_drops_banned_and_keeps_allowlisted():
+    df = pl.DataFrame(
+        {
+            "game_id": ["g1", "g2"],
+            "safe_feature": [1.0, 2.0],
+            "postgame_anytime_td": [1, 0],
+            "final_score": [30, 24],
+        }
+    )
+    cleaned, info = enforce_leak_guard(
+        df,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_prefixes=("safe_",),
+        allow_exact=("game_id",),
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=False,
+    )
+    assert "postgame_anytime_td" not in cleaned.columns
+    assert "final_score" not in cleaned.columns
+    assert "safe_feature" in cleaned.columns
+    assert "game_id" in cleaned.columns
+    assert set(info.dropped) == {"postgame_anytime_td", "final_score"}
+
diff --git a/utils/feature/leak_guard.py b/utils/feature/leak_guard.py
new file mode 100644
index 0000000000000000000000000000000000000000..9faf8cfffc436e0934b2f410aaf252e52f4f95df
--- /dev/null
+++ b/utils/feature/leak_guard.py
@@ -0,0 +1,273 @@
+"""Leak guardrails for feature matrices.
+
+This module centralizes pattern-based leak detection so both feature assembly
+and training can fail fast when post-outcome columns sneak into the data.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+from datetime import datetime
+import json
+import re
+from typing import Iterable, Mapping, Sequence
+
+import polars as pl
+
+from utils.general.constants import IDENTIFIER_COLUMNS, LEAK_PRONE_COLUMNS, NFL_TARGET_COLUMNS
+
+try:  # Optional dependency when imported from training (pandas path)
+    import pandas as pd  # type: ignore
+except Exception:  # pragma: no cover - optional dependency
+    pd = None
+
+
+@dataclass(frozen=True)
+class LeakPolicy:
+    version: str
+    banned_exact: set[str]
+    banned_prefixes: tuple[str, ...]
+    banned_suffixes: tuple[str, ...]
+    banned_regex: tuple[tuple[re.Pattern[str], str], ...]
+    description: str = ""
+
+
+@dataclass
+class LeakCheckResult:
+    policy_version: str
+    banned: dict[str, str]
+    kept: list[str]
+    dropped: list[str]
+    allowlist_kept: list[str]
+
+
+# Core policy tuned for anytime-TD style problems (can be extended per-problem).
+_BASE_BANNED_EXACT = set(LEAK_PRONE_COLUMNS) | {
+    "final_score",
+    "final_total",
+    "points_scored",
+    "actual_td_count",
+    "actual_anytime_td",
+    "postgame_anytime_td",
+    "postgame_td_count",
+}
+_BASE_BANNED_PREFIXES = (
+    "postgame_",
+    "post_game_",
+    "post_",
+    "live_",
+    "actual_",
+    "realized_",
+    "final_",
+    "postmatch_",
+)
+_BASE_BANNED_SUFFIXES = (
+    "_post",
+    "_postgame",
+    "_final",
+    "_fullgame",
+    "_actual",
+)
+_BASE_BANNED_REGEX: tuple[tuple[re.Pattern[str], str], ...] = (
+    (re.compile(r".*post.?game.*", flags=re.IGNORECASE), "postgame marker"),
+    (re.compile(r".*final_score.*", flags=re.IGNORECASE), "final score"),
+    (re.compile(r".*actual.*td.*", flags=re.IGNORECASE), "actual TD total"),
+    (re.compile(r".*anytime_td.*(post|final|actual).*", flags=re.IGNORECASE), "post-decision anytime TD"),
+    (re.compile(r".*fullgame.*", flags=re.IGNORECASE), "full game cumulative value"),
+)
+
+DEFAULT_LEAK_POLICY = LeakPolicy(
+    version="v1",
+    description="Core post-outcome leak guard for NFL anytime TD features.",
+    banned_exact=_BASE_BANNED_EXACT,
+    banned_prefixes=_BASE_BANNED_PREFIXES,
+    banned_suffixes=_BASE_BANNED_SUFFIXES,
+    banned_regex=_BASE_BANNED_REGEX,
+)
+
+
+def _ensure_sequence(value: Sequence[str] | str | None) -> tuple[str, ...]:
+    if value is None:
+        return ()
+    if isinstance(value, str):
+        return (value,)
+    return tuple(value)
+
+
+def evaluate_leak_prone_columns(
+    columns: Iterable[str],
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+) -> LeakCheckResult:
+    """Identify leak-prone columns using the configured policy."""
+
+    banned: dict[str, str] = {}
+    columns_list = list(columns)
+    for col in columns_list:
+        if col in policy.banned_exact:
+            banned[col] = "exact"
+            continue
+        for prefix in policy.banned_prefixes:
+            if col.startswith(prefix):
+                banned[col] = f"prefix:{prefix}"
+                break
+        if col in banned:
+            continue
+        for suffix in policy.banned_suffixes:
+            if col.endswith(suffix):
+                banned[col] = f"suffix:{suffix}"
+                break
+        if col in banned:
+            continue
+        for pattern, reason in policy.banned_regex:
+            if pattern.match(col):
+                banned[col] = reason
+                break
+
+    kept = [c for c in columns_list if c not in banned]
+    return LeakCheckResult(
+        policy_version=policy.version,
+        banned=banned,
+        kept=kept,
+        dropped=[],
+        allowlist_kept=[],
+    )
+
+
+def enforce_leak_guard(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    allow_prefixes: Sequence[str] | str | None = None,
+    allow_exact: Sequence[str] | str | None = None,
+    drop_banned: bool = True,
+    drop_non_allowlisted: bool = False,
+    raise_on_banned: bool = True,
+) -> tuple[pl.DataFrame | "pd.DataFrame", LeakCheckResult]:
+    """Apply leak guardrails to a feature frame.
+
+    Parameters
+    ----------
+    df : DataFrame
+        Polars or pandas DataFrame.
+    policy : LeakPolicy
+        Leak policy to apply.
+    allow_prefixes : Sequence[str] | str | None
+        Optional prefixes that define the allowed feature surface for a problem.
+    allow_exact : Sequence[str] | str | None
+        Explicitly allowed columns (e.g., identifiers).
+    drop_banned : bool
+        If True, drop any banned columns automatically.
+    drop_non_allowlisted : bool
+        If True, drop columns that are not covered by allow_prefixes/allow_exact/identifiers/targets.
+    raise_on_banned : bool
+        If True, raise when banned columns are detected (after optional drop).
+    """
+
+    result = evaluate_leak_prone_columns(df.columns, policy=policy)
+    dropped: list[str] = []
+
+    allow_prefixes = _ensure_sequence(allow_prefixes)
+    allow_exact = set(_ensure_sequence(allow_exact))
+    allow_exact.update({col for col in IDENTIFIER_COLUMNS if col in df.columns})
+    allow_exact.update({col for col in NFL_TARGET_COLUMNS if col in df.columns})
+
+    # Permit allowlisted columns even if they match a banned rule (e.g., labels)
+    banned = {col: reason for col, reason in result.banned.items() if col not in allow_exact}
+
+    if banned and drop_banned:
+        df = df.drop(list(banned.keys()))
+        dropped.extend(banned.keys())
+
+    if banned and raise_on_banned:
+        raise ValueError(f"Leak-prone columns detected: {sorted(banned.items())}")
+
+    allowlist_cols: set[str] = set()
+    if allow_prefixes:
+        allowlist_cols.update({c for c in df.columns if c.startswith(allow_prefixes)})
+    allowlist_cols.update({c for c in allow_exact if c in df.columns})
+
+    if drop_non_allowlisted and allowlist_cols:
+        drop_candidates = [c for c in df.columns if c not in allowlist_cols]
+        if drop_candidates:
+            df = df.drop(drop_candidates)
+            dropped.extend(drop_candidates)
+
+    if drop_non_allowlisted and not allowlist_cols:
+        raise ValueError("No allowlisted columns remain after applying leak guard allowlist.")
+
+    # Store adjusted banned info on the result
+    result.banned = banned
+    result.dropped = dropped
+    result.kept = [c for c in df.columns]
+    result.allowlist_kept = sorted(list(allowlist_cols)) if allowlist_cols else []
+    return df, result
+
+
+def build_schema_snapshot(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    metadata: Mapping[str, object] | None = None,
+    banned: Mapping[str, str] | None = None,
+) -> dict:
+    """Render a schema snapshot describing each column and whether it was flagged."""
+
+    banned = banned or {}
+    meta = {
+        "generated_at_utc": datetime.utcnow().isoformat(),
+        "policy_version": policy.version,
+    }
+    meta.update(metadata or {})
+
+    # Extract columns / dtypes
+    if isinstance(df, pl.DataFrame):
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+    else:  # pandas or pandas-like
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+
+    schema = {
+        "metadata": meta,
+        "columns": [],
+    }
+
+    for col, dtype in cols_and_dtypes:
+        tags: list[str] = []
+        if col in IDENTIFIER_COLUMNS:
+            tags.append("id")
+        if col in NFL_TARGET_COLUMNS:
+            tags.append("label")
+        if col.startswith("market_"):
+            tags.append("odds")
+        if col.startswith("injury_") or col.startswith("practice_"):
+            tags.append("injury")
+        if col.startswith("weather_"):
+            tags.append("weather")
+        if col.startswith("ps_"):
+            tags.append("pre_snap")
+        schema["columns"].append(
+            {
+                "name": col,
+                "dtype": dtype,
+                "banned": col in banned,
+                "tags": tags,
+            }
+        )
+    return schema
+
+
+def write_schema_snapshot(path, schema: Mapping[str, object]) -> None:
+    path.parent.mkdir(parents=True, exist_ok=True)
+    with open(path, "w") as fp:
+        json.dump(schema, fp, indent=2, sort_keys=True)
+
+
+__all__ = [
+    "DEFAULT_LEAK_POLICY",
+    "LeakPolicy",
+    "LeakCheckResult",
+    "evaluate_leak_prone_columns",
+    "enforce_leak_guard",
+    "build_schema_snapshot",
+    "write_schema_snapshot",
+]
diff --git a/utils/general/constants.py b/utils/general/constants.py
index d94b4260ad877484da843fa99ae2caf37e8493f4..dea87caa354d94e4a08b1762d2bd8dcd4c8caa3a
--- a/utils/general/constants.py
+++ b/utils/general/constants.py
@@ -211,7 +211,17 @@
 
 NFL_TARGET_COLUMNS: Tuple[str, ...] = (
     'anytime_td',
+    'anytime_td_offense',
+    'anytime_td_all',
+    'anytime_td_rush',
+    'anytime_td_rec',
+    'anytime_td_pass_thrown',
     'td_count',
+    'td_count_offense',
+    'td_count_all',
+    'passing_td',
+    'rushing_td_count',
+    'receiving_td_count',
     'receiving_yards',
     'rushing_yards',
     'passing_yards',


thinking
**Searching for next method definition**
exec
/bin/zsh -lc "cd /Users/jameswest/Desktop/nfl_predict && sed -n '780,860p' pipeline/train.py" in /Users/jameswest/Desktop/nfl_predict succeeded in 738ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
        df = df.sort_values(sort_cols).reset_index(drop=True)
        shift = int(derived_cfg.get("shift", -1))
        df[target_col] = (
            df.groupby(group_cols, sort=False)[source_col]
            .shift(shift)
            .astype(np.float32)
        )
        before = len(df)
        df = df[df[target_col].notna()].reset_index(drop=True)
        dropped = before - len(df)
        if dropped:
            logger.info(
                "Dropped %d rows with missing derived target for problem '%s'.",
                dropped,
                problem_name,
            )
        return df

    def _ensure_player_game_actuals(self) -> pd.DataFrame:
file update:
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 5ba68e8bf1acd3a789a76a8857674e6f6433017b..0210d5b7e7ed60a8de7a126d64f5ed76326474c8
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -14,7 +14,7 @@
 
 import logging
 import os
-from datetime import date, timedelta
+from datetime import date, datetime, timedelta
 from typing import Sequence
 
 import polars as pl
@@ -37,6 +37,12 @@
     add_offense_context_features_training,
     _append_offense_context_columns,
 )
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    build_schema_snapshot,
+    enforce_leak_guard,
+    write_schema_snapshot,
+)
 from utils.feature.weather_features import (
     add_weather_forecast_features_training,
     append_weather_context_flags,
@@ -931,6 +937,32 @@
     if market_exprs:
         df_player_game_all = df_player_game_all.with_columns(market_exprs)
     
+    # Leak guard + schema snapshot before persisting
+    spec = get_label_spec(label_version)
+    allow_exact = {spec.primary, *spec.labels.keys(), *spec.aliases.keys()}
+    df_player_game_all, leak_result = enforce_leak_guard(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_exact=allow_exact,
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=True,
+    )
+
+    schema = build_schema_snapshot(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        metadata={
+            "cutoff_label": cutoff_label,
+            "label_version": spec.name,
+        },
+        banned=leak_result.banned,
+    )
+    schema_dir = FEATURE_AUDIT_DIR / "schema" / "anytime_td"
+    schema_path = schema_dir / f"{cutoff_label}_{datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')}.json"
+    write_schema_snapshot(schema_path, schema)
+    logging.info("    Schema snapshot written → %s", schema_path)
+
     # Write final feature matrix
     df_player_game_all = df_player_game_all.with_columns(
         pl.lit(current_cutoff_hours).cast(pl.Float32).alias("decision_horizon_hours")
@@ -951,7 +983,6 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    spec = get_label_spec(label_version)
     label_candidates = {spec.primary, "anytime_td"}
     for label_col in label_candidates:
         if label_col in df_player_game_all.columns:
diff --git a/pipeline/train.py b/pipeline/train.py
index fe70207dcdf25d209ee3ad55080b7ce826347c44..d441717695a21ed0a286a5721d248a60c73c68e4
--- a/pipeline/train.py
+++ b/pipeline/train.py
@@ -4,6 +4,7 @@
 import sys
 import logging
 import math
+import re
 
 
 # Move logging to top and remove global thread pinning
@@ -98,6 +99,7 @@
     fit_team_conformal_sums,
     composite_sum_interval,
 )
+from utils.feature.leak_guard import DEFAULT_LEAK_POLICY, enforce_leak_guard
 from utils.feature.targets import require_target_column
 
 # Ignore specific, noisy warnings from dependencies
@@ -2315,7 +2317,30 @@
                             df_problem[col] = df_problem[col].fillna(df_problem[col].mean())
 
                 df_problem = self._inject_composed_features(df_problem)
-            
+
+            # Leak guard on the problem-scoped frame
+            allow_prefixes = tuple(problem_copy.get('feature_prefixes_to_include') or [])
+            allow_exact = set(problem_copy.get('other_features_to_include') or [])
+            allow_exact.update(input_preds or [])
+            if self.target_col:
+                allow_exact.add(self.target_col)
+            df_problem, leak_info = enforce_leak_guard(
+                df_problem,
+                policy=DEFAULT_LEAK_POLICY,
+                allow_prefixes=allow_prefixes,
+                allow_exact=allow_exact,
+                drop_banned=True,
+                drop_non_allowlisted=False,
+                raise_on_banned=True,
+            )
+            if leak_info.dropped:
+                logger.info(
+                    "Dropped %d leak-prone columns for %s: %s",
+                    len(leak_info.dropped),
+                    problem_name,
+                    sorted(leak_info.dropped),
+                )
+
             self._normalize_datetime_like_columns(df_problem, problem_name)
             df_problem[self.time_col] = pd.to_datetime(df_problem[self.time_col])
             sort_cols = [self.time_col]
diff --git a/tests/test_data_leak_guard.py b/tests/test_data_leak_guard.py
index 8061f2760c0898aaeda29026859e1b9ff5644ba4..3e56665921db89ea523bbdb205d1bb90c21893df
--- a/tests/test_data_leak_guard.py
+++ b/tests/test_data_leak_guard.py
@@ -3,6 +3,14 @@
 import yaml
 from pathlib import Path
 
+import polars as pl
+
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    enforce_leak_guard,
+    evaluate_leak_prone_columns,
+)
+
 
 PROJECT_ROOT = Path(__file__).resolve().parents[1]
 TRAINING_CONFIG = PROJECT_ROOT / "config" / "training.yaml"
@@ -48,3 +56,41 @@
     )
 
 
+def test_leak_guard_flags_pattern_columns():
+    cols = [
+        "market_anytime_td_prob",
+        "final_score",
+        "postgame_anytime_td",
+        "actual_td_count",
+        "safe_feature",
+    ]
+    result = evaluate_leak_prone_columns(cols, policy=DEFAULT_LEAK_POLICY)
+    assert set(result.banned.keys()) == {"final_score", "postgame_anytime_td", "actual_td_count"}
+    assert "safe_feature" in result.kept
+    assert "market_anytime_td_prob" in result.kept
+
+
+def test_enforce_leak_guard_drops_banned_and_keeps_allowlisted():
+    df = pl.DataFrame(
+        {
+            "game_id": ["g1", "g2"],
+            "safe_feature": [1.0, 2.0],
+            "postgame_anytime_td": [1, 0],
+            "final_score": [30, 24],
+        }
+    )
+    cleaned, info = enforce_leak_guard(
+        df,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_prefixes=("safe_",),
+        allow_exact=("game_id",),
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=False,
+    )
+    assert "postgame_anytime_td" not in cleaned.columns
+    assert "final_score" not in cleaned.columns
+    assert "safe_feature" in cleaned.columns
+    assert "game_id" in cleaned.columns
+    assert set(info.dropped) == {"postgame_anytime_td", "final_score"}
+
diff --git a/utils/feature/leak_guard.py b/utils/feature/leak_guard.py
new file mode 100644
index 0000000000000000000000000000000000000000..9faf8cfffc436e0934b2f410aaf252e52f4f95df
--- /dev/null
+++ b/utils/feature/leak_guard.py
@@ -0,0 +1,273 @@
+"""Leak guardrails for feature matrices.
+
+This module centralizes pattern-based leak detection so both feature assembly
+and training can fail fast when post-outcome columns sneak into the data.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+from datetime import datetime
+import json
+import re
+from typing import Iterable, Mapping, Sequence
+
+import polars as pl
+
+from utils.general.constants import IDENTIFIER_COLUMNS, LEAK_PRONE_COLUMNS, NFL_TARGET_COLUMNS
+
+try:  # Optional dependency when imported from training (pandas path)
+    import pandas as pd  # type: ignore
+except Exception:  # pragma: no cover - optional dependency
+    pd = None
+
+
+@dataclass(frozen=True)
+class LeakPolicy:
+    version: str
+    banned_exact: set[str]
+    banned_prefixes: tuple[str, ...]
+    banned_suffixes: tuple[str, ...]
+    banned_regex: tuple[tuple[re.Pattern[str], str], ...]
+    description: str = ""
+
+
+@dataclass
+class LeakCheckResult:
+    policy_version: str
+    banned: dict[str, str]
+    kept: list[str]
+    dropped: list[str]
+    allowlist_kept: list[str]
+
+
+# Core policy tuned for anytime-TD style problems (can be extended per-problem).
+_BASE_BANNED_EXACT = set(LEAK_PRONE_COLUMNS) | {
+    "final_score",
+    "final_total",
+    "points_scored",
+    "actual_td_count",
+    "actual_anytime_td",
+    "postgame_anytime_td",
+    "postgame_td_count",
+}
+_BASE_BANNED_PREFIXES = (
+    "postgame_",
+    "post_game_",
+    "post_",
+    "live_",
+    "actual_",
+    "realized_",
+    "final_",
+    "postmatch_",
+)
+_BASE_BANNED_SUFFIXES = (
+    "_post",
+    "_postgame",
+    "_final",
+    "_fullgame",
+    "_actual",
+)
+_BASE_BANNED_REGEX: tuple[tuple[re.Pattern[str], str], ...] = (
+    (re.compile(r".*post.?game.*", flags=re.IGNORECASE), "postgame marker"),
+    (re.compile(r".*final_score.*", flags=re.IGNORECASE), "final score"),
+    (re.compile(r".*actual.*td.*", flags=re.IGNORECASE), "actual TD total"),
+    (re.compile(r".*anytime_td.*(post|final|actual).*", flags=re.IGNORECASE), "post-decision anytime TD"),
+    (re.compile(r".*fullgame.*", flags=re.IGNORECASE), "full game cumulative value"),
+)
+
+DEFAULT_LEAK_POLICY = LeakPolicy(
+    version="v1",
+    description="Core post-outcome leak guard for NFL anytime TD features.",
+    banned_exact=_BASE_BANNED_EXACT,
+    banned_prefixes=_BASE_BANNED_PREFIXES,
+    banned_suffixes=_BASE_BANNED_SUFFIXES,
+    banned_regex=_BASE_BANNED_REGEX,
+)
+
+
+def _ensure_sequence(value: Sequence[str] | str | None) -> tuple[str, ...]:
+    if value is None:
+        return ()
+    if isinstance(value, str):
+        return (value,)
+    return tuple(value)
+
+
+def evaluate_leak_prone_columns(
+    columns: Iterable[str],
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+) -> LeakCheckResult:
+    """Identify leak-prone columns using the configured policy."""
+
+    banned: dict[str, str] = {}
+    columns_list = list(columns)
+    for col in columns_list:
+        if col in policy.banned_exact:
+            banned[col] = "exact"
+            continue
+        for prefix in policy.banned_prefixes:
+            if col.startswith(prefix):
+                banned[col] = f"prefix:{prefix}"
+                break
+        if col in banned:
+            continue
+        for suffix in policy.banned_suffixes:
+            if col.endswith(suffix):
+                banned[col] = f"suffix:{suffix}"
+                break
+        if col in banned:
+            continue
+        for pattern, reason in policy.banned_regex:
+            if pattern.match(col):
+                banned[col] = reason
+                break
+
+    kept = [c for c in columns_list if c not in banned]
+    return LeakCheckResult(
+        policy_version=policy.version,
+        banned=banned,
+        kept=kept,
+        dropped=[],
+        allowlist_kept=[],
+    )
+
+
+def enforce_leak_guard(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    allow_prefixes: Sequence[str] | str | None = None,
+    allow_exact: Sequence[str] | str | None = None,
+    drop_banned: bool = True,
+    drop_non_allowlisted: bool = False,
+    raise_on_banned: bool = True,
+) -> tuple[pl.DataFrame | "pd.DataFrame", LeakCheckResult]:
+    """Apply leak guardrails to a feature frame.
+
+    Parameters
+    ----------
+    df : DataFrame
+        Polars or pandas DataFrame.
+    policy : LeakPolicy
+        Leak policy to apply.
+    allow_prefixes : Sequence[str] | str | None
+        Optional prefixes that define the allowed feature surface for a problem.
+    allow_exact : Sequence[str] | str | None
+        Explicitly allowed columns (e.g., identifiers).
+    drop_banned : bool
+        If True, drop any banned columns automatically.
+    drop_non_allowlisted : bool
+        If True, drop columns that are not covered by allow_prefixes/allow_exact/identifiers/targets.
+    raise_on_banned : bool
+        If True, raise when banned columns are detected (after optional drop).
+    """
+
+    result = evaluate_leak_prone_columns(df.columns, policy=policy)
+    dropped: list[str] = []
+
+    allow_prefixes = _ensure_sequence(allow_prefixes)
+    allow_exact = set(_ensure_sequence(allow_exact))
+    allow_exact.update({col for col in IDENTIFIER_COLUMNS if col in df.columns})
+    allow_exact.update({col for col in NFL_TARGET_COLUMNS if col in df.columns})
+
+    # Permit allowlisted columns even if they match a banned rule (e.g., labels)
+    banned = {col: reason for col, reason in result.banned.items() if col not in allow_exact}
+
+    if banned and drop_banned:
+        df = df.drop(list(banned.keys()))
+        dropped.extend(banned.keys())
+
+    if banned and raise_on_banned:
+        raise ValueError(f"Leak-prone columns detected: {sorted(banned.items())}")
+
+    allowlist_cols: set[str] = set()
+    if allow_prefixes:
+        allowlist_cols.update({c for c in df.columns if c.startswith(allow_prefixes)})
+    allowlist_cols.update({c for c in allow_exact if c in df.columns})
+
+    if drop_non_allowlisted and allowlist_cols:
+        drop_candidates = [c for c in df.columns if c not in allowlist_cols]
+        if drop_candidates:
+            df = df.drop(drop_candidates)
+            dropped.extend(drop_candidates)
+
+    if drop_non_allowlisted and not allowlist_cols:
+        raise ValueError("No allowlisted columns remain after applying leak guard allowlist.")
+
+    # Store adjusted banned info on the result
+    result.banned = banned
+    result.dropped = dropped
+    result.kept = [c for c in df.columns]
+    result.allowlist_kept = sorted(list(allowlist_cols)) if allowlist_cols else []
+    return df, result
+
+
+def build_schema_snapshot(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    metadata: Mapping[str, object] | None = None,
+    banned: Mapping[str, str] | None = None,
+) -> dict:
+    """Render a schema snapshot describing each column and whether it was flagged."""
+
+    banned = banned or {}
+    meta = {
+        "generated_at_utc": datetime.utcnow().isoformat(),
+        "policy_version": policy.version,
+    }
+    meta.update(metadata or {})
+
+    # Extract columns / dtypes
+    if isinstance(df, pl.DataFrame):
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+    else:  # pandas or pandas-like
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+
+    schema = {
+        "metadata": meta,
+        "columns": [],
+    }
+
+    for col, dtype in cols_and_dtypes:
+        tags: list[str] = []
+        if col in IDENTIFIER_COLUMNS:
+            tags.append("id")
+        if col in NFL_TARGET_COLUMNS:
+            tags.append("label")
+        if col.startswith("market_"):
+            tags.append("odds")
+        if col.startswith("injury_") or col.startswith("practice_"):
+            tags.append("injury")
+        if col.startswith("weather_"):
+            tags.append("weather")
+        if col.startswith("ps_"):
+            tags.append("pre_snap")
+        schema["columns"].append(
+            {
+                "name": col,
+                "dtype": dtype,
+                "banned": col in banned,
+                "tags": tags,
+            }
+        )
+    return schema
+
+
+def write_schema_snapshot(path, schema: Mapping[str, object]) -> None:
+    path.parent.mkdir(parents=True, exist_ok=True)
+    with open(path, "w") as fp:
+        json.dump(schema, fp, indent=2, sort_keys=True)
+
+
+__all__ = [
+    "DEFAULT_LEAK_POLICY",
+    "LeakPolicy",
+    "LeakCheckResult",
+    "evaluate_leak_prone_columns",
+    "enforce_leak_guard",
+    "build_schema_snapshot",
+    "write_schema_snapshot",
+]
diff --git a/utils/general/constants.py b/utils/general/constants.py
index d94b4260ad877484da843fa99ae2caf37e8493f4..dea87caa354d94e4a08b1762d2bd8dcd4c8caa3a
--- a/utils/general/constants.py
+++ b/utils/general/constants.py
@@ -211,7 +211,17 @@
 
 NFL_TARGET_COLUMNS: Tuple[str, ...] = (
     'anytime_td',
+    'anytime_td_offense',
+    'anytime_td_all',
+    'anytime_td_rush',
+    'anytime_td_rec',
+    'anytime_td_pass_thrown',
     'td_count',
+    'td_count_offense',
+    'td_count_all',
+    'passing_td',
+    'rushing_td_count',
+    'receiving_td_count',
     'receiving_yards',
     'rushing_yards',
     'passing_yards',


thinking
**Planning method insertion and implementation details**

I'm pinpointing the best place to insert a new _filter_odds_snapshot_columns method between existing methods in the code around lines 760-804 using apply_patch. This method needs to handle pandas DataFrames by filtering columns based on a horizon key, with some string suffix logic and careful column dropping. I’m also considering how to interpret horizon_key values, like mapping certain patterns to "cutoff".

thinking
**Planning horizon suffix mapping**
file update:
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 5ba68e8bf1acd3a789a76a8857674e6f6433017b..0210d5b7e7ed60a8de7a126d64f5ed76326474c8
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -14,7 +14,7 @@
 
 import logging
 import os
-from datetime import date, timedelta
+from datetime import date, datetime, timedelta
 from typing import Sequence
 
 import polars as pl
@@ -37,6 +37,12 @@
     add_offense_context_features_training,
     _append_offense_context_columns,
 )
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    build_schema_snapshot,
+    enforce_leak_guard,
+    write_schema_snapshot,
+)
 from utils.feature.weather_features import (
     add_weather_forecast_features_training,
     append_weather_context_flags,
@@ -931,6 +937,32 @@
     if market_exprs:
         df_player_game_all = df_player_game_all.with_columns(market_exprs)
     
+    # Leak guard + schema snapshot before persisting
+    spec = get_label_spec(label_version)
+    allow_exact = {spec.primary, *spec.labels.keys(), *spec.aliases.keys()}
+    df_player_game_all, leak_result = enforce_leak_guard(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_exact=allow_exact,
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=True,
+    )
+
+    schema = build_schema_snapshot(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        metadata={
+            "cutoff_label": cutoff_label,
+            "label_version": spec.name,
+        },
+        banned=leak_result.banned,
+    )
+    schema_dir = FEATURE_AUDIT_DIR / "schema" / "anytime_td"
+    schema_path = schema_dir / f"{cutoff_label}_{datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')}.json"
+    write_schema_snapshot(schema_path, schema)
+    logging.info("    Schema snapshot written → %s", schema_path)
+
     # Write final feature matrix
     df_player_game_all = df_player_game_all.with_columns(
         pl.lit(current_cutoff_hours).cast(pl.Float32).alias("decision_horizon_hours")
@@ -951,7 +983,6 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    spec = get_label_spec(label_version)
     label_candidates = {spec.primary, "anytime_td"}
     for label_col in label_candidates:
         if label_col in df_player_game_all.columns:
diff --git a/pipeline/train.py b/pipeline/train.py
index fe70207dcdf25d209ee3ad55080b7ce826347c44..d441717695a21ed0a286a5721d248a60c73c68e4
--- a/pipeline/train.py
+++ b/pipeline/train.py
@@ -4,6 +4,7 @@
 import sys
 import logging
 import math
+import re
 
 
 # Move logging to top and remove global thread pinning
@@ -98,6 +99,7 @@
     fit_team_conformal_sums,
     composite_sum_interval,
 )
+from utils.feature.leak_guard import DEFAULT_LEAK_POLICY, enforce_leak_guard
 from utils.feature.targets import require_target_column
 
 # Ignore specific, noisy warnings from dependencies
@@ -2315,7 +2317,30 @@
                             df_problem[col] = df_problem[col].fillna(df_problem[col].mean())
 
                 df_problem = self._inject_composed_features(df_problem)
-            
+
+            # Leak guard on the problem-scoped frame
+            allow_prefixes = tuple(problem_copy.get('feature_prefixes_to_include') or [])
+            allow_exact = set(problem_copy.get('other_features_to_include') or [])
+            allow_exact.update(input_preds or [])
+            if self.target_col:
+                allow_exact.add(self.target_col)
+            df_problem, leak_info = enforce_leak_guard(
+                df_problem,
+                policy=DEFAULT_LEAK_POLICY,
+                allow_prefixes=allow_prefixes,
+                allow_exact=allow_exact,
+                drop_banned=True,
+                drop_non_allowlisted=False,
+                raise_on_banned=True,
+            )
+            if leak_info.dropped:
+                logger.info(
+                    "Dropped %d leak-prone columns for %s: %s",
+                    len(leak_info.dropped),
+                    problem_name,
+                    sorted(leak_info.dropped),
+                )
+
             self._normalize_datetime_like_columns(df_problem, problem_name)
             df_problem[self.time_col] = pd.to_datetime(df_problem[self.time_col])
             sort_cols = [self.time_col]
diff --git a/tests/test_data_leak_guard.py b/tests/test_data_leak_guard.py
index 8061f2760c0898aaeda29026859e1b9ff5644ba4..3e56665921db89ea523bbdb205d1bb90c21893df
--- a/tests/test_data_leak_guard.py
+++ b/tests/test_data_leak_guard.py
@@ -3,6 +3,14 @@
 import yaml
 from pathlib import Path
 
+import polars as pl
+
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    enforce_leak_guard,
+    evaluate_leak_prone_columns,
+)
+
 
 PROJECT_ROOT = Path(__file__).resolve().parents[1]
 TRAINING_CONFIG = PROJECT_ROOT / "config" / "training.yaml"
@@ -48,3 +56,41 @@
     )
 
 
+def test_leak_guard_flags_pattern_columns():
+    cols = [
+        "market_anytime_td_prob",
+        "final_score",
+        "postgame_anytime_td",
+        "actual_td_count",
+        "safe_feature",
+    ]
+    result = evaluate_leak_prone_columns(cols, policy=DEFAULT_LEAK_POLICY)
+    assert set(result.banned.keys()) == {"final_score", "postgame_anytime_td", "actual_td_count"}
+    assert "safe_feature" in result.kept
+    assert "market_anytime_td_prob" in result.kept
+
+
+def test_enforce_leak_guard_drops_banned_and_keeps_allowlisted():
+    df = pl.DataFrame(
+        {
+            "game_id": ["g1", "g2"],
+            "safe_feature": [1.0, 2.0],
+            "postgame_anytime_td": [1, 0],
+            "final_score": [30, 24],
+        }
+    )
+    cleaned, info = enforce_leak_guard(
+        df,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_prefixes=("safe_",),
+        allow_exact=("game_id",),
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=False,
+    )
+    assert "postgame_anytime_td" not in cleaned.columns
+    assert "final_score" not in cleaned.columns
+    assert "safe_feature" in cleaned.columns
+    assert "game_id" in cleaned.columns
+    assert set(info.dropped) == {"postgame_anytime_td", "final_score"}
+
diff --git a/utils/feature/leak_guard.py b/utils/feature/leak_guard.py
new file mode 100644
index 0000000000000000000000000000000000000000..9faf8cfffc436e0934b2f410aaf252e52f4f95df
--- /dev/null
+++ b/utils/feature/leak_guard.py
@@ -0,0 +1,273 @@
+"""Leak guardrails for feature matrices.
+
+This module centralizes pattern-based leak detection so both feature assembly
+and training can fail fast when post-outcome columns sneak into the data.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+from datetime import datetime
+import json
+import re
+from typing import Iterable, Mapping, Sequence
+
+import polars as pl
+
+from utils.general.constants import IDENTIFIER_COLUMNS, LEAK_PRONE_COLUMNS, NFL_TARGET_COLUMNS
+
+try:  # Optional dependency when imported from training (pandas path)
+    import pandas as pd  # type: ignore
+except Exception:  # pragma: no cover - optional dependency
+    pd = None
+
+
+@dataclass(frozen=True)
+class LeakPolicy:
+    version: str
+    banned_exact: set[str]
+    banned_prefixes: tuple[str, ...]
+    banned_suffixes: tuple[str, ...]
+    banned_regex: tuple[tuple[re.Pattern[str], str], ...]
+    description: str = ""
+
+
+@dataclass
+class LeakCheckResult:
+    policy_version: str
+    banned: dict[str, str]
+    kept: list[str]
+    dropped: list[str]
+    allowlist_kept: list[str]
+
+
+# Core policy tuned for anytime-TD style problems (can be extended per-problem).
+_BASE_BANNED_EXACT = set(LEAK_PRONE_COLUMNS) | {
+    "final_score",
+    "final_total",
+    "points_scored",
+    "actual_td_count",
+    "actual_anytime_td",
+    "postgame_anytime_td",
+    "postgame_td_count",
+}
+_BASE_BANNED_PREFIXES = (
+    "postgame_",
+    "post_game_",
+    "post_",
+    "live_",
+    "actual_",
+    "realized_",
+    "final_",
+    "postmatch_",
+)
+_BASE_BANNED_SUFFIXES = (
+    "_post",
+    "_postgame",
+    "_final",
+    "_fullgame",
+    "_actual",
+)
+_BASE_BANNED_REGEX: tuple[tuple[re.Pattern[str], str], ...] = (
+    (re.compile(r".*post.?game.*", flags=re.IGNORECASE), "postgame marker"),
+    (re.compile(r".*final_score.*", flags=re.IGNORECASE), "final score"),
+    (re.compile(r".*actual.*td.*", flags=re.IGNORECASE), "actual TD total"),
+    (re.compile(r".*anytime_td.*(post|final|actual).*", flags=re.IGNORECASE), "post-decision anytime TD"),
+    (re.compile(r".*fullgame.*", flags=re.IGNORECASE), "full game cumulative value"),
+)
+
+DEFAULT_LEAK_POLICY = LeakPolicy(
+    version="v1",
+    description="Core post-outcome leak guard for NFL anytime TD features.",
+    banned_exact=_BASE_BANNED_EXACT,
+    banned_prefixes=_BASE_BANNED_PREFIXES,
+    banned_suffixes=_BASE_BANNED_SUFFIXES,
+    banned_regex=_BASE_BANNED_REGEX,
+)
+
+
+def _ensure_sequence(value: Sequence[str] | str | None) -> tuple[str, ...]:
+    if value is None:
+        return ()
+    if isinstance(value, str):
+        return (value,)
+    return tuple(value)
+
+
+def evaluate_leak_prone_columns(
+    columns: Iterable[str],
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+) -> LeakCheckResult:
+    """Identify leak-prone columns using the configured policy."""
+
+    banned: dict[str, str] = {}
+    columns_list = list(columns)
+    for col in columns_list:
+        if col in policy.banned_exact:
+            banned[col] = "exact"
+            continue
+        for prefix in policy.banned_prefixes:
+            if col.startswith(prefix):
+                banned[col] = f"prefix:{prefix}"
+                break
+        if col in banned:
+            continue
+        for suffix in policy.banned_suffixes:
+            if col.endswith(suffix):
+                banned[col] = f"suffix:{suffix}"
+                break
+        if col in banned:
+            continue
+        for pattern, reason in policy.banned_regex:
+            if pattern.match(col):
+                banned[col] = reason
+                break
+
+    kept = [c for c in columns_list if c not in banned]
+    return LeakCheckResult(
+        policy_version=policy.version,
+        banned=banned,
+        kept=kept,
+        dropped=[],
+        allowlist_kept=[],
+    )
+
+
+def enforce_leak_guard(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    allow_prefixes: Sequence[str] | str | None = None,
+    allow_exact: Sequence[str] | str | None = None,
+    drop_banned: bool = True,
+    drop_non_allowlisted: bool = False,
+    raise_on_banned: bool = True,
+) -> tuple[pl.DataFrame | "pd.DataFrame", LeakCheckResult]:
+    """Apply leak guardrails to a feature frame.
+
+    Parameters
+    ----------
+    df : DataFrame
+        Polars or pandas DataFrame.
+    policy : LeakPolicy
+        Leak policy to apply.
+    allow_prefixes : Sequence[str] | str | None
+        Optional prefixes that define the allowed feature surface for a problem.
+    allow_exact : Sequence[str] | str | None
+        Explicitly allowed columns (e.g., identifiers).
+    drop_banned : bool
+        If True, drop any banned columns automatically.
+    drop_non_allowlisted : bool
+        If True, drop columns that are not covered by allow_prefixes/allow_exact/identifiers/targets.
+    raise_on_banned : bool
+        If True, raise when banned columns are detected (after optional drop).
+    """
+
+    result = evaluate_leak_prone_columns(df.columns, policy=policy)
+    dropped: list[str] = []
+
+    allow_prefixes = _ensure_sequence(allow_prefixes)
+    allow_exact = set(_ensure_sequence(allow_exact))
+    allow_exact.update({col for col in IDENTIFIER_COLUMNS if col in df.columns})
+    allow_exact.update({col for col in NFL_TARGET_COLUMNS if col in df.columns})
+
+    # Permit allowlisted columns even if they match a banned rule (e.g., labels)
+    banned = {col: reason for col, reason in result.banned.items() if col not in allow_exact}
+
+    if banned and drop_banned:
+        df = df.drop(list(banned.keys()))
+        dropped.extend(banned.keys())
+
+    if banned and raise_on_banned:
+        raise ValueError(f"Leak-prone columns detected: {sorted(banned.items())}")
+
+    allowlist_cols: set[str] = set()
+    if allow_prefixes:
+        allowlist_cols.update({c for c in df.columns if c.startswith(allow_prefixes)})
+    allowlist_cols.update({c for c in allow_exact if c in df.columns})
+
+    if drop_non_allowlisted and allowlist_cols:
+        drop_candidates = [c for c in df.columns if c not in allowlist_cols]
+        if drop_candidates:
+            df = df.drop(drop_candidates)
+            dropped.extend(drop_candidates)
+
+    if drop_non_allowlisted and not allowlist_cols:
+        raise ValueError("No allowlisted columns remain after applying leak guard allowlist.")
+
+    # Store adjusted banned info on the result
+    result.banned = banned
+    result.dropped = dropped
+    result.kept = [c for c in df.columns]
+    result.allowlist_kept = sorted(list(allowlist_cols)) if allowlist_cols else []
+    return df, result
+
+
+def build_schema_snapshot(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    metadata: Mapping[str, object] | None = None,
+    banned: Mapping[str, str] | None = None,
+) -> dict:
+    """Render a schema snapshot describing each column and whether it was flagged."""
+
+    banned = banned or {}
+    meta = {
+        "generated_at_utc": datetime.utcnow().isoformat(),
+        "policy_version": policy.version,
+    }
+    meta.update(metadata or {})
+
+    # Extract columns / dtypes
+    if isinstance(df, pl.DataFrame):
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+    else:  # pandas or pandas-like
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+
+    schema = {
+        "metadata": meta,
+        "columns": [],
+    }
+
+    for col, dtype in cols_and_dtypes:
+        tags: list[str] = []
+        if col in IDENTIFIER_COLUMNS:
+            tags.append("id")
+        if col in NFL_TARGET_COLUMNS:
+            tags.append("label")
+        if col.startswith("market_"):
+            tags.append("odds")
+        if col.startswith("injury_") or col.startswith("practice_"):
+            tags.append("injury")
+        if col.startswith("weather_"):
+            tags.append("weather")
+        if col.startswith("ps_"):
+            tags.append("pre_snap")
+        schema["columns"].append(
+            {
+                "name": col,
+                "dtype": dtype,
+                "banned": col in banned,
+                "tags": tags,
+            }
+        )
+    return schema
+
+
+def write_schema_snapshot(path, schema: Mapping[str, object]) -> None:
+    path.parent.mkdir(parents=True, exist_ok=True)
+    with open(path, "w") as fp:
+        json.dump(schema, fp, indent=2, sort_keys=True)
+
+
+__all__ = [
+    "DEFAULT_LEAK_POLICY",
+    "LeakPolicy",
+    "LeakCheckResult",
+    "evaluate_leak_prone_columns",
+    "enforce_leak_guard",
+    "build_schema_snapshot",
+    "write_schema_snapshot",
+]
diff --git a/utils/general/constants.py b/utils/general/constants.py
index d94b4260ad877484da843fa99ae2caf37e8493f4..dea87caa354d94e4a08b1762d2bd8dcd4c8caa3a
--- a/utils/general/constants.py
+++ b/utils/general/constants.py
@@ -211,7 +211,17 @@
 
 NFL_TARGET_COLUMNS: Tuple[str, ...] = (
     'anytime_td',
+    'anytime_td_offense',
+    'anytime_td_all',
+    'anytime_td_rush',
+    'anytime_td_rec',
+    'anytime_td_pass_thrown',
     'td_count',
+    'td_count_offense',
+    'td_count_all',
+    'passing_td',
+    'rushing_td_count',
+    'receiving_td_count',
     'receiving_yards',
     'rushing_yards',
     'passing_yards',


thinking
**Adjusting patch application context**
file update:
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 5ba68e8bf1acd3a789a76a8857674e6f6433017b..0210d5b7e7ed60a8de7a126d64f5ed76326474c8
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -14,7 +14,7 @@
 
 import logging
 import os
-from datetime import date, timedelta
+from datetime import date, datetime, timedelta
 from typing import Sequence
 
 import polars as pl
@@ -37,6 +37,12 @@
     add_offense_context_features_training,
     _append_offense_context_columns,
 )
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    build_schema_snapshot,
+    enforce_leak_guard,
+    write_schema_snapshot,
+)
 from utils.feature.weather_features import (
     add_weather_forecast_features_training,
     append_weather_context_flags,
@@ -931,6 +937,32 @@
     if market_exprs:
         df_player_game_all = df_player_game_all.with_columns(market_exprs)
     
+    # Leak guard + schema snapshot before persisting
+    spec = get_label_spec(label_version)
+    allow_exact = {spec.primary, *spec.labels.keys(), *spec.aliases.keys()}
+    df_player_game_all, leak_result = enforce_leak_guard(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_exact=allow_exact,
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=True,
+    )
+
+    schema = build_schema_snapshot(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        metadata={
+            "cutoff_label": cutoff_label,
+            "label_version": spec.name,
+        },
+        banned=leak_result.banned,
+    )
+    schema_dir = FEATURE_AUDIT_DIR / "schema" / "anytime_td"
+    schema_path = schema_dir / f"{cutoff_label}_{datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')}.json"
+    write_schema_snapshot(schema_path, schema)
+    logging.info("    Schema snapshot written → %s", schema_path)
+
     # Write final feature matrix
     df_player_game_all = df_player_game_all.with_columns(
         pl.lit(current_cutoff_hours).cast(pl.Float32).alias("decision_horizon_hours")
@@ -951,7 +983,6 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    spec = get_label_spec(label_version)
     label_candidates = {spec.primary, "anytime_td"}
     for label_col in label_candidates:
         if label_col in df_player_game_all.columns:
diff --git a/pipeline/train.py b/pipeline/train.py
index fe70207dcdf25d209ee3ad55080b7ce826347c44..d441717695a21ed0a286a5721d248a60c73c68e4
--- a/pipeline/train.py
+++ b/pipeline/train.py
@@ -4,6 +4,7 @@
 import sys
 import logging
 import math
+import re
 
 
 # Move logging to top and remove global thread pinning
@@ -98,6 +99,7 @@
     fit_team_conformal_sums,
     composite_sum_interval,
 )
+from utils.feature.leak_guard import DEFAULT_LEAK_POLICY, enforce_leak_guard
 from utils.feature.targets import require_target_column
 
 # Ignore specific, noisy warnings from dependencies
@@ -2315,7 +2317,30 @@
                             df_problem[col] = df_problem[col].fillna(df_problem[col].mean())
 
                 df_problem = self._inject_composed_features(df_problem)
-            
+
+            # Leak guard on the problem-scoped frame
+            allow_prefixes = tuple(problem_copy.get('feature_prefixes_to_include') or [])
+            allow_exact = set(problem_copy.get('other_features_to_include') or [])
+            allow_exact.update(input_preds or [])
+            if self.target_col:
+                allow_exact.add(self.target_col)
+            df_problem, leak_info = enforce_leak_guard(
+                df_problem,
+                policy=DEFAULT_LEAK_POLICY,
+                allow_prefixes=allow_prefixes,
+                allow_exact=allow_exact,
+                drop_banned=True,
+                drop_non_allowlisted=False,
+                raise_on_banned=True,
+            )
+            if leak_info.dropped:
+                logger.info(
+                    "Dropped %d leak-prone columns for %s: %s",
+                    len(leak_info.dropped),
+                    problem_name,
+                    sorted(leak_info.dropped),
+                )
+
             self._normalize_datetime_like_columns(df_problem, problem_name)
             df_problem[self.time_col] = pd.to_datetime(df_problem[self.time_col])
             sort_cols = [self.time_col]
diff --git a/tests/test_data_leak_guard.py b/tests/test_data_leak_guard.py
index 8061f2760c0898aaeda29026859e1b9ff5644ba4..3e56665921db89ea523bbdb205d1bb90c21893df
--- a/tests/test_data_leak_guard.py
+++ b/tests/test_data_leak_guard.py
@@ -3,6 +3,14 @@
 import yaml
 from pathlib import Path
 
+import polars as pl
+
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    enforce_leak_guard,
+    evaluate_leak_prone_columns,
+)
+
 
 PROJECT_ROOT = Path(__file__).resolve().parents[1]
 TRAINING_CONFIG = PROJECT_ROOT / "config" / "training.yaml"
@@ -48,3 +56,41 @@
     )
 
 
+def test_leak_guard_flags_pattern_columns():
+    cols = [
+        "market_anytime_td_prob",
+        "final_score",
+        "postgame_anytime_td",
+        "actual_td_count",
+        "safe_feature",
+    ]
+    result = evaluate_leak_prone_columns(cols, policy=DEFAULT_LEAK_POLICY)
+    assert set(result.banned.keys()) == {"final_score", "postgame_anytime_td", "actual_td_count"}
+    assert "safe_feature" in result.kept
+    assert "market_anytime_td_prob" in result.kept
+
+
+def test_enforce_leak_guard_drops_banned_and_keeps_allowlisted():
+    df = pl.DataFrame(
+        {
+            "game_id": ["g1", "g2"],
+            "safe_feature": [1.0, 2.0],
+            "postgame_anytime_td": [1, 0],
+            "final_score": [30, 24],
+        }
+    )
+    cleaned, info = enforce_leak_guard(
+        df,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_prefixes=("safe_",),
+        allow_exact=("game_id",),
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=False,
+    )
+    assert "postgame_anytime_td" not in cleaned.columns
+    assert "final_score" not in cleaned.columns
+    assert "safe_feature" in cleaned.columns
+    assert "game_id" in cleaned.columns
+    assert set(info.dropped) == {"postgame_anytime_td", "final_score"}
+
diff --git a/utils/feature/leak_guard.py b/utils/feature/leak_guard.py
new file mode 100644
index 0000000000000000000000000000000000000000..9faf8cfffc436e0934b2f410aaf252e52f4f95df
--- /dev/null
+++ b/utils/feature/leak_guard.py
@@ -0,0 +1,273 @@
+"""Leak guardrails for feature matrices.
+
+This module centralizes pattern-based leak detection so both feature assembly
+and training can fail fast when post-outcome columns sneak into the data.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+from datetime import datetime
+import json
+import re
+from typing import Iterable, Mapping, Sequence
+
+import polars as pl
+
+from utils.general.constants import IDENTIFIER_COLUMNS, LEAK_PRONE_COLUMNS, NFL_TARGET_COLUMNS
+
+try:  # Optional dependency when imported from training (pandas path)
+    import pandas as pd  # type: ignore
+except Exception:  # pragma: no cover - optional dependency
+    pd = None
+
+
+@dataclass(frozen=True)
+class LeakPolicy:
+    version: str
+    banned_exact: set[str]
+    banned_prefixes: tuple[str, ...]
+    banned_suffixes: tuple[str, ...]
+    banned_regex: tuple[tuple[re.Pattern[str], str], ...]
+    description: str = ""
+
+
+@dataclass
+class LeakCheckResult:
+    policy_version: str
+    banned: dict[str, str]
+    kept: list[str]
+    dropped: list[str]
+    allowlist_kept: list[str]
+
+
+# Core policy tuned for anytime-TD style problems (can be extended per-problem).
+_BASE_BANNED_EXACT = set(LEAK_PRONE_COLUMNS) | {
+    "final_score",
+    "final_total",
+    "points_scored",
+    "actual_td_count",
+    "actual_anytime_td",
+    "postgame_anytime_td",
+    "postgame_td_count",
+}
+_BASE_BANNED_PREFIXES = (
+    "postgame_",
+    "post_game_",
+    "post_",
+    "live_",
+    "actual_",
+    "realized_",
+    "final_",
+    "postmatch_",
+)
+_BASE_BANNED_SUFFIXES = (
+    "_post",
+    "_postgame",
+    "_final",
+    "_fullgame",
+    "_actual",
+)
+_BASE_BANNED_REGEX: tuple[tuple[re.Pattern[str], str], ...] = (
+    (re.compile(r".*post.?game.*", flags=re.IGNORECASE), "postgame marker"),
+    (re.compile(r".*final_score.*", flags=re.IGNORECASE), "final score"),
+    (re.compile(r".*actual.*td.*", flags=re.IGNORECASE), "actual TD total"),
+    (re.compile(r".*anytime_td.*(post|final|actual).*", flags=re.IGNORECASE), "post-decision anytime TD"),
+    (re.compile(r".*fullgame.*", flags=re.IGNORECASE), "full game cumulative value"),
+)
+
+DEFAULT_LEAK_POLICY = LeakPolicy(
+    version="v1",
+    description="Core post-outcome leak guard for NFL anytime TD features.",
+    banned_exact=_BASE_BANNED_EXACT,
+    banned_prefixes=_BASE_BANNED_PREFIXES,
+    banned_suffixes=_BASE_BANNED_SUFFIXES,
+    banned_regex=_BASE_BANNED_REGEX,
+)
+
+
+def _ensure_sequence(value: Sequence[str] | str | None) -> tuple[str, ...]:
+    if value is None:
+        return ()
+    if isinstance(value, str):
+        return (value,)
+    return tuple(value)
+
+
+def evaluate_leak_prone_columns(
+    columns: Iterable[str],
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+) -> LeakCheckResult:
+    """Identify leak-prone columns using the configured policy."""
+
+    banned: dict[str, str] = {}
+    columns_list = list(columns)
+    for col in columns_list:
+        if col in policy.banned_exact:
+            banned[col] = "exact"
+            continue
+        for prefix in policy.banned_prefixes:
+            if col.startswith(prefix):
+                banned[col] = f"prefix:{prefix}"
+                break
+        if col in banned:
+            continue
+        for suffix in policy.banned_suffixes:
+            if col.endswith(suffix):
+                banned[col] = f"suffix:{suffix}"
+                break
+        if col in banned:
+            continue
+        for pattern, reason in policy.banned_regex:
+            if pattern.match(col):
+                banned[col] = reason
+                break
+
+    kept = [c for c in columns_list if c not in banned]
+    return LeakCheckResult(
+        policy_version=policy.version,
+        banned=banned,
+        kept=kept,
+        dropped=[],
+        allowlist_kept=[],
+    )
+
+
+def enforce_leak_guard(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    allow_prefixes: Sequence[str] | str | None = None,
+    allow_exact: Sequence[str] | str | None = None,
+    drop_banned: bool = True,
+    drop_non_allowlisted: bool = False,
+    raise_on_banned: bool = True,
+) -> tuple[pl.DataFrame | "pd.DataFrame", LeakCheckResult]:
+    """Apply leak guardrails to a feature frame.
+
+    Parameters
+    ----------
+    df : DataFrame
+        Polars or pandas DataFrame.
+    policy : LeakPolicy
+        Leak policy to apply.
+    allow_prefixes : Sequence[str] | str | None
+        Optional prefixes that define the allowed feature surface for a problem.
+    allow_exact : Sequence[str] | str | None
+        Explicitly allowed columns (e.g., identifiers).
+    drop_banned : bool
+        If True, drop any banned columns automatically.
+    drop_non_allowlisted : bool
+        If True, drop columns that are not covered by allow_prefixes/allow_exact/identifiers/targets.
+    raise_on_banned : bool
+        If True, raise when banned columns are detected (after optional drop).
+    """
+
+    result = evaluate_leak_prone_columns(df.columns, policy=policy)
+    dropped: list[str] = []
+
+    allow_prefixes = _ensure_sequence(allow_prefixes)
+    allow_exact = set(_ensure_sequence(allow_exact))
+    allow_exact.update({col for col in IDENTIFIER_COLUMNS if col in df.columns})
+    allow_exact.update({col for col in NFL_TARGET_COLUMNS if col in df.columns})
+
+    # Permit allowlisted columns even if they match a banned rule (e.g., labels)
+    banned = {col: reason for col, reason in result.banned.items() if col not in allow_exact}
+
+    if banned and drop_banned:
+        df = df.drop(list(banned.keys()))
+        dropped.extend(banned.keys())
+
+    if banned and raise_on_banned:
+        raise ValueError(f"Leak-prone columns detected: {sorted(banned.items())}")
+
+    allowlist_cols: set[str] = set()
+    if allow_prefixes:
+        allowlist_cols.update({c for c in df.columns if c.startswith(allow_prefixes)})
+    allowlist_cols.update({c for c in allow_exact if c in df.columns})
+
+    if drop_non_allowlisted and allowlist_cols:
+        drop_candidates = [c for c in df.columns if c not in allowlist_cols]
+        if drop_candidates:
+            df = df.drop(drop_candidates)
+            dropped.extend(drop_candidates)
+
+    if drop_non_allowlisted and not allowlist_cols:
+        raise ValueError("No allowlisted columns remain after applying leak guard allowlist.")
+
+    # Store adjusted banned info on the result
+    result.banned = banned
+    result.dropped = dropped
+    result.kept = [c for c in df.columns]
+    result.allowlist_kept = sorted(list(allowlist_cols)) if allowlist_cols else []
+    return df, result
+
+
+def build_schema_snapshot(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    metadata: Mapping[str, object] | None = None,
+    banned: Mapping[str, str] | None = None,
+) -> dict:
+    """Render a schema snapshot describing each column and whether it was flagged."""
+
+    banned = banned or {}
+    meta = {
+        "generated_at_utc": datetime.utcnow().isoformat(),
+        "policy_version": policy.version,
+    }
+    meta.update(metadata or {})
+
+    # Extract columns / dtypes
+    if isinstance(df, pl.DataFrame):
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+    else:  # pandas or pandas-like
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+
+    schema = {
+        "metadata": meta,
+        "columns": [],
+    }
+
+    for col, dtype in cols_and_dtypes:
+        tags: list[str] = []
+        if col in IDENTIFIER_COLUMNS:
+            tags.append("id")
+        if col in NFL_TARGET_COLUMNS:
+            tags.append("label")
+        if col.startswith("market_"):
+            tags.append("odds")
+        if col.startswith("injury_") or col.startswith("practice_"):
+            tags.append("injury")
+        if col.startswith("weather_"):
+            tags.append("weather")
+        if col.startswith("ps_"):
+            tags.append("pre_snap")
+        schema["columns"].append(
+            {
+                "name": col,
+                "dtype": dtype,
+                "banned": col in banned,
+                "tags": tags,
+            }
+        )
+    return schema
+
+
+def write_schema_snapshot(path, schema: Mapping[str, object]) -> None:
+    path.parent.mkdir(parents=True, exist_ok=True)
+    with open(path, "w") as fp:
+        json.dump(schema, fp, indent=2, sort_keys=True)
+
+
+__all__ = [
+    "DEFAULT_LEAK_POLICY",
+    "LeakPolicy",
+    "LeakCheckResult",
+    "evaluate_leak_prone_columns",
+    "enforce_leak_guard",
+    "build_schema_snapshot",
+    "write_schema_snapshot",
+]
diff --git a/utils/general/constants.py b/utils/general/constants.py
index d94b4260ad877484da843fa99ae2caf37e8493f4..dea87caa354d94e4a08b1762d2bd8dcd4c8caa3a
--- a/utils/general/constants.py
+++ b/utils/general/constants.py
@@ -211,7 +211,17 @@
 
 NFL_TARGET_COLUMNS: Tuple[str, ...] = (
     'anytime_td',
+    'anytime_td_offense',
+    'anytime_td_all',
+    'anytime_td_rush',
+    'anytime_td_rec',
+    'anytime_td_pass_thrown',
     'td_count',
+    'td_count_offense',
+    'td_count_all',
+    'passing_td',
+    'rushing_td_count',
+    'receiving_td_count',
     'receiving_yards',
     'rushing_yards',
     'passing_yards',


thinking
**Checking whitespace and indentation**
exec
/bin/zsh -lc "cd /Users/jameswest/Desktop/nfl_predict && sed -n '720,820p' pipeline/train.py" in /Users/jameswest/Desktop/nfl_predict succeeded in 695ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
        if "posteam" in df.columns:
            df.rename(columns={"posteam": "team"}, inplace=True)
        if "game_id" in df.columns:
            df["game_id"] = df["game_id"].astype(str)
            
        self._team_game_actuals = df
        logger.info("Loaded team-game actuals with %d rows.", len(df))
        return self._team_game_actuals

    def _derive_target_column(
        self,
        df: pd.DataFrame,
        target_col: str,
        derived_cfg: dict,
        problem_name: str,
    ) -> pd.DataFrame:
        source_col = derived_cfg.get("source_col")
        if not source_col:
            raise ValueError(f"Problem '{problem_name}' missing source_col for derived target.")
file update:
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 5ba68e8bf1acd3a789a76a8857674e6f6433017b..0210d5b7e7ed60a8de7a126d64f5ed76326474c8
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -14,7 +14,7 @@
 
 import logging
 import os
-from datetime import date, timedelta
+from datetime import date, datetime, timedelta
 from typing import Sequence
 
 import polars as pl
@@ -37,6 +37,12 @@
     add_offense_context_features_training,
     _append_offense_context_columns,
 )
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    build_schema_snapshot,
+    enforce_leak_guard,
+    write_schema_snapshot,
+)
 from utils.feature.weather_features import (
     add_weather_forecast_features_training,
     append_weather_context_flags,
@@ -931,6 +937,32 @@
     if market_exprs:
         df_player_game_all = df_player_game_all.with_columns(market_exprs)
     
+    # Leak guard + schema snapshot before persisting
+    spec = get_label_spec(label_version)
+    allow_exact = {spec.primary, *spec.labels.keys(), *spec.aliases.keys()}
+    df_player_game_all, leak_result = enforce_leak_guard(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_exact=allow_exact,
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=True,
+    )
+
+    schema = build_schema_snapshot(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        metadata={
+            "cutoff_label": cutoff_label,
+            "label_version": spec.name,
+        },
+        banned=leak_result.banned,
+    )
+    schema_dir = FEATURE_AUDIT_DIR / "schema" / "anytime_td"
+    schema_path = schema_dir / f"{cutoff_label}_{datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')}.json"
+    write_schema_snapshot(schema_path, schema)
+    logging.info("    Schema snapshot written → %s", schema_path)
+
     # Write final feature matrix
     df_player_game_all = df_player_game_all.with_columns(
         pl.lit(current_cutoff_hours).cast(pl.Float32).alias("decision_horizon_hours")
@@ -951,7 +983,6 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    spec = get_label_spec(label_version)
     label_candidates = {spec.primary, "anytime_td"}
     for label_col in label_candidates:
         if label_col in df_player_game_all.columns:
diff --git a/pipeline/train.py b/pipeline/train.py
index fe70207dcdf25d209ee3ad55080b7ce826347c44..d441717695a21ed0a286a5721d248a60c73c68e4
--- a/pipeline/train.py
+++ b/pipeline/train.py
@@ -4,6 +4,7 @@
 import sys
 import logging
 import math
+import re
 
 
 # Move logging to top and remove global thread pinning
@@ -98,6 +99,7 @@
     fit_team_conformal_sums,
     composite_sum_interval,
 )
+from utils.feature.leak_guard import DEFAULT_LEAK_POLICY, enforce_leak_guard
 from utils.feature.targets import require_target_column
 
 # Ignore specific, noisy warnings from dependencies
@@ -2315,7 +2317,30 @@
                             df_problem[col] = df_problem[col].fillna(df_problem[col].mean())
 
                 df_problem = self._inject_composed_features(df_problem)
-            
+
+            # Leak guard on the problem-scoped frame
+            allow_prefixes = tuple(problem_copy.get('feature_prefixes_to_include') or [])
+            allow_exact = set(problem_copy.get('other_features_to_include') or [])
+            allow_exact.update(input_preds or [])
+            if self.target_col:
+                allow_exact.add(self.target_col)
+            df_problem, leak_info = enforce_leak_guard(
+                df_problem,
+                policy=DEFAULT_LEAK_POLICY,
+                allow_prefixes=allow_prefixes,
+                allow_exact=allow_exact,
+                drop_banned=True,
+                drop_non_allowlisted=False,
+                raise_on_banned=True,
+            )
+            if leak_info.dropped:
+                logger.info(
+                    "Dropped %d leak-prone columns for %s: %s",
+                    len(leak_info.dropped),
+                    problem_name,
+                    sorted(leak_info.dropped),
+                )
+
             self._normalize_datetime_like_columns(df_problem, problem_name)
             df_problem[self.time_col] = pd.to_datetime(df_problem[self.time_col])
             sort_cols = [self.time_col]
diff --git a/tests/test_data_leak_guard.py b/tests/test_data_leak_guard.py
index 8061f2760c0898aaeda29026859e1b9ff5644ba4..3e56665921db89ea523bbdb205d1bb90c21893df
--- a/tests/test_data_leak_guard.py
+++ b/tests/test_data_leak_guard.py
@@ -3,6 +3,14 @@
 import yaml
 from pathlib import Path
 
+import polars as pl
+
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    enforce_leak_guard,
+    evaluate_leak_prone_columns,
+)
+
 
 PROJECT_ROOT = Path(__file__).resolve().parents[1]
 TRAINING_CONFIG = PROJECT_ROOT / "config" / "training.yaml"
@@ -48,3 +56,41 @@
     )
 
 
+def test_leak_guard_flags_pattern_columns():
+    cols = [
+        "market_anytime_td_prob",
+        "final_score",
+        "postgame_anytime_td",
+        "actual_td_count",
+        "safe_feature",
+    ]
+    result = evaluate_leak_prone_columns(cols, policy=DEFAULT_LEAK_POLICY)
+    assert set(result.banned.keys()) == {"final_score", "postgame_anytime_td", "actual_td_count"}
+    assert "safe_feature" in result.kept
+    assert "market_anytime_td_prob" in result.kept
+
+
+def test_enforce_leak_guard_drops_banned_and_keeps_allowlisted():
+    df = pl.DataFrame(
+        {
+            "game_id": ["g1", "g2"],
+            "safe_feature": [1.0, 2.0],
+            "postgame_anytime_td": [1, 0],
+            "final_score": [30, 24],
+        }
+    )
+    cleaned, info = enforce_leak_guard(
+        df,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_prefixes=("safe_",),
+        allow_exact=("game_id",),
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=False,
+    )
+    assert "postgame_anytime_td" not in cleaned.columns
+    assert "final_score" not in cleaned.columns
+    assert "safe_feature" in cleaned.columns
+    assert "game_id" in cleaned.columns
+    assert set(info.dropped) == {"postgame_anytime_td", "final_score"}
+
diff --git a/utils/feature/leak_guard.py b/utils/feature/leak_guard.py
new file mode 100644
index 0000000000000000000000000000000000000000..9faf8cfffc436e0934b2f410aaf252e52f4f95df
--- /dev/null
+++ b/utils/feature/leak_guard.py
@@ -0,0 +1,273 @@
+"""Leak guardrails for feature matrices.
+
+This module centralizes pattern-based leak detection so both feature assembly
+and training can fail fast when post-outcome columns sneak into the data.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+from datetime import datetime
+import json
+import re
+from typing import Iterable, Mapping, Sequence
+
+import polars as pl
+
+from utils.general.constants import IDENTIFIER_COLUMNS, LEAK_PRONE_COLUMNS, NFL_TARGET_COLUMNS
+
+try:  # Optional dependency when imported from training (pandas path)
+    import pandas as pd  # type: ignore
+except Exception:  # pragma: no cover - optional dependency
+    pd = None
+
+
+@dataclass(frozen=True)
+class LeakPolicy:
+    version: str
+    banned_exact: set[str]
+    banned_prefixes: tuple[str, ...]
+    banned_suffixes: tuple[str, ...]
+    banned_regex: tuple[tuple[re.Pattern[str], str], ...]
+    description: str = ""
+
+
+@dataclass
+class LeakCheckResult:
+    policy_version: str
+    banned: dict[str, str]
+    kept: list[str]
+    dropped: list[str]
+    allowlist_kept: list[str]
+
+
+# Core policy tuned for anytime-TD style problems (can be extended per-problem).
+_BASE_BANNED_EXACT = set(LEAK_PRONE_COLUMNS) | {
+    "final_score",
+    "final_total",
+    "points_scored",
+    "actual_td_count",
+    "actual_anytime_td",
+    "postgame_anytime_td",
+    "postgame_td_count",
+}
+_BASE_BANNED_PREFIXES = (
+    "postgame_",
+    "post_game_",
+    "post_",
+    "live_",
+    "actual_",
+    "realized_",
+    "final_",
+    "postmatch_",
+)
+_BASE_BANNED_SUFFIXES = (
+    "_post",
+    "_postgame",
+    "_final",
+    "_fullgame",
+    "_actual",
+)
+_BASE_BANNED_REGEX: tuple[tuple[re.Pattern[str], str], ...] = (
+    (re.compile(r".*post.?game.*", flags=re.IGNORECASE), "postgame marker"),
+    (re.compile(r".*final_score.*", flags=re.IGNORECASE), "final score"),
+    (re.compile(r".*actual.*td.*", flags=re.IGNORECASE), "actual TD total"),
+    (re.compile(r".*anytime_td.*(post|final|actual).*", flags=re.IGNORECASE), "post-decision anytime TD"),
+    (re.compile(r".*fullgame.*", flags=re.IGNORECASE), "full game cumulative value"),
+)
+
+DEFAULT_LEAK_POLICY = LeakPolicy(
+    version="v1",
+    description="Core post-outcome leak guard for NFL anytime TD features.",
+    banned_exact=_BASE_BANNED_EXACT,
+    banned_prefixes=_BASE_BANNED_PREFIXES,
+    banned_suffixes=_BASE_BANNED_SUFFIXES,
+    banned_regex=_BASE_BANNED_REGEX,
+)
+
+
+def _ensure_sequence(value: Sequence[str] | str | None) -> tuple[str, ...]:
+    if value is None:
+        return ()
+    if isinstance(value, str):
+        return (value,)
+    return tuple(value)
+
+
+def evaluate_leak_prone_columns(
+    columns: Iterable[str],
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+) -> LeakCheckResult:
+    """Identify leak-prone columns using the configured policy."""
+
+    banned: dict[str, str] = {}
+    columns_list = list(columns)
+    for col in columns_list:
+        if col in policy.banned_exact:
+            banned[col] = "exact"
+            continue
+        for prefix in policy.banned_prefixes:
+            if col.startswith(prefix):
+                banned[col] = f"prefix:{prefix}"
+                break
+        if col in banned:
+            continue
+        for suffix in policy.banned_suffixes:
+            if col.endswith(suffix):
+                banned[col] = f"suffix:{suffix}"
+                break
+        if col in banned:
+            continue
+        for pattern, reason in policy.banned_regex:
+            if pattern.match(col):
+                banned[col] = reason
+                break
+
+    kept = [c for c in columns_list if c not in banned]
+    return LeakCheckResult(
+        policy_version=policy.version,
+        banned=banned,
+        kept=kept,
+        dropped=[],
+        allowlist_kept=[],
+    )
+
+
+def enforce_leak_guard(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    allow_prefixes: Sequence[str] | str | None = None,
+    allow_exact: Sequence[str] | str | None = None,
+    drop_banned: bool = True,
+    drop_non_allowlisted: bool = False,
+    raise_on_banned: bool = True,
+) -> tuple[pl.DataFrame | "pd.DataFrame", LeakCheckResult]:
+    """Apply leak guardrails to a feature frame.
+
+    Parameters
+    ----------
+    df : DataFrame
+        Polars or pandas DataFrame.
+    policy : LeakPolicy
+        Leak policy to apply.
+    allow_prefixes : Sequence[str] | str | None
+        Optional prefixes that define the allowed feature surface for a problem.
+    allow_exact : Sequence[str] | str | None
+        Explicitly allowed columns (e.g., identifiers).
+    drop_banned : bool
+        If True, drop any banned columns automatically.
+    drop_non_allowlisted : bool
+        If True, drop columns that are not covered by allow_prefixes/allow_exact/identifiers/targets.
+    raise_on_banned : bool
+        If True, raise when banned columns are detected (after optional drop).
+    """
+
+    result = evaluate_leak_prone_columns(df.columns, policy=policy)
+    dropped: list[str] = []
+
+    allow_prefixes = _ensure_sequence(allow_prefixes)
+    allow_exact = set(_ensure_sequence(allow_exact))
+    allow_exact.update({col for col in IDENTIFIER_COLUMNS if col in df.columns})
+    allow_exact.update({col for col in NFL_TARGET_COLUMNS if col in df.columns})
+
+    # Permit allowlisted columns even if they match a banned rule (e.g., labels)
+    banned = {col: reason for col, reason in result.banned.items() if col not in allow_exact}
+
+    if banned and drop_banned:
+        df = df.drop(list(banned.keys()))
+        dropped.extend(banned.keys())
+
+    if banned and raise_on_banned:
+        raise ValueError(f"Leak-prone columns detected: {sorted(banned.items())}")
+
+    allowlist_cols: set[str] = set()
+    if allow_prefixes:
+        allowlist_cols.update({c for c in df.columns if c.startswith(allow_prefixes)})
+    allowlist_cols.update({c for c in allow_exact if c in df.columns})
+
+    if drop_non_allowlisted and allowlist_cols:
+        drop_candidates = [c for c in df.columns if c not in allowlist_cols]
+        if drop_candidates:
+            df = df.drop(drop_candidates)
+            dropped.extend(drop_candidates)
+
+    if drop_non_allowlisted and not allowlist_cols:
+        raise ValueError("No allowlisted columns remain after applying leak guard allowlist.")
+
+    # Store adjusted banned info on the result
+    result.banned = banned
+    result.dropped = dropped
+    result.kept = [c for c in df.columns]
+    result.allowlist_kept = sorted(list(allowlist_cols)) if allowlist_cols else []
+    return df, result
+
+
+def build_schema_snapshot(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    metadata: Mapping[str, object] | None = None,
+    banned: Mapping[str, str] | None = None,
+) -> dict:
+    """Render a schema snapshot describing each column and whether it was flagged."""
+
+    banned = banned or {}
+    meta = {
+        "generated_at_utc": datetime.utcnow().isoformat(),
+        "policy_version": policy.version,
+    }
+    meta.update(metadata or {})
+
+    # Extract columns / dtypes
+    if isinstance(df, pl.DataFrame):
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+    else:  # pandas or pandas-like
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+
+    schema = {
+        "metadata": meta,
+        "columns": [],
+    }
+
+    for col, dtype in cols_and_dtypes:
+        tags: list[str] = []
+        if col in IDENTIFIER_COLUMNS:
+            tags.append("id")
+        if col in NFL_TARGET_COLUMNS:
+            tags.append("label")
+        if col.startswith("market_"):
+            tags.append("odds")
+        if col.startswith("injury_") or col.startswith("practice_"):
+            tags.append("injury")
+        if col.startswith("weather_"):
+            tags.append("weather")
+        if col.startswith("ps_"):
+            tags.append("pre_snap")
+        schema["columns"].append(
+            {
+                "name": col,
+                "dtype": dtype,
+                "banned": col in banned,
+                "tags": tags,
+            }
+        )
+    return schema
+
+
+def write_schema_snapshot(path, schema: Mapping[str, object]) -> None:
+    path.parent.mkdir(parents=True, exist_ok=True)
+    with open(path, "w") as fp:
+        json.dump(schema, fp, indent=2, sort_keys=True)
+
+
+__all__ = [
+    "DEFAULT_LEAK_POLICY",
+    "LeakPolicy",
+    "LeakCheckResult",
+    "evaluate_leak_prone_columns",
+    "enforce_leak_guard",
+    "build_schema_snapshot",
+    "write_schema_snapshot",
+]
diff --git a/utils/general/constants.py b/utils/general/constants.py
index d94b4260ad877484da843fa99ae2caf37e8493f4..dea87caa354d94e4a08b1762d2bd8dcd4c8caa3a
--- a/utils/general/constants.py
+++ b/utils/general/constants.py
@@ -211,7 +211,17 @@
 
 NFL_TARGET_COLUMNS: Tuple[str, ...] = (
     'anytime_td',
+    'anytime_td_offense',
+    'anytime_td_all',
+    'anytime_td_rush',
+    'anytime_td_rec',
+    'anytime_td_pass_thrown',
     'td_count',
+    'td_count_offense',
+    'td_count_all',
+    'passing_td',
+    'rushing_td_count',
+    'receiving_td_count',
     'receiving_yards',
     'rushing_yards',
     'passing_yards',


thinking
**Locating insertion point for new method**
file update
M /Users/jameswest/Desktop/nfl_predict/pipeline/train.py
@@ -797,2 +797,52 @@
 
+    def _filter_odds_snapshot_columns(self, df: pd.DataFrame, horizon_key: str | None) -> pd.DataFrame:
+        """Keep a single odds snapshot horizon (drop other suffixes)."""
+        if df is None or df.empty or not horizon_key:
+            return df
+
+        normalized = str(horizon_key).strip().lower()
+        horizon_map = {
+            "cutoff": "",
+            "default": "",
+            "": "",
+            "2h": "_2h",
+            "h120m": "_2h",
+            "6h": "_6h",
+            "h360m": "_6h",
+            "24h": "_24h",
+            "h1440m": "_24h",
+            "open": "_open",
+        }
+        allowed_suffix = horizon_map.get(normalized, normalized)
+        if allowed_suffix and not allowed_suffix.startswith("_"):
+            allowed_suffix = f"_{allowed_suffix.lstrip('_')}"
+
+        horizon_re = re.compile(r"^(?P<base>.+)(?P<suffix>_2h|_6h|_24h|_open)$")
+        suffixes_seen: dict[str, set[str]] = {}
+        for col in df.columns:
+            match = horizon_re.match(col)
+            if match:
+                suffixes_seen.setdefault(match.group("base"), set()).add(match.group("suffix"))
+
+        drop_cols: list[str] = []
+        for col in df.columns:
+            match = horizon_re.match(col)
+            if match:
+                suffix = match.group("suffix")
+                if suffix != allowed_suffix:
+                    drop_cols.append(col)
+            else:
+                base = col
+                if base in suffixes_seen and allowed_suffix:
+                    drop_cols.append(col)
+
+        if drop_cols:
+            df = df.drop(columns=drop_cols, errors="ignore")
+            logger.info(
+                "Removed %d odds snapshot columns outside horizon '%s'.",
+                len(drop_cols),
+                horizon_key,
+            )
+        return df
+
     def _ensure_player_game_actuals(self) -> pd.DataFrame:
apply_patch(auto_approved=true) exited 0 in 76ms:
Success. Updated the following files:
M pipeline/train.py
file update:
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 5ba68e8bf1acd3a789a76a8857674e6f6433017b..0210d5b7e7ed60a8de7a126d64f5ed76326474c8
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -14,7 +14,7 @@
 
 import logging
 import os
-from datetime import date, timedelta
+from datetime import date, datetime, timedelta
 from typing import Sequence
 
 import polars as pl
@@ -37,6 +37,12 @@
     add_offense_context_features_training,
     _append_offense_context_columns,
 )
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    build_schema_snapshot,
+    enforce_leak_guard,
+    write_schema_snapshot,
+)
 from utils.feature.weather_features import (
     add_weather_forecast_features_training,
     append_weather_context_flags,
@@ -931,6 +937,32 @@
     if market_exprs:
         df_player_game_all = df_player_game_all.with_columns(market_exprs)
     
+    # Leak guard + schema snapshot before persisting
+    spec = get_label_spec(label_version)
+    allow_exact = {spec.primary, *spec.labels.keys(), *spec.aliases.keys()}
+    df_player_game_all, leak_result = enforce_leak_guard(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_exact=allow_exact,
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=True,
+    )
+
+    schema = build_schema_snapshot(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        metadata={
+            "cutoff_label": cutoff_label,
+            "label_version": spec.name,
+        },
+        banned=leak_result.banned,
+    )
+    schema_dir = FEATURE_AUDIT_DIR / "schema" / "anytime_td"
+    schema_path = schema_dir / f"{cutoff_label}_{datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')}.json"
+    write_schema_snapshot(schema_path, schema)
+    logging.info("    Schema snapshot written → %s", schema_path)
+
     # Write final feature matrix
     df_player_game_all = df_player_game_all.with_columns(
         pl.lit(current_cutoff_hours).cast(pl.Float32).alias("decision_horizon_hours")
@@ -951,7 +983,6 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    spec = get_label_spec(label_version)
     label_candidates = {spec.primary, "anytime_td"}
     for label_col in label_candidates:
         if label_col in df_player_game_all.columns:
diff --git a/pipeline/train.py b/pipeline/train.py
index fe70207dcdf25d209ee3ad55080b7ce826347c44..51928323609a1347d5b77e456006a53dd99d0be2
--- a/pipeline/train.py
+++ b/pipeline/train.py
@@ -4,6 +4,7 @@
 import sys
 import logging
 import math
+import re
 
 
 # Move logging to top and remove global thread pinning
@@ -98,6 +99,7 @@
     fit_team_conformal_sums,
     composite_sum_interval,
 )
+from utils.feature.leak_guard import DEFAULT_LEAK_POLICY, enforce_leak_guard
 from utils.feature.targets import require_target_column
 
 # Ignore specific, noisy warnings from dependencies
@@ -793,6 +795,56 @@
             )
         return df
 
+    def _filter_odds_snapshot_columns(self, df: pd.DataFrame, horizon_key: str | None) -> pd.DataFrame:
+        """Keep a single odds snapshot horizon (drop other suffixes)."""
+        if df is None or df.empty or not horizon_key:
+            return df
+
+        normalized = str(horizon_key).strip().lower()
+        horizon_map = {
+            "cutoff": "",
+            "default": "",
+            "": "",
+            "2h": "_2h",
+            "h120m": "_2h",
+            "6h": "_6h",
+            "h360m": "_6h",
+            "24h": "_24h",
+            "h1440m": "_24h",
+            "open": "_open",
+        }
+        allowed_suffix = horizon_map.get(normalized, normalized)
+        if allowed_suffix and not allowed_suffix.startswith("_"):
+            allowed_suffix = f"_{allowed_suffix.lstrip('_')}"
+
+        horizon_re = re.compile(r"^(?P<base>.+)(?P<suffix>_2h|_6h|_24h|_open)$")
+        suffixes_seen: dict[str, set[str]] = {}
+        for col in df.columns:
+            match = horizon_re.match(col)
+            if match:
+                suffixes_seen.setdefault(match.group("base"), set()).add(match.group("suffix"))
+
+        drop_cols: list[str] = []
+        for col in df.columns:
+            match = horizon_re.match(col)
+            if match:
+                suffix = match.group("suffix")
+                if suffix != allowed_suffix:
+                    drop_cols.append(col)
+            else:
+                base = col
+                if base in suffixes_seen and allowed_suffix:
+                    drop_cols.append(col)
+
+        if drop_cols:
+            df = df.drop(columns=drop_cols, errors="ignore")
+            logger.info(
+                "Removed %d odds snapshot columns outside horizon '%s'.",
+                len(drop_cols),
+                horizon_key,
+            )
+        return df
+
     def _ensure_player_game_actuals(self) -> pd.DataFrame:
         if self._player_game_actuals is not None:
             return self._player_game_actuals
@@ -2315,7 +2367,30 @@
                             df_problem[col] = df_problem[col].fillna(df_problem[col].mean())
 
                 df_problem = self._inject_composed_features(df_problem)
-            
+
+            # Leak guard on the problem-scoped frame
+            allow_prefixes = tuple(problem_copy.get('feature_prefixes_to_include') or [])
+            allow_exact = set(problem_copy.get('other_features_to_include') or [])
+            allow_exact.update(input_preds or [])
+            if self.target_col:
+                allow_exact.add(self.target_col)
+            df_problem, leak_info = enforce_leak_guard(
+                df_problem,
+                policy=DEFAULT_LEAK_POLICY,
+                allow_prefixes=allow_prefixes,
+                allow_exact=allow_exact,
+                drop_banned=True,
+                drop_non_allowlisted=False,
+                raise_on_banned=True,
+            )
+            if leak_info.dropped:
+                logger.info(
+                    "Dropped %d leak-prone columns for %s: %s",
+                    len(leak_info.dropped),
+                    problem_name,
+                    sorted(leak_info.dropped),
+                )
+
             self._normalize_datetime_like_columns(df_problem, problem_name)
             df_problem[self.time_col] = pd.to_datetime(df_problem[self.time_col])
             sort_cols = [self.time_col]
diff --git a/tests/test_data_leak_guard.py b/tests/test_data_leak_guard.py
index 8061f2760c0898aaeda29026859e1b9ff5644ba4..3e56665921db89ea523bbdb205d1bb90c21893df
--- a/tests/test_data_leak_guard.py
+++ b/tests/test_data_leak_guard.py
@@ -3,6 +3,14 @@
 import yaml
 from pathlib import Path
 
+import polars as pl
+
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    enforce_leak_guard,
+    evaluate_leak_prone_columns,
+)
+
 
 PROJECT_ROOT = Path(__file__).resolve().parents[1]
 TRAINING_CONFIG = PROJECT_ROOT / "config" / "training.yaml"
@@ -48,3 +56,41 @@
     )
 
 
+def test_leak_guard_flags_pattern_columns():
+    cols = [
+        "market_anytime_td_prob",
+        "final_score",
+        "postgame_anytime_td",
+        "actual_td_count",
+        "safe_feature",
+    ]
+    result = evaluate_leak_prone_columns(cols, policy=DEFAULT_LEAK_POLICY)
+    assert set(result.banned.keys()) == {"final_score", "postgame_anytime_td", "actual_td_count"}
+    assert "safe_feature" in result.kept
+    assert "market_anytime_td_prob" in result.kept
+
+
+def test_enforce_leak_guard_drops_banned_and_keeps_allowlisted():
+    df = pl.DataFrame(
+        {
+            "game_id": ["g1", "g2"],
+            "safe_feature": [1.0, 2.0],
+            "postgame_anytime_td": [1, 0],
+            "final_score": [30, 24],
+        }
+    )
+    cleaned, info = enforce_leak_guard(
+        df,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_prefixes=("safe_",),
+        allow_exact=("game_id",),
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=False,
+    )
+    assert "postgame_anytime_td" not in cleaned.columns
+    assert "final_score" not in cleaned.columns
+    assert "safe_feature" in cleaned.columns
+    assert "game_id" in cleaned.columns
+    assert set(info.dropped) == {"postgame_anytime_td", "final_score"}
+
diff --git a/utils/feature/leak_guard.py b/utils/feature/leak_guard.py
new file mode 100644
index 0000000000000000000000000000000000000000..9faf8cfffc436e0934b2f410aaf252e52f4f95df
--- /dev/null
+++ b/utils/feature/leak_guard.py
@@ -0,0 +1,273 @@
+"""Leak guardrails for feature matrices.
+
+This module centralizes pattern-based leak detection so both feature assembly
+and training can fail fast when post-outcome columns sneak into the data.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+from datetime import datetime
+import json
+import re
+from typing import Iterable, Mapping, Sequence
+
+import polars as pl
+
+from utils.general.constants import IDENTIFIER_COLUMNS, LEAK_PRONE_COLUMNS, NFL_TARGET_COLUMNS
+
+try:  # Optional dependency when imported from training (pandas path)
+    import pandas as pd  # type: ignore
+except Exception:  # pragma: no cover - optional dependency
+    pd = None
+
+
+@dataclass(frozen=True)
+class LeakPolicy:
+    version: str
+    banned_exact: set[str]
+    banned_prefixes: tuple[str, ...]
+    banned_suffixes: tuple[str, ...]
+    banned_regex: tuple[tuple[re.Pattern[str], str], ...]
+    description: str = ""
+
+
+@dataclass
+class LeakCheckResult:
+    policy_version: str
+    banned: dict[str, str]
+    kept: list[str]
+    dropped: list[str]
+    allowlist_kept: list[str]
+
+
+# Core policy tuned for anytime-TD style problems (can be extended per-problem).
+_BASE_BANNED_EXACT = set(LEAK_PRONE_COLUMNS) | {
+    "final_score",
+    "final_total",
+    "points_scored",
+    "actual_td_count",
+    "actual_anytime_td",
+    "postgame_anytime_td",
+    "postgame_td_count",
+}
+_BASE_BANNED_PREFIXES = (
+    "postgame_",
+    "post_game_",
+    "post_",
+    "live_",
+    "actual_",
+    "realized_",
+    "final_",
+    "postmatch_",
+)
+_BASE_BANNED_SUFFIXES = (
+    "_post",
+    "_postgame",
+    "_final",
+    "_fullgame",
+    "_actual",
+)
+_BASE_BANNED_REGEX: tuple[tuple[re.Pattern[str], str], ...] = (
+    (re.compile(r".*post.?game.*", flags=re.IGNORECASE), "postgame marker"),
+    (re.compile(r".*final_score.*", flags=re.IGNORECASE), "final score"),
+    (re.compile(r".*actual.*td.*", flags=re.IGNORECASE), "actual TD total"),
+    (re.compile(r".*anytime_td.*(post|final|actual).*", flags=re.IGNORECASE), "post-decision anytime TD"),
+    (re.compile(r".*fullgame.*", flags=re.IGNORECASE), "full game cumulative value"),
+)
+
+DEFAULT_LEAK_POLICY = LeakPolicy(
+    version="v1",
+    description="Core post-outcome leak guard for NFL anytime TD features.",
+    banned_exact=_BASE_BANNED_EXACT,
+    banned_prefixes=_BASE_BANNED_PREFIXES,
+    banned_suffixes=_BASE_BANNED_SUFFIXES,
+    banned_regex=_BASE_BANNED_REGEX,
+)
+
+
+def _ensure_sequence(value: Sequence[str] | str | None) -> tuple[str, ...]:
+    if value is None:
+        return ()
+    if isinstance(value, str):
+        return (value,)
+    return tuple(value)
+
+
+def evaluate_leak_prone_columns(
+    columns: Iterable[str],
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+) -> LeakCheckResult:
+    """Identify leak-prone columns using the configured policy."""
+
+    banned: dict[str, str] = {}
+    columns_list = list(columns)
+    for col in columns_list:
+        if col in policy.banned_exact:
+            banned[col] = "exact"
+            continue
+        for prefix in policy.banned_prefixes:
+            if col.startswith(prefix):
+                banned[col] = f"prefix:{prefix}"
+                break
+        if col in banned:
+            continue
+        for suffix in policy.banned_suffixes:
+            if col.endswith(suffix):
+                banned[col] = f"suffix:{suffix}"
+                break
+        if col in banned:
+            continue
+        for pattern, reason in policy.banned_regex:
+            if pattern.match(col):
+                banned[col] = reason
+                break
+
+    kept = [c for c in columns_list if c not in banned]
+    return LeakCheckResult(
+        policy_version=policy.version,
+        banned=banned,
+        kept=kept,
+        dropped=[],
+        allowlist_kept=[],
+    )
+
+
+def enforce_leak_guard(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    allow_prefixes: Sequence[str] | str | None = None,
+    allow_exact: Sequence[str] | str | None = None,
+    drop_banned: bool = True,
+    drop_non_allowlisted: bool = False,
+    raise_on_banned: bool = True,
+) -> tuple[pl.DataFrame | "pd.DataFrame", LeakCheckResult]:
+    """Apply leak guardrails to a feature frame.
+
+    Parameters
+    ----------
+    df : DataFrame
+        Polars or pandas DataFrame.
+    policy : LeakPolicy
+        Leak policy to apply.
+    allow_prefixes : Sequence[str] | str | None
+        Optional prefixes that define the allowed feature surface for a problem.
+    allow_exact : Sequence[str] | str | None
+        Explicitly allowed columns (e.g., identifiers).
+    drop_banned : bool
+        If True, drop any banned columns automatically.
+    drop_non_allowlisted : bool
+        If True, drop columns that are not covered by allow_prefixes/allow_exact/identifiers/targets.
+    raise_on_banned : bool
+        If True, raise when banned columns are detected (after optional drop).
+    """
+
+    result = evaluate_leak_prone_columns(df.columns, policy=policy)
+    dropped: list[str] = []
+
+    allow_prefixes = _ensure_sequence(allow_prefixes)
+    allow_exact = set(_ensure_sequence(allow_exact))
+    allow_exact.update({col for col in IDENTIFIER_COLUMNS if col in df.columns})
+    allow_exact.update({col for col in NFL_TARGET_COLUMNS if col in df.columns})
+
+    # Permit allowlisted columns even if they match a banned rule (e.g., labels)
+    banned = {col: reason for col, reason in result.banned.items() if col not in allow_exact}
+
+    if banned and drop_banned:
+        df = df.drop(list(banned.keys()))
+        dropped.extend(banned.keys())
+
+    if banned and raise_on_banned:
+        raise ValueError(f"Leak-prone columns detected: {sorted(banned.items())}")
+
+    allowlist_cols: set[str] = set()
+    if allow_prefixes:
+        allowlist_cols.update({c for c in df.columns if c.startswith(allow_prefixes)})
+    allowlist_cols.update({c for c in allow_exact if c in df.columns})
+
+    if drop_non_allowlisted and allowlist_cols:
+        drop_candidates = [c for c in df.columns if c not in allowlist_cols]
+        if drop_candidates:
+            df = df.drop(drop_candidates)
+            dropped.extend(drop_candidates)
+
+    if drop_non_allowlisted and not allowlist_cols:
+        raise ValueError("No allowlisted columns remain after applying leak guard allowlist.")
+
+    # Store adjusted banned info on the result
+    result.banned = banned
+    result.dropped = dropped
+    result.kept = [c for c in df.columns]
+    result.allowlist_kept = sorted(list(allowlist_cols)) if allowlist_cols else []
+    return df, result
+
+
+def build_schema_snapshot(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    metadata: Mapping[str, object] | None = None,
+    banned: Mapping[str, str] | None = None,
+) -> dict:
+    """Render a schema snapshot describing each column and whether it was flagged."""
+
+    banned = banned or {}
+    meta = {
+        "generated_at_utc": datetime.utcnow().isoformat(),
+        "policy_version": policy.version,
+    }
+    meta.update(metadata or {})
+
+    # Extract columns / dtypes
+    if isinstance(df, pl.DataFrame):
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+    else:  # pandas or pandas-like
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+
+    schema = {
+        "metadata": meta,
+        "columns": [],
+    }
+
+    for col, dtype in cols_and_dtypes:
+        tags: list[str] = []
+        if col in IDENTIFIER_COLUMNS:
+            tags.append("id")
+        if col in NFL_TARGET_COLUMNS:
+            tags.append("label")
+        if col.startswith("market_"):
+            tags.append("odds")
+        if col.startswith("injury_") or col.startswith("practice_"):
+            tags.append("injury")
+        if col.startswith("weather_"):
+            tags.append("weather")
+        if col.startswith("ps_"):
+            tags.append("pre_snap")
+        schema["columns"].append(
+            {
+                "name": col,
+                "dtype": dtype,
+                "banned": col in banned,
+                "tags": tags,
+            }
+        )
+    return schema
+
+
+def write_schema_snapshot(path, schema: Mapping[str, object]) -> None:
+    path.parent.mkdir(parents=True, exist_ok=True)
+    with open(path, "w") as fp:
+        json.dump(schema, fp, indent=2, sort_keys=True)
+
+
+__all__ = [
+    "DEFAULT_LEAK_POLICY",
+    "LeakPolicy",
+    "LeakCheckResult",
+    "evaluate_leak_prone_columns",
+    "enforce_leak_guard",
+    "build_schema_snapshot",
+    "write_schema_snapshot",
+]
diff --git a/utils/general/constants.py b/utils/general/constants.py
index d94b4260ad877484da843fa99ae2caf37e8493f4..dea87caa354d94e4a08b1762d2bd8dcd4c8caa3a
--- a/utils/general/constants.py
+++ b/utils/general/constants.py
@@ -211,7 +211,17 @@
 
 NFL_TARGET_COLUMNS: Tuple[str, ...] = (
     'anytime_td',
+    'anytime_td_offense',
+    'anytime_td_all',
+    'anytime_td_rush',
+    'anytime_td_rec',
+    'anytime_td_pass_thrown',
     'td_count',
+    'td_count_offense',
+    'td_count_all',
+    'passing_td',
+    'rushing_td_count',
+    'receiving_td_count',
     'receiving_yards',
     'rushing_yards',
     'passing_yards',

file update:
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 5ba68e8bf1acd3a789a76a8857674e6f6433017b..0210d5b7e7ed60a8de7a126d64f5ed76326474c8
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -14,7 +14,7 @@
 
 import logging
 import os
-from datetime import date, timedelta
+from datetime import date, datetime, timedelta
 from typing import Sequence
 
 import polars as pl
@@ -37,6 +37,12 @@
     add_offense_context_features_training,
     _append_offense_context_columns,
 )
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    build_schema_snapshot,
+    enforce_leak_guard,
+    write_schema_snapshot,
+)
 from utils.feature.weather_features import (
     add_weather_forecast_features_training,
     append_weather_context_flags,
@@ -931,6 +937,32 @@
     if market_exprs:
         df_player_game_all = df_player_game_all.with_columns(market_exprs)
     
+    # Leak guard + schema snapshot before persisting
+    spec = get_label_spec(label_version)
+    allow_exact = {spec.primary, *spec.labels.keys(), *spec.aliases.keys()}
+    df_player_game_all, leak_result = enforce_leak_guard(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_exact=allow_exact,
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=True,
+    )
+
+    schema = build_schema_snapshot(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        metadata={
+            "cutoff_label": cutoff_label,
+            "label_version": spec.name,
+        },
+        banned=leak_result.banned,
+    )
+    schema_dir = FEATURE_AUDIT_DIR / "schema" / "anytime_td"
+    schema_path = schema_dir / f"{cutoff_label}_{datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')}.json"
+    write_schema_snapshot(schema_path, schema)
+    logging.info("    Schema snapshot written → %s", schema_path)
+
     # Write final feature matrix
     df_player_game_all = df_player_game_all.with_columns(
         pl.lit(current_cutoff_hours).cast(pl.Float32).alias("decision_horizon_hours")
@@ -951,7 +983,6 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    spec = get_label_spec(label_version)
     label_candidates = {spec.primary, "anytime_td"}
     for label_col in label_candidates:
         if label_col in df_player_game_all.columns:
diff --git a/pipeline/train.py b/pipeline/train.py
index fe70207dcdf25d209ee3ad55080b7ce826347c44..51928323609a1347d5b77e456006a53dd99d0be2
--- a/pipeline/train.py
+++ b/pipeline/train.py
@@ -4,6 +4,7 @@
 import sys
 import logging
 import math
+import re
 
 
 # Move logging to top and remove global thread pinning
@@ -98,6 +99,7 @@
     fit_team_conformal_sums,
     composite_sum_interval,
 )
+from utils.feature.leak_guard import DEFAULT_LEAK_POLICY, enforce_leak_guard
 from utils.feature.targets import require_target_column
 
 # Ignore specific, noisy warnings from dependencies
@@ -793,6 +795,56 @@
             )
         return df
 
+    def _filter_odds_snapshot_columns(self, df: pd.DataFrame, horizon_key: str | None) -> pd.DataFrame:
+        """Keep a single odds snapshot horizon (drop other suffixes)."""
+        if df is None or df.empty or not horizon_key:
+            return df
+
+        normalized = str(horizon_key).strip().lower()
+        horizon_map = {
+            "cutoff": "",
+            "default": "",
+            "": "",
+            "2h": "_2h",
+            "h120m": "_2h",
+            "6h": "_6h",
+            "h360m": "_6h",
+            "24h": "_24h",
+            "h1440m": "_24h",
+            "open": "_open",
+        }
+        allowed_suffix = horizon_map.get(normalized, normalized)
+        if allowed_suffix and not allowed_suffix.startswith("_"):
+            allowed_suffix = f"_{allowed_suffix.lstrip('_')}"
+
+        horizon_re = re.compile(r"^(?P<base>.+)(?P<suffix>_2h|_6h|_24h|_open)$")
+        suffixes_seen: dict[str, set[str]] = {}
+        for col in df.columns:
+            match = horizon_re.match(col)
+            if match:
+                suffixes_seen.setdefault(match.group("base"), set()).add(match.group("suffix"))
+
+        drop_cols: list[str] = []
+        for col in df.columns:
+            match = horizon_re.match(col)
+            if match:
+                suffix = match.group("suffix")
+                if suffix != allowed_suffix:
+                    drop_cols.append(col)
+            else:
+                base = col
+                if base in suffixes_seen and allowed_suffix:
+                    drop_cols.append(col)
+
+        if drop_cols:
+            df = df.drop(columns=drop_cols, errors="ignore")
+            logger.info(
+                "Removed %d odds snapshot columns outside horizon '%s'.",
+                len(drop_cols),
+                horizon_key,
+            )
+        return df
+
     def _ensure_player_game_actuals(self) -> pd.DataFrame:
         if self._player_game_actuals is not None:
             return self._player_game_actuals
@@ -2315,7 +2367,30 @@
                             df_problem[col] = df_problem[col].fillna(df_problem[col].mean())
 
                 df_problem = self._inject_composed_features(df_problem)
-            
+
+            # Leak guard on the problem-scoped frame
+            allow_prefixes = tuple(problem_copy.get('feature_prefixes_to_include') or [])
+            allow_exact = set(problem_copy.get('other_features_to_include') or [])
+            allow_exact.update(input_preds or [])
+            if self.target_col:
+                allow_exact.add(self.target_col)
+            df_problem, leak_info = enforce_leak_guard(
+                df_problem,
+                policy=DEFAULT_LEAK_POLICY,
+                allow_prefixes=allow_prefixes,
+                allow_exact=allow_exact,
+                drop_banned=True,
+                drop_non_allowlisted=False,
+                raise_on_banned=True,
+            )
+            if leak_info.dropped:
+                logger.info(
+                    "Dropped %d leak-prone columns for %s: %s",
+                    len(leak_info.dropped),
+                    problem_name,
+                    sorted(leak_info.dropped),
+                )
+
             self._normalize_datetime_like_columns(df_problem, problem_name)
             df_problem[self.time_col] = pd.to_datetime(df_problem[self.time_col])
             sort_cols = [self.time_col]
diff --git a/tests/test_data_leak_guard.py b/tests/test_data_leak_guard.py
index 8061f2760c0898aaeda29026859e1b9ff5644ba4..3e56665921db89ea523bbdb205d1bb90c21893df
--- a/tests/test_data_leak_guard.py
+++ b/tests/test_data_leak_guard.py
@@ -3,6 +3,14 @@
 import yaml
 from pathlib import Path
 
+import polars as pl
+
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    enforce_leak_guard,
+    evaluate_leak_prone_columns,
+)
+
 
 PROJECT_ROOT = Path(__file__).resolve().parents[1]
 TRAINING_CONFIG = PROJECT_ROOT / "config" / "training.yaml"
@@ -48,3 +56,41 @@
     )
 
 
+def test_leak_guard_flags_pattern_columns():
+    cols = [
+        "market_anytime_td_prob",
+        "final_score",
+        "postgame_anytime_td",
+        "actual_td_count",
+        "safe_feature",
+    ]
+    result = evaluate_leak_prone_columns(cols, policy=DEFAULT_LEAK_POLICY)
+    assert set(result.banned.keys()) == {"final_score", "postgame_anytime_td", "actual_td_count"}
+    assert "safe_feature" in result.kept
+    assert "market_anytime_td_prob" in result.kept
+
+
+def test_enforce_leak_guard_drops_banned_and_keeps_allowlisted():
+    df = pl.DataFrame(
+        {
+            "game_id": ["g1", "g2"],
+            "safe_feature": [1.0, 2.0],
+            "postgame_anytime_td": [1, 0],
+            "final_score": [30, 24],
+        }
+    )
+    cleaned, info = enforce_leak_guard(
+        df,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_prefixes=("safe_",),
+        allow_exact=("game_id",),
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=False,
+    )
+    assert "postgame_anytime_td" not in cleaned.columns
+    assert "final_score" not in cleaned.columns
+    assert "safe_feature" in cleaned.columns
+    assert "game_id" in cleaned.columns
+    assert set(info.dropped) == {"postgame_anytime_td", "final_score"}
+
diff --git a/utils/feature/leak_guard.py b/utils/feature/leak_guard.py
new file mode 100644
index 0000000000000000000000000000000000000000..9faf8cfffc436e0934b2f410aaf252e52f4f95df
--- /dev/null
+++ b/utils/feature/leak_guard.py
@@ -0,0 +1,273 @@
+"""Leak guardrails for feature matrices.
+
+This module centralizes pattern-based leak detection so both feature assembly
+and training can fail fast when post-outcome columns sneak into the data.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+from datetime import datetime
+import json
+import re
+from typing import Iterable, Mapping, Sequence
+
+import polars as pl
+
+from utils.general.constants import IDENTIFIER_COLUMNS, LEAK_PRONE_COLUMNS, NFL_TARGET_COLUMNS
+
+try:  # Optional dependency when imported from training (pandas path)
+    import pandas as pd  # type: ignore
+except Exception:  # pragma: no cover - optional dependency
+    pd = None
+
+
+@dataclass(frozen=True)
+class LeakPolicy:
+    version: str
+    banned_exact: set[str]
+    banned_prefixes: tuple[str, ...]
+    banned_suffixes: tuple[str, ...]
+    banned_regex: tuple[tuple[re.Pattern[str], str], ...]
+    description: str = ""
+
+
+@dataclass
+class LeakCheckResult:
+    policy_version: str
+    banned: dict[str, str]
+    kept: list[str]
+    dropped: list[str]
+    allowlist_kept: list[str]
+
+
+# Core policy tuned for anytime-TD style problems (can be extended per-problem).
+_BASE_BANNED_EXACT = set(LEAK_PRONE_COLUMNS) | {
+    "final_score",
+    "final_total",
+    "points_scored",
+    "actual_td_count",
+    "actual_anytime_td",
+    "postgame_anytime_td",
+    "postgame_td_count",
+}
+_BASE_BANNED_PREFIXES = (
+    "postgame_",
+    "post_game_",
+    "post_",
+    "live_",
+    "actual_",
+    "realized_",
+    "final_",
+    "postmatch_",
+)
+_BASE_BANNED_SUFFIXES = (
+    "_post",
+    "_postgame",
+    "_final",
+    "_fullgame",
+    "_actual",
+)
+_BASE_BANNED_REGEX: tuple[tuple[re.Pattern[str], str], ...] = (
+    (re.compile(r".*post.?game.*", flags=re.IGNORECASE), "postgame marker"),
+    (re.compile(r".*final_score.*", flags=re.IGNORECASE), "final score"),
+    (re.compile(r".*actual.*td.*", flags=re.IGNORECASE), "actual TD total"),
+    (re.compile(r".*anytime_td.*(post|final|actual).*", flags=re.IGNORECASE), "post-decision anytime TD"),
+    (re.compile(r".*fullgame.*", flags=re.IGNORECASE), "full game cumulative value"),
+)
+
+DEFAULT_LEAK_POLICY = LeakPolicy(
+    version="v1",
+    description="Core post-outcome leak guard for NFL anytime TD features.",
+    banned_exact=_BASE_BANNED_EXACT,
+    banned_prefixes=_BASE_BANNED_PREFIXES,
+    banned_suffixes=_BASE_BANNED_SUFFIXES,
+    banned_regex=_BASE_BANNED_REGEX,
+)
+
+
+def _ensure_sequence(value: Sequence[str] | str | None) -> tuple[str, ...]:
+    if value is None:
+        return ()
+    if isinstance(value, str):
+        return (value,)
+    return tuple(value)
+
+
+def evaluate_leak_prone_columns(
+    columns: Iterable[str],
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+) -> LeakCheckResult:
+    """Identify leak-prone columns using the configured policy."""
+
+    banned: dict[str, str] = {}
+    columns_list = list(columns)
+    for col in columns_list:
+        if col in policy.banned_exact:
+            banned[col] = "exact"
+            continue
+        for prefix in policy.banned_prefixes:
+            if col.startswith(prefix):
+                banned[col] = f"prefix:{prefix}"
+                break
+        if col in banned:
+            continue
+        for suffix in policy.banned_suffixes:
+            if col.endswith(suffix):
+                banned[col] = f"suffix:{suffix}"
+                break
+        if col in banned:
+            continue
+        for pattern, reason in policy.banned_regex:
+            if pattern.match(col):
+                banned[col] = reason
+                break
+
+    kept = [c for c in columns_list if c not in banned]
+    return LeakCheckResult(
+        policy_version=policy.version,
+        banned=banned,
+        kept=kept,
+        dropped=[],
+        allowlist_kept=[],
+    )
+
+
+def enforce_leak_guard(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    allow_prefixes: Sequence[str] | str | None = None,
+    allow_exact: Sequence[str] | str | None = None,
+    drop_banned: bool = True,
+    drop_non_allowlisted: bool = False,
+    raise_on_banned: bool = True,
+) -> tuple[pl.DataFrame | "pd.DataFrame", LeakCheckResult]:
+    """Apply leak guardrails to a feature frame.
+
+    Parameters
+    ----------
+    df : DataFrame
+        Polars or pandas DataFrame.
+    policy : LeakPolicy
+        Leak policy to apply.
+    allow_prefixes : Sequence[str] | str | None
+        Optional prefixes that define the allowed feature surface for a problem.
+    allow_exact : Sequence[str] | str | None
+        Explicitly allowed columns (e.g., identifiers).
+    drop_banned : bool
+        If True, drop any banned columns automatically.
+    drop_non_allowlisted : bool
+        If True, drop columns that are not covered by allow_prefixes/allow_exact/identifiers/targets.
+    raise_on_banned : bool
+        If True, raise when banned columns are detected (after optional drop).
+    """
+
+    result = evaluate_leak_prone_columns(df.columns, policy=policy)
+    dropped: list[str] = []
+
+    allow_prefixes = _ensure_sequence(allow_prefixes)
+    allow_exact = set(_ensure_sequence(allow_exact))
+    allow_exact.update({col for col in IDENTIFIER_COLUMNS if col in df.columns})
+    allow_exact.update({col for col in NFL_TARGET_COLUMNS if col in df.columns})
+
+    # Permit allowlisted columns even if they match a banned rule (e.g., labels)
+    banned = {col: reason for col, reason in result.banned.items() if col not in allow_exact}
+
+    if banned and drop_banned:
+        df = df.drop(list(banned.keys()))
+        dropped.extend(banned.keys())
+
+    if banned and raise_on_banned:
+        raise ValueError(f"Leak-prone columns detected: {sorted(banned.items())}")
+
+    allowlist_cols: set[str] = set()
+    if allow_prefixes:
+        allowlist_cols.update({c for c in df.columns if c.startswith(allow_prefixes)})
+    allowlist_cols.update({c for c in allow_exact if c in df.columns})
+
+    if drop_non_allowlisted and allowlist_cols:
+        drop_candidates = [c for c in df.columns if c not in allowlist_cols]
+        if drop_candidates:
+            df = df.drop(drop_candidates)
+            dropped.extend(drop_candidates)
+
+    if drop_non_allowlisted and not allowlist_cols:
+        raise ValueError("No allowlisted columns remain after applying leak guard allowlist.")
+
+    # Store adjusted banned info on the result
+    result.banned = banned
+    result.dropped = dropped
+    result.kept = [c for c in df.columns]
+    result.allowlist_kept = sorted(list(allowlist_cols)) if allowlist_cols else []
+    return df, result
+
+
+def build_schema_snapshot(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    metadata: Mapping[str, object] | None = None,
+    banned: Mapping[str, str] | None = None,
+) -> dict:
+    """Render a schema snapshot describing each column and whether it was flagged."""
+
+    banned = banned or {}
+    meta = {
+        "generated_at_utc": datetime.utcnow().isoformat(),
+        "policy_version": policy.version,
+    }
+    meta.update(metadata or {})
+
+    # Extract columns / dtypes
+    if isinstance(df, pl.DataFrame):
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+    else:  # pandas or pandas-like
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+
+    schema = {
+        "metadata": meta,
+        "columns": [],
+    }
+
+    for col, dtype in cols_and_dtypes:
+        tags: list[str] = []
+        if col in IDENTIFIER_COLUMNS:
+            tags.append("id")
+        if col in NFL_TARGET_COLUMNS:
+            tags.append("label")
+        if col.startswith("market_"):
+            tags.append("odds")
+        if col.startswith("injury_") or col.startswith("practice_"):
+            tags.append("injury")
+        if col.startswith("weather_"):
+            tags.append("weather")
+        if col.startswith("ps_"):
+            tags.append("pre_snap")
+        schema["columns"].append(
+            {
+                "name": col,
+                "dtype": dtype,
+                "banned": col in banned,
+                "tags": tags,
+            }
+        )
+    return schema
+
+
+def write_schema_snapshot(path, schema: Mapping[str, object]) -> None:
+    path.parent.mkdir(parents=True, exist_ok=True)
+    with open(path, "w") as fp:
+        json.dump(schema, fp, indent=2, sort_keys=True)
+
+
+__all__ = [
+    "DEFAULT_LEAK_POLICY",
+    "LeakPolicy",
+    "LeakCheckResult",
+    "evaluate_leak_prone_columns",
+    "enforce_leak_guard",
+    "build_schema_snapshot",
+    "write_schema_snapshot",
+]
diff --git a/utils/general/constants.py b/utils/general/constants.py
index d94b4260ad877484da843fa99ae2caf37e8493f4..dea87caa354d94e4a08b1762d2bd8dcd4c8caa3a
--- a/utils/general/constants.py
+++ b/utils/general/constants.py
@@ -211,7 +211,17 @@
 
 NFL_TARGET_COLUMNS: Tuple[str, ...] = (
     'anytime_td',
+    'anytime_td_offense',
+    'anytime_td_all',
+    'anytime_td_rush',
+    'anytime_td_rec',
+    'anytime_td_pass_thrown',
     'td_count',
+    'td_count_offense',
+    'td_count_all',
+    'passing_td',
+    'rushing_td_count',
+    'receiving_td_count',
     'receiving_yards',
     'rushing_yards',
     'passing_yards',


thinking
**Planning method insertion before leak guard**
exec
/bin/zsh -lc "cd /Users/jameswest/Desktop/nfl_predict && sed -n '2270,2345p' pipeline/train.py" in /Users/jameswest/Desktop/nfl_predict succeeded in 826ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
                    self.feature_columns = artifacts['feature_columns']
                    self.imputation_values[problem_name] = artifacts['imputation_values']
                    self.category_levels[problem_name] = artifacts['category_levels']
                    self.categorical_features[problem_name] = artifacts.get('categorical_features', []) # Use .get for safety
            else:
                 use_cached_for_problem = False # Cache doesn't exist or we're not using it

            # Determine which columns to load for this problem
            if use_cached_for_problem:
                needed_cols = list({self.time_col, 'game_pk', *target_load_cols, *self.feature_columns})
            else:
                include_prefixes = tuple(problem_copy.get('feature_prefixes_to_include') or [])
                other_features = problem_copy.get('other_features_to_include') or []
                if all_parquet_cols is None:
                    logger.warning("Parquet schema unavailable; falling back to loading full dataset for this problem.")
                    needed_cols = None
                else:
                    prefix_features = [col for col in all_parquet_cols if col.startswith(include_prefixes)]
                    prelim_features = sorted(list(set(prefix_features + [c for c in other_features if c in all_parquet_cols])))
file update:
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 5ba68e8bf1acd3a789a76a8857674e6f6433017b..0210d5b7e7ed60a8de7a126d64f5ed76326474c8
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -14,7 +14,7 @@
 
 import logging
 import os
-from datetime import date, timedelta
+from datetime import date, datetime, timedelta
 from typing import Sequence
 
 import polars as pl
@@ -37,6 +37,12 @@
     add_offense_context_features_training,
     _append_offense_context_columns,
 )
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    build_schema_snapshot,
+    enforce_leak_guard,
+    write_schema_snapshot,
+)
 from utils.feature.weather_features import (
     add_weather_forecast_features_training,
     append_weather_context_flags,
@@ -931,6 +937,32 @@
     if market_exprs:
         df_player_game_all = df_player_game_all.with_columns(market_exprs)
     
+    # Leak guard + schema snapshot before persisting
+    spec = get_label_spec(label_version)
+    allow_exact = {spec.primary, *spec.labels.keys(), *spec.aliases.keys()}
+    df_player_game_all, leak_result = enforce_leak_guard(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_exact=allow_exact,
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=True,
+    )
+
+    schema = build_schema_snapshot(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        metadata={
+            "cutoff_label": cutoff_label,
+            "label_version": spec.name,
+        },
+        banned=leak_result.banned,
+    )
+    schema_dir = FEATURE_AUDIT_DIR / "schema" / "anytime_td"
+    schema_path = schema_dir / f"{cutoff_label}_{datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')}.json"
+    write_schema_snapshot(schema_path, schema)
+    logging.info("    Schema snapshot written → %s", schema_path)
+
     # Write final feature matrix
     df_player_game_all = df_player_game_all.with_columns(
         pl.lit(current_cutoff_hours).cast(pl.Float32).alias("decision_horizon_hours")
@@ -951,7 +983,6 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    spec = get_label_spec(label_version)
     label_candidates = {spec.primary, "anytime_td"}
     for label_col in label_candidates:
         if label_col in df_player_game_all.columns:
diff --git a/pipeline/train.py b/pipeline/train.py
index fe70207dcdf25d209ee3ad55080b7ce826347c44..51928323609a1347d5b77e456006a53dd99d0be2
--- a/pipeline/train.py
+++ b/pipeline/train.py
@@ -4,6 +4,7 @@
 import sys
 import logging
 import math
+import re
 
 
 # Move logging to top and remove global thread pinning
@@ -98,6 +99,7 @@
     fit_team_conformal_sums,
     composite_sum_interval,
 )
+from utils.feature.leak_guard import DEFAULT_LEAK_POLICY, enforce_leak_guard
 from utils.feature.targets import require_target_column
 
 # Ignore specific, noisy warnings from dependencies
@@ -793,6 +795,56 @@
             )
         return df
 
+    def _filter_odds_snapshot_columns(self, df: pd.DataFrame, horizon_key: str | None) -> pd.DataFrame:
+        """Keep a single odds snapshot horizon (drop other suffixes)."""
+        if df is None or df.empty or not horizon_key:
+            return df
+
+        normalized = str(horizon_key).strip().lower()
+        horizon_map = {
+            "cutoff": "",
+            "default": "",
+            "": "",
+            "2h": "_2h",
+            "h120m": "_2h",
+            "6h": "_6h",
+            "h360m": "_6h",
+            "24h": "_24h",
+            "h1440m": "_24h",
+            "open": "_open",
+        }
+        allowed_suffix = horizon_map.get(normalized, normalized)
+        if allowed_suffix and not allowed_suffix.startswith("_"):
+            allowed_suffix = f"_{allowed_suffix.lstrip('_')}"
+
+        horizon_re = re.compile(r"^(?P<base>.+)(?P<suffix>_2h|_6h|_24h|_open)$")
+        suffixes_seen: dict[str, set[str]] = {}
+        for col in df.columns:
+            match = horizon_re.match(col)
+            if match:
+                suffixes_seen.setdefault(match.group("base"), set()).add(match.group("suffix"))
+
+        drop_cols: list[str] = []
+        for col in df.columns:
+            match = horizon_re.match(col)
+            if match:
+                suffix = match.group("suffix")
+                if suffix != allowed_suffix:
+                    drop_cols.append(col)
+            else:
+                base = col
+                if base in suffixes_seen and allowed_suffix:
+                    drop_cols.append(col)
+
+        if drop_cols:
+            df = df.drop(columns=drop_cols, errors="ignore")
+            logger.info(
+                "Removed %d odds snapshot columns outside horizon '%s'.",
+                len(drop_cols),
+                horizon_key,
+            )
+        return df
+
     def _ensure_player_game_actuals(self) -> pd.DataFrame:
         if self._player_game_actuals is not None:
             return self._player_game_actuals
@@ -2315,7 +2367,30 @@
                             df_problem[col] = df_problem[col].fillna(df_problem[col].mean())
 
                 df_problem = self._inject_composed_features(df_problem)
-            
+
+            # Leak guard on the problem-scoped frame
+            allow_prefixes = tuple(problem_copy.get('feature_prefixes_to_include') or [])
+            allow_exact = set(problem_copy.get('other_features_to_include') or [])
+            allow_exact.update(input_preds or [])
+            if self.target_col:
+                allow_exact.add(self.target_col)
+            df_problem, leak_info = enforce_leak_guard(
+                df_problem,
+                policy=DEFAULT_LEAK_POLICY,
+                allow_prefixes=allow_prefixes,
+                allow_exact=allow_exact,
+                drop_banned=True,
+                drop_non_allowlisted=False,
+                raise_on_banned=True,
+            )
+            if leak_info.dropped:
+                logger.info(
+                    "Dropped %d leak-prone columns for %s: %s",
+                    len(leak_info.dropped),
+                    problem_name,
+                    sorted(leak_info.dropped),
+                )
+
             self._normalize_datetime_like_columns(df_problem, problem_name)
             df_problem[self.time_col] = pd.to_datetime(df_problem[self.time_col])
             sort_cols = [self.time_col]
diff --git a/tests/test_data_leak_guard.py b/tests/test_data_leak_guard.py
index 8061f2760c0898aaeda29026859e1b9ff5644ba4..3e56665921db89ea523bbdb205d1bb90c21893df
--- a/tests/test_data_leak_guard.py
+++ b/tests/test_data_leak_guard.py
@@ -3,6 +3,14 @@
 import yaml
 from pathlib import Path
 
+import polars as pl
+
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    enforce_leak_guard,
+    evaluate_leak_prone_columns,
+)
+
 
 PROJECT_ROOT = Path(__file__).resolve().parents[1]
 TRAINING_CONFIG = PROJECT_ROOT / "config" / "training.yaml"
@@ -48,3 +56,41 @@
     )
 
 
+def test_leak_guard_flags_pattern_columns():
+    cols = [
+        "market_anytime_td_prob",
+        "final_score",
+        "postgame_anytime_td",
+        "actual_td_count",
+        "safe_feature",
+    ]
+    result = evaluate_leak_prone_columns(cols, policy=DEFAULT_LEAK_POLICY)
+    assert set(result.banned.keys()) == {"final_score", "postgame_anytime_td", "actual_td_count"}
+    assert "safe_feature" in result.kept
+    assert "market_anytime_td_prob" in result.kept
+
+
+def test_enforce_leak_guard_drops_banned_and_keeps_allowlisted():
+    df = pl.DataFrame(
+        {
+            "game_id": ["g1", "g2"],
+            "safe_feature": [1.0, 2.0],
+            "postgame_anytime_td": [1, 0],
+            "final_score": [30, 24],
+        }
+    )
+    cleaned, info = enforce_leak_guard(
+        df,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_prefixes=("safe_",),
+        allow_exact=("game_id",),
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=False,
+    )
+    assert "postgame_anytime_td" not in cleaned.columns
+    assert "final_score" not in cleaned.columns
+    assert "safe_feature" in cleaned.columns
+    assert "game_id" in cleaned.columns
+    assert set(info.dropped) == {"postgame_anytime_td", "final_score"}
+
diff --git a/utils/feature/leak_guard.py b/utils/feature/leak_guard.py
new file mode 100644
index 0000000000000000000000000000000000000000..9faf8cfffc436e0934b2f410aaf252e52f4f95df
--- /dev/null
+++ b/utils/feature/leak_guard.py
@@ -0,0 +1,273 @@
+"""Leak guardrails for feature matrices.
+
+This module centralizes pattern-based leak detection so both feature assembly
+and training can fail fast when post-outcome columns sneak into the data.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+from datetime import datetime
+import json
+import re
+from typing import Iterable, Mapping, Sequence
+
+import polars as pl
+
+from utils.general.constants import IDENTIFIER_COLUMNS, LEAK_PRONE_COLUMNS, NFL_TARGET_COLUMNS
+
+try:  # Optional dependency when imported from training (pandas path)
+    import pandas as pd  # type: ignore
+except Exception:  # pragma: no cover - optional dependency
+    pd = None
+
+
+@dataclass(frozen=True)
+class LeakPolicy:
+    version: str
+    banned_exact: set[str]
+    banned_prefixes: tuple[str, ...]
+    banned_suffixes: tuple[str, ...]
+    banned_regex: tuple[tuple[re.Pattern[str], str], ...]
+    description: str = ""
+
+
+@dataclass
+class LeakCheckResult:
+    policy_version: str
+    banned: dict[str, str]
+    kept: list[str]
+    dropped: list[str]
+    allowlist_kept: list[str]
+
+
+# Core policy tuned for anytime-TD style problems (can be extended per-problem).
+_BASE_BANNED_EXACT = set(LEAK_PRONE_COLUMNS) | {
+    "final_score",
+    "final_total",
+    "points_scored",
+    "actual_td_count",
+    "actual_anytime_td",
+    "postgame_anytime_td",
+    "postgame_td_count",
+}
+_BASE_BANNED_PREFIXES = (
+    "postgame_",
+    "post_game_",
+    "post_",
+    "live_",
+    "actual_",
+    "realized_",
+    "final_",
+    "postmatch_",
+)
+_BASE_BANNED_SUFFIXES = (
+    "_post",
+    "_postgame",
+    "_final",
+    "_fullgame",
+    "_actual",
+)
+_BASE_BANNED_REGEX: tuple[tuple[re.Pattern[str], str], ...] = (
+    (re.compile(r".*post.?game.*", flags=re.IGNORECASE), "postgame marker"),
+    (re.compile(r".*final_score.*", flags=re.IGNORECASE), "final score"),
+    (re.compile(r".*actual.*td.*", flags=re.IGNORECASE), "actual TD total"),
+    (re.compile(r".*anytime_td.*(post|final|actual).*", flags=re.IGNORECASE), "post-decision anytime TD"),
+    (re.compile(r".*fullgame.*", flags=re.IGNORECASE), "full game cumulative value"),
+)
+
+DEFAULT_LEAK_POLICY = LeakPolicy(
+    version="v1",
+    description="Core post-outcome leak guard for NFL anytime TD features.",
+    banned_exact=_BASE_BANNED_EXACT,
+    banned_prefixes=_BASE_BANNED_PREFIXES,
+    banned_suffixes=_BASE_BANNED_SUFFIXES,
+    banned_regex=_BASE_BANNED_REGEX,
+)
+
+
+def _ensure_sequence(value: Sequence[str] | str | None) -> tuple[str, ...]:
+    if value is None:
+        return ()
+    if isinstance(value, str):
+        return (value,)
+    return tuple(value)
+
+
+def evaluate_leak_prone_columns(
+    columns: Iterable[str],
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+) -> LeakCheckResult:
+    """Identify leak-prone columns using the configured policy."""
+
+    banned: dict[str, str] = {}
+    columns_list = list(columns)
+    for col in columns_list:
+        if col in policy.banned_exact:
+            banned[col] = "exact"
+            continue
+        for prefix in policy.banned_prefixes:
+            if col.startswith(prefix):
+                banned[col] = f"prefix:{prefix}"
+                break
+        if col in banned:
+            continue
+        for suffix in policy.banned_suffixes:
+            if col.endswith(suffix):
+                banned[col] = f"suffix:{suffix}"
+                break
+        if col in banned:
+            continue
+        for pattern, reason in policy.banned_regex:
+            if pattern.match(col):
+                banned[col] = reason
+                break
+
+    kept = [c for c in columns_list if c not in banned]
+    return LeakCheckResult(
+        policy_version=policy.version,
+        banned=banned,
+        kept=kept,
+        dropped=[],
+        allowlist_kept=[],
+    )
+
+
+def enforce_leak_guard(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    allow_prefixes: Sequence[str] | str | None = None,
+    allow_exact: Sequence[str] | str | None = None,
+    drop_banned: bool = True,
+    drop_non_allowlisted: bool = False,
+    raise_on_banned: bool = True,
+) -> tuple[pl.DataFrame | "pd.DataFrame", LeakCheckResult]:
+    """Apply leak guardrails to a feature frame.
+
+    Parameters
+    ----------
+    df : DataFrame
+        Polars or pandas DataFrame.
+    policy : LeakPolicy
+        Leak policy to apply.
+    allow_prefixes : Sequence[str] | str | None
+        Optional prefixes that define the allowed feature surface for a problem.
+    allow_exact : Sequence[str] | str | None
+        Explicitly allowed columns (e.g., identifiers).
+    drop_banned : bool
+        If True, drop any banned columns automatically.
+    drop_non_allowlisted : bool
+        If True, drop columns that are not covered by allow_prefixes/allow_exact/identifiers/targets.
+    raise_on_banned : bool
+        If True, raise when banned columns are detected (after optional drop).
+    """
+
+    result = evaluate_leak_prone_columns(df.columns, policy=policy)
+    dropped: list[str] = []
+
+    allow_prefixes = _ensure_sequence(allow_prefixes)
+    allow_exact = set(_ensure_sequence(allow_exact))
+    allow_exact.update({col for col in IDENTIFIER_COLUMNS if col in df.columns})
+    allow_exact.update({col for col in NFL_TARGET_COLUMNS if col in df.columns})
+
+    # Permit allowlisted columns even if they match a banned rule (e.g., labels)
+    banned = {col: reason for col, reason in result.banned.items() if col not in allow_exact}
+
+    if banned and drop_banned:
+        df = df.drop(list(banned.keys()))
+        dropped.extend(banned.keys())
+
+    if banned and raise_on_banned:
+        raise ValueError(f"Leak-prone columns detected: {sorted(banned.items())}")
+
+    allowlist_cols: set[str] = set()
+    if allow_prefixes:
+        allowlist_cols.update({c for c in df.columns if c.startswith(allow_prefixes)})
+    allowlist_cols.update({c for c in allow_exact if c in df.columns})
+
+    if drop_non_allowlisted and allowlist_cols:
+        drop_candidates = [c for c in df.columns if c not in allowlist_cols]
+        if drop_candidates:
+            df = df.drop(drop_candidates)
+            dropped.extend(drop_candidates)
+
+    if drop_non_allowlisted and not allowlist_cols:
+        raise ValueError("No allowlisted columns remain after applying leak guard allowlist.")
+
+    # Store adjusted banned info on the result
+    result.banned = banned
+    result.dropped = dropped
+    result.kept = [c for c in df.columns]
+    result.allowlist_kept = sorted(list(allowlist_cols)) if allowlist_cols else []
+    return df, result
+
+
+def build_schema_snapshot(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    metadata: Mapping[str, object] | None = None,
+    banned: Mapping[str, str] | None = None,
+) -> dict:
+    """Render a schema snapshot describing each column and whether it was flagged."""
+
+    banned = banned or {}
+    meta = {
+        "generated_at_utc": datetime.utcnow().isoformat(),
+        "policy_version": policy.version,
+    }
+    meta.update(metadata or {})
+
+    # Extract columns / dtypes
+    if isinstance(df, pl.DataFrame):
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+    else:  # pandas or pandas-like
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+
+    schema = {
+        "metadata": meta,
+        "columns": [],
+    }
+
+    for col, dtype in cols_and_dtypes:
+        tags: list[str] = []
+        if col in IDENTIFIER_COLUMNS:
+            tags.append("id")
+        if col in NFL_TARGET_COLUMNS:
+            tags.append("label")
+        if col.startswith("market_"):
+            tags.append("odds")
+        if col.startswith("injury_") or col.startswith("practice_"):
+            tags.append("injury")
+        if col.startswith("weather_"):
+            tags.append("weather")
+        if col.startswith("ps_"):
+            tags.append("pre_snap")
+        schema["columns"].append(
+            {
+                "name": col,
+                "dtype": dtype,
+                "banned": col in banned,
+                "tags": tags,
+            }
+        )
+    return schema
+
+
+def write_schema_snapshot(path, schema: Mapping[str, object]) -> None:
+    path.parent.mkdir(parents=True, exist_ok=True)
+    with open(path, "w") as fp:
+        json.dump(schema, fp, indent=2, sort_keys=True)
+
+
+__all__ = [
+    "DEFAULT_LEAK_POLICY",
+    "LeakPolicy",
+    "LeakCheckResult",
+    "evaluate_leak_prone_columns",
+    "enforce_leak_guard",
+    "build_schema_snapshot",
+    "write_schema_snapshot",
+]
diff --git a/utils/general/constants.py b/utils/general/constants.py
index d94b4260ad877484da843fa99ae2caf37e8493f4..dea87caa354d94e4a08b1762d2bd8dcd4c8caa3a
--- a/utils/general/constants.py
+++ b/utils/general/constants.py
@@ -211,7 +211,17 @@
 
 NFL_TARGET_COLUMNS: Tuple[str, ...] = (
     'anytime_td',
+    'anytime_td_offense',
+    'anytime_td_all',
+    'anytime_td_rush',
+    'anytime_td_rec',
+    'anytime_td_pass_thrown',
     'td_count',
+    'td_count_offense',
+    'td_count_all',
+    'passing_td',
+    'rushing_td_count',
+    'receiving_td_count',
     'receiving_yards',
     'rushing_yards',
     'passing_yards',


thinking
**Planning horizon filtering insertion**
exec
/bin/zsh -lc "cd /Users/jameswest/Desktop/nfl_predict && sed -n '2345,2405p' pipeline/train.py" in /Users/jameswest/Desktop/nfl_predict succeeded in 748ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
                    if pred_df is None or pred_col not in pred_df.columns:
                        logger.warning(f"Prediction column {pred_col} missing for '{pred_name}'.")
                        continue
                    merge_keys = [col for col in pred_keys if col in df_problem.columns]
                    if not merge_keys:
                        logger.warning(f"No overlapping merge keys for '{pred_name}'. Available keys: {pred_keys}")
                        continue

                    extra_pred_cols = [c for c in pred_df.columns if c.startswith(pred_col)]
                    logger.info(
                        f"Merging {pred_name} (shape {pred_df.shape}, keys={merge_keys}, cols={extra_pred_cols}) into current frame (shape {df_problem.shape})"
                    )
                    df_problem = df_problem.merge(
                        pred_df[merge_keys + extra_pred_cols],
                        on=merge_keys,
                        how='left',
                    )

                    for col in extra_pred_cols:
file update:
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 5ba68e8bf1acd3a789a76a8857674e6f6433017b..0210d5b7e7ed60a8de7a126d64f5ed76326474c8
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -14,7 +14,7 @@
 
 import logging
 import os
-from datetime import date, timedelta
+from datetime import date, datetime, timedelta
 from typing import Sequence
 
 import polars as pl
@@ -37,6 +37,12 @@
     add_offense_context_features_training,
     _append_offense_context_columns,
 )
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    build_schema_snapshot,
+    enforce_leak_guard,
+    write_schema_snapshot,
+)
 from utils.feature.weather_features import (
     add_weather_forecast_features_training,
     append_weather_context_flags,
@@ -931,6 +937,32 @@
     if market_exprs:
         df_player_game_all = df_player_game_all.with_columns(market_exprs)
     
+    # Leak guard + schema snapshot before persisting
+    spec = get_label_spec(label_version)
+    allow_exact = {spec.primary, *spec.labels.keys(), *spec.aliases.keys()}
+    df_player_game_all, leak_result = enforce_leak_guard(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_exact=allow_exact,
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=True,
+    )
+
+    schema = build_schema_snapshot(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        metadata={
+            "cutoff_label": cutoff_label,
+            "label_version": spec.name,
+        },
+        banned=leak_result.banned,
+    )
+    schema_dir = FEATURE_AUDIT_DIR / "schema" / "anytime_td"
+    schema_path = schema_dir / f"{cutoff_label}_{datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')}.json"
+    write_schema_snapshot(schema_path, schema)
+    logging.info("    Schema snapshot written → %s", schema_path)
+
     # Write final feature matrix
     df_player_game_all = df_player_game_all.with_columns(
         pl.lit(current_cutoff_hours).cast(pl.Float32).alias("decision_horizon_hours")
@@ -951,7 +983,6 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    spec = get_label_spec(label_version)
     label_candidates = {spec.primary, "anytime_td"}
     for label_col in label_candidates:
         if label_col in df_player_game_all.columns:
diff --git a/pipeline/train.py b/pipeline/train.py
index fe70207dcdf25d209ee3ad55080b7ce826347c44..51928323609a1347d5b77e456006a53dd99d0be2
--- a/pipeline/train.py
+++ b/pipeline/train.py
@@ -4,6 +4,7 @@
 import sys
 import logging
 import math
+import re
 
 
 # Move logging to top and remove global thread pinning
@@ -98,6 +99,7 @@
     fit_team_conformal_sums,
     composite_sum_interval,
 )
+from utils.feature.leak_guard import DEFAULT_LEAK_POLICY, enforce_leak_guard
 from utils.feature.targets import require_target_column
 
 # Ignore specific, noisy warnings from dependencies
@@ -793,6 +795,56 @@
             )
         return df
 
+    def _filter_odds_snapshot_columns(self, df: pd.DataFrame, horizon_key: str | None) -> pd.DataFrame:
+        """Keep a single odds snapshot horizon (drop other suffixes)."""
+        if df is None or df.empty or not horizon_key:
+            return df
+
+        normalized = str(horizon_key).strip().lower()
+        horizon_map = {
+            "cutoff": "",
+            "default": "",
+            "": "",
+            "2h": "_2h",
+            "h120m": "_2h",
+            "6h": "_6h",
+            "h360m": "_6h",
+            "24h": "_24h",
+            "h1440m": "_24h",
+            "open": "_open",
+        }
+        allowed_suffix = horizon_map.get(normalized, normalized)
+        if allowed_suffix and not allowed_suffix.startswith("_"):
+            allowed_suffix = f"_{allowed_suffix.lstrip('_')}"
+
+        horizon_re = re.compile(r"^(?P<base>.+)(?P<suffix>_2h|_6h|_24h|_open)$")
+        suffixes_seen: dict[str, set[str]] = {}
+        for col in df.columns:
+            match = horizon_re.match(col)
+            if match:
+                suffixes_seen.setdefault(match.group("base"), set()).add(match.group("suffix"))
+
+        drop_cols: list[str] = []
+        for col in df.columns:
+            match = horizon_re.match(col)
+            if match:
+                suffix = match.group("suffix")
+                if suffix != allowed_suffix:
+                    drop_cols.append(col)
+            else:
+                base = col
+                if base in suffixes_seen and allowed_suffix:
+                    drop_cols.append(col)
+
+        if drop_cols:
+            df = df.drop(columns=drop_cols, errors="ignore")
+            logger.info(
+                "Removed %d odds snapshot columns outside horizon '%s'.",
+                len(drop_cols),
+                horizon_key,
+            )
+        return df
+
     def _ensure_player_game_actuals(self) -> pd.DataFrame:
         if self._player_game_actuals is not None:
             return self._player_game_actuals
@@ -2315,7 +2367,30 @@
                             df_problem[col] = df_problem[col].fillna(df_problem[col].mean())
 
                 df_problem = self._inject_composed_features(df_problem)
-            
+
+            # Leak guard on the problem-scoped frame
+            allow_prefixes = tuple(problem_copy.get('feature_prefixes_to_include') or [])
+            allow_exact = set(problem_copy.get('other_features_to_include') or [])
+            allow_exact.update(input_preds or [])
+            if self.target_col:
+                allow_exact.add(self.target_col)
+            df_problem, leak_info = enforce_leak_guard(
+                df_problem,
+                policy=DEFAULT_LEAK_POLICY,
+                allow_prefixes=allow_prefixes,
+                allow_exact=allow_exact,
+                drop_banned=True,
+                drop_non_allowlisted=False,
+                raise_on_banned=True,
+            )
+            if leak_info.dropped:
+                logger.info(
+                    "Dropped %d leak-prone columns for %s: %s",
+                    len(leak_info.dropped),
+                    problem_name,
+                    sorted(leak_info.dropped),
+                )
+
             self._normalize_datetime_like_columns(df_problem, problem_name)
             df_problem[self.time_col] = pd.to_datetime(df_problem[self.time_col])
             sort_cols = [self.time_col]
diff --git a/tests/test_data_leak_guard.py b/tests/test_data_leak_guard.py
index 8061f2760c0898aaeda29026859e1b9ff5644ba4..3e56665921db89ea523bbdb205d1bb90c21893df
--- a/tests/test_data_leak_guard.py
+++ b/tests/test_data_leak_guard.py
@@ -3,6 +3,14 @@
 import yaml
 from pathlib import Path
 
+import polars as pl
+
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    enforce_leak_guard,
+    evaluate_leak_prone_columns,
+)
+
 
 PROJECT_ROOT = Path(__file__).resolve().parents[1]
 TRAINING_CONFIG = PROJECT_ROOT / "config" / "training.yaml"
@@ -48,3 +56,41 @@
     )
 
 
+def test_leak_guard_flags_pattern_columns():
+    cols = [
+        "market_anytime_td_prob",
+        "final_score",
+        "postgame_anytime_td",
+        "actual_td_count",
+        "safe_feature",
+    ]
+    result = evaluate_leak_prone_columns(cols, policy=DEFAULT_LEAK_POLICY)
+    assert set(result.banned.keys()) == {"final_score", "postgame_anytime_td", "actual_td_count"}
+    assert "safe_feature" in result.kept
+    assert "market_anytime_td_prob" in result.kept
+
+
+def test_enforce_leak_guard_drops_banned_and_keeps_allowlisted():
+    df = pl.DataFrame(
+        {
+            "game_id": ["g1", "g2"],
+            "safe_feature": [1.0, 2.0],
+            "postgame_anytime_td": [1, 0],
+            "final_score": [30, 24],
+        }
+    )
+    cleaned, info = enforce_leak_guard(
+        df,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_prefixes=("safe_",),
+        allow_exact=("game_id",),
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=False,
+    )
+    assert "postgame_anytime_td" not in cleaned.columns
+    assert "final_score" not in cleaned.columns
+    assert "safe_feature" in cleaned.columns
+    assert "game_id" in cleaned.columns
+    assert set(info.dropped) == {"postgame_anytime_td", "final_score"}
+
diff --git a/utils/feature/leak_guard.py b/utils/feature/leak_guard.py
new file mode 100644
index 0000000000000000000000000000000000000000..9faf8cfffc436e0934b2f410aaf252e52f4f95df
--- /dev/null
+++ b/utils/feature/leak_guard.py
@@ -0,0 +1,273 @@
+"""Leak guardrails for feature matrices.
+
+This module centralizes pattern-based leak detection so both feature assembly
+and training can fail fast when post-outcome columns sneak into the data.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+from datetime import datetime
+import json
+import re
+from typing import Iterable, Mapping, Sequence
+
+import polars as pl
+
+from utils.general.constants import IDENTIFIER_COLUMNS, LEAK_PRONE_COLUMNS, NFL_TARGET_COLUMNS
+
+try:  # Optional dependency when imported from training (pandas path)
+    import pandas as pd  # type: ignore
+except Exception:  # pragma: no cover - optional dependency
+    pd = None
+
+
+@dataclass(frozen=True)
+class LeakPolicy:
+    version: str
+    banned_exact: set[str]
+    banned_prefixes: tuple[str, ...]
+    banned_suffixes: tuple[str, ...]
+    banned_regex: tuple[tuple[re.Pattern[str], str], ...]
+    description: str = ""
+
+
+@dataclass
+class LeakCheckResult:
+    policy_version: str
+    banned: dict[str, str]
+    kept: list[str]
+    dropped: list[str]
+    allowlist_kept: list[str]
+
+
+# Core policy tuned for anytime-TD style problems (can be extended per-problem).
+_BASE_BANNED_EXACT = set(LEAK_PRONE_COLUMNS) | {
+    "final_score",
+    "final_total",
+    "points_scored",
+    "actual_td_count",
+    "actual_anytime_td",
+    "postgame_anytime_td",
+    "postgame_td_count",
+}
+_BASE_BANNED_PREFIXES = (
+    "postgame_",
+    "post_game_",
+    "post_",
+    "live_",
+    "actual_",
+    "realized_",
+    "final_",
+    "postmatch_",
+)
+_BASE_BANNED_SUFFIXES = (
+    "_post",
+    "_postgame",
+    "_final",
+    "_fullgame",
+    "_actual",
+)
+_BASE_BANNED_REGEX: tuple[tuple[re.Pattern[str], str], ...] = (
+    (re.compile(r".*post.?game.*", flags=re.IGNORECASE), "postgame marker"),
+    (re.compile(r".*final_score.*", flags=re.IGNORECASE), "final score"),
+    (re.compile(r".*actual.*td.*", flags=re.IGNORECASE), "actual TD total"),
+    (re.compile(r".*anytime_td.*(post|final|actual).*", flags=re.IGNORECASE), "post-decision anytime TD"),
+    (re.compile(r".*fullgame.*", flags=re.IGNORECASE), "full game cumulative value"),
+)
+
+DEFAULT_LEAK_POLICY = LeakPolicy(
+    version="v1",
+    description="Core post-outcome leak guard for NFL anytime TD features.",
+    banned_exact=_BASE_BANNED_EXACT,
+    banned_prefixes=_BASE_BANNED_PREFIXES,
+    banned_suffixes=_BASE_BANNED_SUFFIXES,
+    banned_regex=_BASE_BANNED_REGEX,
+)
+
+
+def _ensure_sequence(value: Sequence[str] | str | None) -> tuple[str, ...]:
+    if value is None:
+        return ()
+    if isinstance(value, str):
+        return (value,)
+    return tuple(value)
+
+
+def evaluate_leak_prone_columns(
+    columns: Iterable[str],
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+) -> LeakCheckResult:
+    """Identify leak-prone columns using the configured policy."""
+
+    banned: dict[str, str] = {}
+    columns_list = list(columns)
+    for col in columns_list:
+        if col in policy.banned_exact:
+            banned[col] = "exact"
+            continue
+        for prefix in policy.banned_prefixes:
+            if col.startswith(prefix):
+                banned[col] = f"prefix:{prefix}"
+                break
+        if col in banned:
+            continue
+        for suffix in policy.banned_suffixes:
+            if col.endswith(suffix):
+                banned[col] = f"suffix:{suffix}"
+                break
+        if col in banned:
+            continue
+        for pattern, reason in policy.banned_regex:
+            if pattern.match(col):
+                banned[col] = reason
+                break
+
+    kept = [c for c in columns_list if c not in banned]
+    return LeakCheckResult(
+        policy_version=policy.version,
+        banned=banned,
+        kept=kept,
+        dropped=[],
+        allowlist_kept=[],
+    )
+
+
+def enforce_leak_guard(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    allow_prefixes: Sequence[str] | str | None = None,
+    allow_exact: Sequence[str] | str | None = None,
+    drop_banned: bool = True,
+    drop_non_allowlisted: bool = False,
+    raise_on_banned: bool = True,
+) -> tuple[pl.DataFrame | "pd.DataFrame", LeakCheckResult]:
+    """Apply leak guardrails to a feature frame.
+
+    Parameters
+    ----------
+    df : DataFrame
+        Polars or pandas DataFrame.
+    policy : LeakPolicy
+        Leak policy to apply.
+    allow_prefixes : Sequence[str] | str | None
+        Optional prefixes that define the allowed feature surface for a problem.
+    allow_exact : Sequence[str] | str | None
+        Explicitly allowed columns (e.g., identifiers).
+    drop_banned : bool
+        If True, drop any banned columns automatically.
+    drop_non_allowlisted : bool
+        If True, drop columns that are not covered by allow_prefixes/allow_exact/identifiers/targets.
+    raise_on_banned : bool
+        If True, raise when banned columns are detected (after optional drop).
+    """
+
+    result = evaluate_leak_prone_columns(df.columns, policy=policy)
+    dropped: list[str] = []
+
+    allow_prefixes = _ensure_sequence(allow_prefixes)
+    allow_exact = set(_ensure_sequence(allow_exact))
+    allow_exact.update({col for col in IDENTIFIER_COLUMNS if col in df.columns})
+    allow_exact.update({col for col in NFL_TARGET_COLUMNS if col in df.columns})
+
+    # Permit allowlisted columns even if they match a banned rule (e.g., labels)
+    banned = {col: reason for col, reason in result.banned.items() if col not in allow_exact}
+
+    if banned and drop_banned:
+        df = df.drop(list(banned.keys()))
+        dropped.extend(banned.keys())
+
+    if banned and raise_on_banned:
+        raise ValueError(f"Leak-prone columns detected: {sorted(banned.items())}")
+
+    allowlist_cols: set[str] = set()
+    if allow_prefixes:
+        allowlist_cols.update({c for c in df.columns if c.startswith(allow_prefixes)})
+    allowlist_cols.update({c for c in allow_exact if c in df.columns})
+
+    if drop_non_allowlisted and allowlist_cols:
+        drop_candidates = [c for c in df.columns if c not in allowlist_cols]
+        if drop_candidates:
+            df = df.drop(drop_candidates)
+            dropped.extend(drop_candidates)
+
+    if drop_non_allowlisted and not allowlist_cols:
+        raise ValueError("No allowlisted columns remain after applying leak guard allowlist.")
+
+    # Store adjusted banned info on the result
+    result.banned = banned
+    result.dropped = dropped
+    result.kept = [c for c in df.columns]
+    result.allowlist_kept = sorted(list(allowlist_cols)) if allowlist_cols else []
+    return df, result
+
+
+def build_schema_snapshot(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    metadata: Mapping[str, object] | None = None,
+    banned: Mapping[str, str] | None = None,
+) -> dict:
+    """Render a schema snapshot describing each column and whether it was flagged."""
+
+    banned = banned or {}
+    meta = {
+        "generated_at_utc": datetime.utcnow().isoformat(),
+        "policy_version": policy.version,
+    }
+    meta.update(metadata or {})
+
+    # Extract columns / dtypes
+    if isinstance(df, pl.DataFrame):
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+    else:  # pandas or pandas-like
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+
+    schema = {
+        "metadata": meta,
+        "columns": [],
+    }
+
+    for col, dtype in cols_and_dtypes:
+        tags: list[str] = []
+        if col in IDENTIFIER_COLUMNS:
+            tags.append("id")
+        if col in NFL_TARGET_COLUMNS:
+            tags.append("label")
+        if col.startswith("market_"):
+            tags.append("odds")
+        if col.startswith("injury_") or col.startswith("practice_"):
+            tags.append("injury")
+        if col.startswith("weather_"):
+            tags.append("weather")
+        if col.startswith("ps_"):
+            tags.append("pre_snap")
+        schema["columns"].append(
+            {
+                "name": col,
+                "dtype": dtype,
+                "banned": col in banned,
+                "tags": tags,
+            }
+        )
+    return schema
+
+
+def write_schema_snapshot(path, schema: Mapping[str, object]) -> None:
+    path.parent.mkdir(parents=True, exist_ok=True)
+    with open(path, "w") as fp:
+        json.dump(schema, fp, indent=2, sort_keys=True)
+
+
+__all__ = [
+    "DEFAULT_LEAK_POLICY",
+    "LeakPolicy",
+    "LeakCheckResult",
+    "evaluate_leak_prone_columns",
+    "enforce_leak_guard",
+    "build_schema_snapshot",
+    "write_schema_snapshot",
+]
diff --git a/utils/general/constants.py b/utils/general/constants.py
index d94b4260ad877484da843fa99ae2caf37e8493f4..dea87caa354d94e4a08b1762d2bd8dcd4c8caa3a
--- a/utils/general/constants.py
+++ b/utils/general/constants.py
@@ -211,7 +211,17 @@
 
 NFL_TARGET_COLUMNS: Tuple[str, ...] = (
     'anytime_td',
+    'anytime_td_offense',
+    'anytime_td_all',
+    'anytime_td_rush',
+    'anytime_td_rec',
+    'anytime_td_pass_thrown',
     'td_count',
+    'td_count_offense',
+    'td_count_all',
+    'passing_td',
+    'rushing_td_count',
+    'receiving_td_count',
     'receiving_yards',
     'rushing_yards',
     'passing_yards',


thinking
**Adding odds horizon filtering**
file update
M /Users/jameswest/Desktop/nfl_predict/pipeline/train.py
@@ -2370,2 +2370,6 @@
 
+            odds_horizon = problem_copy.get("odds_horizon")
+            if odds_horizon:
+                df_problem = self._filter_odds_snapshot_columns(df_problem, odds_horizon)
+
             # Leak guard on the problem-scoped frame
apply_patch(auto_approved=true) exited 0 in 81ms:
Success. Updated the following files:
M pipeline/train.py
file update:
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 5ba68e8bf1acd3a789a76a8857674e6f6433017b..0210d5b7e7ed60a8de7a126d64f5ed76326474c8
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -14,7 +14,7 @@
 
 import logging
 import os
-from datetime import date, timedelta
+from datetime import date, datetime, timedelta
 from typing import Sequence
 
 import polars as pl
@@ -37,6 +37,12 @@
     add_offense_context_features_training,
     _append_offense_context_columns,
 )
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    build_schema_snapshot,
+    enforce_leak_guard,
+    write_schema_snapshot,
+)
 from utils.feature.weather_features import (
     add_weather_forecast_features_training,
     append_weather_context_flags,
@@ -931,6 +937,32 @@
     if market_exprs:
         df_player_game_all = df_player_game_all.with_columns(market_exprs)
     
+    # Leak guard + schema snapshot before persisting
+    spec = get_label_spec(label_version)
+    allow_exact = {spec.primary, *spec.labels.keys(), *spec.aliases.keys()}
+    df_player_game_all, leak_result = enforce_leak_guard(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_exact=allow_exact,
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=True,
+    )
+
+    schema = build_schema_snapshot(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        metadata={
+            "cutoff_label": cutoff_label,
+            "label_version": spec.name,
+        },
+        banned=leak_result.banned,
+    )
+    schema_dir = FEATURE_AUDIT_DIR / "schema" / "anytime_td"
+    schema_path = schema_dir / f"{cutoff_label}_{datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')}.json"
+    write_schema_snapshot(schema_path, schema)
+    logging.info("    Schema snapshot written → %s", schema_path)
+
     # Write final feature matrix
     df_player_game_all = df_player_game_all.with_columns(
         pl.lit(current_cutoff_hours).cast(pl.Float32).alias("decision_horizon_hours")
@@ -951,7 +983,6 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    spec = get_label_spec(label_version)
     label_candidates = {spec.primary, "anytime_td"}
     for label_col in label_candidates:
         if label_col in df_player_game_all.columns:
diff --git a/pipeline/train.py b/pipeline/train.py
index fe70207dcdf25d209ee3ad55080b7ce826347c44..e840b9274643f79a93b56f6407f7ad9cbbdad6c2
--- a/pipeline/train.py
+++ b/pipeline/train.py
@@ -4,6 +4,7 @@
 import sys
 import logging
 import math
+import re
 
 
 # Move logging to top and remove global thread pinning
@@ -98,6 +99,7 @@
     fit_team_conformal_sums,
     composite_sum_interval,
 )
+from utils.feature.leak_guard import DEFAULT_LEAK_POLICY, enforce_leak_guard
 from utils.feature.targets import require_target_column
 
 # Ignore specific, noisy warnings from dependencies
@@ -793,6 +795,56 @@
             )
         return df
 
+    def _filter_odds_snapshot_columns(self, df: pd.DataFrame, horizon_key: str | None) -> pd.DataFrame:
+        """Keep a single odds snapshot horizon (drop other suffixes)."""
+        if df is None or df.empty or not horizon_key:
+            return df
+
+        normalized = str(horizon_key).strip().lower()
+        horizon_map = {
+            "cutoff": "",
+            "default": "",
+            "": "",
+            "2h": "_2h",
+            "h120m": "_2h",
+            "6h": "_6h",
+            "h360m": "_6h",
+            "24h": "_24h",
+            "h1440m": "_24h",
+            "open": "_open",
+        }
+        allowed_suffix = horizon_map.get(normalized, normalized)
+        if allowed_suffix and not allowed_suffix.startswith("_"):
+            allowed_suffix = f"_{allowed_suffix.lstrip('_')}"
+
+        horizon_re = re.compile(r"^(?P<base>.+)(?P<suffix>_2h|_6h|_24h|_open)$")
+        suffixes_seen: dict[str, set[str]] = {}
+        for col in df.columns:
+            match = horizon_re.match(col)
+            if match:
+                suffixes_seen.setdefault(match.group("base"), set()).add(match.group("suffix"))
+
+        drop_cols: list[str] = []
+        for col in df.columns:
+            match = horizon_re.match(col)
+            if match:
+                suffix = match.group("suffix")
+                if suffix != allowed_suffix:
+                    drop_cols.append(col)
+            else:
+                base = col
+                if base in suffixes_seen and allowed_suffix:
+                    drop_cols.append(col)
+
+        if drop_cols:
+            df = df.drop(columns=drop_cols, errors="ignore")
+            logger.info(
+                "Removed %d odds snapshot columns outside horizon '%s'.",
+                len(drop_cols),
+                horizon_key,
+            )
+        return df
+
     def _ensure_player_game_actuals(self) -> pd.DataFrame:
         if self._player_game_actuals is not None:
             return self._player_game_actuals
@@ -2315,7 +2367,34 @@
                             df_problem[col] = df_problem[col].fillna(df_problem[col].mean())
 
                 df_problem = self._inject_composed_features(df_problem)
-            
+
+            odds_horizon = problem_copy.get("odds_horizon")
+            if odds_horizon:
+                df_problem = self._filter_odds_snapshot_columns(df_problem, odds_horizon)
+
+            # Leak guard on the problem-scoped frame
+            allow_prefixes = tuple(problem_copy.get('feature_prefixes_to_include') or [])
+            allow_exact = set(problem_copy.get('other_features_to_include') or [])
+            allow_exact.update(input_preds or [])
+            if self.target_col:
+                allow_exact.add(self.target_col)
+            df_problem, leak_info = enforce_leak_guard(
+                df_problem,
+                policy=DEFAULT_LEAK_POLICY,
+                allow_prefixes=allow_prefixes,
+                allow_exact=allow_exact,
+                drop_banned=True,
+                drop_non_allowlisted=False,
+                raise_on_banned=True,
+            )
+            if leak_info.dropped:
+                logger.info(
+                    "Dropped %d leak-prone columns for %s: %s",
+                    len(leak_info.dropped),
+                    problem_name,
+                    sorted(leak_info.dropped),
+                )
+
             self._normalize_datetime_like_columns(df_problem, problem_name)
             df_problem[self.time_col] = pd.to_datetime(df_problem[self.time_col])
             sort_cols = [self.time_col]
diff --git a/tests/test_data_leak_guard.py b/tests/test_data_leak_guard.py
index 8061f2760c0898aaeda29026859e1b9ff5644ba4..3e56665921db89ea523bbdb205d1bb90c21893df
--- a/tests/test_data_leak_guard.py
+++ b/tests/test_data_leak_guard.py
@@ -3,6 +3,14 @@
 import yaml
 from pathlib import Path
 
+import polars as pl
+
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    enforce_leak_guard,
+    evaluate_leak_prone_columns,
+)
+
 
 PROJECT_ROOT = Path(__file__).resolve().parents[1]
 TRAINING_CONFIG = PROJECT_ROOT / "config" / "training.yaml"
@@ -48,3 +56,41 @@
     )
 
 
+def test_leak_guard_flags_pattern_columns():
+    cols = [
+        "market_anytime_td_prob",
+        "final_score",
+        "postgame_anytime_td",
+        "actual_td_count",
+        "safe_feature",
+    ]
+    result = evaluate_leak_prone_columns(cols, policy=DEFAULT_LEAK_POLICY)
+    assert set(result.banned.keys()) == {"final_score", "postgame_anytime_td", "actual_td_count"}
+    assert "safe_feature" in result.kept
+    assert "market_anytime_td_prob" in result.kept
+
+
+def test_enforce_leak_guard_drops_banned_and_keeps_allowlisted():
+    df = pl.DataFrame(
+        {
+            "game_id": ["g1", "g2"],
+            "safe_feature": [1.0, 2.0],
+            "postgame_anytime_td": [1, 0],
+            "final_score": [30, 24],
+        }
+    )
+    cleaned, info = enforce_leak_guard(
+        df,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_prefixes=("safe_",),
+        allow_exact=("game_id",),
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=False,
+    )
+    assert "postgame_anytime_td" not in cleaned.columns
+    assert "final_score" not in cleaned.columns
+    assert "safe_feature" in cleaned.columns
+    assert "game_id" in cleaned.columns
+    assert set(info.dropped) == {"postgame_anytime_td", "final_score"}
+
diff --git a/utils/feature/leak_guard.py b/utils/feature/leak_guard.py
new file mode 100644
index 0000000000000000000000000000000000000000..9faf8cfffc436e0934b2f410aaf252e52f4f95df
--- /dev/null
+++ b/utils/feature/leak_guard.py
@@ -0,0 +1,273 @@
+"""Leak guardrails for feature matrices.
+
+This module centralizes pattern-based leak detection so both feature assembly
+and training can fail fast when post-outcome columns sneak into the data.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+from datetime import datetime
+import json
+import re
+from typing import Iterable, Mapping, Sequence
+
+import polars as pl
+
+from utils.general.constants import IDENTIFIER_COLUMNS, LEAK_PRONE_COLUMNS, NFL_TARGET_COLUMNS
+
+try:  # Optional dependency when imported from training (pandas path)
+    import pandas as pd  # type: ignore
+except Exception:  # pragma: no cover - optional dependency
+    pd = None
+
+
+@dataclass(frozen=True)
+class LeakPolicy:
+    version: str
+    banned_exact: set[str]
+    banned_prefixes: tuple[str, ...]
+    banned_suffixes: tuple[str, ...]
+    banned_regex: tuple[tuple[re.Pattern[str], str], ...]
+    description: str = ""
+
+
+@dataclass
+class LeakCheckResult:
+    policy_version: str
+    banned: dict[str, str]
+    kept: list[str]
+    dropped: list[str]
+    allowlist_kept: list[str]
+
+
+# Core policy tuned for anytime-TD style problems (can be extended per-problem).
+_BASE_BANNED_EXACT = set(LEAK_PRONE_COLUMNS) | {
+    "final_score",
+    "final_total",
+    "points_scored",
+    "actual_td_count",
+    "actual_anytime_td",
+    "postgame_anytime_td",
+    "postgame_td_count",
+}
+_BASE_BANNED_PREFIXES = (
+    "postgame_",
+    "post_game_",
+    "post_",
+    "live_",
+    "actual_",
+    "realized_",
+    "final_",
+    "postmatch_",
+)
+_BASE_BANNED_SUFFIXES = (
+    "_post",
+    "_postgame",
+    "_final",
+    "_fullgame",
+    "_actual",
+)
+_BASE_BANNED_REGEX: tuple[tuple[re.Pattern[str], str], ...] = (
+    (re.compile(r".*post.?game.*", flags=re.IGNORECASE), "postgame marker"),
+    (re.compile(r".*final_score.*", flags=re.IGNORECASE), "final score"),
+    (re.compile(r".*actual.*td.*", flags=re.IGNORECASE), "actual TD total"),
+    (re.compile(r".*anytime_td.*(post|final|actual).*", flags=re.IGNORECASE), "post-decision anytime TD"),
+    (re.compile(r".*fullgame.*", flags=re.IGNORECASE), "full game cumulative value"),
+)
+
+DEFAULT_LEAK_POLICY = LeakPolicy(
+    version="v1",
+    description="Core post-outcome leak guard for NFL anytime TD features.",
+    banned_exact=_BASE_BANNED_EXACT,
+    banned_prefixes=_BASE_BANNED_PREFIXES,
+    banned_suffixes=_BASE_BANNED_SUFFIXES,
+    banned_regex=_BASE_BANNED_REGEX,
+)
+
+
+def _ensure_sequence(value: Sequence[str] | str | None) -> tuple[str, ...]:
+    if value is None:
+        return ()
+    if isinstance(value, str):
+        return (value,)
+    return tuple(value)
+
+
+def evaluate_leak_prone_columns(
+    columns: Iterable[str],
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+) -> LeakCheckResult:
+    """Identify leak-prone columns using the configured policy."""
+
+    banned: dict[str, str] = {}
+    columns_list = list(columns)
+    for col in columns_list:
+        if col in policy.banned_exact:
+            banned[col] = "exact"
+            continue
+        for prefix in policy.banned_prefixes:
+            if col.startswith(prefix):
+                banned[col] = f"prefix:{prefix}"
+                break
+        if col in banned:
+            continue
+        for suffix in policy.banned_suffixes:
+            if col.endswith(suffix):
+                banned[col] = f"suffix:{suffix}"
+                break
+        if col in banned:
+            continue
+        for pattern, reason in policy.banned_regex:
+            if pattern.match(col):
+                banned[col] = reason
+                break
+
+    kept = [c for c in columns_list if c not in banned]
+    return LeakCheckResult(
+        policy_version=policy.version,
+        banned=banned,
+        kept=kept,
+        dropped=[],
+        allowlist_kept=[],
+    )
+
+
+def enforce_leak_guard(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    allow_prefixes: Sequence[str] | str | None = None,
+    allow_exact: Sequence[str] | str | None = None,
+    drop_banned: bool = True,
+    drop_non_allowlisted: bool = False,
+    raise_on_banned: bool = True,
+) -> tuple[pl.DataFrame | "pd.DataFrame", LeakCheckResult]:
+    """Apply leak guardrails to a feature frame.
+
+    Parameters
+    ----------
+    df : DataFrame
+        Polars or pandas DataFrame.
+    policy : LeakPolicy
+        Leak policy to apply.
+    allow_prefixes : Sequence[str] | str | None
+        Optional prefixes that define the allowed feature surface for a problem.
+    allow_exact : Sequence[str] | str | None
+        Explicitly allowed columns (e.g., identifiers).
+    drop_banned : bool
+        If True, drop any banned columns automatically.
+    drop_non_allowlisted : bool
+        If True, drop columns that are not covered by allow_prefixes/allow_exact/identifiers/targets.
+    raise_on_banned : bool
+        If True, raise when banned columns are detected (after optional drop).
+    """
+
+    result = evaluate_leak_prone_columns(df.columns, policy=policy)
+    dropped: list[str] = []
+
+    allow_prefixes = _ensure_sequence(allow_prefixes)
+    allow_exact = set(_ensure_sequence(allow_exact))
+    allow_exact.update({col for col in IDENTIFIER_COLUMNS if col in df.columns})
+    allow_exact.update({col for col in NFL_TARGET_COLUMNS if col in df.columns})
+
+    # Permit allowlisted columns even if they match a banned rule (e.g., labels)
+    banned = {col: reason for col, reason in result.banned.items() if col not in allow_exact}
+
+    if banned and drop_banned:
+        df = df.drop(list(banned.keys()))
+        dropped.extend(banned.keys())
+
+    if banned and raise_on_banned:
+        raise ValueError(f"Leak-prone columns detected: {sorted(banned.items())}")
+
+    allowlist_cols: set[str] = set()
+    if allow_prefixes:
+        allowlist_cols.update({c for c in df.columns if c.startswith(allow_prefixes)})
+    allowlist_cols.update({c for c in allow_exact if c in df.columns})
+
+    if drop_non_allowlisted and allowlist_cols:
+        drop_candidates = [c for c in df.columns if c not in allowlist_cols]
+        if drop_candidates:
+            df = df.drop(drop_candidates)
+            dropped.extend(drop_candidates)
+
+    if drop_non_allowlisted and not allowlist_cols:
+        raise ValueError("No allowlisted columns remain after applying leak guard allowlist.")
+
+    # Store adjusted banned info on the result
+    result.banned = banned
+    result.dropped = dropped
+    result.kept = [c for c in df.columns]
+    result.allowlist_kept = sorted(list(allowlist_cols)) if allowlist_cols else []
+    return df, result
+
+
+def build_schema_snapshot(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    metadata: Mapping[str, object] | None = None,
+    banned: Mapping[str, str] | None = None,
+) -> dict:
+    """Render a schema snapshot describing each column and whether it was flagged."""
+
+    banned = banned or {}
+    meta = {
+        "generated_at_utc": datetime.utcnow().isoformat(),
+        "policy_version": policy.version,
+    }
+    meta.update(metadata or {})
+
+    # Extract columns / dtypes
+    if isinstance(df, pl.DataFrame):
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+    else:  # pandas or pandas-like
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+
+    schema = {
+        "metadata": meta,
+        "columns": [],
+    }
+
+    for col, dtype in cols_and_dtypes:
+        tags: list[str] = []
+        if col in IDENTIFIER_COLUMNS:
+            tags.append("id")
+        if col in NFL_TARGET_COLUMNS:
+            tags.append("label")
+        if col.startswith("market_"):
+            tags.append("odds")
+        if col.startswith("injury_") or col.startswith("practice_"):
+            tags.append("injury")
+        if col.startswith("weather_"):
+            tags.append("weather")
+        if col.startswith("ps_"):
+            tags.append("pre_snap")
+        schema["columns"].append(
+            {
+                "name": col,
+                "dtype": dtype,
+                "banned": col in banned,
+                "tags": tags,
+            }
+        )
+    return schema
+
+
+def write_schema_snapshot(path, schema: Mapping[str, object]) -> None:
+    path.parent.mkdir(parents=True, exist_ok=True)
+    with open(path, "w") as fp:
+        json.dump(schema, fp, indent=2, sort_keys=True)
+
+
+__all__ = [
+    "DEFAULT_LEAK_POLICY",
+    "LeakPolicy",
+    "LeakCheckResult",
+    "evaluate_leak_prone_columns",
+    "enforce_leak_guard",
+    "build_schema_snapshot",
+    "write_schema_snapshot",
+]
diff --git a/utils/general/constants.py b/utils/general/constants.py
index d94b4260ad877484da843fa99ae2caf37e8493f4..dea87caa354d94e4a08b1762d2bd8dcd4c8caa3a
--- a/utils/general/constants.py
+++ b/utils/general/constants.py
@@ -211,7 +211,17 @@
 
 NFL_TARGET_COLUMNS: Tuple[str, ...] = (
     'anytime_td',
+    'anytime_td_offense',
+    'anytime_td_all',
+    'anytime_td_rush',
+    'anytime_td_rec',
+    'anytime_td_pass_thrown',
     'td_count',
+    'td_count_offense',
+    'td_count_all',
+    'passing_td',
+    'rushing_td_count',
+    'receiving_td_count',
     'receiving_yards',
     'rushing_yards',
     'passing_yards',

file update:
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 5ba68e8bf1acd3a789a76a8857674e6f6433017b..0210d5b7e7ed60a8de7a126d64f5ed76326474c8
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -14,7 +14,7 @@
 
 import logging
 import os
-from datetime import date, timedelta
+from datetime import date, datetime, timedelta
 from typing import Sequence
 
 import polars as pl
@@ -37,6 +37,12 @@
     add_offense_context_features_training,
     _append_offense_context_columns,
 )
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    build_schema_snapshot,
+    enforce_leak_guard,
+    write_schema_snapshot,
+)
 from utils.feature.weather_features import (
     add_weather_forecast_features_training,
     append_weather_context_flags,
@@ -931,6 +937,32 @@
     if market_exprs:
         df_player_game_all = df_player_game_all.with_columns(market_exprs)
     
+    # Leak guard + schema snapshot before persisting
+    spec = get_label_spec(label_version)
+    allow_exact = {spec.primary, *spec.labels.keys(), *spec.aliases.keys()}
+    df_player_game_all, leak_result = enforce_leak_guard(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_exact=allow_exact,
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=True,
+    )
+
+    schema = build_schema_snapshot(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        metadata={
+            "cutoff_label": cutoff_label,
+            "label_version": spec.name,
+        },
+        banned=leak_result.banned,
+    )
+    schema_dir = FEATURE_AUDIT_DIR / "schema" / "anytime_td"
+    schema_path = schema_dir / f"{cutoff_label}_{datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')}.json"
+    write_schema_snapshot(schema_path, schema)
+    logging.info("    Schema snapshot written → %s", schema_path)
+
     # Write final feature matrix
     df_player_game_all = df_player_game_all.with_columns(
         pl.lit(current_cutoff_hours).cast(pl.Float32).alias("decision_horizon_hours")
@@ -951,7 +983,6 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    spec = get_label_spec(label_version)
     label_candidates = {spec.primary, "anytime_td"}
     for label_col in label_candidates:
         if label_col in df_player_game_all.columns:
diff --git a/pipeline/train.py b/pipeline/train.py
index fe70207dcdf25d209ee3ad55080b7ce826347c44..e840b9274643f79a93b56f6407f7ad9cbbdad6c2
--- a/pipeline/train.py
+++ b/pipeline/train.py
@@ -4,6 +4,7 @@
 import sys
 import logging
 import math
+import re
 
 
 # Move logging to top and remove global thread pinning
@@ -98,6 +99,7 @@
     fit_team_conformal_sums,
     composite_sum_interval,
 )
+from utils.feature.leak_guard import DEFAULT_LEAK_POLICY, enforce_leak_guard
 from utils.feature.targets import require_target_column
 
 # Ignore specific, noisy warnings from dependencies
@@ -793,6 +795,56 @@
             )
         return df
 
+    def _filter_odds_snapshot_columns(self, df: pd.DataFrame, horizon_key: str | None) -> pd.DataFrame:
+        """Keep a single odds snapshot horizon (drop other suffixes)."""
+        if df is None or df.empty or not horizon_key:
+            return df
+
+        normalized = str(horizon_key).strip().lower()
+        horizon_map = {
+            "cutoff": "",
+            "default": "",
+            "": "",
+            "2h": "_2h",
+            "h120m": "_2h",
+            "6h": "_6h",
+            "h360m": "_6h",
+            "24h": "_24h",
+            "h1440m": "_24h",
+            "open": "_open",
+        }
+        allowed_suffix = horizon_map.get(normalized, normalized)
+        if allowed_suffix and not allowed_suffix.startswith("_"):
+            allowed_suffix = f"_{allowed_suffix.lstrip('_')}"
+
+        horizon_re = re.compile(r"^(?P<base>.+)(?P<suffix>_2h|_6h|_24h|_open)$")
+        suffixes_seen: dict[str, set[str]] = {}
+        for col in df.columns:
+            match = horizon_re.match(col)
+            if match:
+                suffixes_seen.setdefault(match.group("base"), set()).add(match.group("suffix"))
+
+        drop_cols: list[str] = []
+        for col in df.columns:
+            match = horizon_re.match(col)
+            if match:
+                suffix = match.group("suffix")
+                if suffix != allowed_suffix:
+                    drop_cols.append(col)
+            else:
+                base = col
+                if base in suffixes_seen and allowed_suffix:
+                    drop_cols.append(col)
+
+        if drop_cols:
+            df = df.drop(columns=drop_cols, errors="ignore")
+            logger.info(
+                "Removed %d odds snapshot columns outside horizon '%s'.",
+                len(drop_cols),
+                horizon_key,
+            )
+        return df
+
     def _ensure_player_game_actuals(self) -> pd.DataFrame:
         if self._player_game_actuals is not None:
             return self._player_game_actuals
@@ -2315,7 +2367,34 @@
                             df_problem[col] = df_problem[col].fillna(df_problem[col].mean())
 
                 df_problem = self._inject_composed_features(df_problem)
-            
+
+            odds_horizon = problem_copy.get("odds_horizon")
+            if odds_horizon:
+                df_problem = self._filter_odds_snapshot_columns(df_problem, odds_horizon)
+
+            # Leak guard on the problem-scoped frame
+            allow_prefixes = tuple(problem_copy.get('feature_prefixes_to_include') or [])
+            allow_exact = set(problem_copy.get('other_features_to_include') or [])
+            allow_exact.update(input_preds or [])
+            if self.target_col:
+                allow_exact.add(self.target_col)
+            df_problem, leak_info = enforce_leak_guard(
+                df_problem,
+                policy=DEFAULT_LEAK_POLICY,
+                allow_prefixes=allow_prefixes,
+                allow_exact=allow_exact,
+                drop_banned=True,
+                drop_non_allowlisted=False,
+                raise_on_banned=True,
+            )
+            if leak_info.dropped:
+                logger.info(
+                    "Dropped %d leak-prone columns for %s: %s",
+                    len(leak_info.dropped),
+                    problem_name,
+                    sorted(leak_info.dropped),
+                )
+
             self._normalize_datetime_like_columns(df_problem, problem_name)
             df_problem[self.time_col] = pd.to_datetime(df_problem[self.time_col])
             sort_cols = [self.time_col]
diff --git a/tests/test_data_leak_guard.py b/tests/test_data_leak_guard.py
index 8061f2760c0898aaeda29026859e1b9ff5644ba4..3e56665921db89ea523bbdb205d1bb90c21893df
--- a/tests/test_data_leak_guard.py
+++ b/tests/test_data_leak_guard.py
@@ -3,6 +3,14 @@
 import yaml
 from pathlib import Path
 
+import polars as pl
+
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    enforce_leak_guard,
+    evaluate_leak_prone_columns,
+)
+
 
 PROJECT_ROOT = Path(__file__).resolve().parents[1]
 TRAINING_CONFIG = PROJECT_ROOT / "config" / "training.yaml"
@@ -48,3 +56,41 @@
     )
 
 
+def test_leak_guard_flags_pattern_columns():
+    cols = [
+        "market_anytime_td_prob",
+        "final_score",
+        "postgame_anytime_td",
+        "actual_td_count",
+        "safe_feature",
+    ]
+    result = evaluate_leak_prone_columns(cols, policy=DEFAULT_LEAK_POLICY)
+    assert set(result.banned.keys()) == {"final_score", "postgame_anytime_td", "actual_td_count"}
+    assert "safe_feature" in result.kept
+    assert "market_anytime_td_prob" in result.kept
+
+
+def test_enforce_leak_guard_drops_banned_and_keeps_allowlisted():
+    df = pl.DataFrame(
+        {
+            "game_id": ["g1", "g2"],
+            "safe_feature": [1.0, 2.0],
+            "postgame_anytime_td": [1, 0],
+            "final_score": [30, 24],
+        }
+    )
+    cleaned, info = enforce_leak_guard(
+        df,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_prefixes=("safe_",),
+        allow_exact=("game_id",),
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=False,
+    )
+    assert "postgame_anytime_td" not in cleaned.columns
+    assert "final_score" not in cleaned.columns
+    assert "safe_feature" in cleaned.columns
+    assert "game_id" in cleaned.columns
+    assert set(info.dropped) == {"postgame_anytime_td", "final_score"}
+
diff --git a/utils/feature/leak_guard.py b/utils/feature/leak_guard.py
new file mode 100644
index 0000000000000000000000000000000000000000..9faf8cfffc436e0934b2f410aaf252e52f4f95df
--- /dev/null
+++ b/utils/feature/leak_guard.py
@@ -0,0 +1,273 @@
+"""Leak guardrails for feature matrices.
+
+This module centralizes pattern-based leak detection so both feature assembly
+and training can fail fast when post-outcome columns sneak into the data.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+from datetime import datetime
+import json
+import re
+from typing import Iterable, Mapping, Sequence
+
+import polars as pl
+
+from utils.general.constants import IDENTIFIER_COLUMNS, LEAK_PRONE_COLUMNS, NFL_TARGET_COLUMNS
+
+try:  # Optional dependency when imported from training (pandas path)
+    import pandas as pd  # type: ignore
+except Exception:  # pragma: no cover - optional dependency
+    pd = None
+
+
+@dataclass(frozen=True)
+class LeakPolicy:
+    version: str
+    banned_exact: set[str]
+    banned_prefixes: tuple[str, ...]
+    banned_suffixes: tuple[str, ...]
+    banned_regex: tuple[tuple[re.Pattern[str], str], ...]
+    description: str = ""
+
+
+@dataclass
+class LeakCheckResult:
+    policy_version: str
+    banned: dict[str, str]
+    kept: list[str]
+    dropped: list[str]
+    allowlist_kept: list[str]
+
+
+# Core policy tuned for anytime-TD style problems (can be extended per-problem).
+_BASE_BANNED_EXACT = set(LEAK_PRONE_COLUMNS) | {
+    "final_score",
+    "final_total",
+    "points_scored",
+    "actual_td_count",
+    "actual_anytime_td",
+    "postgame_anytime_td",
+    "postgame_td_count",
+}
+_BASE_BANNED_PREFIXES = (
+    "postgame_",
+    "post_game_",
+    "post_",
+    "live_",
+    "actual_",
+    "realized_",
+    "final_",
+    "postmatch_",
+)
+_BASE_BANNED_SUFFIXES = (
+    "_post",
+    "_postgame",
+    "_final",
+    "_fullgame",
+    "_actual",
+)
+_BASE_BANNED_REGEX: tuple[tuple[re.Pattern[str], str], ...] = (
+    (re.compile(r".*post.?game.*", flags=re.IGNORECASE), "postgame marker"),
+    (re.compile(r".*final_score.*", flags=re.IGNORECASE), "final score"),
+    (re.compile(r".*actual.*td.*", flags=re.IGNORECASE), "actual TD total"),
+    (re.compile(r".*anytime_td.*(post|final|actual).*", flags=re.IGNORECASE), "post-decision anytime TD"),
+    (re.compile(r".*fullgame.*", flags=re.IGNORECASE), "full game cumulative value"),
+)
+
+DEFAULT_LEAK_POLICY = LeakPolicy(
+    version="v1",
+    description="Core post-outcome leak guard for NFL anytime TD features.",
+    banned_exact=_BASE_BANNED_EXACT,
+    banned_prefixes=_BASE_BANNED_PREFIXES,
+    banned_suffixes=_BASE_BANNED_SUFFIXES,
+    banned_regex=_BASE_BANNED_REGEX,
+)
+
+
+def _ensure_sequence(value: Sequence[str] | str | None) -> tuple[str, ...]:
+    if value is None:
+        return ()
+    if isinstance(value, str):
+        return (value,)
+    return tuple(value)
+
+
+def evaluate_leak_prone_columns(
+    columns: Iterable[str],
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+) -> LeakCheckResult:
+    """Identify leak-prone columns using the configured policy."""
+
+    banned: dict[str, str] = {}
+    columns_list = list(columns)
+    for col in columns_list:
+        if col in policy.banned_exact:
+            banned[col] = "exact"
+            continue
+        for prefix in policy.banned_prefixes:
+            if col.startswith(prefix):
+                banned[col] = f"prefix:{prefix}"
+                break
+        if col in banned:
+            continue
+        for suffix in policy.banned_suffixes:
+            if col.endswith(suffix):
+                banned[col] = f"suffix:{suffix}"
+                break
+        if col in banned:
+            continue
+        for pattern, reason in policy.banned_regex:
+            if pattern.match(col):
+                banned[col] = reason
+                break
+
+    kept = [c for c in columns_list if c not in banned]
+    return LeakCheckResult(
+        policy_version=policy.version,
+        banned=banned,
+        kept=kept,
+        dropped=[],
+        allowlist_kept=[],
+    )
+
+
+def enforce_leak_guard(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    allow_prefixes: Sequence[str] | str | None = None,
+    allow_exact: Sequence[str] | str | None = None,
+    drop_banned: bool = True,
+    drop_non_allowlisted: bool = False,
+    raise_on_banned: bool = True,
+) -> tuple[pl.DataFrame | "pd.DataFrame", LeakCheckResult]:
+    """Apply leak guardrails to a feature frame.
+
+    Parameters
+    ----------
+    df : DataFrame
+        Polars or pandas DataFrame.
+    policy : LeakPolicy
+        Leak policy to apply.
+    allow_prefixes : Sequence[str] | str | None
+        Optional prefixes that define the allowed feature surface for a problem.
+    allow_exact : Sequence[str] | str | None
+        Explicitly allowed columns (e.g., identifiers).
+    drop_banned : bool
+        If True, drop any banned columns automatically.
+    drop_non_allowlisted : bool
+        If True, drop columns that are not covered by allow_prefixes/allow_exact/identifiers/targets.
+    raise_on_banned : bool
+        If True, raise when banned columns are detected (after optional drop).
+    """
+
+    result = evaluate_leak_prone_columns(df.columns, policy=policy)
+    dropped: list[str] = []
+
+    allow_prefixes = _ensure_sequence(allow_prefixes)
+    allow_exact = set(_ensure_sequence(allow_exact))
+    allow_exact.update({col for col in IDENTIFIER_COLUMNS if col in df.columns})
+    allow_exact.update({col for col in NFL_TARGET_COLUMNS if col in df.columns})
+
+    # Permit allowlisted columns even if they match a banned rule (e.g., labels)
+    banned = {col: reason for col, reason in result.banned.items() if col not in allow_exact}
+
+    if banned and drop_banned:
+        df = df.drop(list(banned.keys()))
+        dropped.extend(banned.keys())
+
+    if banned and raise_on_banned:
+        raise ValueError(f"Leak-prone columns detected: {sorted(banned.items())}")
+
+    allowlist_cols: set[str] = set()
+    if allow_prefixes:
+        allowlist_cols.update({c for c in df.columns if c.startswith(allow_prefixes)})
+    allowlist_cols.update({c for c in allow_exact if c in df.columns})
+
+    if drop_non_allowlisted and allowlist_cols:
+        drop_candidates = [c for c in df.columns if c not in allowlist_cols]
+        if drop_candidates:
+            df = df.drop(drop_candidates)
+            dropped.extend(drop_candidates)
+
+    if drop_non_allowlisted and not allowlist_cols:
+        raise ValueError("No allowlisted columns remain after applying leak guard allowlist.")
+
+    # Store adjusted banned info on the result
+    result.banned = banned
+    result.dropped = dropped
+    result.kept = [c for c in df.columns]
+    result.allowlist_kept = sorted(list(allowlist_cols)) if allowlist_cols else []
+    return df, result
+
+
+def build_schema_snapshot(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    metadata: Mapping[str, object] | None = None,
+    banned: Mapping[str, str] | None = None,
+) -> dict:
+    """Render a schema snapshot describing each column and whether it was flagged."""
+
+    banned = banned or {}
+    meta = {
+        "generated_at_utc": datetime.utcnow().isoformat(),
+        "policy_version": policy.version,
+    }
+    meta.update(metadata or {})
+
+    # Extract columns / dtypes
+    if isinstance(df, pl.DataFrame):
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+    else:  # pandas or pandas-like
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+
+    schema = {
+        "metadata": meta,
+        "columns": [],
+    }
+
+    for col, dtype in cols_and_dtypes:
+        tags: list[str] = []
+        if col in IDENTIFIER_COLUMNS:
+            tags.append("id")
+        if col in NFL_TARGET_COLUMNS:
+            tags.append("label")
+        if col.startswith("market_"):
+            tags.append("odds")
+        if col.startswith("injury_") or col.startswith("practice_"):
+            tags.append("injury")
+        if col.startswith("weather_"):
+            tags.append("weather")
+        if col.startswith("ps_"):
+            tags.append("pre_snap")
+        schema["columns"].append(
+            {
+                "name": col,
+                "dtype": dtype,
+                "banned": col in banned,
+                "tags": tags,
+            }
+        )
+    return schema
+
+
+def write_schema_snapshot(path, schema: Mapping[str, object]) -> None:
+    path.parent.mkdir(parents=True, exist_ok=True)
+    with open(path, "w") as fp:
+        json.dump(schema, fp, indent=2, sort_keys=True)
+
+
+__all__ = [
+    "DEFAULT_LEAK_POLICY",
+    "LeakPolicy",
+    "LeakCheckResult",
+    "evaluate_leak_prone_columns",
+    "enforce_leak_guard",
+    "build_schema_snapshot",
+    "write_schema_snapshot",
+]
diff --git a/utils/general/constants.py b/utils/general/constants.py
index d94b4260ad877484da843fa99ae2caf37e8493f4..dea87caa354d94e4a08b1762d2bd8dcd4c8caa3a
--- a/utils/general/constants.py
+++ b/utils/general/constants.py
@@ -211,7 +211,17 @@
 
 NFL_TARGET_COLUMNS: Tuple[str, ...] = (
     'anytime_td',
+    'anytime_td_offense',
+    'anytime_td_all',
+    'anytime_td_rush',
+    'anytime_td_rec',
+    'anytime_td_pass_thrown',
     'td_count',
+    'td_count_offense',
+    'td_count_all',
+    'passing_td',
+    'rushing_td_count',
+    'receiving_td_count',
     'receiving_yards',
     'rushing_yards',
     'passing_yards',


thinking
**Planning config update for odds horizon**
file update
M /Users/jameswest/Desktop/nfl_predict/config/training.yaml
@@ -478,2 +478,3 @@
     label_version: 'v1_any_offense'
+    odds_horizon: 'cutoff'  # Restrict odds features to the decision-time snapshot
     task_type: 'classification'
apply_patch(auto_approved=true) exited 0 in 85ms:
Success. Updated the following files:
M config/training.yaml
file update:
diff --git a/config/training.yaml b/config/training.yaml
index 3953818d861d0410246bff132110722a3ce44007..c2b6053b488caa71f9078ff100d049f723ae1548
--- a/config/training.yaml
+++ b/config/training.yaml
@@ -476,6 +476,7 @@
   - name: 'anytime_td'
     target_col: 'anytime_td'
     label_version: 'v1_any_offense'
+    odds_horizon: 'cutoff'  # Restrict odds features to the decision-time snapshot
     task_type: 'classification'
     input_predictions:
       - 'availability_active'
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 5ba68e8bf1acd3a789a76a8857674e6f6433017b..0210d5b7e7ed60a8de7a126d64f5ed76326474c8
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -14,7 +14,7 @@
 
 import logging
 import os
-from datetime import date, timedelta
+from datetime import date, datetime, timedelta
 from typing import Sequence
 
 import polars as pl
@@ -37,6 +37,12 @@
     add_offense_context_features_training,
     _append_offense_context_columns,
 )
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    build_schema_snapshot,
+    enforce_leak_guard,
+    write_schema_snapshot,
+)
 from utils.feature.weather_features import (
     add_weather_forecast_features_training,
     append_weather_context_flags,
@@ -931,6 +937,32 @@
     if market_exprs:
         df_player_game_all = df_player_game_all.with_columns(market_exprs)
     
+    # Leak guard + schema snapshot before persisting
+    spec = get_label_spec(label_version)
+    allow_exact = {spec.primary, *spec.labels.keys(), *spec.aliases.keys()}
+    df_player_game_all, leak_result = enforce_leak_guard(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_exact=allow_exact,
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=True,
+    )
+
+    schema = build_schema_snapshot(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        metadata={
+            "cutoff_label": cutoff_label,
+            "label_version": spec.name,
+        },
+        banned=leak_result.banned,
+    )
+    schema_dir = FEATURE_AUDIT_DIR / "schema" / "anytime_td"
+    schema_path = schema_dir / f"{cutoff_label}_{datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')}.json"
+    write_schema_snapshot(schema_path, schema)
+    logging.info("    Schema snapshot written → %s", schema_path)
+
     # Write final feature matrix
     df_player_game_all = df_player_game_all.with_columns(
         pl.lit(current_cutoff_hours).cast(pl.Float32).alias("decision_horizon_hours")
@@ -951,7 +983,6 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    spec = get_label_spec(label_version)
     label_candidates = {spec.primary, "anytime_td"}
     for label_col in label_candidates:
         if label_col in df_player_game_all.columns:
diff --git a/pipeline/train.py b/pipeline/train.py
index fe70207dcdf25d209ee3ad55080b7ce826347c44..e840b9274643f79a93b56f6407f7ad9cbbdad6c2
--- a/pipeline/train.py
+++ b/pipeline/train.py
@@ -4,6 +4,7 @@
 import sys
 import logging
 import math
+import re
 
 
 # Move logging to top and remove global thread pinning
@@ -98,6 +99,7 @@
     fit_team_conformal_sums,
     composite_sum_interval,
 )
+from utils.feature.leak_guard import DEFAULT_LEAK_POLICY, enforce_leak_guard
 from utils.feature.targets import require_target_column
 
 # Ignore specific, noisy warnings from dependencies
@@ -793,6 +795,56 @@
             )
         return df
 
+    def _filter_odds_snapshot_columns(self, df: pd.DataFrame, horizon_key: str | None) -> pd.DataFrame:
+        """Keep a single odds snapshot horizon (drop other suffixes)."""
+        if df is None or df.empty or not horizon_key:
+            return df
+
+        normalized = str(horizon_key).strip().lower()
+        horizon_map = {
+            "cutoff": "",
+            "default": "",
+            "": "",
+            "2h": "_2h",
+            "h120m": "_2h",
+            "6h": "_6h",
+            "h360m": "_6h",
+            "24h": "_24h",
+            "h1440m": "_24h",
+            "open": "_open",
+        }
+        allowed_suffix = horizon_map.get(normalized, normalized)
+        if allowed_suffix and not allowed_suffix.startswith("_"):
+            allowed_suffix = f"_{allowed_suffix.lstrip('_')}"
+
+        horizon_re = re.compile(r"^(?P<base>.+)(?P<suffix>_2h|_6h|_24h|_open)$")
+        suffixes_seen: dict[str, set[str]] = {}
+        for col in df.columns:
+            match = horizon_re.match(col)
+            if match:
+                suffixes_seen.setdefault(match.group("base"), set()).add(match.group("suffix"))
+
+        drop_cols: list[str] = []
+        for col in df.columns:
+            match = horizon_re.match(col)
+            if match:
+                suffix = match.group("suffix")
+                if suffix != allowed_suffix:
+                    drop_cols.append(col)
+            else:
+                base = col
+                if base in suffixes_seen and allowed_suffix:
+                    drop_cols.append(col)
+
+        if drop_cols:
+            df = df.drop(columns=drop_cols, errors="ignore")
+            logger.info(
+                "Removed %d odds snapshot columns outside horizon '%s'.",
+                len(drop_cols),
+                horizon_key,
+            )
+        return df
+
     def _ensure_player_game_actuals(self) -> pd.DataFrame:
         if self._player_game_actuals is not None:
             return self._player_game_actuals
@@ -2315,7 +2367,34 @@
                             df_problem[col] = df_problem[col].fillna(df_problem[col].mean())
 
                 df_problem = self._inject_composed_features(df_problem)
-            
+
+            odds_horizon = problem_copy.get("odds_horizon")
+            if odds_horizon:
+                df_problem = self._filter_odds_snapshot_columns(df_problem, odds_horizon)
+
+            # Leak guard on the problem-scoped frame
+            allow_prefixes = tuple(problem_copy.get('feature_prefixes_to_include') or [])
+            allow_exact = set(problem_copy.get('other_features_to_include') or [])
+            allow_exact.update(input_preds or [])
+            if self.target_col:
+                allow_exact.add(self.target_col)
+            df_problem, leak_info = enforce_leak_guard(
+                df_problem,
+                policy=DEFAULT_LEAK_POLICY,
+                allow_prefixes=allow_prefixes,
+                allow_exact=allow_exact,
+                drop_banned=True,
+                drop_non_allowlisted=False,
+                raise_on_banned=True,
+            )
+            if leak_info.dropped:
+                logger.info(
+                    "Dropped %d leak-prone columns for %s: %s",
+                    len(leak_info.dropped),
+                    problem_name,
+                    sorted(leak_info.dropped),
+                )
+
             self._normalize_datetime_like_columns(df_problem, problem_name)
             df_problem[self.time_col] = pd.to_datetime(df_problem[self.time_col])
             sort_cols = [self.time_col]
diff --git a/tests/test_data_leak_guard.py b/tests/test_data_leak_guard.py
index 8061f2760c0898aaeda29026859e1b9ff5644ba4..3e56665921db89ea523bbdb205d1bb90c21893df
--- a/tests/test_data_leak_guard.py
+++ b/tests/test_data_leak_guard.py
@@ -3,6 +3,14 @@
 import yaml
 from pathlib import Path
 
+import polars as pl
+
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    enforce_leak_guard,
+    evaluate_leak_prone_columns,
+)
+
 
 PROJECT_ROOT = Path(__file__).resolve().parents[1]
 TRAINING_CONFIG = PROJECT_ROOT / "config" / "training.yaml"
@@ -48,3 +56,41 @@
     )
 
 
+def test_leak_guard_flags_pattern_columns():
+    cols = [
+        "market_anytime_td_prob",
+        "final_score",
+        "postgame_anytime_td",
+        "actual_td_count",
+        "safe_feature",
+    ]
+    result = evaluate_leak_prone_columns(cols, policy=DEFAULT_LEAK_POLICY)
+    assert set(result.banned.keys()) == {"final_score", "postgame_anytime_td", "actual_td_count"}
+    assert "safe_feature" in result.kept
+    assert "market_anytime_td_prob" in result.kept
+
+
+def test_enforce_leak_guard_drops_banned_and_keeps_allowlisted():
+    df = pl.DataFrame(
+        {
+            "game_id": ["g1", "g2"],
+            "safe_feature": [1.0, 2.0],
+            "postgame_anytime_td": [1, 0],
+            "final_score": [30, 24],
+        }
+    )
+    cleaned, info = enforce_leak_guard(
+        df,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_prefixes=("safe_",),
+        allow_exact=("game_id",),
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=False,
+    )
+    assert "postgame_anytime_td" not in cleaned.columns
+    assert "final_score" not in cleaned.columns
+    assert "safe_feature" in cleaned.columns
+    assert "game_id" in cleaned.columns
+    assert set(info.dropped) == {"postgame_anytime_td", "final_score"}
+
diff --git a/utils/feature/leak_guard.py b/utils/feature/leak_guard.py
new file mode 100644
index 0000000000000000000000000000000000000000..9faf8cfffc436e0934b2f410aaf252e52f4f95df
--- /dev/null
+++ b/utils/feature/leak_guard.py
@@ -0,0 +1,273 @@
+"""Leak guardrails for feature matrices.
+
+This module centralizes pattern-based leak detection so both feature assembly
+and training can fail fast when post-outcome columns sneak into the data.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+from datetime import datetime
+import json
+import re
+from typing import Iterable, Mapping, Sequence
+
+import polars as pl
+
+from utils.general.constants import IDENTIFIER_COLUMNS, LEAK_PRONE_COLUMNS, NFL_TARGET_COLUMNS
+
+try:  # Optional dependency when imported from training (pandas path)
+    import pandas as pd  # type: ignore
+except Exception:  # pragma: no cover - optional dependency
+    pd = None
+
+
+@dataclass(frozen=True)
+class LeakPolicy:
+    version: str
+    banned_exact: set[str]
+    banned_prefixes: tuple[str, ...]
+    banned_suffixes: tuple[str, ...]
+    banned_regex: tuple[tuple[re.Pattern[str], str], ...]
+    description: str = ""
+
+
+@dataclass
+class LeakCheckResult:
+    policy_version: str
+    banned: dict[str, str]
+    kept: list[str]
+    dropped: list[str]
+    allowlist_kept: list[str]
+
+
+# Core policy tuned for anytime-TD style problems (can be extended per-problem).
+_BASE_BANNED_EXACT = set(LEAK_PRONE_COLUMNS) | {
+    "final_score",
+    "final_total",
+    "points_scored",
+    "actual_td_count",
+    "actual_anytime_td",
+    "postgame_anytime_td",
+    "postgame_td_count",
+}
+_BASE_BANNED_PREFIXES = (
+    "postgame_",
+    "post_game_",
+    "post_",
+    "live_",
+    "actual_",
+    "realized_",
+    "final_",
+    "postmatch_",
+)
+_BASE_BANNED_SUFFIXES = (
+    "_post",
+    "_postgame",
+    "_final",
+    "_fullgame",
+    "_actual",
+)
+_BASE_BANNED_REGEX: tuple[tuple[re.Pattern[str], str], ...] = (
+    (re.compile(r".*post.?game.*", flags=re.IGNORECASE), "postgame marker"),
+    (re.compile(r".*final_score.*", flags=re.IGNORECASE), "final score"),
+    (re.compile(r".*actual.*td.*", flags=re.IGNORECASE), "actual TD total"),
+    (re.compile(r".*anytime_td.*(post|final|actual).*", flags=re.IGNORECASE), "post-decision anytime TD"),
+    (re.compile(r".*fullgame.*", flags=re.IGNORECASE), "full game cumulative value"),
+)
+
+DEFAULT_LEAK_POLICY = LeakPolicy(
+    version="v1",
+    description="Core post-outcome leak guard for NFL anytime TD features.",
+    banned_exact=_BASE_BANNED_EXACT,
+    banned_prefixes=_BASE_BANNED_PREFIXES,
+    banned_suffixes=_BASE_BANNED_SUFFIXES,
+    banned_regex=_BASE_BANNED_REGEX,
+)
+
+
+def _ensure_sequence(value: Sequence[str] | str | None) -> tuple[str, ...]:
+    if value is None:
+        return ()
+    if isinstance(value, str):
+        return (value,)
+    return tuple(value)
+
+
+def evaluate_leak_prone_columns(
+    columns: Iterable[str],
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+) -> LeakCheckResult:
+    """Identify leak-prone columns using the configured policy."""
+
+    banned: dict[str, str] = {}
+    columns_list = list(columns)
+    for col in columns_list:
+        if col in policy.banned_exact:
+            banned[col] = "exact"
+            continue
+        for prefix in policy.banned_prefixes:
+            if col.startswith(prefix):
+                banned[col] = f"prefix:{prefix}"
+                break
+        if col in banned:
+            continue
+        for suffix in policy.banned_suffixes:
+            if col.endswith(suffix):
+                banned[col] = f"suffix:{suffix}"
+                break
+        if col in banned:
+            continue
+        for pattern, reason in policy.banned_regex:
+            if pattern.match(col):
+                banned[col] = reason
+                break
+
+    kept = [c for c in columns_list if c not in banned]
+    return LeakCheckResult(
+        policy_version=policy.version,
+        banned=banned,
+        kept=kept,
+        dropped=[],
+        allowlist_kept=[],
+    )
+
+
+def enforce_leak_guard(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    allow_prefixes: Sequence[str] | str | None = None,
+    allow_exact: Sequence[str] | str | None = None,
+    drop_banned: bool = True,
+    drop_non_allowlisted: bool = False,
+    raise_on_banned: bool = True,
+) -> tuple[pl.DataFrame | "pd.DataFrame", LeakCheckResult]:
+    """Apply leak guardrails to a feature frame.
+
+    Parameters
+    ----------
+    df : DataFrame
+        Polars or pandas DataFrame.
+    policy : LeakPolicy
+        Leak policy to apply.
+    allow_prefixes : Sequence[str] | str | None
+        Optional prefixes that define the allowed feature surface for a problem.
+    allow_exact : Sequence[str] | str | None
+        Explicitly allowed columns (e.g., identifiers).
+    drop_banned : bool
+        If True, drop any banned columns automatically.
+    drop_non_allowlisted : bool
+        If True, drop columns that are not covered by allow_prefixes/allow_exact/identifiers/targets.
+    raise_on_banned : bool
+        If True, raise when banned columns are detected (after optional drop).
+    """
+
+    result = evaluate_leak_prone_columns(df.columns, policy=policy)
+    dropped: list[str] = []
+
+    allow_prefixes = _ensure_sequence(allow_prefixes)
+    allow_exact = set(_ensure_sequence(allow_exact))
+    allow_exact.update({col for col in IDENTIFIER_COLUMNS if col in df.columns})
+    allow_exact.update({col for col in NFL_TARGET_COLUMNS if col in df.columns})
+
+    # Permit allowlisted columns even if they match a banned rule (e.g., labels)
+    banned = {col: reason for col, reason in result.banned.items() if col not in allow_exact}
+
+    if banned and drop_banned:
+        df = df.drop(list(banned.keys()))
+        dropped.extend(banned.keys())
+
+    if banned and raise_on_banned:
+        raise ValueError(f"Leak-prone columns detected: {sorted(banned.items())}")
+
+    allowlist_cols: set[str] = set()
+    if allow_prefixes:
+        allowlist_cols.update({c for c in df.columns if c.startswith(allow_prefixes)})
+    allowlist_cols.update({c for c in allow_exact if c in df.columns})
+
+    if drop_non_allowlisted and allowlist_cols:
+        drop_candidates = [c for c in df.columns if c not in allowlist_cols]
+        if drop_candidates:
+            df = df.drop(drop_candidates)
+            dropped.extend(drop_candidates)
+
+    if drop_non_allowlisted and not allowlist_cols:
+        raise ValueError("No allowlisted columns remain after applying leak guard allowlist.")
+
+    # Store adjusted banned info on the result
+    result.banned = banned
+    result.dropped = dropped
+    result.kept = [c for c in df.columns]
+    result.allowlist_kept = sorted(list(allowlist_cols)) if allowlist_cols else []
+    return df, result
+
+
+def build_schema_snapshot(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    metadata: Mapping[str, object] | None = None,
+    banned: Mapping[str, str] | None = None,
+) -> dict:
+    """Render a schema snapshot describing each column and whether it was flagged."""
+
+    banned = banned or {}
+    meta = {
+        "generated_at_utc": datetime.utcnow().isoformat(),
+        "policy_version": policy.version,
+    }
+    meta.update(metadata or {})
+
+    # Extract columns / dtypes
+    if isinstance(df, pl.DataFrame):
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+    else:  # pandas or pandas-like
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+
+    schema = {
+        "metadata": meta,
+        "columns": [],
+    }
+
+    for col, dtype in cols_and_dtypes:
+        tags: list[str] = []
+        if col in IDENTIFIER_COLUMNS:
+            tags.append("id")
+        if col in NFL_TARGET_COLUMNS:
+            tags.append("label")
+        if col.startswith("market_"):
+            tags.append("odds")
+        if col.startswith("injury_") or col.startswith("practice_"):
+            tags.append("injury")
+        if col.startswith("weather_"):
+            tags.append("weather")
+        if col.startswith("ps_"):
+            tags.append("pre_snap")
+        schema["columns"].append(
+            {
+                "name": col,
+                "dtype": dtype,
+                "banned": col in banned,
+                "tags": tags,
+            }
+        )
+    return schema
+
+
+def write_schema_snapshot(path, schema: Mapping[str, object]) -> None:
+    path.parent.mkdir(parents=True, exist_ok=True)
+    with open(path, "w") as fp:
+        json.dump(schema, fp, indent=2, sort_keys=True)
+
+
+__all__ = [
+    "DEFAULT_LEAK_POLICY",
+    "LeakPolicy",
+    "LeakCheckResult",
+    "evaluate_leak_prone_columns",
+    "enforce_leak_guard",
+    "build_schema_snapshot",
+    "write_schema_snapshot",
+]
diff --git a/utils/general/constants.py b/utils/general/constants.py
index d94b4260ad877484da843fa99ae2caf37e8493f4..dea87caa354d94e4a08b1762d2bd8dcd4c8caa3a
--- a/utils/general/constants.py
+++ b/utils/general/constants.py
@@ -211,7 +211,17 @@
 
 NFL_TARGET_COLUMNS: Tuple[str, ...] = (
     'anytime_td',
+    'anytime_td_offense',
+    'anytime_td_all',
+    'anytime_td_rush',
+    'anytime_td_rec',
+    'anytime_td_pass_thrown',
     'td_count',
+    'td_count_offense',
+    'td_count_all',
+    'passing_td',
+    'rushing_td_count',
+    'receiving_td_count',
     'receiving_yards',
     'rushing_yards',
     'passing_yards',

file update:
diff --git a/config/training.yaml b/config/training.yaml
index 3953818d861d0410246bff132110722a3ce44007..c2b6053b488caa71f9078ff100d049f723ae1548
--- a/config/training.yaml
+++ b/config/training.yaml
@@ -476,6 +476,7 @@
   - name: 'anytime_td'
     target_col: 'anytime_td'
     label_version: 'v1_any_offense'
+    odds_horizon: 'cutoff'  # Restrict odds features to the decision-time snapshot
     task_type: 'classification'
     input_predictions:
       - 'availability_active'
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 5ba68e8bf1acd3a789a76a8857674e6f6433017b..0210d5b7e7ed60a8de7a126d64f5ed76326474c8
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -14,7 +14,7 @@
 
 import logging
 import os
-from datetime import date, timedelta
+from datetime import date, datetime, timedelta
 from typing import Sequence
 
 import polars as pl
@@ -37,6 +37,12 @@
     add_offense_context_features_training,
     _append_offense_context_columns,
 )
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    build_schema_snapshot,
+    enforce_leak_guard,
+    write_schema_snapshot,
+)
 from utils.feature.weather_features import (
     add_weather_forecast_features_training,
     append_weather_context_flags,
@@ -931,6 +937,32 @@
     if market_exprs:
         df_player_game_all = df_player_game_all.with_columns(market_exprs)
     
+    # Leak guard + schema snapshot before persisting
+    spec = get_label_spec(label_version)
+    allow_exact = {spec.primary, *spec.labels.keys(), *spec.aliases.keys()}
+    df_player_game_all, leak_result = enforce_leak_guard(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_exact=allow_exact,
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=True,
+    )
+
+    schema = build_schema_snapshot(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        metadata={
+            "cutoff_label": cutoff_label,
+            "label_version": spec.name,
+        },
+        banned=leak_result.banned,
+    )
+    schema_dir = FEATURE_AUDIT_DIR / "schema" / "anytime_td"
+    schema_path = schema_dir / f"{cutoff_label}_{datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')}.json"
+    write_schema_snapshot(schema_path, schema)
+    logging.info("    Schema snapshot written → %s", schema_path)
+
     # Write final feature matrix
     df_player_game_all = df_player_game_all.with_columns(
         pl.lit(current_cutoff_hours).cast(pl.Float32).alias("decision_horizon_hours")
@@ -951,7 +983,6 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    spec = get_label_spec(label_version)
     label_candidates = {spec.primary, "anytime_td"}
     for label_col in label_candidates:
         if label_col in df_player_game_all.columns:
diff --git a/pipeline/train.py b/pipeline/train.py
index fe70207dcdf25d209ee3ad55080b7ce826347c44..e840b9274643f79a93b56f6407f7ad9cbbdad6c2
--- a/pipeline/train.py
+++ b/pipeline/train.py
@@ -4,6 +4,7 @@
 import sys
 import logging
 import math
+import re
 
 
 # Move logging to top and remove global thread pinning
@@ -98,6 +99,7 @@
     fit_team_conformal_sums,
     composite_sum_interval,
 )
+from utils.feature.leak_guard import DEFAULT_LEAK_POLICY, enforce_leak_guard
 from utils.feature.targets import require_target_column
 
 # Ignore specific, noisy warnings from dependencies
@@ -793,6 +795,56 @@
             )
         return df
 
+    def _filter_odds_snapshot_columns(self, df: pd.DataFrame, horizon_key: str | None) -> pd.DataFrame:
+        """Keep a single odds snapshot horizon (drop other suffixes)."""
+        if df is None or df.empty or not horizon_key:
+            return df
+
+        normalized = str(horizon_key).strip().lower()
+        horizon_map = {
+            "cutoff": "",
+            "default": "",
+            "": "",
+            "2h": "_2h",
+            "h120m": "_2h",
+            "6h": "_6h",
+            "h360m": "_6h",
+            "24h": "_24h",
+            "h1440m": "_24h",
+            "open": "_open",
+        }
+        allowed_suffix = horizon_map.get(normalized, normalized)
+        if allowed_suffix and not allowed_suffix.startswith("_"):
+            allowed_suffix = f"_{allowed_suffix.lstrip('_')}"
+
+        horizon_re = re.compile(r"^(?P<base>.+)(?P<suffix>_2h|_6h|_24h|_open)$")
+        suffixes_seen: dict[str, set[str]] = {}
+        for col in df.columns:
+            match = horizon_re.match(col)
+            if match:
+                suffixes_seen.setdefault(match.group("base"), set()).add(match.group("suffix"))
+
+        drop_cols: list[str] = []
+        for col in df.columns:
+            match = horizon_re.match(col)
+            if match:
+                suffix = match.group("suffix")
+                if suffix != allowed_suffix:
+                    drop_cols.append(col)
+            else:
+                base = col
+                if base in suffixes_seen and allowed_suffix:
+                    drop_cols.append(col)
+
+        if drop_cols:
+            df = df.drop(columns=drop_cols, errors="ignore")
+            logger.info(
+                "Removed %d odds snapshot columns outside horizon '%s'.",
+                len(drop_cols),
+                horizon_key,
+            )
+        return df
+
     def _ensure_player_game_actuals(self) -> pd.DataFrame:
         if self._player_game_actuals is not None:
             return self._player_game_actuals
@@ -2315,7 +2367,34 @@
                             df_problem[col] = df_problem[col].fillna(df_problem[col].mean())
 
                 df_problem = self._inject_composed_features(df_problem)
-            
+
+            odds_horizon = problem_copy.get("odds_horizon")
+            if odds_horizon:
+                df_problem = self._filter_odds_snapshot_columns(df_problem, odds_horizon)
+
+            # Leak guard on the problem-scoped frame
+            allow_prefixes = tuple(problem_copy.get('feature_prefixes_to_include') or [])
+            allow_exact = set(problem_copy.get('other_features_to_include') or [])
+            allow_exact.update(input_preds or [])
+            if self.target_col:
+                allow_exact.add(self.target_col)
+            df_problem, leak_info = enforce_leak_guard(
+                df_problem,
+                policy=DEFAULT_LEAK_POLICY,
+                allow_prefixes=allow_prefixes,
+                allow_exact=allow_exact,
+                drop_banned=True,
+                drop_non_allowlisted=False,
+                raise_on_banned=True,
+            )
+            if leak_info.dropped:
+                logger.info(
+                    "Dropped %d leak-prone columns for %s: %s",
+                    len(leak_info.dropped),
+                    problem_name,
+                    sorted(leak_info.dropped),
+                )
+
             self._normalize_datetime_like_columns(df_problem, problem_name)
             df_problem[self.time_col] = pd.to_datetime(df_problem[self.time_col])
             sort_cols = [self.time_col]
diff --git a/tests/test_data_leak_guard.py b/tests/test_data_leak_guard.py
index 8061f2760c0898aaeda29026859e1b9ff5644ba4..3e56665921db89ea523bbdb205d1bb90c21893df
--- a/tests/test_data_leak_guard.py
+++ b/tests/test_data_leak_guard.py
@@ -3,6 +3,14 @@
 import yaml
 from pathlib import Path
 
+import polars as pl
+
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    enforce_leak_guard,
+    evaluate_leak_prone_columns,
+)
+
 
 PROJECT_ROOT = Path(__file__).resolve().parents[1]
 TRAINING_CONFIG = PROJECT_ROOT / "config" / "training.yaml"
@@ -48,3 +56,41 @@
     )
 
 
+def test_leak_guard_flags_pattern_columns():
+    cols = [
+        "market_anytime_td_prob",
+        "final_score",
+        "postgame_anytime_td",
+        "actual_td_count",
+        "safe_feature",
+    ]
+    result = evaluate_leak_prone_columns(cols, policy=DEFAULT_LEAK_POLICY)
+    assert set(result.banned.keys()) == {"final_score", "postgame_anytime_td", "actual_td_count"}
+    assert "safe_feature" in result.kept
+    assert "market_anytime_td_prob" in result.kept
+
+
+def test_enforce_leak_guard_drops_banned_and_keeps_allowlisted():
+    df = pl.DataFrame(
+        {
+            "game_id": ["g1", "g2"],
+            "safe_feature": [1.0, 2.0],
+            "postgame_anytime_td": [1, 0],
+            "final_score": [30, 24],
+        }
+    )
+    cleaned, info = enforce_leak_guard(
+        df,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_prefixes=("safe_",),
+        allow_exact=("game_id",),
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=False,
+    )
+    assert "postgame_anytime_td" not in cleaned.columns
+    assert "final_score" not in cleaned.columns
+    assert "safe_feature" in cleaned.columns
+    assert "game_id" in cleaned.columns
+    assert set(info.dropped) == {"postgame_anytime_td", "final_score"}
+
diff --git a/utils/feature/leak_guard.py b/utils/feature/leak_guard.py
new file mode 100644
index 0000000000000000000000000000000000000000..9faf8cfffc436e0934b2f410aaf252e52f4f95df
--- /dev/null
+++ b/utils/feature/leak_guard.py
@@ -0,0 +1,273 @@
+"""Leak guardrails for feature matrices.
+
+This module centralizes pattern-based leak detection so both feature assembly
+and training can fail fast when post-outcome columns sneak into the data.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+from datetime import datetime
+import json
+import re
+from typing import Iterable, Mapping, Sequence
+
+import polars as pl
+
+from utils.general.constants import IDENTIFIER_COLUMNS, LEAK_PRONE_COLUMNS, NFL_TARGET_COLUMNS
+
+try:  # Optional dependency when imported from training (pandas path)
+    import pandas as pd  # type: ignore
+except Exception:  # pragma: no cover - optional dependency
+    pd = None
+
+
+@dataclass(frozen=True)
+class LeakPolicy:
+    version: str
+    banned_exact: set[str]
+    banned_prefixes: tuple[str, ...]
+    banned_suffixes: tuple[str, ...]
+    banned_regex: tuple[tuple[re.Pattern[str], str], ...]
+    description: str = ""
+
+
+@dataclass
+class LeakCheckResult:
+    policy_version: str
+    banned: dict[str, str]
+    kept: list[str]
+    dropped: list[str]
+    allowlist_kept: list[str]
+
+
+# Core policy tuned for anytime-TD style problems (can be extended per-problem).
+_BASE_BANNED_EXACT = set(LEAK_PRONE_COLUMNS) | {
+    "final_score",
+    "final_total",
+    "points_scored",
+    "actual_td_count",
+    "actual_anytime_td",
+    "postgame_anytime_td",
+    "postgame_td_count",
+}
+_BASE_BANNED_PREFIXES = (
+    "postgame_",
+    "post_game_",
+    "post_",
+    "live_",
+    "actual_",
+    "realized_",
+    "final_",
+    "postmatch_",
+)
+_BASE_BANNED_SUFFIXES = (
+    "_post",
+    "_postgame",
+    "_final",
+    "_fullgame",
+    "_actual",
+)
+_BASE_BANNED_REGEX: tuple[tuple[re.Pattern[str], str], ...] = (
+    (re.compile(r".*post.?game.*", flags=re.IGNORECASE), "postgame marker"),
+    (re.compile(r".*final_score.*", flags=re.IGNORECASE), "final score"),
+    (re.compile(r".*actual.*td.*", flags=re.IGNORECASE), "actual TD total"),
+    (re.compile(r".*anytime_td.*(post|final|actual).*", flags=re.IGNORECASE), "post-decision anytime TD"),
+    (re.compile(r".*fullgame.*", flags=re.IGNORECASE), "full game cumulative value"),
+)
+
+DEFAULT_LEAK_POLICY = LeakPolicy(
+    version="v1",
+    description="Core post-outcome leak guard for NFL anytime TD features.",
+    banned_exact=_BASE_BANNED_EXACT,
+    banned_prefixes=_BASE_BANNED_PREFIXES,
+    banned_suffixes=_BASE_BANNED_SUFFIXES,
+    banned_regex=_BASE_BANNED_REGEX,
+)
+
+
+def _ensure_sequence(value: Sequence[str] | str | None) -> tuple[str, ...]:
+    if value is None:
+        return ()
+    if isinstance(value, str):
+        return (value,)
+    return tuple(value)
+
+
+def evaluate_leak_prone_columns(
+    columns: Iterable[str],
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+) -> LeakCheckResult:
+    """Identify leak-prone columns using the configured policy."""
+
+    banned: dict[str, str] = {}
+    columns_list = list(columns)
+    for col in columns_list:
+        if col in policy.banned_exact:
+            banned[col] = "exact"
+            continue
+        for prefix in policy.banned_prefixes:
+            if col.startswith(prefix):
+                banned[col] = f"prefix:{prefix}"
+                break
+        if col in banned:
+            continue
+        for suffix in policy.banned_suffixes:
+            if col.endswith(suffix):
+                banned[col] = f"suffix:{suffix}"
+                break
+        if col in banned:
+            continue
+        for pattern, reason in policy.banned_regex:
+            if pattern.match(col):
+                banned[col] = reason
+                break
+
+    kept = [c for c in columns_list if c not in banned]
+    return LeakCheckResult(
+        policy_version=policy.version,
+        banned=banned,
+        kept=kept,
+        dropped=[],
+        allowlist_kept=[],
+    )
+
+
+def enforce_leak_guard(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    allow_prefixes: Sequence[str] | str | None = None,
+    allow_exact: Sequence[str] | str | None = None,
+    drop_banned: bool = True,
+    drop_non_allowlisted: bool = False,
+    raise_on_banned: bool = True,
+) -> tuple[pl.DataFrame | "pd.DataFrame", LeakCheckResult]:
+    """Apply leak guardrails to a feature frame.
+
+    Parameters
+    ----------
+    df : DataFrame
+        Polars or pandas DataFrame.
+    policy : LeakPolicy
+        Leak policy to apply.
+    allow_prefixes : Sequence[str] | str | None
+        Optional prefixes that define the allowed feature surface for a problem.
+    allow_exact : Sequence[str] | str | None
+        Explicitly allowed columns (e.g., identifiers).
+    drop_banned : bool
+        If True, drop any banned columns automatically.
+    drop_non_allowlisted : bool
+        If True, drop columns that are not covered by allow_prefixes/allow_exact/identifiers/targets.
+    raise_on_banned : bool
+        If True, raise when banned columns are detected (after optional drop).
+    """
+
+    result = evaluate_leak_prone_columns(df.columns, policy=policy)
+    dropped: list[str] = []
+
+    allow_prefixes = _ensure_sequence(allow_prefixes)
+    allow_exact = set(_ensure_sequence(allow_exact))
+    allow_exact.update({col for col in IDENTIFIER_COLUMNS if col in df.columns})
+    allow_exact.update({col for col in NFL_TARGET_COLUMNS if col in df.columns})
+
+    # Permit allowlisted columns even if they match a banned rule (e.g., labels)
+    banned = {col: reason for col, reason in result.banned.items() if col not in allow_exact}
+
+    if banned and drop_banned:
+        df = df.drop(list(banned.keys()))
+        dropped.extend(banned.keys())
+
+    if banned and raise_on_banned:
+        raise ValueError(f"Leak-prone columns detected: {sorted(banned.items())}")
+
+    allowlist_cols: set[str] = set()
+    if allow_prefixes:
+        allowlist_cols.update({c for c in df.columns if c.startswith(allow_prefixes)})
+    allowlist_cols.update({c for c in allow_exact if c in df.columns})
+
+    if drop_non_allowlisted and allowlist_cols:
+        drop_candidates = [c for c in df.columns if c not in allowlist_cols]
+        if drop_candidates:
+            df = df.drop(drop_candidates)
+            dropped.extend(drop_candidates)
+
+    if drop_non_allowlisted and not allowlist_cols:
+        raise ValueError("No allowlisted columns remain after applying leak guard allowlist.")
+
+    # Store adjusted banned info on the result
+    result.banned = banned
+    result.dropped = dropped
+    result.kept = [c for c in df.columns]
+    result.allowlist_kept = sorted(list(allowlist_cols)) if allowlist_cols else []
+    return df, result
+
+
+def build_schema_snapshot(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    metadata: Mapping[str, object] | None = None,
+    banned: Mapping[str, str] | None = None,
+) -> dict:
+    """Render a schema snapshot describing each column and whether it was flagged."""
+
+    banned = banned or {}
+    meta = {
+        "generated_at_utc": datetime.utcnow().isoformat(),
+        "policy_version": policy.version,
+    }
+    meta.update(metadata or {})
+
+    # Extract columns / dtypes
+    if isinstance(df, pl.DataFrame):
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+    else:  # pandas or pandas-like
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+
+    schema = {
+        "metadata": meta,
+        "columns": [],
+    }
+
+    for col, dtype in cols_and_dtypes:
+        tags: list[str] = []
+        if col in IDENTIFIER_COLUMNS:
+            tags.append("id")
+        if col in NFL_TARGET_COLUMNS:
+            tags.append("label")
+        if col.startswith("market_"):
+            tags.append("odds")
+        if col.startswith("injury_") or col.startswith("practice_"):
+            tags.append("injury")
+        if col.startswith("weather_"):
+            tags.append("weather")
+        if col.startswith("ps_"):
+            tags.append("pre_snap")
+        schema["columns"].append(
+            {
+                "name": col,
+                "dtype": dtype,
+                "banned": col in banned,
+                "tags": tags,
+            }
+        )
+    return schema
+
+
+def write_schema_snapshot(path, schema: Mapping[str, object]) -> None:
+    path.parent.mkdir(parents=True, exist_ok=True)
+    with open(path, "w") as fp:
+        json.dump(schema, fp, indent=2, sort_keys=True)
+
+
+__all__ = [
+    "DEFAULT_LEAK_POLICY",
+    "LeakPolicy",
+    "LeakCheckResult",
+    "evaluate_leak_prone_columns",
+    "enforce_leak_guard",
+    "build_schema_snapshot",
+    "write_schema_snapshot",
+]
diff --git a/utils/general/constants.py b/utils/general/constants.py
index d94b4260ad877484da843fa99ae2caf37e8493f4..dea87caa354d94e4a08b1762d2bd8dcd4c8caa3a
--- a/utils/general/constants.py
+++ b/utils/general/constants.py
@@ -211,7 +211,17 @@
 
 NFL_TARGET_COLUMNS: Tuple[str, ...] = (
     'anytime_td',
+    'anytime_td_offense',
+    'anytime_td_all',
+    'anytime_td_rush',
+    'anytime_td_rec',
+    'anytime_td_pass_thrown',
     'td_count',
+    'td_count_offense',
+    'td_count_all',
+    'passing_td',
+    'rushing_td_count',
+    'receiving_td_count',
     'receiving_yards',
     'rushing_yards',
     'passing_yards',


thinking
**Evaluating test strategy for odds filtering method**

thinking
**Considering static method conversion**

thinking
**Updating static method usage**
file update
M /Users/jameswest/Desktop/nfl_predict/pipeline/train.py
@@ -797,3 +797,4 @@
 
-    def _filter_odds_snapshot_columns(self, df: pd.DataFrame, horizon_key: str | None) -> pd.DataFrame:
+    @staticmethod
+    def _filter_odds_snapshot_columns(df: pd.DataFrame, horizon_key: str | None) -> pd.DataFrame:
         """Keep a single odds snapshot horizon (drop other suffixes)."""
apply_patch(auto_approved=true) exited 0 in 88ms:
Success. Updated the following files:
M pipeline/train.py
file update:
diff --git a/config/training.yaml b/config/training.yaml
index 3953818d861d0410246bff132110722a3ce44007..c2b6053b488caa71f9078ff100d049f723ae1548
--- a/config/training.yaml
+++ b/config/training.yaml
@@ -476,6 +476,7 @@
   - name: 'anytime_td'
     target_col: 'anytime_td'
     label_version: 'v1_any_offense'
+    odds_horizon: 'cutoff'  # Restrict odds features to the decision-time snapshot
     task_type: 'classification'
     input_predictions:
       - 'availability_active'
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 5ba68e8bf1acd3a789a76a8857674e6f6433017b..0210d5b7e7ed60a8de7a126d64f5ed76326474c8
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -14,7 +14,7 @@
 
 import logging
 import os
-from datetime import date, timedelta
+from datetime import date, datetime, timedelta
 from typing import Sequence
 
 import polars as pl
@@ -37,6 +37,12 @@
     add_offense_context_features_training,
     _append_offense_context_columns,
 )
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    build_schema_snapshot,
+    enforce_leak_guard,
+    write_schema_snapshot,
+)
 from utils.feature.weather_features import (
     add_weather_forecast_features_training,
     append_weather_context_flags,
@@ -931,6 +937,32 @@
     if market_exprs:
         df_player_game_all = df_player_game_all.with_columns(market_exprs)
     
+    # Leak guard + schema snapshot before persisting
+    spec = get_label_spec(label_version)
+    allow_exact = {spec.primary, *spec.labels.keys(), *spec.aliases.keys()}
+    df_player_game_all, leak_result = enforce_leak_guard(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_exact=allow_exact,
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=True,
+    )
+
+    schema = build_schema_snapshot(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        metadata={
+            "cutoff_label": cutoff_label,
+            "label_version": spec.name,
+        },
+        banned=leak_result.banned,
+    )
+    schema_dir = FEATURE_AUDIT_DIR / "schema" / "anytime_td"
+    schema_path = schema_dir / f"{cutoff_label}_{datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')}.json"
+    write_schema_snapshot(schema_path, schema)
+    logging.info("    Schema snapshot written → %s", schema_path)
+
     # Write final feature matrix
     df_player_game_all = df_player_game_all.with_columns(
         pl.lit(current_cutoff_hours).cast(pl.Float32).alias("decision_horizon_hours")
@@ -951,7 +983,6 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    spec = get_label_spec(label_version)
     label_candidates = {spec.primary, "anytime_td"}
     for label_col in label_candidates:
         if label_col in df_player_game_all.columns:
diff --git a/pipeline/train.py b/pipeline/train.py
index fe70207dcdf25d209ee3ad55080b7ce826347c44..7c220514d006a3d4815d65a8af9ec7551ccf587e
--- a/pipeline/train.py
+++ b/pipeline/train.py
@@ -4,6 +4,7 @@
 import sys
 import logging
 import math
+import re
 
 
 # Move logging to top and remove global thread pinning
@@ -98,6 +99,7 @@
     fit_team_conformal_sums,
     composite_sum_interval,
 )
+from utils.feature.leak_guard import DEFAULT_LEAK_POLICY, enforce_leak_guard
 from utils.feature.targets import require_target_column
 
 # Ignore specific, noisy warnings from dependencies
@@ -793,6 +795,57 @@
             )
         return df
 
+    @staticmethod
+    def _filter_odds_snapshot_columns(df: pd.DataFrame, horizon_key: str | None) -> pd.DataFrame:
+        """Keep a single odds snapshot horizon (drop other suffixes)."""
+        if df is None or df.empty or not horizon_key:
+            return df
+
+        normalized = str(horizon_key).strip().lower()
+        horizon_map = {
+            "cutoff": "",
+            "default": "",
+            "": "",
+            "2h": "_2h",
+            "h120m": "_2h",
+            "6h": "_6h",
+            "h360m": "_6h",
+            "24h": "_24h",
+            "h1440m": "_24h",
+            "open": "_open",
+        }
+        allowed_suffix = horizon_map.get(normalized, normalized)
+        if allowed_suffix and not allowed_suffix.startswith("_"):
+            allowed_suffix = f"_{allowed_suffix.lstrip('_')}"
+
+        horizon_re = re.compile(r"^(?P<base>.+)(?P<suffix>_2h|_6h|_24h|_open)$")
+        suffixes_seen: dict[str, set[str]] = {}
+        for col in df.columns:
+            match = horizon_re.match(col)
+            if match:
+                suffixes_seen.setdefault(match.group("base"), set()).add(match.group("suffix"))
+
+        drop_cols: list[str] = []
+        for col in df.columns:
+            match = horizon_re.match(col)
+            if match:
+                suffix = match.group("suffix")
+                if suffix != allowed_suffix:
+                    drop_cols.append(col)
+            else:
+                base = col
+                if base in suffixes_seen and allowed_suffix:
+                    drop_cols.append(col)
+
+        if drop_cols:
+            df = df.drop(columns=drop_cols, errors="ignore")
+            logger.info(
+                "Removed %d odds snapshot columns outside horizon '%s'.",
+                len(drop_cols),
+                horizon_key,
+            )
+        return df
+
     def _ensure_player_game_actuals(self) -> pd.DataFrame:
         if self._player_game_actuals is not None:
             return self._player_game_actuals
@@ -2315,7 +2368,34 @@
                             df_problem[col] = df_problem[col].fillna(df_problem[col].mean())
 
                 df_problem = self._inject_composed_features(df_problem)
-            
+
+            odds_horizon = problem_copy.get("odds_horizon")
+            if odds_horizon:
+                df_problem = self._filter_odds_snapshot_columns(df_problem, odds_horizon)
+
+            # Leak guard on the problem-scoped frame
+            allow_prefixes = tuple(problem_copy.get('feature_prefixes_to_include') or [])
+            allow_exact = set(problem_copy.get('other_features_to_include') or [])
+            allow_exact.update(input_preds or [])
+            if self.target_col:
+                allow_exact.add(self.target_col)
+            df_problem, leak_info = enforce_leak_guard(
+                df_problem,
+                policy=DEFAULT_LEAK_POLICY,
+                allow_prefixes=allow_prefixes,
+                allow_exact=allow_exact,
+                drop_banned=True,
+                drop_non_allowlisted=False,
+                raise_on_banned=True,
+            )
+            if leak_info.dropped:
+                logger.info(
+                    "Dropped %d leak-prone columns for %s: %s",
+                    len(leak_info.dropped),
+                    problem_name,
+                    sorted(leak_info.dropped),
+                )
+
             self._normalize_datetime_like_columns(df_problem, problem_name)
             df_problem[self.time_col] = pd.to_datetime(df_problem[self.time_col])
             sort_cols = [self.time_col]
diff --git a/tests/test_data_leak_guard.py b/tests/test_data_leak_guard.py
index 8061f2760c0898aaeda29026859e1b9ff5644ba4..3e56665921db89ea523bbdb205d1bb90c21893df
--- a/tests/test_data_leak_guard.py
+++ b/tests/test_data_leak_guard.py
@@ -3,6 +3,14 @@
 import yaml
 from pathlib import Path
 
+import polars as pl
+
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    enforce_leak_guard,
+    evaluate_leak_prone_columns,
+)
+
 
 PROJECT_ROOT = Path(__file__).resolve().parents[1]
 TRAINING_CONFIG = PROJECT_ROOT / "config" / "training.yaml"
@@ -48,3 +56,41 @@
     )
 
 
+def test_leak_guard_flags_pattern_columns():
+    cols = [
+        "market_anytime_td_prob",
+        "final_score",
+        "postgame_anytime_td",
+        "actual_td_count",
+        "safe_feature",
+    ]
+    result = evaluate_leak_prone_columns(cols, policy=DEFAULT_LEAK_POLICY)
+    assert set(result.banned.keys()) == {"final_score", "postgame_anytime_td", "actual_td_count"}
+    assert "safe_feature" in result.kept
+    assert "market_anytime_td_prob" in result.kept
+
+
+def test_enforce_leak_guard_drops_banned_and_keeps_allowlisted():
+    df = pl.DataFrame(
+        {
+            "game_id": ["g1", "g2"],
+            "safe_feature": [1.0, 2.0],
+            "postgame_anytime_td": [1, 0],
+            "final_score": [30, 24],
+        }
+    )
+    cleaned, info = enforce_leak_guard(
+        df,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_prefixes=("safe_",),
+        allow_exact=("game_id",),
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=False,
+    )
+    assert "postgame_anytime_td" not in cleaned.columns
+    assert "final_score" not in cleaned.columns
+    assert "safe_feature" in cleaned.columns
+    assert "game_id" in cleaned.columns
+    assert set(info.dropped) == {"postgame_anytime_td", "final_score"}
+
diff --git a/utils/feature/leak_guard.py b/utils/feature/leak_guard.py
new file mode 100644
index 0000000000000000000000000000000000000000..9faf8cfffc436e0934b2f410aaf252e52f4f95df
--- /dev/null
+++ b/utils/feature/leak_guard.py
@@ -0,0 +1,273 @@
+"""Leak guardrails for feature matrices.
+
+This module centralizes pattern-based leak detection so both feature assembly
+and training can fail fast when post-outcome columns sneak into the data.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+from datetime import datetime
+import json
+import re
+from typing import Iterable, Mapping, Sequence
+
+import polars as pl
+
+from utils.general.constants import IDENTIFIER_COLUMNS, LEAK_PRONE_COLUMNS, NFL_TARGET_COLUMNS
+
+try:  # Optional dependency when imported from training (pandas path)
+    import pandas as pd  # type: ignore
+except Exception:  # pragma: no cover - optional dependency
+    pd = None
+
+
+@dataclass(frozen=True)
+class LeakPolicy:
+    version: str
+    banned_exact: set[str]
+    banned_prefixes: tuple[str, ...]
+    banned_suffixes: tuple[str, ...]
+    banned_regex: tuple[tuple[re.Pattern[str], str], ...]
+    description: str = ""
+
+
+@dataclass
+class LeakCheckResult:
+    policy_version: str
+    banned: dict[str, str]
+    kept: list[str]
+    dropped: list[str]
+    allowlist_kept: list[str]
+
+
+# Core policy tuned for anytime-TD style problems (can be extended per-problem).
+_BASE_BANNED_EXACT = set(LEAK_PRONE_COLUMNS) | {
+    "final_score",
+    "final_total",
+    "points_scored",
+    "actual_td_count",
+    "actual_anytime_td",
+    "postgame_anytime_td",
+    "postgame_td_count",
+}
+_BASE_BANNED_PREFIXES = (
+    "postgame_",
+    "post_game_",
+    "post_",
+    "live_",
+    "actual_",
+    "realized_",
+    "final_",
+    "postmatch_",
+)
+_BASE_BANNED_SUFFIXES = (
+    "_post",
+    "_postgame",
+    "_final",
+    "_fullgame",
+    "_actual",
+)
+_BASE_BANNED_REGEX: tuple[tuple[re.Pattern[str], str], ...] = (
+    (re.compile(r".*post.?game.*", flags=re.IGNORECASE), "postgame marker"),
+    (re.compile(r".*final_score.*", flags=re.IGNORECASE), "final score"),
+    (re.compile(r".*actual.*td.*", flags=re.IGNORECASE), "actual TD total"),
+    (re.compile(r".*anytime_td.*(post|final|actual).*", flags=re.IGNORECASE), "post-decision anytime TD"),
+    (re.compile(r".*fullgame.*", flags=re.IGNORECASE), "full game cumulative value"),
+)
+
+DEFAULT_LEAK_POLICY = LeakPolicy(
+    version="v1",
+    description="Core post-outcome leak guard for NFL anytime TD features.",
+    banned_exact=_BASE_BANNED_EXACT,
+    banned_prefixes=_BASE_BANNED_PREFIXES,
+    banned_suffixes=_BASE_BANNED_SUFFIXES,
+    banned_regex=_BASE_BANNED_REGEX,
+)
+
+
+def _ensure_sequence(value: Sequence[str] | str | None) -> tuple[str, ...]:
+    if value is None:
+        return ()
+    if isinstance(value, str):
+        return (value,)
+    return tuple(value)
+
+
+def evaluate_leak_prone_columns(
+    columns: Iterable[str],
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+) -> LeakCheckResult:
+    """Identify leak-prone columns using the configured policy."""
+
+    banned: dict[str, str] = {}
+    columns_list = list(columns)
+    for col in columns_list:
+        if col in policy.banned_exact:
+            banned[col] = "exact"
+            continue
+        for prefix in policy.banned_prefixes:
+            if col.startswith(prefix):
+                banned[col] = f"prefix:{prefix}"
+                break
+        if col in banned:
+            continue
+        for suffix in policy.banned_suffixes:
+            if col.endswith(suffix):
+                banned[col] = f"suffix:{suffix}"
+                break
+        if col in banned:
+            continue
+        for pattern, reason in policy.banned_regex:
+            if pattern.match(col):
+                banned[col] = reason
+                break
+
+    kept = [c for c in columns_list if c not in banned]
+    return LeakCheckResult(
+        policy_version=policy.version,
+        banned=banned,
+        kept=kept,
+        dropped=[],
+        allowlist_kept=[],
+    )
+
+
+def enforce_leak_guard(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    allow_prefixes: Sequence[str] | str | None = None,
+    allow_exact: Sequence[str] | str | None = None,
+    drop_banned: bool = True,
+    drop_non_allowlisted: bool = False,
+    raise_on_banned: bool = True,
+) -> tuple[pl.DataFrame | "pd.DataFrame", LeakCheckResult]:
+    """Apply leak guardrails to a feature frame.
+
+    Parameters
+    ----------
+    df : DataFrame
+        Polars or pandas DataFrame.
+    policy : LeakPolicy
+        Leak policy to apply.
+    allow_prefixes : Sequence[str] | str | None
+        Optional prefixes that define the allowed feature surface for a problem.
+    allow_exact : Sequence[str] | str | None
+        Explicitly allowed columns (e.g., identifiers).
+    drop_banned : bool
+        If True, drop any banned columns automatically.
+    drop_non_allowlisted : bool
+        If True, drop columns that are not covered by allow_prefixes/allow_exact/identifiers/targets.
+    raise_on_banned : bool
+        If True, raise when banned columns are detected (after optional drop).
+    """
+
+    result = evaluate_leak_prone_columns(df.columns, policy=policy)
+    dropped: list[str] = []
+
+    allow_prefixes = _ensure_sequence(allow_prefixes)
+    allow_exact = set(_ensure_sequence(allow_exact))
+    allow_exact.update({col for col in IDENTIFIER_COLUMNS if col in df.columns})
+    allow_exact.update({col for col in NFL_TARGET_COLUMNS if col in df.columns})
+
+    # Permit allowlisted columns even if they match a banned rule (e.g., labels)
+    banned = {col: reason for col, reason in result.banned.items() if col not in allow_exact}
+
+    if banned and drop_banned:
+        df = df.drop(list(banned.keys()))
+        dropped.extend(banned.keys())
+
+    if banned and raise_on_banned:
+        raise ValueError(f"Leak-prone columns detected: {sorted(banned.items())}")
+
+    allowlist_cols: set[str] = set()
+    if allow_prefixes:
+        allowlist_cols.update({c for c in df.columns if c.startswith(allow_prefixes)})
+    allowlist_cols.update({c for c in allow_exact if c in df.columns})
+
+    if drop_non_allowlisted and allowlist_cols:
+        drop_candidates = [c for c in df.columns if c not in allowlist_cols]
+        if drop_candidates:
+            df = df.drop(drop_candidates)
+            dropped.extend(drop_candidates)
+
+    if drop_non_allowlisted and not allowlist_cols:
+        raise ValueError("No allowlisted columns remain after applying leak guard allowlist.")
+
+    # Store adjusted banned info on the result
+    result.banned = banned
+    result.dropped = dropped
+    result.kept = [c for c in df.columns]
+    result.allowlist_kept = sorted(list(allowlist_cols)) if allowlist_cols else []
+    return df, result
+
+
+def build_schema_snapshot(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    metadata: Mapping[str, object] | None = None,
+    banned: Mapping[str, str] | None = None,
+) -> dict:
+    """Render a schema snapshot describing each column and whether it was flagged."""
+
+    banned = banned or {}
+    meta = {
+        "generated_at_utc": datetime.utcnow().isoformat(),
+        "policy_version": policy.version,
+    }
+    meta.update(metadata or {})
+
+    # Extract columns / dtypes
+    if isinstance(df, pl.DataFrame):
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+    else:  # pandas or pandas-like
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+
+    schema = {
+        "metadata": meta,
+        "columns": [],
+    }
+
+    for col, dtype in cols_and_dtypes:
+        tags: list[str] = []
+        if col in IDENTIFIER_COLUMNS:
+            tags.append("id")
+        if col in NFL_TARGET_COLUMNS:
+            tags.append("label")
+        if col.startswith("market_"):
+            tags.append("odds")
+        if col.startswith("injury_") or col.startswith("practice_"):
+            tags.append("injury")
+        if col.startswith("weather_"):
+            tags.append("weather")
+        if col.startswith("ps_"):
+            tags.append("pre_snap")
+        schema["columns"].append(
+            {
+                "name": col,
+                "dtype": dtype,
+                "banned": col in banned,
+                "tags": tags,
+            }
+        )
+    return schema
+
+
+def write_schema_snapshot(path, schema: Mapping[str, object]) -> None:
+    path.parent.mkdir(parents=True, exist_ok=True)
+    with open(path, "w") as fp:
+        json.dump(schema, fp, indent=2, sort_keys=True)
+
+
+__all__ = [
+    "DEFAULT_LEAK_POLICY",
+    "LeakPolicy",
+    "LeakCheckResult",
+    "evaluate_leak_prone_columns",
+    "enforce_leak_guard",
+    "build_schema_snapshot",
+    "write_schema_snapshot",
+]
diff --git a/utils/general/constants.py b/utils/general/constants.py
index d94b4260ad877484da843fa99ae2caf37e8493f4..dea87caa354d94e4a08b1762d2bd8dcd4c8caa3a
--- a/utils/general/constants.py
+++ b/utils/general/constants.py
@@ -211,7 +211,17 @@
 
 NFL_TARGET_COLUMNS: Tuple[str, ...] = (
     'anytime_td',
+    'anytime_td_offense',
+    'anytime_td_all',
+    'anytime_td_rush',
+    'anytime_td_rec',
+    'anytime_td_pass_thrown',
     'td_count',
+    'td_count_offense',
+    'td_count_all',
+    'passing_td',
+    'rushing_td_count',
+    'receiving_td_count',
     'receiving_yards',
     'rushing_yards',
     'passing_yards',

file update:
diff --git a/config/training.yaml b/config/training.yaml
index 3953818d861d0410246bff132110722a3ce44007..c2b6053b488caa71f9078ff100d049f723ae1548
--- a/config/training.yaml
+++ b/config/training.yaml
@@ -476,6 +476,7 @@
   - name: 'anytime_td'
     target_col: 'anytime_td'
     label_version: 'v1_any_offense'
+    odds_horizon: 'cutoff'  # Restrict odds features to the decision-time snapshot
     task_type: 'classification'
     input_predictions:
       - 'availability_active'
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 5ba68e8bf1acd3a789a76a8857674e6f6433017b..0210d5b7e7ed60a8de7a126d64f5ed76326474c8
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -14,7 +14,7 @@
 
 import logging
 import os
-from datetime import date, timedelta
+from datetime import date, datetime, timedelta
 from typing import Sequence
 
 import polars as pl
@@ -37,6 +37,12 @@
     add_offense_context_features_training,
     _append_offense_context_columns,
 )
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    build_schema_snapshot,
+    enforce_leak_guard,
+    write_schema_snapshot,
+)
 from utils.feature.weather_features import (
     add_weather_forecast_features_training,
     append_weather_context_flags,
@@ -931,6 +937,32 @@
     if market_exprs:
         df_player_game_all = df_player_game_all.with_columns(market_exprs)
     
+    # Leak guard + schema snapshot before persisting
+    spec = get_label_spec(label_version)
+    allow_exact = {spec.primary, *spec.labels.keys(), *spec.aliases.keys()}
+    df_player_game_all, leak_result = enforce_leak_guard(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_exact=allow_exact,
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=True,
+    )
+
+    schema = build_schema_snapshot(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        metadata={
+            "cutoff_label": cutoff_label,
+            "label_version": spec.name,
+        },
+        banned=leak_result.banned,
+    )
+    schema_dir = FEATURE_AUDIT_DIR / "schema" / "anytime_td"
+    schema_path = schema_dir / f"{cutoff_label}_{datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')}.json"
+    write_schema_snapshot(schema_path, schema)
+    logging.info("    Schema snapshot written → %s", schema_path)
+
     # Write final feature matrix
     df_player_game_all = df_player_game_all.with_columns(
         pl.lit(current_cutoff_hours).cast(pl.Float32).alias("decision_horizon_hours")
@@ -951,7 +983,6 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    spec = get_label_spec(label_version)
     label_candidates = {spec.primary, "anytime_td"}
     for label_col in label_candidates:
         if label_col in df_player_game_all.columns:
diff --git a/pipeline/train.py b/pipeline/train.py
index fe70207dcdf25d209ee3ad55080b7ce826347c44..7c220514d006a3d4815d65a8af9ec7551ccf587e
--- a/pipeline/train.py
+++ b/pipeline/train.py
@@ -4,6 +4,7 @@
 import sys
 import logging
 import math
+import re
 
 
 # Move logging to top and remove global thread pinning
@@ -98,6 +99,7 @@
     fit_team_conformal_sums,
     composite_sum_interval,
 )
+from utils.feature.leak_guard import DEFAULT_LEAK_POLICY, enforce_leak_guard
 from utils.feature.targets import require_target_column
 
 # Ignore specific, noisy warnings from dependencies
@@ -793,6 +795,57 @@
             )
         return df
 
+    @staticmethod
+    def _filter_odds_snapshot_columns(df: pd.DataFrame, horizon_key: str | None) -> pd.DataFrame:
+        """Keep a single odds snapshot horizon (drop other suffixes)."""
+        if df is None or df.empty or not horizon_key:
+            return df
+
+        normalized = str(horizon_key).strip().lower()
+        horizon_map = {
+            "cutoff": "",
+            "default": "",
+            "": "",
+            "2h": "_2h",
+            "h120m": "_2h",
+            "6h": "_6h",
+            "h360m": "_6h",
+            "24h": "_24h",
+            "h1440m": "_24h",
+            "open": "_open",
+        }
+        allowed_suffix = horizon_map.get(normalized, normalized)
+        if allowed_suffix and not allowed_suffix.startswith("_"):
+            allowed_suffix = f"_{allowed_suffix.lstrip('_')}"
+
+        horizon_re = re.compile(r"^(?P<base>.+)(?P<suffix>_2h|_6h|_24h|_open)$")
+        suffixes_seen: dict[str, set[str]] = {}
+        for col in df.columns:
+            match = horizon_re.match(col)
+            if match:
+                suffixes_seen.setdefault(match.group("base"), set()).add(match.group("suffix"))
+
+        drop_cols: list[str] = []
+        for col in df.columns:
+            match = horizon_re.match(col)
+            if match:
+                suffix = match.group("suffix")
+                if suffix != allowed_suffix:
+                    drop_cols.append(col)
+            else:
+                base = col
+                if base in suffixes_seen and allowed_suffix:
+                    drop_cols.append(col)
+
+        if drop_cols:
+            df = df.drop(columns=drop_cols, errors="ignore")
+            logger.info(
+                "Removed %d odds snapshot columns outside horizon '%s'.",
+                len(drop_cols),
+                horizon_key,
+            )
+        return df
+
     def _ensure_player_game_actuals(self) -> pd.DataFrame:
         if self._player_game_actuals is not None:
             return self._player_game_actuals
@@ -2315,7 +2368,34 @@
                             df_problem[col] = df_problem[col].fillna(df_problem[col].mean())
 
                 df_problem = self._inject_composed_features(df_problem)
-            
+
+            odds_horizon = problem_copy.get("odds_horizon")
+            if odds_horizon:
+                df_problem = self._filter_odds_snapshot_columns(df_problem, odds_horizon)
+
+            # Leak guard on the problem-scoped frame
+            allow_prefixes = tuple(problem_copy.get('feature_prefixes_to_include') or [])
+            allow_exact = set(problem_copy.get('other_features_to_include') or [])
+            allow_exact.update(input_preds or [])
+            if self.target_col:
+                allow_exact.add(self.target_col)
+            df_problem, leak_info = enforce_leak_guard(
+                df_problem,
+                policy=DEFAULT_LEAK_POLICY,
+                allow_prefixes=allow_prefixes,
+                allow_exact=allow_exact,
+                drop_banned=True,
+                drop_non_allowlisted=False,
+                raise_on_banned=True,
+            )
+            if leak_info.dropped:
+                logger.info(
+                    "Dropped %d leak-prone columns for %s: %s",
+                    len(leak_info.dropped),
+                    problem_name,
+                    sorted(leak_info.dropped),
+                )
+
             self._normalize_datetime_like_columns(df_problem, problem_name)
             df_problem[self.time_col] = pd.to_datetime(df_problem[self.time_col])
             sort_cols = [self.time_col]
diff --git a/tests/test_data_leak_guard.py b/tests/test_data_leak_guard.py
index 8061f2760c0898aaeda29026859e1b9ff5644ba4..3e56665921db89ea523bbdb205d1bb90c21893df
--- a/tests/test_data_leak_guard.py
+++ b/tests/test_data_leak_guard.py
@@ -3,6 +3,14 @@
 import yaml
 from pathlib import Path
 
+import polars as pl
+
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    enforce_leak_guard,
+    evaluate_leak_prone_columns,
+)
+
 
 PROJECT_ROOT = Path(__file__).resolve().parents[1]
 TRAINING_CONFIG = PROJECT_ROOT / "config" / "training.yaml"
@@ -48,3 +56,41 @@
     )
 
 
+def test_leak_guard_flags_pattern_columns():
+    cols = [
+        "market_anytime_td_prob",
+        "final_score",
+        "postgame_anytime_td",
+        "actual_td_count",
+        "safe_feature",
+    ]
+    result = evaluate_leak_prone_columns(cols, policy=DEFAULT_LEAK_POLICY)
+    assert set(result.banned.keys()) == {"final_score", "postgame_anytime_td", "actual_td_count"}
+    assert "safe_feature" in result.kept
+    assert "market_anytime_td_prob" in result.kept
+
+
+def test_enforce_leak_guard_drops_banned_and_keeps_allowlisted():
+    df = pl.DataFrame(
+        {
+            "game_id": ["g1", "g2"],
+            "safe_feature": [1.0, 2.0],
+            "postgame_anytime_td": [1, 0],
+            "final_score": [30, 24],
+        }
+    )
+    cleaned, info = enforce_leak_guard(
+        df,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_prefixes=("safe_",),
+        allow_exact=("game_id",),
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=False,
+    )
+    assert "postgame_anytime_td" not in cleaned.columns
+    assert "final_score" not in cleaned.columns
+    assert "safe_feature" in cleaned.columns
+    assert "game_id" in cleaned.columns
+    assert set(info.dropped) == {"postgame_anytime_td", "final_score"}
+
diff --git a/utils/feature/leak_guard.py b/utils/feature/leak_guard.py
new file mode 100644
index 0000000000000000000000000000000000000000..9faf8cfffc436e0934b2f410aaf252e52f4f95df
--- /dev/null
+++ b/utils/feature/leak_guard.py
@@ -0,0 +1,273 @@
+"""Leak guardrails for feature matrices.
+
+This module centralizes pattern-based leak detection so both feature assembly
+and training can fail fast when post-outcome columns sneak into the data.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+from datetime import datetime
+import json
+import re
+from typing import Iterable, Mapping, Sequence
+
+import polars as pl
+
+from utils.general.constants import IDENTIFIER_COLUMNS, LEAK_PRONE_COLUMNS, NFL_TARGET_COLUMNS
+
+try:  # Optional dependency when imported from training (pandas path)
+    import pandas as pd  # type: ignore
+except Exception:  # pragma: no cover - optional dependency
+    pd = None
+
+
+@dataclass(frozen=True)
+class LeakPolicy:
+    version: str
+    banned_exact: set[str]
+    banned_prefixes: tuple[str, ...]
+    banned_suffixes: tuple[str, ...]
+    banned_regex: tuple[tuple[re.Pattern[str], str], ...]
+    description: str = ""
+
+
+@dataclass
+class LeakCheckResult:
+    policy_version: str
+    banned: dict[str, str]
+    kept: list[str]
+    dropped: list[str]
+    allowlist_kept: list[str]
+
+
+# Core policy tuned for anytime-TD style problems (can be extended per-problem).
+_BASE_BANNED_EXACT = set(LEAK_PRONE_COLUMNS) | {
+    "final_score",
+    "final_total",
+    "points_scored",
+    "actual_td_count",
+    "actual_anytime_td",
+    "postgame_anytime_td",
+    "postgame_td_count",
+}
+_BASE_BANNED_PREFIXES = (
+    "postgame_",
+    "post_game_",
+    "post_",
+    "live_",
+    "actual_",
+    "realized_",
+    "final_",
+    "postmatch_",
+)
+_BASE_BANNED_SUFFIXES = (
+    "_post",
+    "_postgame",
+    "_final",
+    "_fullgame",
+    "_actual",
+)
+_BASE_BANNED_REGEX: tuple[tuple[re.Pattern[str], str], ...] = (
+    (re.compile(r".*post.?game.*", flags=re.IGNORECASE), "postgame marker"),
+    (re.compile(r".*final_score.*", flags=re.IGNORECASE), "final score"),
+    (re.compile(r".*actual.*td.*", flags=re.IGNORECASE), "actual TD total"),
+    (re.compile(r".*anytime_td.*(post|final|actual).*", flags=re.IGNORECASE), "post-decision anytime TD"),
+    (re.compile(r".*fullgame.*", flags=re.IGNORECASE), "full game cumulative value"),
+)
+
+DEFAULT_LEAK_POLICY = LeakPolicy(
+    version="v1",
+    description="Core post-outcome leak guard for NFL anytime TD features.",
+    banned_exact=_BASE_BANNED_EXACT,
+    banned_prefixes=_BASE_BANNED_PREFIXES,
+    banned_suffixes=_BASE_BANNED_SUFFIXES,
+    banned_regex=_BASE_BANNED_REGEX,
+)
+
+
+def _ensure_sequence(value: Sequence[str] | str | None) -> tuple[str, ...]:
+    if value is None:
+        return ()
+    if isinstance(value, str):
+        return (value,)
+    return tuple(value)
+
+
+def evaluate_leak_prone_columns(
+    columns: Iterable[str],
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+) -> LeakCheckResult:
+    """Identify leak-prone columns using the configured policy."""
+
+    banned: dict[str, str] = {}
+    columns_list = list(columns)
+    for col in columns_list:
+        if col in policy.banned_exact:
+            banned[col] = "exact"
+            continue
+        for prefix in policy.banned_prefixes:
+            if col.startswith(prefix):
+                banned[col] = f"prefix:{prefix}"
+                break
+        if col in banned:
+            continue
+        for suffix in policy.banned_suffixes:
+            if col.endswith(suffix):
+                banned[col] = f"suffix:{suffix}"
+                break
+        if col in banned:
+            continue
+        for pattern, reason in policy.banned_regex:
+            if pattern.match(col):
+                banned[col] = reason
+                break
+
+    kept = [c for c in columns_list if c not in banned]
+    return LeakCheckResult(
+        policy_version=policy.version,
+        banned=banned,
+        kept=kept,
+        dropped=[],
+        allowlist_kept=[],
+    )
+
+
+def enforce_leak_guard(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    allow_prefixes: Sequence[str] | str | None = None,
+    allow_exact: Sequence[str] | str | None = None,
+    drop_banned: bool = True,
+    drop_non_allowlisted: bool = False,
+    raise_on_banned: bool = True,
+) -> tuple[pl.DataFrame | "pd.DataFrame", LeakCheckResult]:
+    """Apply leak guardrails to a feature frame.
+
+    Parameters
+    ----------
+    df : DataFrame
+        Polars or pandas DataFrame.
+    policy : LeakPolicy
+        Leak policy to apply.
+    allow_prefixes : Sequence[str] | str | None
+        Optional prefixes that define the allowed feature surface for a problem.
+    allow_exact : Sequence[str] | str | None
+        Explicitly allowed columns (e.g., identifiers).
+    drop_banned : bool
+        If True, drop any banned columns automatically.
+    drop_non_allowlisted : bool
+        If True, drop columns that are not covered by allow_prefixes/allow_exact/identifiers/targets.
+    raise_on_banned : bool
+        If True, raise when banned columns are detected (after optional drop).
+    """
+
+    result = evaluate_leak_prone_columns(df.columns, policy=policy)
+    dropped: list[str] = []
+
+    allow_prefixes = _ensure_sequence(allow_prefixes)
+    allow_exact = set(_ensure_sequence(allow_exact))
+    allow_exact.update({col for col in IDENTIFIER_COLUMNS if col in df.columns})
+    allow_exact.update({col for col in NFL_TARGET_COLUMNS if col in df.columns})
+
+    # Permit allowlisted columns even if they match a banned rule (e.g., labels)
+    banned = {col: reason for col, reason in result.banned.items() if col not in allow_exact}
+
+    if banned and drop_banned:
+        df = df.drop(list(banned.keys()))
+        dropped.extend(banned.keys())
+
+    if banned and raise_on_banned:
+        raise ValueError(f"Leak-prone columns detected: {sorted(banned.items())}")
+
+    allowlist_cols: set[str] = set()
+    if allow_prefixes:
+        allowlist_cols.update({c for c in df.columns if c.startswith(allow_prefixes)})
+    allowlist_cols.update({c for c in allow_exact if c in df.columns})
+
+    if drop_non_allowlisted and allowlist_cols:
+        drop_candidates = [c for c in df.columns if c not in allowlist_cols]
+        if drop_candidates:
+            df = df.drop(drop_candidates)
+            dropped.extend(drop_candidates)
+
+    if drop_non_allowlisted and not allowlist_cols:
+        raise ValueError("No allowlisted columns remain after applying leak guard allowlist.")
+
+    # Store adjusted banned info on the result
+    result.banned = banned
+    result.dropped = dropped
+    result.kept = [c for c in df.columns]
+    result.allowlist_kept = sorted(list(allowlist_cols)) if allowlist_cols else []
+    return df, result
+
+
+def build_schema_snapshot(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    metadata: Mapping[str, object] | None = None,
+    banned: Mapping[str, str] | None = None,
+) -> dict:
+    """Render a schema snapshot describing each column and whether it was flagged."""
+
+    banned = banned or {}
+    meta = {
+        "generated_at_utc": datetime.utcnow().isoformat(),
+        "policy_version": policy.version,
+    }
+    meta.update(metadata or {})
+
+    # Extract columns / dtypes
+    if isinstance(df, pl.DataFrame):
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+    else:  # pandas or pandas-like
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+
+    schema = {
+        "metadata": meta,
+        "columns": [],
+    }
+
+    for col, dtype in cols_and_dtypes:
+        tags: list[str] = []
+        if col in IDENTIFIER_COLUMNS:
+            tags.append("id")
+        if col in NFL_TARGET_COLUMNS:
+            tags.append("label")
+        if col.startswith("market_"):
+            tags.append("odds")
+        if col.startswith("injury_") or col.startswith("practice_"):
+            tags.append("injury")
+        if col.startswith("weather_"):
+            tags.append("weather")
+        if col.startswith("ps_"):
+            tags.append("pre_snap")
+        schema["columns"].append(
+            {
+                "name": col,
+                "dtype": dtype,
+                "banned": col in banned,
+                "tags": tags,
+            }
+        )
+    return schema
+
+
+def write_schema_snapshot(path, schema: Mapping[str, object]) -> None:
+    path.parent.mkdir(parents=True, exist_ok=True)
+    with open(path, "w") as fp:
+        json.dump(schema, fp, indent=2, sort_keys=True)
+
+
+__all__ = [
+    "DEFAULT_LEAK_POLICY",
+    "LeakPolicy",
+    "LeakCheckResult",
+    "evaluate_leak_prone_columns",
+    "enforce_leak_guard",
+    "build_schema_snapshot",
+    "write_schema_snapshot",
+]
diff --git a/utils/general/constants.py b/utils/general/constants.py
index d94b4260ad877484da843fa99ae2caf37e8493f4..dea87caa354d94e4a08b1762d2bd8dcd4c8caa3a
--- a/utils/general/constants.py
+++ b/utils/general/constants.py
@@ -211,7 +211,17 @@
 
 NFL_TARGET_COLUMNS: Tuple[str, ...] = (
     'anytime_td',
+    'anytime_td_offense',
+    'anytime_td_all',
+    'anytime_td_rush',
+    'anytime_td_rec',
+    'anytime_td_pass_thrown',
     'td_count',
+    'td_count_offense',
+    'td_count_all',
+    'passing_td',
+    'rushing_td_count',
+    'receiving_td_count',
     'receiving_yards',
     'rushing_yards',
     'passing_yards',


thinking
**Adding tests for odds filter helper**
file update
A /Users/jameswest/Desktop/nfl_predict/tests/test_odds_horizon_filter.py
from __future__ import annotations

import pandas as pd

from pipeline.train import ModelTrainer


def test_filter_odds_snapshot_columns_cutoff_keeps_base_only():
    df = pd.DataFrame(
        {
            "market_anytime_td_prob": [0.1, 0.2],
            "market_anytime_td_prob_2h": [0.15, 0.25],
            "market_anytime_td_prob_6h": [0.2, 0.3],
            "other_feature": [1, 2],
        }
    )
    filtered = ModelTrainer._filter_odds_snapshot_columns(df.copy(), "cutoff")
    assert "market_anytime_td_prob" in filtered.columns
    assert "market_anytime_td_prob_2h" not in filtered.columns
    assert "market_anytime_td_prob_6h" not in filtered.columns
    assert "other_feature" in filtered.columns


def test_filter_odds_snapshot_columns_specific_suffix():
    df = pd.DataFrame(
        {
            "market_anytime_td_prob": [0.1, 0.2],
            "market_anytime_td_prob_2h": [0.15, 0.25],
            "market_anytime_td_prob_6h": [0.2, 0.3],
        }
    )
    filtered = ModelTrainer._filter_odds_snapshot_columns(df.copy(), "6h")
    assert list(filtered.columns) == ["market_anytime_td_prob_6h"]
apply_patch(auto_approved=true) exited 0 in 99ms:
Success. Updated the following files:
A tests/test_odds_horizon_filter.py
file update:
diff --git a/config/training.yaml b/config/training.yaml
index 3953818d861d0410246bff132110722a3ce44007..c2b6053b488caa71f9078ff100d049f723ae1548
--- a/config/training.yaml
+++ b/config/training.yaml
@@ -476,6 +476,7 @@
   - name: 'anytime_td'
     target_col: 'anytime_td'
     label_version: 'v1_any_offense'
+    odds_horizon: 'cutoff'  # Restrict odds features to the decision-time snapshot
     task_type: 'classification'
     input_predictions:
       - 'availability_active'
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 5ba68e8bf1acd3a789a76a8857674e6f6433017b..0210d5b7e7ed60a8de7a126d64f5ed76326474c8
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -14,7 +14,7 @@
 
 import logging
 import os
-from datetime import date, timedelta
+from datetime import date, datetime, timedelta
 from typing import Sequence
 
 import polars as pl
@@ -37,6 +37,12 @@
     add_offense_context_features_training,
     _append_offense_context_columns,
 )
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    build_schema_snapshot,
+    enforce_leak_guard,
+    write_schema_snapshot,
+)
 from utils.feature.weather_features import (
     add_weather_forecast_features_training,
     append_weather_context_flags,
@@ -931,6 +937,32 @@
     if market_exprs:
         df_player_game_all = df_player_game_all.with_columns(market_exprs)
     
+    # Leak guard + schema snapshot before persisting
+    spec = get_label_spec(label_version)
+    allow_exact = {spec.primary, *spec.labels.keys(), *spec.aliases.keys()}
+    df_player_game_all, leak_result = enforce_leak_guard(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_exact=allow_exact,
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=True,
+    )
+
+    schema = build_schema_snapshot(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        metadata={
+            "cutoff_label": cutoff_label,
+            "label_version": spec.name,
+        },
+        banned=leak_result.banned,
+    )
+    schema_dir = FEATURE_AUDIT_DIR / "schema" / "anytime_td"
+    schema_path = schema_dir / f"{cutoff_label}_{datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')}.json"
+    write_schema_snapshot(schema_path, schema)
+    logging.info("    Schema snapshot written → %s", schema_path)
+
     # Write final feature matrix
     df_player_game_all = df_player_game_all.with_columns(
         pl.lit(current_cutoff_hours).cast(pl.Float32).alias("decision_horizon_hours")
@@ -951,7 +983,6 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    spec = get_label_spec(label_version)
     label_candidates = {spec.primary, "anytime_td"}
     for label_col in label_candidates:
         if label_col in df_player_game_all.columns:
diff --git a/pipeline/train.py b/pipeline/train.py
index fe70207dcdf25d209ee3ad55080b7ce826347c44..7c220514d006a3d4815d65a8af9ec7551ccf587e
--- a/pipeline/train.py
+++ b/pipeline/train.py
@@ -4,6 +4,7 @@
 import sys
 import logging
 import math
+import re
 
 
 # Move logging to top and remove global thread pinning
@@ -98,6 +99,7 @@
     fit_team_conformal_sums,
     composite_sum_interval,
 )
+from utils.feature.leak_guard import DEFAULT_LEAK_POLICY, enforce_leak_guard
 from utils.feature.targets import require_target_column
 
 # Ignore specific, noisy warnings from dependencies
@@ -793,6 +795,57 @@
             )
         return df
 
+    @staticmethod
+    def _filter_odds_snapshot_columns(df: pd.DataFrame, horizon_key: str | None) -> pd.DataFrame:
+        """Keep a single odds snapshot horizon (drop other suffixes)."""
+        if df is None or df.empty or not horizon_key:
+            return df
+
+        normalized = str(horizon_key).strip().lower()
+        horizon_map = {
+            "cutoff": "",
+            "default": "",
+            "": "",
+            "2h": "_2h",
+            "h120m": "_2h",
+            "6h": "_6h",
+            "h360m": "_6h",
+            "24h": "_24h",
+            "h1440m": "_24h",
+            "open": "_open",
+        }
+        allowed_suffix = horizon_map.get(normalized, normalized)
+        if allowed_suffix and not allowed_suffix.startswith("_"):
+            allowed_suffix = f"_{allowed_suffix.lstrip('_')}"
+
+        horizon_re = re.compile(r"^(?P<base>.+)(?P<suffix>_2h|_6h|_24h|_open)$")
+        suffixes_seen: dict[str, set[str]] = {}
+        for col in df.columns:
+            match = horizon_re.match(col)
+            if match:
+                suffixes_seen.setdefault(match.group("base"), set()).add(match.group("suffix"))
+
+        drop_cols: list[str] = []
+        for col in df.columns:
+            match = horizon_re.match(col)
+            if match:
+                suffix = match.group("suffix")
+                if suffix != allowed_suffix:
+                    drop_cols.append(col)
+            else:
+                base = col
+                if base in suffixes_seen and allowed_suffix:
+                    drop_cols.append(col)
+
+        if drop_cols:
+            df = df.drop(columns=drop_cols, errors="ignore")
+            logger.info(
+                "Removed %d odds snapshot columns outside horizon '%s'.",
+                len(drop_cols),
+                horizon_key,
+            )
+        return df
+
     def _ensure_player_game_actuals(self) -> pd.DataFrame:
         if self._player_game_actuals is not None:
             return self._player_game_actuals
@@ -2315,7 +2368,34 @@
                             df_problem[col] = df_problem[col].fillna(df_problem[col].mean())
 
                 df_problem = self._inject_composed_features(df_problem)
-            
+
+            odds_horizon = problem_copy.get("odds_horizon")
+            if odds_horizon:
+                df_problem = self._filter_odds_snapshot_columns(df_problem, odds_horizon)
+
+            # Leak guard on the problem-scoped frame
+            allow_prefixes = tuple(problem_copy.get('feature_prefixes_to_include') or [])
+            allow_exact = set(problem_copy.get('other_features_to_include') or [])
+            allow_exact.update(input_preds or [])
+            if self.target_col:
+                allow_exact.add(self.target_col)
+            df_problem, leak_info = enforce_leak_guard(
+                df_problem,
+                policy=DEFAULT_LEAK_POLICY,
+                allow_prefixes=allow_prefixes,
+                allow_exact=allow_exact,
+                drop_banned=True,
+                drop_non_allowlisted=False,
+                raise_on_banned=True,
+            )
+            if leak_info.dropped:
+                logger.info(
+                    "Dropped %d leak-prone columns for %s: %s",
+                    len(leak_info.dropped),
+                    problem_name,
+                    sorted(leak_info.dropped),
+                )
+
             self._normalize_datetime_like_columns(df_problem, problem_name)
             df_problem[self.time_col] = pd.to_datetime(df_problem[self.time_col])
             sort_cols = [self.time_col]
diff --git a/tests/test_data_leak_guard.py b/tests/test_data_leak_guard.py
index 8061f2760c0898aaeda29026859e1b9ff5644ba4..3e56665921db89ea523bbdb205d1bb90c21893df
--- a/tests/test_data_leak_guard.py
+++ b/tests/test_data_leak_guard.py
@@ -3,6 +3,14 @@
 import yaml
 from pathlib import Path
 
+import polars as pl
+
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    enforce_leak_guard,
+    evaluate_leak_prone_columns,
+)
+
 
 PROJECT_ROOT = Path(__file__).resolve().parents[1]
 TRAINING_CONFIG = PROJECT_ROOT / "config" / "training.yaml"
@@ -48,3 +56,41 @@
     )
 
 
+def test_leak_guard_flags_pattern_columns():
+    cols = [
+        "market_anytime_td_prob",
+        "final_score",
+        "postgame_anytime_td",
+        "actual_td_count",
+        "safe_feature",
+    ]
+    result = evaluate_leak_prone_columns(cols, policy=DEFAULT_LEAK_POLICY)
+    assert set(result.banned.keys()) == {"final_score", "postgame_anytime_td", "actual_td_count"}
+    assert "safe_feature" in result.kept
+    assert "market_anytime_td_prob" in result.kept
+
+
+def test_enforce_leak_guard_drops_banned_and_keeps_allowlisted():
+    df = pl.DataFrame(
+        {
+            "game_id": ["g1", "g2"],
+            "safe_feature": [1.0, 2.0],
+            "postgame_anytime_td": [1, 0],
+            "final_score": [30, 24],
+        }
+    )
+    cleaned, info = enforce_leak_guard(
+        df,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_prefixes=("safe_",),
+        allow_exact=("game_id",),
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=False,
+    )
+    assert "postgame_anytime_td" not in cleaned.columns
+    assert "final_score" not in cleaned.columns
+    assert "safe_feature" in cleaned.columns
+    assert "game_id" in cleaned.columns
+    assert set(info.dropped) == {"postgame_anytime_td", "final_score"}
+
diff --git a/tests/test_odds_horizon_filter.py b/tests/test_odds_horizon_filter.py
new file mode 100644
index 0000000000000000000000000000000000000000..0a9d9aa2ef7eeb1272426c615e5126b18f8e10ba
--- /dev/null
+++ b/tests/test_odds_horizon_filter.py
@@ -0,0 +1,33 @@
+from __future__ import annotations
+
+import pandas as pd
+
+from pipeline.train import ModelTrainer
+
+
+def test_filter_odds_snapshot_columns_cutoff_keeps_base_only():
+    df = pd.DataFrame(
+        {
+            "market_anytime_td_prob": [0.1, 0.2],
+            "market_anytime_td_prob_2h": [0.15, 0.25],
+            "market_anytime_td_prob_6h": [0.2, 0.3],
+            "other_feature": [1, 2],
+        }
+    )
+    filtered = ModelTrainer._filter_odds_snapshot_columns(df.copy(), "cutoff")
+    assert "market_anytime_td_prob" in filtered.columns
+    assert "market_anytime_td_prob_2h" not in filtered.columns
+    assert "market_anytime_td_prob_6h" not in filtered.columns
+    assert "other_feature" in filtered.columns
+
+
+def test_filter_odds_snapshot_columns_specific_suffix():
+    df = pd.DataFrame(
+        {
+            "market_anytime_td_prob": [0.1, 0.2],
+            "market_anytime_td_prob_2h": [0.15, 0.25],
+            "market_anytime_td_prob_6h": [0.2, 0.3],
+        }
+    )
+    filtered = ModelTrainer._filter_odds_snapshot_columns(df.copy(), "6h")
+    assert list(filtered.columns) == ["market_anytime_td_prob_6h"]
diff --git a/utils/feature/leak_guard.py b/utils/feature/leak_guard.py
new file mode 100644
index 0000000000000000000000000000000000000000..9faf8cfffc436e0934b2f410aaf252e52f4f95df
--- /dev/null
+++ b/utils/feature/leak_guard.py
@@ -0,0 +1,273 @@
+"""Leak guardrails for feature matrices.
+
+This module centralizes pattern-based leak detection so both feature assembly
+and training can fail fast when post-outcome columns sneak into the data.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+from datetime import datetime
+import json
+import re
+from typing import Iterable, Mapping, Sequence
+
+import polars as pl
+
+from utils.general.constants import IDENTIFIER_COLUMNS, LEAK_PRONE_COLUMNS, NFL_TARGET_COLUMNS
+
+try:  # Optional dependency when imported from training (pandas path)
+    import pandas as pd  # type: ignore
+except Exception:  # pragma: no cover - optional dependency
+    pd = None
+
+
+@dataclass(frozen=True)
+class LeakPolicy:
+    version: str
+    banned_exact: set[str]
+    banned_prefixes: tuple[str, ...]
+    banned_suffixes: tuple[str, ...]
+    banned_regex: tuple[tuple[re.Pattern[str], str], ...]
+    description: str = ""
+
+
+@dataclass
+class LeakCheckResult:
+    policy_version: str
+    banned: dict[str, str]
+    kept: list[str]
+    dropped: list[str]
+    allowlist_kept: list[str]
+
+
+# Core policy tuned for anytime-TD style problems (can be extended per-problem).
+_BASE_BANNED_EXACT = set(LEAK_PRONE_COLUMNS) | {
+    "final_score",
+    "final_total",
+    "points_scored",
+    "actual_td_count",
+    "actual_anytime_td",
+    "postgame_anytime_td",
+    "postgame_td_count",
+}
+_BASE_BANNED_PREFIXES = (
+    "postgame_",
+    "post_game_",
+    "post_",
+    "live_",
+    "actual_",
+    "realized_",
+    "final_",
+    "postmatch_",
+)
+_BASE_BANNED_SUFFIXES = (
+    "_post",
+    "_postgame",
+    "_final",
+    "_fullgame",
+    "_actual",
+)
+_BASE_BANNED_REGEX: tuple[tuple[re.Pattern[str], str], ...] = (
+    (re.compile(r".*post.?game.*", flags=re.IGNORECASE), "postgame marker"),
+    (re.compile(r".*final_score.*", flags=re.IGNORECASE), "final score"),
+    (re.compile(r".*actual.*td.*", flags=re.IGNORECASE), "actual TD total"),
+    (re.compile(r".*anytime_td.*(post|final|actual).*", flags=re.IGNORECASE), "post-decision anytime TD"),
+    (re.compile(r".*fullgame.*", flags=re.IGNORECASE), "full game cumulative value"),
+)
+
+DEFAULT_LEAK_POLICY = LeakPolicy(
+    version="v1",
+    description="Core post-outcome leak guard for NFL anytime TD features.",
+    banned_exact=_BASE_BANNED_EXACT,
+    banned_prefixes=_BASE_BANNED_PREFIXES,
+    banned_suffixes=_BASE_BANNED_SUFFIXES,
+    banned_regex=_BASE_BANNED_REGEX,
+)
+
+
+def _ensure_sequence(value: Sequence[str] | str | None) -> tuple[str, ...]:
+    if value is None:
+        return ()
+    if isinstance(value, str):
+        return (value,)
+    return tuple(value)
+
+
+def evaluate_leak_prone_columns(
+    columns: Iterable[str],
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+) -> LeakCheckResult:
+    """Identify leak-prone columns using the configured policy."""
+
+    banned: dict[str, str] = {}
+    columns_list = list(columns)
+    for col in columns_list:
+        if col in policy.banned_exact:
+            banned[col] = "exact"
+            continue
+        for prefix in policy.banned_prefixes:
+            if col.startswith(prefix):
+                banned[col] = f"prefix:{prefix}"
+                break
+        if col in banned:
+            continue
+        for suffix in policy.banned_suffixes:
+            if col.endswith(suffix):
+                banned[col] = f"suffix:{suffix}"
+                break
+        if col in banned:
+            continue
+        for pattern, reason in policy.banned_regex:
+            if pattern.match(col):
+                banned[col] = reason
+                break
+
+    kept = [c for c in columns_list if c not in banned]
+    return LeakCheckResult(
+        policy_version=policy.version,
+        banned=banned,
+        kept=kept,
+        dropped=[],
+        allowlist_kept=[],
+    )
+
+
+def enforce_leak_guard(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    allow_prefixes: Sequence[str] | str | None = None,
+    allow_exact: Sequence[str] | str | None = None,
+    drop_banned: bool = True,
+    drop_non_allowlisted: bool = False,
+    raise_on_banned: bool = True,
+) -> tuple[pl.DataFrame | "pd.DataFrame", LeakCheckResult]:
+    """Apply leak guardrails to a feature frame.
+
+    Parameters
+    ----------
+    df : DataFrame
+        Polars or pandas DataFrame.
+    policy : LeakPolicy
+        Leak policy to apply.
+    allow_prefixes : Sequence[str] | str | None
+        Optional prefixes that define the allowed feature surface for a problem.
+    allow_exact : Sequence[str] | str | None
+        Explicitly allowed columns (e.g., identifiers).
+    drop_banned : bool
+        If True, drop any banned columns automatically.
+    drop_non_allowlisted : bool
+        If True, drop columns that are not covered by allow_prefixes/allow_exact/identifiers/targets.
+    raise_on_banned : bool
+        If True, raise when banned columns are detected (after optional drop).
+    """
+
+    result = evaluate_leak_prone_columns(df.columns, policy=policy)
+    dropped: list[str] = []
+
+    allow_prefixes = _ensure_sequence(allow_prefixes)
+    allow_exact = set(_ensure_sequence(allow_exact))
+    allow_exact.update({col for col in IDENTIFIER_COLUMNS if col in df.columns})
+    allow_exact.update({col for col in NFL_TARGET_COLUMNS if col in df.columns})
+
+    # Permit allowlisted columns even if they match a banned rule (e.g., labels)
+    banned = {col: reason for col, reason in result.banned.items() if col not in allow_exact}
+
+    if banned and drop_banned:
+        df = df.drop(list(banned.keys()))
+        dropped.extend(banned.keys())
+
+    if banned and raise_on_banned:
+        raise ValueError(f"Leak-prone columns detected: {sorted(banned.items())}")
+
+    allowlist_cols: set[str] = set()
+    if allow_prefixes:
+        allowlist_cols.update({c for c in df.columns if c.startswith(allow_prefixes)})
+    allowlist_cols.update({c for c in allow_exact if c in df.columns})
+
+    if drop_non_allowlisted and allowlist_cols:
+        drop_candidates = [c for c in df.columns if c not in allowlist_cols]
+        if drop_candidates:
+            df = df.drop(drop_candidates)
+            dropped.extend(drop_candidates)
+
+    if drop_non_allowlisted and not allowlist_cols:
+        raise ValueError("No allowlisted columns remain after applying leak guard allowlist.")
+
+    # Store adjusted banned info on the result
+    result.banned = banned
+    result.dropped = dropped
+    result.kept = [c for c in df.columns]
+    result.allowlist_kept = sorted(list(allowlist_cols)) if allowlist_cols else []
+    return df, result
+
+
+def build_schema_snapshot(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    metadata: Mapping[str, object] | None = None,
+    banned: Mapping[str, str] | None = None,
+) -> dict:
+    """Render a schema snapshot describing each column and whether it was flagged."""
+
+    banned = banned or {}
+    meta = {
+        "generated_at_utc": datetime.utcnow().isoformat(),
+        "policy_version": policy.version,
+    }
+    meta.update(metadata or {})
+
+    # Extract columns / dtypes
+    if isinstance(df, pl.DataFrame):
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+    else:  # pandas or pandas-like
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+
+    schema = {
+        "metadata": meta,
+        "columns": [],
+    }
+
+    for col, dtype in cols_and_dtypes:
+        tags: list[str] = []
+        if col in IDENTIFIER_COLUMNS:
+            tags.append("id")
+        if col in NFL_TARGET_COLUMNS:
+            tags.append("label")
+        if col.startswith("market_"):
+            tags.append("odds")
+        if col.startswith("injury_") or col.startswith("practice_"):
+            tags.append("injury")
+        if col.startswith("weather_"):
+            tags.append("weather")
+        if col.startswith("ps_"):
+            tags.append("pre_snap")
+        schema["columns"].append(
+            {
+                "name": col,
+                "dtype": dtype,
+                "banned": col in banned,
+                "tags": tags,
+            }
+        )
+    return schema
+
+
+def write_schema_snapshot(path, schema: Mapping[str, object]) -> None:
+    path.parent.mkdir(parents=True, exist_ok=True)
+    with open(path, "w") as fp:
+        json.dump(schema, fp, indent=2, sort_keys=True)
+
+
+__all__ = [
+    "DEFAULT_LEAK_POLICY",
+    "LeakPolicy",
+    "LeakCheckResult",
+    "evaluate_leak_prone_columns",
+    "enforce_leak_guard",
+    "build_schema_snapshot",
+    "write_schema_snapshot",
+]
diff --git a/utils/general/constants.py b/utils/general/constants.py
index d94b4260ad877484da843fa99ae2caf37e8493f4..dea87caa354d94e4a08b1762d2bd8dcd4c8caa3a
--- a/utils/general/constants.py
+++ b/utils/general/constants.py
@@ -211,7 +211,17 @@
 
 NFL_TARGET_COLUMNS: Tuple[str, ...] = (
     'anytime_td',
+    'anytime_td_offense',
+    'anytime_td_all',
+    'anytime_td_rush',
+    'anytime_td_rec',
+    'anytime_td_pass_thrown',
     'td_count',
+    'td_count_offense',
+    'td_count_all',
+    'passing_td',
+    'rushing_td_count',
+    'receiving_td_count',
     'receiving_yards',
     'rushing_yards',
     'passing_yards',

file update:
diff --git a/config/training.yaml b/config/training.yaml
index 3953818d861d0410246bff132110722a3ce44007..c2b6053b488caa71f9078ff100d049f723ae1548
--- a/config/training.yaml
+++ b/config/training.yaml
@@ -476,6 +476,7 @@
   - name: 'anytime_td'
     target_col: 'anytime_td'
     label_version: 'v1_any_offense'
+    odds_horizon: 'cutoff'  # Restrict odds features to the decision-time snapshot
     task_type: 'classification'
     input_predictions:
       - 'availability_active'
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 5ba68e8bf1acd3a789a76a8857674e6f6433017b..0210d5b7e7ed60a8de7a126d64f5ed76326474c8
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -14,7 +14,7 @@
 
 import logging
 import os
-from datetime import date, timedelta
+from datetime import date, datetime, timedelta
 from typing import Sequence
 
 import polars as pl
@@ -37,6 +37,12 @@
     add_offense_context_features_training,
     _append_offense_context_columns,
 )
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    build_schema_snapshot,
+    enforce_leak_guard,
+    write_schema_snapshot,
+)
 from utils.feature.weather_features import (
     add_weather_forecast_features_training,
     append_weather_context_flags,
@@ -931,6 +937,32 @@
     if market_exprs:
         df_player_game_all = df_player_game_all.with_columns(market_exprs)
     
+    # Leak guard + schema snapshot before persisting
+    spec = get_label_spec(label_version)
+    allow_exact = {spec.primary, *spec.labels.keys(), *spec.aliases.keys()}
+    df_player_game_all, leak_result = enforce_leak_guard(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_exact=allow_exact,
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=True,
+    )
+
+    schema = build_schema_snapshot(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        metadata={
+            "cutoff_label": cutoff_label,
+            "label_version": spec.name,
+        },
+        banned=leak_result.banned,
+    )
+    schema_dir = FEATURE_AUDIT_DIR / "schema" / "anytime_td"
+    schema_path = schema_dir / f"{cutoff_label}_{datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')}.json"
+    write_schema_snapshot(schema_path, schema)
+    logging.info("    Schema snapshot written → %s", schema_path)
+
     # Write final feature matrix
     df_player_game_all = df_player_game_all.with_columns(
         pl.lit(current_cutoff_hours).cast(pl.Float32).alias("decision_horizon_hours")
@@ -951,7 +983,6 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    spec = get_label_spec(label_version)
     label_candidates = {spec.primary, "anytime_td"}
     for label_col in label_candidates:
         if label_col in df_player_game_all.columns:
diff --git a/pipeline/train.py b/pipeline/train.py
index fe70207dcdf25d209ee3ad55080b7ce826347c44..7c220514d006a3d4815d65a8af9ec7551ccf587e
--- a/pipeline/train.py
+++ b/pipeline/train.py
@@ -4,6 +4,7 @@
 import sys
 import logging
 import math
+import re
 
 
 # Move logging to top and remove global thread pinning
@@ -98,6 +99,7 @@
     fit_team_conformal_sums,
     composite_sum_interval,
 )
+from utils.feature.leak_guard import DEFAULT_LEAK_POLICY, enforce_leak_guard
 from utils.feature.targets import require_target_column
 
 # Ignore specific, noisy warnings from dependencies
@@ -793,6 +795,57 @@
             )
         return df
 
+    @staticmethod
+    def _filter_odds_snapshot_columns(df: pd.DataFrame, horizon_key: str | None) -> pd.DataFrame:
+        """Keep a single odds snapshot horizon (drop other suffixes)."""
+        if df is None or df.empty or not horizon_key:
+            return df
+
+        normalized = str(horizon_key).strip().lower()
+        horizon_map = {
+            "cutoff": "",
+            "default": "",
+            "": "",
+            "2h": "_2h",
+            "h120m": "_2h",
+            "6h": "_6h",
+            "h360m": "_6h",
+            "24h": "_24h",
+            "h1440m": "_24h",
+            "open": "_open",
+        }
+        allowed_suffix = horizon_map.get(normalized, normalized)
+        if allowed_suffix and not allowed_suffix.startswith("_"):
+            allowed_suffix = f"_{allowed_suffix.lstrip('_')}"
+
+        horizon_re = re.compile(r"^(?P<base>.+)(?P<suffix>_2h|_6h|_24h|_open)$")
+        suffixes_seen: dict[str, set[str]] = {}
+        for col in df.columns:
+            match = horizon_re.match(col)
+            if match:
+                suffixes_seen.setdefault(match.group("base"), set()).add(match.group("suffix"))
+
+        drop_cols: list[str] = []
+        for col in df.columns:
+            match = horizon_re.match(col)
+            if match:
+                suffix = match.group("suffix")
+                if suffix != allowed_suffix:
+                    drop_cols.append(col)
+            else:
+                base = col
+                if base in suffixes_seen and allowed_suffix:
+                    drop_cols.append(col)
+
+        if drop_cols:
+            df = df.drop(columns=drop_cols, errors="ignore")
+            logger.info(
+                "Removed %d odds snapshot columns outside horizon '%s'.",
+                len(drop_cols),
+                horizon_key,
+            )
+        return df
+
     def _ensure_player_game_actuals(self) -> pd.DataFrame:
         if self._player_game_actuals is not None:
             return self._player_game_actuals
@@ -2315,7 +2368,34 @@
                             df_problem[col] = df_problem[col].fillna(df_problem[col].mean())
 
                 df_problem = self._inject_composed_features(df_problem)
-            
+
+            odds_horizon = problem_copy.get("odds_horizon")
+            if odds_horizon:
+                df_problem = self._filter_odds_snapshot_columns(df_problem, odds_horizon)
+
+            # Leak guard on the problem-scoped frame
+            allow_prefixes = tuple(problem_copy.get('feature_prefixes_to_include') or [])
+            allow_exact = set(problem_copy.get('other_features_to_include') or [])
+            allow_exact.update(input_preds or [])
+            if self.target_col:
+                allow_exact.add(self.target_col)
+            df_problem, leak_info = enforce_leak_guard(
+                df_problem,
+                policy=DEFAULT_LEAK_POLICY,
+                allow_prefixes=allow_prefixes,
+                allow_exact=allow_exact,
+                drop_banned=True,
+                drop_non_allowlisted=False,
+                raise_on_banned=True,
+            )
+            if leak_info.dropped:
+                logger.info(
+                    "Dropped %d leak-prone columns for %s: %s",
+                    len(leak_info.dropped),
+                    problem_name,
+                    sorted(leak_info.dropped),
+                )
+
             self._normalize_datetime_like_columns(df_problem, problem_name)
             df_problem[self.time_col] = pd.to_datetime(df_problem[self.time_col])
             sort_cols = [self.time_col]
diff --git a/tests/test_data_leak_guard.py b/tests/test_data_leak_guard.py
index 8061f2760c0898aaeda29026859e1b9ff5644ba4..3e56665921db89ea523bbdb205d1bb90c21893df
--- a/tests/test_data_leak_guard.py
+++ b/tests/test_data_leak_guard.py
@@ -3,6 +3,14 @@
 import yaml
 from pathlib import Path
 
+import polars as pl
+
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    enforce_leak_guard,
+    evaluate_leak_prone_columns,
+)
+
 
 PROJECT_ROOT = Path(__file__).resolve().parents[1]
 TRAINING_CONFIG = PROJECT_ROOT / "config" / "training.yaml"
@@ -48,3 +56,41 @@
     )
 
 
+def test_leak_guard_flags_pattern_columns():
+    cols = [
+        "market_anytime_td_prob",
+        "final_score",
+        "postgame_anytime_td",
+        "actual_td_count",
+        "safe_feature",
+    ]
+    result = evaluate_leak_prone_columns(cols, policy=DEFAULT_LEAK_POLICY)
+    assert set(result.banned.keys()) == {"final_score", "postgame_anytime_td", "actual_td_count"}
+    assert "safe_feature" in result.kept
+    assert "market_anytime_td_prob" in result.kept
+
+
+def test_enforce_leak_guard_drops_banned_and_keeps_allowlisted():
+    df = pl.DataFrame(
+        {
+            "game_id": ["g1", "g2"],
+            "safe_feature": [1.0, 2.0],
+            "postgame_anytime_td": [1, 0],
+            "final_score": [30, 24],
+        }
+    )
+    cleaned, info = enforce_leak_guard(
+        df,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_prefixes=("safe_",),
+        allow_exact=("game_id",),
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=False,
+    )
+    assert "postgame_anytime_td" not in cleaned.columns
+    assert "final_score" not in cleaned.columns
+    assert "safe_feature" in cleaned.columns
+    assert "game_id" in cleaned.columns
+    assert set(info.dropped) == {"postgame_anytime_td", "final_score"}
+
diff --git a/tests/test_odds_horizon_filter.py b/tests/test_odds_horizon_filter.py
new file mode 100644
index 0000000000000000000000000000000000000000..0a9d9aa2ef7eeb1272426c615e5126b18f8e10ba
--- /dev/null
+++ b/tests/test_odds_horizon_filter.py
@@ -0,0 +1,33 @@
+from __future__ import annotations
+
+import pandas as pd
+
+from pipeline.train import ModelTrainer
+
+
+def test_filter_odds_snapshot_columns_cutoff_keeps_base_only():
+    df = pd.DataFrame(
+        {
+            "market_anytime_td_prob": [0.1, 0.2],
+            "market_anytime_td_prob_2h": [0.15, 0.25],
+            "market_anytime_td_prob_6h": [0.2, 0.3],
+            "other_feature": [1, 2],
+        }
+    )
+    filtered = ModelTrainer._filter_odds_snapshot_columns(df.copy(), "cutoff")
+    assert "market_anytime_td_prob" in filtered.columns
+    assert "market_anytime_td_prob_2h" not in filtered.columns
+    assert "market_anytime_td_prob_6h" not in filtered.columns
+    assert "other_feature" in filtered.columns
+
+
+def test_filter_odds_snapshot_columns_specific_suffix():
+    df = pd.DataFrame(
+        {
+            "market_anytime_td_prob": [0.1, 0.2],
+            "market_anytime_td_prob_2h": [0.15, 0.25],
+            "market_anytime_td_prob_6h": [0.2, 0.3],
+        }
+    )
+    filtered = ModelTrainer._filter_odds_snapshot_columns(df.copy(), "6h")
+    assert list(filtered.columns) == ["market_anytime_td_prob_6h"]
diff --git a/utils/feature/leak_guard.py b/utils/feature/leak_guard.py
new file mode 100644
index 0000000000000000000000000000000000000000..9faf8cfffc436e0934b2f410aaf252e52f4f95df
--- /dev/null
+++ b/utils/feature/leak_guard.py
@@ -0,0 +1,273 @@
+"""Leak guardrails for feature matrices.
+
+This module centralizes pattern-based leak detection so both feature assembly
+and training can fail fast when post-outcome columns sneak into the data.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+from datetime import datetime
+import json
+import re
+from typing import Iterable, Mapping, Sequence
+
+import polars as pl
+
+from utils.general.constants import IDENTIFIER_COLUMNS, LEAK_PRONE_COLUMNS, NFL_TARGET_COLUMNS
+
+try:  # Optional dependency when imported from training (pandas path)
+    import pandas as pd  # type: ignore
+except Exception:  # pragma: no cover - optional dependency
+    pd = None
+
+
+@dataclass(frozen=True)
+class LeakPolicy:
+    version: str
+    banned_exact: set[str]
+    banned_prefixes: tuple[str, ...]
+    banned_suffixes: tuple[str, ...]
+    banned_regex: tuple[tuple[re.Pattern[str], str], ...]
+    description: str = ""
+
+
+@dataclass
+class LeakCheckResult:
+    policy_version: str
+    banned: dict[str, str]
+    kept: list[str]
+    dropped: list[str]
+    allowlist_kept: list[str]
+
+
+# Core policy tuned for anytime-TD style problems (can be extended per-problem).
+_BASE_BANNED_EXACT = set(LEAK_PRONE_COLUMNS) | {
+    "final_score",
+    "final_total",
+    "points_scored",
+    "actual_td_count",
+    "actual_anytime_td",
+    "postgame_anytime_td",
+    "postgame_td_count",
+}
+_BASE_BANNED_PREFIXES = (
+    "postgame_",
+    "post_game_",
+    "post_",
+    "live_",
+    "actual_",
+    "realized_",
+    "final_",
+    "postmatch_",
+)
+_BASE_BANNED_SUFFIXES = (
+    "_post",
+    "_postgame",
+    "_final",
+    "_fullgame",
+    "_actual",
+)
+_BASE_BANNED_REGEX: tuple[tuple[re.Pattern[str], str], ...] = (
+    (re.compile(r".*post.?game.*", flags=re.IGNORECASE), "postgame marker"),
+    (re.compile(r".*final_score.*", flags=re.IGNORECASE), "final score"),
+    (re.compile(r".*actual.*td.*", flags=re.IGNORECASE), "actual TD total"),
+    (re.compile(r".*anytime_td.*(post|final|actual).*", flags=re.IGNORECASE), "post-decision anytime TD"),
+    (re.compile(r".*fullgame.*", flags=re.IGNORECASE), "full game cumulative value"),
+)
+
+DEFAULT_LEAK_POLICY = LeakPolicy(
+    version="v1",
+    description="Core post-outcome leak guard for NFL anytime TD features.",
+    banned_exact=_BASE_BANNED_EXACT,
+    banned_prefixes=_BASE_BANNED_PREFIXES,
+    banned_suffixes=_BASE_BANNED_SUFFIXES,
+    banned_regex=_BASE_BANNED_REGEX,
+)
+
+
+def _ensure_sequence(value: Sequence[str] | str | None) -> tuple[str, ...]:
+    if value is None:
+        return ()
+    if isinstance(value, str):
+        return (value,)
+    return tuple(value)
+
+
+def evaluate_leak_prone_columns(
+    columns: Iterable[str],
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+) -> LeakCheckResult:
+    """Identify leak-prone columns using the configured policy."""
+
+    banned: dict[str, str] = {}
+    columns_list = list(columns)
+    for col in columns_list:
+        if col in policy.banned_exact:
+            banned[col] = "exact"
+            continue
+        for prefix in policy.banned_prefixes:
+            if col.startswith(prefix):
+                banned[col] = f"prefix:{prefix}"
+                break
+        if col in banned:
+            continue
+        for suffix in policy.banned_suffixes:
+            if col.endswith(suffix):
+                banned[col] = f"suffix:{suffix}"
+                break
+        if col in banned:
+            continue
+        for pattern, reason in policy.banned_regex:
+            if pattern.match(col):
+                banned[col] = reason
+                break
+
+    kept = [c for c in columns_list if c not in banned]
+    return LeakCheckResult(
+        policy_version=policy.version,
+        banned=banned,
+        kept=kept,
+        dropped=[],
+        allowlist_kept=[],
+    )
+
+
+def enforce_leak_guard(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    allow_prefixes: Sequence[str] | str | None = None,
+    allow_exact: Sequence[str] | str | None = None,
+    drop_banned: bool = True,
+    drop_non_allowlisted: bool = False,
+    raise_on_banned: bool = True,
+) -> tuple[pl.DataFrame | "pd.DataFrame", LeakCheckResult]:
+    """Apply leak guardrails to a feature frame.
+
+    Parameters
+    ----------
+    df : DataFrame
+        Polars or pandas DataFrame.
+    policy : LeakPolicy
+        Leak policy to apply.
+    allow_prefixes : Sequence[str] | str | None
+        Optional prefixes that define the allowed feature surface for a problem.
+    allow_exact : Sequence[str] | str | None
+        Explicitly allowed columns (e.g., identifiers).
+    drop_banned : bool
+        If True, drop any banned columns automatically.
+    drop_non_allowlisted : bool
+        If True, drop columns that are not covered by allow_prefixes/allow_exact/identifiers/targets.
+    raise_on_banned : bool
+        If True, raise when banned columns are detected (after optional drop).
+    """
+
+    result = evaluate_leak_prone_columns(df.columns, policy=policy)
+    dropped: list[str] = []
+
+    allow_prefixes = _ensure_sequence(allow_prefixes)
+    allow_exact = set(_ensure_sequence(allow_exact))
+    allow_exact.update({col for col in IDENTIFIER_COLUMNS if col in df.columns})
+    allow_exact.update({col for col in NFL_TARGET_COLUMNS if col in df.columns})
+
+    # Permit allowlisted columns even if they match a banned rule (e.g., labels)
+    banned = {col: reason for col, reason in result.banned.items() if col not in allow_exact}
+
+    if banned and drop_banned:
+        df = df.drop(list(banned.keys()))
+        dropped.extend(banned.keys())
+
+    if banned and raise_on_banned:
+        raise ValueError(f"Leak-prone columns detected: {sorted(banned.items())}")
+
+    allowlist_cols: set[str] = set()
+    if allow_prefixes:
+        allowlist_cols.update({c for c in df.columns if c.startswith(allow_prefixes)})
+    allowlist_cols.update({c for c in allow_exact if c in df.columns})
+
+    if drop_non_allowlisted and allowlist_cols:
+        drop_candidates = [c for c in df.columns if c not in allowlist_cols]
+        if drop_candidates:
+            df = df.drop(drop_candidates)
+            dropped.extend(drop_candidates)
+
+    if drop_non_allowlisted and not allowlist_cols:
+        raise ValueError("No allowlisted columns remain after applying leak guard allowlist.")
+
+    # Store adjusted banned info on the result
+    result.banned = banned
+    result.dropped = dropped
+    result.kept = [c for c in df.columns]
+    result.allowlist_kept = sorted(list(allowlist_cols)) if allowlist_cols else []
+    return df, result
+
+
+def build_schema_snapshot(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    metadata: Mapping[str, object] | None = None,
+    banned: Mapping[str, str] | None = None,
+) -> dict:
+    """Render a schema snapshot describing each column and whether it was flagged."""
+
+    banned = banned or {}
+    meta = {
+        "generated_at_utc": datetime.utcnow().isoformat(),
+        "policy_version": policy.version,
+    }
+    meta.update(metadata or {})
+
+    # Extract columns / dtypes
+    if isinstance(df, pl.DataFrame):
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+    else:  # pandas or pandas-like
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+
+    schema = {
+        "metadata": meta,
+        "columns": [],
+    }
+
+    for col, dtype in cols_and_dtypes:
+        tags: list[str] = []
+        if col in IDENTIFIER_COLUMNS:
+            tags.append("id")
+        if col in NFL_TARGET_COLUMNS:
+            tags.append("label")
+        if col.startswith("market_"):
+            tags.append("odds")
+        if col.startswith("injury_") or col.startswith("practice_"):
+            tags.append("injury")
+        if col.startswith("weather_"):
+            tags.append("weather")
+        if col.startswith("ps_"):
+            tags.append("pre_snap")
+        schema["columns"].append(
+            {
+                "name": col,
+                "dtype": dtype,
+                "banned": col in banned,
+                "tags": tags,
+            }
+        )
+    return schema
+
+
+def write_schema_snapshot(path, schema: Mapping[str, object]) -> None:
+    path.parent.mkdir(parents=True, exist_ok=True)
+    with open(path, "w") as fp:
+        json.dump(schema, fp, indent=2, sort_keys=True)
+
+
+__all__ = [
+    "DEFAULT_LEAK_POLICY",
+    "LeakPolicy",
+    "LeakCheckResult",
+    "evaluate_leak_prone_columns",
+    "enforce_leak_guard",
+    "build_schema_snapshot",
+    "write_schema_snapshot",
+]
diff --git a/utils/general/constants.py b/utils/general/constants.py
index d94b4260ad877484da843fa99ae2caf37e8493f4..dea87caa354d94e4a08b1762d2bd8dcd4c8caa3a
--- a/utils/general/constants.py
+++ b/utils/general/constants.py
@@ -211,7 +211,17 @@
 
 NFL_TARGET_COLUMNS: Tuple[str, ...] = (
     'anytime_td',
+    'anytime_td_offense',
+    'anytime_td_all',
+    'anytime_td_rush',
+    'anytime_td_rec',
+    'anytime_td_pass_thrown',
     'td_count',
+    'td_count_offense',
+    'td_count_all',
+    'passing_td',
+    'rushing_td_count',
+    'receiving_td_count',
     'receiving_yards',
     'rushing_yards',
     'passing_yards',


thinking
**Evaluating import dependency risks**

thinking
**Preparing test imports for optional dependencies**
file update
M /Users/jameswest/Desktop/nfl_predict/tests/test_odds_horizon_filter.py
@@ -3,4 +3,6 @@
 import pandas as pd
+import pytest
 
-from pipeline.train import ModelTrainer
+train_module = pytest.importorskip("pipeline.train")
+ModelTrainer = train_module.ModelTrainer
 
apply_patch(auto_approved=true) exited 0 in 100ms:
Success. Updated the following files:
M tests/test_odds_horizon_filter.py
file update:
diff --git a/config/training.yaml b/config/training.yaml
index 3953818d861d0410246bff132110722a3ce44007..c2b6053b488caa71f9078ff100d049f723ae1548
--- a/config/training.yaml
+++ b/config/training.yaml
@@ -476,6 +476,7 @@
   - name: 'anytime_td'
     target_col: 'anytime_td'
     label_version: 'v1_any_offense'
+    odds_horizon: 'cutoff'  # Restrict odds features to the decision-time snapshot
     task_type: 'classification'
     input_predictions:
       - 'availability_active'
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 5ba68e8bf1acd3a789a76a8857674e6f6433017b..0210d5b7e7ed60a8de7a126d64f5ed76326474c8
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -14,7 +14,7 @@
 
 import logging
 import os
-from datetime import date, timedelta
+from datetime import date, datetime, timedelta
 from typing import Sequence
 
 import polars as pl
@@ -37,6 +37,12 @@
     add_offense_context_features_training,
     _append_offense_context_columns,
 )
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    build_schema_snapshot,
+    enforce_leak_guard,
+    write_schema_snapshot,
+)
 from utils.feature.weather_features import (
     add_weather_forecast_features_training,
     append_weather_context_flags,
@@ -931,6 +937,32 @@
     if market_exprs:
         df_player_game_all = df_player_game_all.with_columns(market_exprs)
     
+    # Leak guard + schema snapshot before persisting
+    spec = get_label_spec(label_version)
+    allow_exact = {spec.primary, *spec.labels.keys(), *spec.aliases.keys()}
+    df_player_game_all, leak_result = enforce_leak_guard(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_exact=allow_exact,
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=True,
+    )
+
+    schema = build_schema_snapshot(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        metadata={
+            "cutoff_label": cutoff_label,
+            "label_version": spec.name,
+        },
+        banned=leak_result.banned,
+    )
+    schema_dir = FEATURE_AUDIT_DIR / "schema" / "anytime_td"
+    schema_path = schema_dir / f"{cutoff_label}_{datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')}.json"
+    write_schema_snapshot(schema_path, schema)
+    logging.info("    Schema snapshot written → %s", schema_path)
+
     # Write final feature matrix
     df_player_game_all = df_player_game_all.with_columns(
         pl.lit(current_cutoff_hours).cast(pl.Float32).alias("decision_horizon_hours")
@@ -951,7 +983,6 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    spec = get_label_spec(label_version)
     label_candidates = {spec.primary, "anytime_td"}
     for label_col in label_candidates:
         if label_col in df_player_game_all.columns:
diff --git a/pipeline/train.py b/pipeline/train.py
index fe70207dcdf25d209ee3ad55080b7ce826347c44..7c220514d006a3d4815d65a8af9ec7551ccf587e
--- a/pipeline/train.py
+++ b/pipeline/train.py
@@ -4,6 +4,7 @@
 import sys
 import logging
 import math
+import re
 
 
 # Move logging to top and remove global thread pinning
@@ -98,6 +99,7 @@
     fit_team_conformal_sums,
     composite_sum_interval,
 )
+from utils.feature.leak_guard import DEFAULT_LEAK_POLICY, enforce_leak_guard
 from utils.feature.targets import require_target_column
 
 # Ignore specific, noisy warnings from dependencies
@@ -793,6 +795,57 @@
             )
         return df
 
+    @staticmethod
+    def _filter_odds_snapshot_columns(df: pd.DataFrame, horizon_key: str | None) -> pd.DataFrame:
+        """Keep a single odds snapshot horizon (drop other suffixes)."""
+        if df is None or df.empty or not horizon_key:
+            return df
+
+        normalized = str(horizon_key).strip().lower()
+        horizon_map = {
+            "cutoff": "",
+            "default": "",
+            "": "",
+            "2h": "_2h",
+            "h120m": "_2h",
+            "6h": "_6h",
+            "h360m": "_6h",
+            "24h": "_24h",
+            "h1440m": "_24h",
+            "open": "_open",
+        }
+        allowed_suffix = horizon_map.get(normalized, normalized)
+        if allowed_suffix and not allowed_suffix.startswith("_"):
+            allowed_suffix = f"_{allowed_suffix.lstrip('_')}"
+
+        horizon_re = re.compile(r"^(?P<base>.+)(?P<suffix>_2h|_6h|_24h|_open)$")
+        suffixes_seen: dict[str, set[str]] = {}
+        for col in df.columns:
+            match = horizon_re.match(col)
+            if match:
+                suffixes_seen.setdefault(match.group("base"), set()).add(match.group("suffix"))
+
+        drop_cols: list[str] = []
+        for col in df.columns:
+            match = horizon_re.match(col)
+            if match:
+                suffix = match.group("suffix")
+                if suffix != allowed_suffix:
+                    drop_cols.append(col)
+            else:
+                base = col
+                if base in suffixes_seen and allowed_suffix:
+                    drop_cols.append(col)
+
+        if drop_cols:
+            df = df.drop(columns=drop_cols, errors="ignore")
+            logger.info(
+                "Removed %d odds snapshot columns outside horizon '%s'.",
+                len(drop_cols),
+                horizon_key,
+            )
+        return df
+
     def _ensure_player_game_actuals(self) -> pd.DataFrame:
         if self._player_game_actuals is not None:
             return self._player_game_actuals
@@ -2315,7 +2368,34 @@
                             df_problem[col] = df_problem[col].fillna(df_problem[col].mean())
 
                 df_problem = self._inject_composed_features(df_problem)
-            
+
+            odds_horizon = problem_copy.get("odds_horizon")
+            if odds_horizon:
+                df_problem = self._filter_odds_snapshot_columns(df_problem, odds_horizon)
+
+            # Leak guard on the problem-scoped frame
+            allow_prefixes = tuple(problem_copy.get('feature_prefixes_to_include') or [])
+            allow_exact = set(problem_copy.get('other_features_to_include') or [])
+            allow_exact.update(input_preds or [])
+            if self.target_col:
+                allow_exact.add(self.target_col)
+            df_problem, leak_info = enforce_leak_guard(
+                df_problem,
+                policy=DEFAULT_LEAK_POLICY,
+                allow_prefixes=allow_prefixes,
+                allow_exact=allow_exact,
+                drop_banned=True,
+                drop_non_allowlisted=False,
+                raise_on_banned=True,
+            )
+            if leak_info.dropped:
+                logger.info(
+                    "Dropped %d leak-prone columns for %s: %s",
+                    len(leak_info.dropped),
+                    problem_name,
+                    sorted(leak_info.dropped),
+                )
+
             self._normalize_datetime_like_columns(df_problem, problem_name)
             df_problem[self.time_col] = pd.to_datetime(df_problem[self.time_col])
             sort_cols = [self.time_col]
diff --git a/tests/test_data_leak_guard.py b/tests/test_data_leak_guard.py
index 8061f2760c0898aaeda29026859e1b9ff5644ba4..3e56665921db89ea523bbdb205d1bb90c21893df
--- a/tests/test_data_leak_guard.py
+++ b/tests/test_data_leak_guard.py
@@ -3,6 +3,14 @@
 import yaml
 from pathlib import Path
 
+import polars as pl
+
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    enforce_leak_guard,
+    evaluate_leak_prone_columns,
+)
+
 
 PROJECT_ROOT = Path(__file__).resolve().parents[1]
 TRAINING_CONFIG = PROJECT_ROOT / "config" / "training.yaml"
@@ -48,3 +56,41 @@
     )
 
 
+def test_leak_guard_flags_pattern_columns():
+    cols = [
+        "market_anytime_td_prob",
+        "final_score",
+        "postgame_anytime_td",
+        "actual_td_count",
+        "safe_feature",
+    ]
+    result = evaluate_leak_prone_columns(cols, policy=DEFAULT_LEAK_POLICY)
+    assert set(result.banned.keys()) == {"final_score", "postgame_anytime_td", "actual_td_count"}
+    assert "safe_feature" in result.kept
+    assert "market_anytime_td_prob" in result.kept
+
+
+def test_enforce_leak_guard_drops_banned_and_keeps_allowlisted():
+    df = pl.DataFrame(
+        {
+            "game_id": ["g1", "g2"],
+            "safe_feature": [1.0, 2.0],
+            "postgame_anytime_td": [1, 0],
+            "final_score": [30, 24],
+        }
+    )
+    cleaned, info = enforce_leak_guard(
+        df,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_prefixes=("safe_",),
+        allow_exact=("game_id",),
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=False,
+    )
+    assert "postgame_anytime_td" not in cleaned.columns
+    assert "final_score" not in cleaned.columns
+    assert "safe_feature" in cleaned.columns
+    assert "game_id" in cleaned.columns
+    assert set(info.dropped) == {"postgame_anytime_td", "final_score"}
+
diff --git a/tests/test_odds_horizon_filter.py b/tests/test_odds_horizon_filter.py
new file mode 100644
index 0000000000000000000000000000000000000000..70e9c681f63972bbb6e70008e286cf13f6881853
--- /dev/null
+++ b/tests/test_odds_horizon_filter.py
@@ -0,0 +1,35 @@
+from __future__ import annotations
+
+import pandas as pd
+import pytest
+
+train_module = pytest.importorskip("pipeline.train")
+ModelTrainer = train_module.ModelTrainer
+
+
+def test_filter_odds_snapshot_columns_cutoff_keeps_base_only():
+    df = pd.DataFrame(
+        {
+            "market_anytime_td_prob": [0.1, 0.2],
+            "market_anytime_td_prob_2h": [0.15, 0.25],
+            "market_anytime_td_prob_6h": [0.2, 0.3],
+            "other_feature": [1, 2],
+        }
+    )
+    filtered = ModelTrainer._filter_odds_snapshot_columns(df.copy(), "cutoff")
+    assert "market_anytime_td_prob" in filtered.columns
+    assert "market_anytime_td_prob_2h" not in filtered.columns
+    assert "market_anytime_td_prob_6h" not in filtered.columns
+    assert "other_feature" in filtered.columns
+
+
+def test_filter_odds_snapshot_columns_specific_suffix():
+    df = pd.DataFrame(
+        {
+            "market_anytime_td_prob": [0.1, 0.2],
+            "market_anytime_td_prob_2h": [0.15, 0.25],
+            "market_anytime_td_prob_6h": [0.2, 0.3],
+        }
+    )
+    filtered = ModelTrainer._filter_odds_snapshot_columns(df.copy(), "6h")
+    assert list(filtered.columns) == ["market_anytime_td_prob_6h"]
diff --git a/utils/feature/leak_guard.py b/utils/feature/leak_guard.py
new file mode 100644
index 0000000000000000000000000000000000000000..9faf8cfffc436e0934b2f410aaf252e52f4f95df
--- /dev/null
+++ b/utils/feature/leak_guard.py
@@ -0,0 +1,273 @@
+"""Leak guardrails for feature matrices.
+
+This module centralizes pattern-based leak detection so both feature assembly
+and training can fail fast when post-outcome columns sneak into the data.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+from datetime import datetime
+import json
+import re
+from typing import Iterable, Mapping, Sequence
+
+import polars as pl
+
+from utils.general.constants import IDENTIFIER_COLUMNS, LEAK_PRONE_COLUMNS, NFL_TARGET_COLUMNS
+
+try:  # Optional dependency when imported from training (pandas path)
+    import pandas as pd  # type: ignore
+except Exception:  # pragma: no cover - optional dependency
+    pd = None
+
+
+@dataclass(frozen=True)
+class LeakPolicy:
+    version: str
+    banned_exact: set[str]
+    banned_prefixes: tuple[str, ...]
+    banned_suffixes: tuple[str, ...]
+    banned_regex: tuple[tuple[re.Pattern[str], str], ...]
+    description: str = ""
+
+
+@dataclass
+class LeakCheckResult:
+    policy_version: str
+    banned: dict[str, str]
+    kept: list[str]
+    dropped: list[str]
+    allowlist_kept: list[str]
+
+
+# Core policy tuned for anytime-TD style problems (can be extended per-problem).
+_BASE_BANNED_EXACT = set(LEAK_PRONE_COLUMNS) | {
+    "final_score",
+    "final_total",
+    "points_scored",
+    "actual_td_count",
+    "actual_anytime_td",
+    "postgame_anytime_td",
+    "postgame_td_count",
+}
+_BASE_BANNED_PREFIXES = (
+    "postgame_",
+    "post_game_",
+    "post_",
+    "live_",
+    "actual_",
+    "realized_",
+    "final_",
+    "postmatch_",
+)
+_BASE_BANNED_SUFFIXES = (
+    "_post",
+    "_postgame",
+    "_final",
+    "_fullgame",
+    "_actual",
+)
+_BASE_BANNED_REGEX: tuple[tuple[re.Pattern[str], str], ...] = (
+    (re.compile(r".*post.?game.*", flags=re.IGNORECASE), "postgame marker"),
+    (re.compile(r".*final_score.*", flags=re.IGNORECASE), "final score"),
+    (re.compile(r".*actual.*td.*", flags=re.IGNORECASE), "actual TD total"),
+    (re.compile(r".*anytime_td.*(post|final|actual).*", flags=re.IGNORECASE), "post-decision anytime TD"),
+    (re.compile(r".*fullgame.*", flags=re.IGNORECASE), "full game cumulative value"),
+)
+
+DEFAULT_LEAK_POLICY = LeakPolicy(
+    version="v1",
+    description="Core post-outcome leak guard for NFL anytime TD features.",
+    banned_exact=_BASE_BANNED_EXACT,
+    banned_prefixes=_BASE_BANNED_PREFIXES,
+    banned_suffixes=_BASE_BANNED_SUFFIXES,
+    banned_regex=_BASE_BANNED_REGEX,
+)
+
+
+def _ensure_sequence(value: Sequence[str] | str | None) -> tuple[str, ...]:
+    if value is None:
+        return ()
+    if isinstance(value, str):
+        return (value,)
+    return tuple(value)
+
+
+def evaluate_leak_prone_columns(
+    columns: Iterable[str],
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+) -> LeakCheckResult:
+    """Identify leak-prone columns using the configured policy."""
+
+    banned: dict[str, str] = {}
+    columns_list = list(columns)
+    for col in columns_list:
+        if col in policy.banned_exact:
+            banned[col] = "exact"
+            continue
+        for prefix in policy.banned_prefixes:
+            if col.startswith(prefix):
+                banned[col] = f"prefix:{prefix}"
+                break
+        if col in banned:
+            continue
+        for suffix in policy.banned_suffixes:
+            if col.endswith(suffix):
+                banned[col] = f"suffix:{suffix}"
+                break
+        if col in banned:
+            continue
+        for pattern, reason in policy.banned_regex:
+            if pattern.match(col):
+                banned[col] = reason
+                break
+
+    kept = [c for c in columns_list if c not in banned]
+    return LeakCheckResult(
+        policy_version=policy.version,
+        banned=banned,
+        kept=kept,
+        dropped=[],
+        allowlist_kept=[],
+    )
+
+
+def enforce_leak_guard(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    allow_prefixes: Sequence[str] | str | None = None,
+    allow_exact: Sequence[str] | str | None = None,
+    drop_banned: bool = True,
+    drop_non_allowlisted: bool = False,
+    raise_on_banned: bool = True,
+) -> tuple[pl.DataFrame | "pd.DataFrame", LeakCheckResult]:
+    """Apply leak guardrails to a feature frame.
+
+    Parameters
+    ----------
+    df : DataFrame
+        Polars or pandas DataFrame.
+    policy : LeakPolicy
+        Leak policy to apply.
+    allow_prefixes : Sequence[str] | str | None
+        Optional prefixes that define the allowed feature surface for a problem.
+    allow_exact : Sequence[str] | str | None
+        Explicitly allowed columns (e.g., identifiers).
+    drop_banned : bool
+        If True, drop any banned columns automatically.
+    drop_non_allowlisted : bool
+        If True, drop columns that are not covered by allow_prefixes/allow_exact/identifiers/targets.
+    raise_on_banned : bool
+        If True, raise when banned columns are detected (after optional drop).
+    """
+
+    result = evaluate_leak_prone_columns(df.columns, policy=policy)
+    dropped: list[str] = []
+
+    allow_prefixes = _ensure_sequence(allow_prefixes)
+    allow_exact = set(_ensure_sequence(allow_exact))
+    allow_exact.update({col for col in IDENTIFIER_COLUMNS if col in df.columns})
+    allow_exact.update({col for col in NFL_TARGET_COLUMNS if col in df.columns})
+
+    # Permit allowlisted columns even if they match a banned rule (e.g., labels)
+    banned = {col: reason for col, reason in result.banned.items() if col not in allow_exact}
+
+    if banned and drop_banned:
+        df = df.drop(list(banned.keys()))
+        dropped.extend(banned.keys())
+
+    if banned and raise_on_banned:
+        raise ValueError(f"Leak-prone columns detected: {sorted(banned.items())}")
+
+    allowlist_cols: set[str] = set()
+    if allow_prefixes:
+        allowlist_cols.update({c for c in df.columns if c.startswith(allow_prefixes)})
+    allowlist_cols.update({c for c in allow_exact if c in df.columns})
+
+    if drop_non_allowlisted and allowlist_cols:
+        drop_candidates = [c for c in df.columns if c not in allowlist_cols]
+        if drop_candidates:
+            df = df.drop(drop_candidates)
+            dropped.extend(drop_candidates)
+
+    if drop_non_allowlisted and not allowlist_cols:
+        raise ValueError("No allowlisted columns remain after applying leak guard allowlist.")
+
+    # Store adjusted banned info on the result
+    result.banned = banned
+    result.dropped = dropped
+    result.kept = [c for c in df.columns]
+    result.allowlist_kept = sorted(list(allowlist_cols)) if allowlist_cols else []
+    return df, result
+
+
+def build_schema_snapshot(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    metadata: Mapping[str, object] | None = None,
+    banned: Mapping[str, str] | None = None,
+) -> dict:
+    """Render a schema snapshot describing each column and whether it was flagged."""
+
+    banned = banned or {}
+    meta = {
+        "generated_at_utc": datetime.utcnow().isoformat(),
+        "policy_version": policy.version,
+    }
+    meta.update(metadata or {})
+
+    # Extract columns / dtypes
+    if isinstance(df, pl.DataFrame):
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+    else:  # pandas or pandas-like
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+
+    schema = {
+        "metadata": meta,
+        "columns": [],
+    }
+
+    for col, dtype in cols_and_dtypes:
+        tags: list[str] = []
+        if col in IDENTIFIER_COLUMNS:
+            tags.append("id")
+        if col in NFL_TARGET_COLUMNS:
+            tags.append("label")
+        if col.startswith("market_"):
+            tags.append("odds")
+        if col.startswith("injury_") or col.startswith("practice_"):
+            tags.append("injury")
+        if col.startswith("weather_"):
+            tags.append("weather")
+        if col.startswith("ps_"):
+            tags.append("pre_snap")
+        schema["columns"].append(
+            {
+                "name": col,
+                "dtype": dtype,
+                "banned": col in banned,
+                "tags": tags,
+            }
+        )
+    return schema
+
+
+def write_schema_snapshot(path, schema: Mapping[str, object]) -> None:
+    path.parent.mkdir(parents=True, exist_ok=True)
+    with open(path, "w") as fp:
+        json.dump(schema, fp, indent=2, sort_keys=True)
+
+
+__all__ = [
+    "DEFAULT_LEAK_POLICY",
+    "LeakPolicy",
+    "LeakCheckResult",
+    "evaluate_leak_prone_columns",
+    "enforce_leak_guard",
+    "build_schema_snapshot",
+    "write_schema_snapshot",
+]
diff --git a/utils/general/constants.py b/utils/general/constants.py
index d94b4260ad877484da843fa99ae2caf37e8493f4..dea87caa354d94e4a08b1762d2bd8dcd4c8caa3a
--- a/utils/general/constants.py
+++ b/utils/general/constants.py
@@ -211,7 +211,17 @@
 
 NFL_TARGET_COLUMNS: Tuple[str, ...] = (
     'anytime_td',
+    'anytime_td_offense',
+    'anytime_td_all',
+    'anytime_td_rush',
+    'anytime_td_rec',
+    'anytime_td_pass_thrown',
     'td_count',
+    'td_count_offense',
+    'td_count_all',
+    'passing_td',
+    'rushing_td_count',
+    'receiving_td_count',
     'receiving_yards',
     'rushing_yards',
     'passing_yards',

file update:
diff --git a/config/training.yaml b/config/training.yaml
index 3953818d861d0410246bff132110722a3ce44007..c2b6053b488caa71f9078ff100d049f723ae1548
--- a/config/training.yaml
+++ b/config/training.yaml
@@ -476,6 +476,7 @@
   - name: 'anytime_td'
     target_col: 'anytime_td'
     label_version: 'v1_any_offense'
+    odds_horizon: 'cutoff'  # Restrict odds features to the decision-time snapshot
     task_type: 'classification'
     input_predictions:
       - 'availability_active'
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 5ba68e8bf1acd3a789a76a8857674e6f6433017b..0210d5b7e7ed60a8de7a126d64f5ed76326474c8
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -14,7 +14,7 @@
 
 import logging
 import os
-from datetime import date, timedelta
+from datetime import date, datetime, timedelta
 from typing import Sequence
 
 import polars as pl
@@ -37,6 +37,12 @@
     add_offense_context_features_training,
     _append_offense_context_columns,
 )
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    build_schema_snapshot,
+    enforce_leak_guard,
+    write_schema_snapshot,
+)
 from utils.feature.weather_features import (
     add_weather_forecast_features_training,
     append_weather_context_flags,
@@ -931,6 +937,32 @@
     if market_exprs:
         df_player_game_all = df_player_game_all.with_columns(market_exprs)
     
+    # Leak guard + schema snapshot before persisting
+    spec = get_label_spec(label_version)
+    allow_exact = {spec.primary, *spec.labels.keys(), *spec.aliases.keys()}
+    df_player_game_all, leak_result = enforce_leak_guard(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_exact=allow_exact,
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=True,
+    )
+
+    schema = build_schema_snapshot(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        metadata={
+            "cutoff_label": cutoff_label,
+            "label_version": spec.name,
+        },
+        banned=leak_result.banned,
+    )
+    schema_dir = FEATURE_AUDIT_DIR / "schema" / "anytime_td"
+    schema_path = schema_dir / f"{cutoff_label}_{datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')}.json"
+    write_schema_snapshot(schema_path, schema)
+    logging.info("    Schema snapshot written → %s", schema_path)
+
     # Write final feature matrix
     df_player_game_all = df_player_game_all.with_columns(
         pl.lit(current_cutoff_hours).cast(pl.Float32).alias("decision_horizon_hours")
@@ -951,7 +983,6 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    spec = get_label_spec(label_version)
     label_candidates = {spec.primary, "anytime_td"}
     for label_col in label_candidates:
         if label_col in df_player_game_all.columns:
diff --git a/pipeline/train.py b/pipeline/train.py
index fe70207dcdf25d209ee3ad55080b7ce826347c44..7c220514d006a3d4815d65a8af9ec7551ccf587e
--- a/pipeline/train.py
+++ b/pipeline/train.py
@@ -4,6 +4,7 @@
 import sys
 import logging
 import math
+import re
 
 
 # Move logging to top and remove global thread pinning
@@ -98,6 +99,7 @@
     fit_team_conformal_sums,
     composite_sum_interval,
 )
+from utils.feature.leak_guard import DEFAULT_LEAK_POLICY, enforce_leak_guard
 from utils.feature.targets import require_target_column
 
 # Ignore specific, noisy warnings from dependencies
@@ -793,6 +795,57 @@
             )
         return df
 
+    @staticmethod
+    def _filter_odds_snapshot_columns(df: pd.DataFrame, horizon_key: str | None) -> pd.DataFrame:
+        """Keep a single odds snapshot horizon (drop other suffixes)."""
+        if df is None or df.empty or not horizon_key:
+            return df
+
+        normalized = str(horizon_key).strip().lower()
+        horizon_map = {
+            "cutoff": "",
+            "default": "",
+            "": "",
+            "2h": "_2h",
+            "h120m": "_2h",
+            "6h": "_6h",
+            "h360m": "_6h",
+            "24h": "_24h",
+            "h1440m": "_24h",
+            "open": "_open",
+        }
+        allowed_suffix = horizon_map.get(normalized, normalized)
+        if allowed_suffix and not allowed_suffix.startswith("_"):
+            allowed_suffix = f"_{allowed_suffix.lstrip('_')}"
+
+        horizon_re = re.compile(r"^(?P<base>.+)(?P<suffix>_2h|_6h|_24h|_open)$")
+        suffixes_seen: dict[str, set[str]] = {}
+        for col in df.columns:
+            match = horizon_re.match(col)
+            if match:
+                suffixes_seen.setdefault(match.group("base"), set()).add(match.group("suffix"))
+
+        drop_cols: list[str] = []
+        for col in df.columns:
+            match = horizon_re.match(col)
+            if match:
+                suffix = match.group("suffix")
+                if suffix != allowed_suffix:
+                    drop_cols.append(col)
+            else:
+                base = col
+                if base in suffixes_seen and allowed_suffix:
+                    drop_cols.append(col)
+
+        if drop_cols:
+            df = df.drop(columns=drop_cols, errors="ignore")
+            logger.info(
+                "Removed %d odds snapshot columns outside horizon '%s'.",
+                len(drop_cols),
+                horizon_key,
+            )
+        return df
+
     def _ensure_player_game_actuals(self) -> pd.DataFrame:
         if self._player_game_actuals is not None:
             return self._player_game_actuals
@@ -2315,7 +2368,34 @@
                             df_problem[col] = df_problem[col].fillna(df_problem[col].mean())
 
                 df_problem = self._inject_composed_features(df_problem)
-            
+
+            odds_horizon = problem_copy.get("odds_horizon")
+            if odds_horizon:
+                df_problem = self._filter_odds_snapshot_columns(df_problem, odds_horizon)
+
+            # Leak guard on the problem-scoped frame
+            allow_prefixes = tuple(problem_copy.get('feature_prefixes_to_include') or [])
+            allow_exact = set(problem_copy.get('other_features_to_include') or [])
+            allow_exact.update(input_preds or [])
+            if self.target_col:
+                allow_exact.add(self.target_col)
+            df_problem, leak_info = enforce_leak_guard(
+                df_problem,
+                policy=DEFAULT_LEAK_POLICY,
+                allow_prefixes=allow_prefixes,
+                allow_exact=allow_exact,
+                drop_banned=True,
+                drop_non_allowlisted=False,
+                raise_on_banned=True,
+            )
+            if leak_info.dropped:
+                logger.info(
+                    "Dropped %d leak-prone columns for %s: %s",
+                    len(leak_info.dropped),
+                    problem_name,
+                    sorted(leak_info.dropped),
+                )
+
             self._normalize_datetime_like_columns(df_problem, problem_name)
             df_problem[self.time_col] = pd.to_datetime(df_problem[self.time_col])
             sort_cols = [self.time_col]
diff --git a/tests/test_data_leak_guard.py b/tests/test_data_leak_guard.py
index 8061f2760c0898aaeda29026859e1b9ff5644ba4..3e56665921db89ea523bbdb205d1bb90c21893df
--- a/tests/test_data_leak_guard.py
+++ b/tests/test_data_leak_guard.py
@@ -3,6 +3,14 @@
 import yaml
 from pathlib import Path
 
+import polars as pl
+
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    enforce_leak_guard,
+    evaluate_leak_prone_columns,
+)
+
 
 PROJECT_ROOT = Path(__file__).resolve().parents[1]
 TRAINING_CONFIG = PROJECT_ROOT / "config" / "training.yaml"
@@ -48,3 +56,41 @@
     )
 
 
+def test_leak_guard_flags_pattern_columns():
+    cols = [
+        "market_anytime_td_prob",
+        "final_score",
+        "postgame_anytime_td",
+        "actual_td_count",
+        "safe_feature",
+    ]
+    result = evaluate_leak_prone_columns(cols, policy=DEFAULT_LEAK_POLICY)
+    assert set(result.banned.keys()) == {"final_score", "postgame_anytime_td", "actual_td_count"}
+    assert "safe_feature" in result.kept
+    assert "market_anytime_td_prob" in result.kept
+
+
+def test_enforce_leak_guard_drops_banned_and_keeps_allowlisted():
+    df = pl.DataFrame(
+        {
+            "game_id": ["g1", "g2"],
+            "safe_feature": [1.0, 2.0],
+            "postgame_anytime_td": [1, 0],
+            "final_score": [30, 24],
+        }
+    )
+    cleaned, info = enforce_leak_guard(
+        df,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_prefixes=("safe_",),
+        allow_exact=("game_id",),
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=False,
+    )
+    assert "postgame_anytime_td" not in cleaned.columns
+    assert "final_score" not in cleaned.columns
+    assert "safe_feature" in cleaned.columns
+    assert "game_id" in cleaned.columns
+    assert set(info.dropped) == {"postgame_anytime_td", "final_score"}
+
diff --git a/tests/test_odds_horizon_filter.py b/tests/test_odds_horizon_filter.py
new file mode 100644
index 0000000000000000000000000000000000000000..70e9c681f63972bbb6e70008e286cf13f6881853
--- /dev/null
+++ b/tests/test_odds_horizon_filter.py
@@ -0,0 +1,35 @@
+from __future__ import annotations
+
+import pandas as pd
+import pytest
+
+train_module = pytest.importorskip("pipeline.train")
+ModelTrainer = train_module.ModelTrainer
+
+
+def test_filter_odds_snapshot_columns_cutoff_keeps_base_only():
+    df = pd.DataFrame(
+        {
+            "market_anytime_td_prob": [0.1, 0.2],
+            "market_anytime_td_prob_2h": [0.15, 0.25],
+            "market_anytime_td_prob_6h": [0.2, 0.3],
+            "other_feature": [1, 2],
+        }
+    )
+    filtered = ModelTrainer._filter_odds_snapshot_columns(df.copy(), "cutoff")
+    assert "market_anytime_td_prob" in filtered.columns
+    assert "market_anytime_td_prob_2h" not in filtered.columns
+    assert "market_anytime_td_prob_6h" not in filtered.columns
+    assert "other_feature" in filtered.columns
+
+
+def test_filter_odds_snapshot_columns_specific_suffix():
+    df = pd.DataFrame(
+        {
+            "market_anytime_td_prob": [0.1, 0.2],
+            "market_anytime_td_prob_2h": [0.15, 0.25],
+            "market_anytime_td_prob_6h": [0.2, 0.3],
+        }
+    )
+    filtered = ModelTrainer._filter_odds_snapshot_columns(df.copy(), "6h")
+    assert list(filtered.columns) == ["market_anytime_td_prob_6h"]
diff --git a/utils/feature/leak_guard.py b/utils/feature/leak_guard.py
new file mode 100644
index 0000000000000000000000000000000000000000..9faf8cfffc436e0934b2f410aaf252e52f4f95df
--- /dev/null
+++ b/utils/feature/leak_guard.py
@@ -0,0 +1,273 @@
+"""Leak guardrails for feature matrices.
+
+This module centralizes pattern-based leak detection so both feature assembly
+and training can fail fast when post-outcome columns sneak into the data.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+from datetime import datetime
+import json
+import re
+from typing import Iterable, Mapping, Sequence
+
+import polars as pl
+
+from utils.general.constants import IDENTIFIER_COLUMNS, LEAK_PRONE_COLUMNS, NFL_TARGET_COLUMNS
+
+try:  # Optional dependency when imported from training (pandas path)
+    import pandas as pd  # type: ignore
+except Exception:  # pragma: no cover - optional dependency
+    pd = None
+
+
+@dataclass(frozen=True)
+class LeakPolicy:
+    version: str
+    banned_exact: set[str]
+    banned_prefixes: tuple[str, ...]
+    banned_suffixes: tuple[str, ...]
+    banned_regex: tuple[tuple[re.Pattern[str], str], ...]
+    description: str = ""
+
+
+@dataclass
+class LeakCheckResult:
+    policy_version: str
+    banned: dict[str, str]
+    kept: list[str]
+    dropped: list[str]
+    allowlist_kept: list[str]
+
+
+# Core policy tuned for anytime-TD style problems (can be extended per-problem).
+_BASE_BANNED_EXACT = set(LEAK_PRONE_COLUMNS) | {
+    "final_score",
+    "final_total",
+    "points_scored",
+    "actual_td_count",
+    "actual_anytime_td",
+    "postgame_anytime_td",
+    "postgame_td_count",
+}
+_BASE_BANNED_PREFIXES = (
+    "postgame_",
+    "post_game_",
+    "post_",
+    "live_",
+    "actual_",
+    "realized_",
+    "final_",
+    "postmatch_",
+)
+_BASE_BANNED_SUFFIXES = (
+    "_post",
+    "_postgame",
+    "_final",
+    "_fullgame",
+    "_actual",
+)
+_BASE_BANNED_REGEX: tuple[tuple[re.Pattern[str], str], ...] = (
+    (re.compile(r".*post.?game.*", flags=re.IGNORECASE), "postgame marker"),
+    (re.compile(r".*final_score.*", flags=re.IGNORECASE), "final score"),
+    (re.compile(r".*actual.*td.*", flags=re.IGNORECASE), "actual TD total"),
+    (re.compile(r".*anytime_td.*(post|final|actual).*", flags=re.IGNORECASE), "post-decision anytime TD"),
+    (re.compile(r".*fullgame.*", flags=re.IGNORECASE), "full game cumulative value"),
+)
+
+DEFAULT_LEAK_POLICY = LeakPolicy(
+    version="v1",
+    description="Core post-outcome leak guard for NFL anytime TD features.",
+    banned_exact=_BASE_BANNED_EXACT,
+    banned_prefixes=_BASE_BANNED_PREFIXES,
+    banned_suffixes=_BASE_BANNED_SUFFIXES,
+    banned_regex=_BASE_BANNED_REGEX,
+)
+
+
+def _ensure_sequence(value: Sequence[str] | str | None) -> tuple[str, ...]:
+    if value is None:
+        return ()
+    if isinstance(value, str):
+        return (value,)
+    return tuple(value)
+
+
+def evaluate_leak_prone_columns(
+    columns: Iterable[str],
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+) -> LeakCheckResult:
+    """Identify leak-prone columns using the configured policy."""
+
+    banned: dict[str, str] = {}
+    columns_list = list(columns)
+    for col in columns_list:
+        if col in policy.banned_exact:
+            banned[col] = "exact"
+            continue
+        for prefix in policy.banned_prefixes:
+            if col.startswith(prefix):
+                banned[col] = f"prefix:{prefix}"
+                break
+        if col in banned:
+            continue
+        for suffix in policy.banned_suffixes:
+            if col.endswith(suffix):
+                banned[col] = f"suffix:{suffix}"
+                break
+        if col in banned:
+            continue
+        for pattern, reason in policy.banned_regex:
+            if pattern.match(col):
+                banned[col] = reason
+                break
+
+    kept = [c for c in columns_list if c not in banned]
+    return LeakCheckResult(
+        policy_version=policy.version,
+        banned=banned,
+        kept=kept,
+        dropped=[],
+        allowlist_kept=[],
+    )
+
+
+def enforce_leak_guard(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    allow_prefixes: Sequence[str] | str | None = None,
+    allow_exact: Sequence[str] | str | None = None,
+    drop_banned: bool = True,
+    drop_non_allowlisted: bool = False,
+    raise_on_banned: bool = True,
+) -> tuple[pl.DataFrame | "pd.DataFrame", LeakCheckResult]:
+    """Apply leak guardrails to a feature frame.
+
+    Parameters
+    ----------
+    df : DataFrame
+        Polars or pandas DataFrame.
+    policy : LeakPolicy
+        Leak policy to apply.
+    allow_prefixes : Sequence[str] | str | None
+        Optional prefixes that define the allowed feature surface for a problem.
+    allow_exact : Sequence[str] | str | None
+        Explicitly allowed columns (e.g., identifiers).
+    drop_banned : bool
+        If True, drop any banned columns automatically.
+    drop_non_allowlisted : bool
+        If True, drop columns that are not covered by allow_prefixes/allow_exact/identifiers/targets.
+    raise_on_banned : bool
+        If True, raise when banned columns are detected (after optional drop).
+    """
+
+    result = evaluate_leak_prone_columns(df.columns, policy=policy)
+    dropped: list[str] = []
+
+    allow_prefixes = _ensure_sequence(allow_prefixes)
+    allow_exact = set(_ensure_sequence(allow_exact))
+    allow_exact.update({col for col in IDENTIFIER_COLUMNS if col in df.columns})
+    allow_exact.update({col for col in NFL_TARGET_COLUMNS if col in df.columns})
+
+    # Permit allowlisted columns even if they match a banned rule (e.g., labels)
+    banned = {col: reason for col, reason in result.banned.items() if col not in allow_exact}
+
+    if banned and drop_banned:
+        df = df.drop(list(banned.keys()))
+        dropped.extend(banned.keys())
+
+    if banned and raise_on_banned:
+        raise ValueError(f"Leak-prone columns detected: {sorted(banned.items())}")
+
+    allowlist_cols: set[str] = set()
+    if allow_prefixes:
+        allowlist_cols.update({c for c in df.columns if c.startswith(allow_prefixes)})
+    allowlist_cols.update({c for c in allow_exact if c in df.columns})
+
+    if drop_non_allowlisted and allowlist_cols:
+        drop_candidates = [c for c in df.columns if c not in allowlist_cols]
+        if drop_candidates:
+            df = df.drop(drop_candidates)
+            dropped.extend(drop_candidates)
+
+    if drop_non_allowlisted and not allowlist_cols:
+        raise ValueError("No allowlisted columns remain after applying leak guard allowlist.")
+
+    # Store adjusted banned info on the result
+    result.banned = banned
+    result.dropped = dropped
+    result.kept = [c for c in df.columns]
+    result.allowlist_kept = sorted(list(allowlist_cols)) if allowlist_cols else []
+    return df, result
+
+
+def build_schema_snapshot(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    metadata: Mapping[str, object] | None = None,
+    banned: Mapping[str, str] | None = None,
+) -> dict:
+    """Render a schema snapshot describing each column and whether it was flagged."""
+
+    banned = banned or {}
+    meta = {
+        "generated_at_utc": datetime.utcnow().isoformat(),
+        "policy_version": policy.version,
+    }
+    meta.update(metadata or {})
+
+    # Extract columns / dtypes
+    if isinstance(df, pl.DataFrame):
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+    else:  # pandas or pandas-like
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+
+    schema = {
+        "metadata": meta,
+        "columns": [],
+    }
+
+    for col, dtype in cols_and_dtypes:
+        tags: list[str] = []
+        if col in IDENTIFIER_COLUMNS:
+            tags.append("id")
+        if col in NFL_TARGET_COLUMNS:
+            tags.append("label")
+        if col.startswith("market_"):
+            tags.append("odds")
+        if col.startswith("injury_") or col.startswith("practice_"):
+            tags.append("injury")
+        if col.startswith("weather_"):
+            tags.append("weather")
+        if col.startswith("ps_"):
+            tags.append("pre_snap")
+        schema["columns"].append(
+            {
+                "name": col,
+                "dtype": dtype,
+                "banned": col in banned,
+                "tags": tags,
+            }
+        )
+    return schema
+
+
+def write_schema_snapshot(path, schema: Mapping[str, object]) -> None:
+    path.parent.mkdir(parents=True, exist_ok=True)
+    with open(path, "w") as fp:
+        json.dump(schema, fp, indent=2, sort_keys=True)
+
+
+__all__ = [
+    "DEFAULT_LEAK_POLICY",
+    "LeakPolicy",
+    "LeakCheckResult",
+    "evaluate_leak_prone_columns",
+    "enforce_leak_guard",
+    "build_schema_snapshot",
+    "write_schema_snapshot",
+]
diff --git a/utils/general/constants.py b/utils/general/constants.py
index d94b4260ad877484da843fa99ae2caf37e8493f4..dea87caa354d94e4a08b1762d2bd8dcd4c8caa3a
--- a/utils/general/constants.py
+++ b/utils/general/constants.py
@@ -211,7 +211,17 @@
 
 NFL_TARGET_COLUMNS: Tuple[str, ...] = (
     'anytime_td',
+    'anytime_td_offense',
+    'anytime_td_all',
+    'anytime_td_rush',
+    'anytime_td_rec',
+    'anytime_td_pass_thrown',
     'td_count',
+    'td_count_offense',
+    'td_count_all',
+    'passing_td',
+    'rushing_td_count',
+    'receiving_td_count',
     'receiving_yards',
     'rushing_yards',
     'passing_yards',


thinking
**Verifying test environment and schema paths**

I’m making sure the schema writing path handles directory creation correctly and checking that the default policy won’t cause errors with existing columns. Before running tests, I want to confirm the environment allows it, then run selected pytest commands on relevant test files to validate changes.
exec
/bin/zsh -lc 'cd /Users/jameswest/Desktop/nfl_predict && pytest tests/test_data_leak_guard.py tests/test_odds_horizon_filter.py -q' in /Users/jameswest/Desktop/nfl_predict exited 127 in 739ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
zsh:1: command not found: pytest
file update:
diff --git a/config/training.yaml b/config/training.yaml
index 3953818d861d0410246bff132110722a3ce44007..c2b6053b488caa71f9078ff100d049f723ae1548
--- a/config/training.yaml
+++ b/config/training.yaml
@@ -476,6 +476,7 @@
   - name: 'anytime_td'
     target_col: 'anytime_td'
     label_version: 'v1_any_offense'
+    odds_horizon: 'cutoff'  # Restrict odds features to the decision-time snapshot
     task_type: 'classification'
     input_predictions:
       - 'availability_active'
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 5ba68e8bf1acd3a789a76a8857674e6f6433017b..0210d5b7e7ed60a8de7a126d64f5ed76326474c8
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -14,7 +14,7 @@
 
 import logging
 import os
-from datetime import date, timedelta
+from datetime import date, datetime, timedelta
 from typing import Sequence
 
 import polars as pl
@@ -37,6 +37,12 @@
     add_offense_context_features_training,
     _append_offense_context_columns,
 )
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    build_schema_snapshot,
+    enforce_leak_guard,
+    write_schema_snapshot,
+)
 from utils.feature.weather_features import (
     add_weather_forecast_features_training,
     append_weather_context_flags,
@@ -931,6 +937,32 @@
     if market_exprs:
         df_player_game_all = df_player_game_all.with_columns(market_exprs)
     
+    # Leak guard + schema snapshot before persisting
+    spec = get_label_spec(label_version)
+    allow_exact = {spec.primary, *spec.labels.keys(), *spec.aliases.keys()}
+    df_player_game_all, leak_result = enforce_leak_guard(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_exact=allow_exact,
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=True,
+    )
+
+    schema = build_schema_snapshot(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        metadata={
+            "cutoff_label": cutoff_label,
+            "label_version": spec.name,
+        },
+        banned=leak_result.banned,
+    )
+    schema_dir = FEATURE_AUDIT_DIR / "schema" / "anytime_td"
+    schema_path = schema_dir / f"{cutoff_label}_{datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')}.json"
+    write_schema_snapshot(schema_path, schema)
+    logging.info("    Schema snapshot written → %s", schema_path)
+
     # Write final feature matrix
     df_player_game_all = df_player_game_all.with_columns(
         pl.lit(current_cutoff_hours).cast(pl.Float32).alias("decision_horizon_hours")
@@ -951,7 +983,6 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    spec = get_label_spec(label_version)
     label_candidates = {spec.primary, "anytime_td"}
     for label_col in label_candidates:
         if label_col in df_player_game_all.columns:
diff --git a/pipeline/train.py b/pipeline/train.py
index fe70207dcdf25d209ee3ad55080b7ce826347c44..7c220514d006a3d4815d65a8af9ec7551ccf587e
--- a/pipeline/train.py
+++ b/pipeline/train.py
@@ -4,6 +4,7 @@
 import sys
 import logging
 import math
+import re
 
 
 # Move logging to top and remove global thread pinning
@@ -98,6 +99,7 @@
     fit_team_conformal_sums,
     composite_sum_interval,
 )
+from utils.feature.leak_guard import DEFAULT_LEAK_POLICY, enforce_leak_guard
 from utils.feature.targets import require_target_column
 
 # Ignore specific, noisy warnings from dependencies
@@ -793,6 +795,57 @@
             )
         return df
 
+    @staticmethod
+    def _filter_odds_snapshot_columns(df: pd.DataFrame, horizon_key: str | None) -> pd.DataFrame:
+        """Keep a single odds snapshot horizon (drop other suffixes)."""
+        if df is None or df.empty or not horizon_key:
+            return df
+
+        normalized = str(horizon_key).strip().lower()
+        horizon_map = {
+            "cutoff": "",
+            "default": "",
+            "": "",
+            "2h": "_2h",
+            "h120m": "_2h",
+            "6h": "_6h",
+            "h360m": "_6h",
+            "24h": "_24h",
+            "h1440m": "_24h",
+            "open": "_open",
+        }
+        allowed_suffix = horizon_map.get(normalized, normalized)
+        if allowed_suffix and not allowed_suffix.startswith("_"):
+            allowed_suffix = f"_{allowed_suffix.lstrip('_')}"
+
+        horizon_re = re.compile(r"^(?P<base>.+)(?P<suffix>_2h|_6h|_24h|_open)$")
+        suffixes_seen: dict[str, set[str]] = {}
+        for col in df.columns:
+            match = horizon_re.match(col)
+            if match:
+                suffixes_seen.setdefault(match.group("base"), set()).add(match.group("suffix"))
+
+        drop_cols: list[str] = []
+        for col in df.columns:
+            match = horizon_re.match(col)
+            if match:
+                suffix = match.group("suffix")
+                if suffix != allowed_suffix:
+                    drop_cols.append(col)
+            else:
+                base = col
+                if base in suffixes_seen and allowed_suffix:
+                    drop_cols.append(col)
+
+        if drop_cols:
+            df = df.drop(columns=drop_cols, errors="ignore")
+            logger.info(
+                "Removed %d odds snapshot columns outside horizon '%s'.",
+                len(drop_cols),
+                horizon_key,
+            )
+        return df
+
     def _ensure_player_game_actuals(self) -> pd.DataFrame:
         if self._player_game_actuals is not None:
             return self._player_game_actuals
@@ -2315,7 +2368,34 @@
                             df_problem[col] = df_problem[col].fillna(df_problem[col].mean())
 
                 df_problem = self._inject_composed_features(df_problem)
-            
+
+            odds_horizon = problem_copy.get("odds_horizon")
+            if odds_horizon:
+                df_problem = self._filter_odds_snapshot_columns(df_problem, odds_horizon)
+
+            # Leak guard on the problem-scoped frame
+            allow_prefixes = tuple(problem_copy.get('feature_prefixes_to_include') or [])
+            allow_exact = set(problem_copy.get('other_features_to_include') or [])
+            allow_exact.update(input_preds or [])
+            if self.target_col:
+                allow_exact.add(self.target_col)
+            df_problem, leak_info = enforce_leak_guard(
+                df_problem,
+                policy=DEFAULT_LEAK_POLICY,
+                allow_prefixes=allow_prefixes,
+                allow_exact=allow_exact,
+                drop_banned=True,
+                drop_non_allowlisted=False,
+                raise_on_banned=True,
+            )
+            if leak_info.dropped:
+                logger.info(
+                    "Dropped %d leak-prone columns for %s: %s",
+                    len(leak_info.dropped),
+                    problem_name,
+                    sorted(leak_info.dropped),
+                )
+
             self._normalize_datetime_like_columns(df_problem, problem_name)
             df_problem[self.time_col] = pd.to_datetime(df_problem[self.time_col])
             sort_cols = [self.time_col]
diff --git a/tests/test_data_leak_guard.py b/tests/test_data_leak_guard.py
index 8061f2760c0898aaeda29026859e1b9ff5644ba4..3e56665921db89ea523bbdb205d1bb90c21893df
--- a/tests/test_data_leak_guard.py
+++ b/tests/test_data_leak_guard.py
@@ -3,6 +3,14 @@
 import yaml
 from pathlib import Path
 
+import polars as pl
+
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    enforce_leak_guard,
+    evaluate_leak_prone_columns,
+)
+
 
 PROJECT_ROOT = Path(__file__).resolve().parents[1]
 TRAINING_CONFIG = PROJECT_ROOT / "config" / "training.yaml"
@@ -48,3 +56,41 @@
     )
 
 
+def test_leak_guard_flags_pattern_columns():
+    cols = [
+        "market_anytime_td_prob",
+        "final_score",
+        "postgame_anytime_td",
+        "actual_td_count",
+        "safe_feature",
+    ]
+    result = evaluate_leak_prone_columns(cols, policy=DEFAULT_LEAK_POLICY)
+    assert set(result.banned.keys()) == {"final_score", "postgame_anytime_td", "actual_td_count"}
+    assert "safe_feature" in result.kept
+    assert "market_anytime_td_prob" in result.kept
+
+
+def test_enforce_leak_guard_drops_banned_and_keeps_allowlisted():
+    df = pl.DataFrame(
+        {
+            "game_id": ["g1", "g2"],
+            "safe_feature": [1.0, 2.0],
+            "postgame_anytime_td": [1, 0],
+            "final_score": [30, 24],
+        }
+    )
+    cleaned, info = enforce_leak_guard(
+        df,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_prefixes=("safe_",),
+        allow_exact=("game_id",),
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=False,
+    )
+    assert "postgame_anytime_td" not in cleaned.columns
+    assert "final_score" not in cleaned.columns
+    assert "safe_feature" in cleaned.columns
+    assert "game_id" in cleaned.columns
+    assert set(info.dropped) == {"postgame_anytime_td", "final_score"}
+
diff --git a/tests/test_odds_horizon_filter.py b/tests/test_odds_horizon_filter.py
new file mode 100644
index 0000000000000000000000000000000000000000..70e9c681f63972bbb6e70008e286cf13f6881853
--- /dev/null
+++ b/tests/test_odds_horizon_filter.py
@@ -0,0 +1,35 @@
+from __future__ import annotations
+
+import pandas as pd
+import pytest
+
+train_module = pytest.importorskip("pipeline.train")
+ModelTrainer = train_module.ModelTrainer
+
+
+def test_filter_odds_snapshot_columns_cutoff_keeps_base_only():
+    df = pd.DataFrame(
+        {
+            "market_anytime_td_prob": [0.1, 0.2],
+            "market_anytime_td_prob_2h": [0.15, 0.25],
+            "market_anytime_td_prob_6h": [0.2, 0.3],
+            "other_feature": [1, 2],
+        }
+    )
+    filtered = ModelTrainer._filter_odds_snapshot_columns(df.copy(), "cutoff")
+    assert "market_anytime_td_prob" in filtered.columns
+    assert "market_anytime_td_prob_2h" not in filtered.columns
+    assert "market_anytime_td_prob_6h" not in filtered.columns
+    assert "other_feature" in filtered.columns
+
+
+def test_filter_odds_snapshot_columns_specific_suffix():
+    df = pd.DataFrame(
+        {
+            "market_anytime_td_prob": [0.1, 0.2],
+            "market_anytime_td_prob_2h": [0.15, 0.25],
+            "market_anytime_td_prob_6h": [0.2, 0.3],
+        }
+    )
+    filtered = ModelTrainer._filter_odds_snapshot_columns(df.copy(), "6h")
+    assert list(filtered.columns) == ["market_anytime_td_prob_6h"]
diff --git a/utils/feature/leak_guard.py b/utils/feature/leak_guard.py
new file mode 100644
index 0000000000000000000000000000000000000000..9faf8cfffc436e0934b2f410aaf252e52f4f95df
--- /dev/null
+++ b/utils/feature/leak_guard.py
@@ -0,0 +1,273 @@
+"""Leak guardrails for feature matrices.
+
+This module centralizes pattern-based leak detection so both feature assembly
+and training can fail fast when post-outcome columns sneak into the data.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+from datetime import datetime
+import json
+import re
+from typing import Iterable, Mapping, Sequence
+
+import polars as pl
+
+from utils.general.constants import IDENTIFIER_COLUMNS, LEAK_PRONE_COLUMNS, NFL_TARGET_COLUMNS
+
+try:  # Optional dependency when imported from training (pandas path)
+    import pandas as pd  # type: ignore
+except Exception:  # pragma: no cover - optional dependency
+    pd = None
+
+
+@dataclass(frozen=True)
+class LeakPolicy:
+    version: str
+    banned_exact: set[str]
+    banned_prefixes: tuple[str, ...]
+    banned_suffixes: tuple[str, ...]
+    banned_regex: tuple[tuple[re.Pattern[str], str], ...]
+    description: str = ""
+
+
+@dataclass
+class LeakCheckResult:
+    policy_version: str
+    banned: dict[str, str]
+    kept: list[str]
+    dropped: list[str]
+    allowlist_kept: list[str]
+
+
+# Core policy tuned for anytime-TD style problems (can be extended per-problem).
+_BASE_BANNED_EXACT = set(LEAK_PRONE_COLUMNS) | {
+    "final_score",
+    "final_total",
+    "points_scored",
+    "actual_td_count",
+    "actual_anytime_td",
+    "postgame_anytime_td",
+    "postgame_td_count",
+}
+_BASE_BANNED_PREFIXES = (
+    "postgame_",
+    "post_game_",
+    "post_",
+    "live_",
+    "actual_",
+    "realized_",
+    "final_",
+    "postmatch_",
+)
+_BASE_BANNED_SUFFIXES = (
+    "_post",
+    "_postgame",
+    "_final",
+    "_fullgame",
+    "_actual",
+)
+_BASE_BANNED_REGEX: tuple[tuple[re.Pattern[str], str], ...] = (
+    (re.compile(r".*post.?game.*", flags=re.IGNORECASE), "postgame marker"),
+    (re.compile(r".*final_score.*", flags=re.IGNORECASE), "final score"),
+    (re.compile(r".*actual.*td.*", flags=re.IGNORECASE), "actual TD total"),
+    (re.compile(r".*anytime_td.*(post|final|actual).*", flags=re.IGNORECASE), "post-decision anytime TD"),
+    (re.compile(r".*fullgame.*", flags=re.IGNORECASE), "full game cumulative value"),
+)
+
+DEFAULT_LEAK_POLICY = LeakPolicy(
+    version="v1",
+    description="Core post-outcome leak guard for NFL anytime TD features.",
+    banned_exact=_BASE_BANNED_EXACT,
+    banned_prefixes=_BASE_BANNED_PREFIXES,
+    banned_suffixes=_BASE_BANNED_SUFFIXES,
+    banned_regex=_BASE_BANNED_REGEX,
+)
+
+
+def _ensure_sequence(value: Sequence[str] | str | None) -> tuple[str, ...]:
+    if value is None:
+        return ()
+    if isinstance(value, str):
+        return (value,)
+    return tuple(value)
+
+
+def evaluate_leak_prone_columns(
+    columns: Iterable[str],
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+) -> LeakCheckResult:
+    """Identify leak-prone columns using the configured policy."""
+
+    banned: dict[str, str] = {}
+    columns_list = list(columns)
+    for col in columns_list:
+        if col in policy.banned_exact:
+            banned[col] = "exact"
+            continue
+        for prefix in policy.banned_prefixes:
+            if col.startswith(prefix):
+                banned[col] = f"prefix:{prefix}"
+                break
+        if col in banned:
+            continue
+        for suffix in policy.banned_suffixes:
+            if col.endswith(suffix):
+                banned[col] = f"suffix:{suffix}"
+                break
+        if col in banned:
+            continue
+        for pattern, reason in policy.banned_regex:
+            if pattern.match(col):
+                banned[col] = reason
+                break
+
+    kept = [c for c in columns_list if c not in banned]
+    return LeakCheckResult(
+        policy_version=policy.version,
+        banned=banned,
+        kept=kept,
+        dropped=[],
+        allowlist_kept=[],
+    )
+
+
+def enforce_leak_guard(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    allow_prefixes: Sequence[str] | str | None = None,
+    allow_exact: Sequence[str] | str | None = None,
+    drop_banned: bool = True,
+    drop_non_allowlisted: bool = False,
+    raise_on_banned: bool = True,
+) -> tuple[pl.DataFrame | "pd.DataFrame", LeakCheckResult]:
+    """Apply leak guardrails to a feature frame.
+
+    Parameters
+    ----------
+    df : DataFrame
+        Polars or pandas DataFrame.
+    policy : LeakPolicy
+        Leak policy to apply.
+    allow_prefixes : Sequence[str] | str | None
+        Optional prefixes that define the allowed feature surface for a problem.
+    allow_exact : Sequence[str] | str | None
+        Explicitly allowed columns (e.g., identifiers).
+    drop_banned : bool
+        If True, drop any banned columns automatically.
+    drop_non_allowlisted : bool
+        If True, drop columns that are not covered by allow_prefixes/allow_exact/identifiers/targets.
+    raise_on_banned : bool
+        If True, raise when banned columns are detected (after optional drop).
+    """
+
+    result = evaluate_leak_prone_columns(df.columns, policy=policy)
+    dropped: list[str] = []
+
+    allow_prefixes = _ensure_sequence(allow_prefixes)
+    allow_exact = set(_ensure_sequence(allow_exact))
+    allow_exact.update({col for col in IDENTIFIER_COLUMNS if col in df.columns})
+    allow_exact.update({col for col in NFL_TARGET_COLUMNS if col in df.columns})
+
+    # Permit allowlisted columns even if they match a banned rule (e.g., labels)
+    banned = {col: reason for col, reason in result.banned.items() if col not in allow_exact}
+
+    if banned and drop_banned:
+        df = df.drop(list(banned.keys()))
+        dropped.extend(banned.keys())
+
+    if banned and raise_on_banned:
+        raise ValueError(f"Leak-prone columns detected: {sorted(banned.items())}")
+
+    allowlist_cols: set[str] = set()
+    if allow_prefixes:
+        allowlist_cols.update({c for c in df.columns if c.startswith(allow_prefixes)})
+    allowlist_cols.update({c for c in allow_exact if c in df.columns})
+
+    if drop_non_allowlisted and allowlist_cols:
+        drop_candidates = [c for c in df.columns if c not in allowlist_cols]
+        if drop_candidates:
+            df = df.drop(drop_candidates)
+            dropped.extend(drop_candidates)
+
+    if drop_non_allowlisted and not allowlist_cols:
+        raise ValueError("No allowlisted columns remain after applying leak guard allowlist.")
+
+    # Store adjusted banned info on the result
+    result.banned = banned
+    result.dropped = dropped
+    result.kept = [c for c in df.columns]
+    result.allowlist_kept = sorted(list(allowlist_cols)) if allowlist_cols else []
+    return df, result
+
+
+def build_schema_snapshot(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    metadata: Mapping[str, object] | None = None,
+    banned: Mapping[str, str] | None = None,
+) -> dict:
+    """Render a schema snapshot describing each column and whether it was flagged."""
+
+    banned = banned or {}
+    meta = {
+        "generated_at_utc": datetime.utcnow().isoformat(),
+        "policy_version": policy.version,
+    }
+    meta.update(metadata or {})
+
+    # Extract columns / dtypes
+    if isinstance(df, pl.DataFrame):
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+    else:  # pandas or pandas-like
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+
+    schema = {
+        "metadata": meta,
+        "columns": [],
+    }
+
+    for col, dtype in cols_and_dtypes:
+        tags: list[str] = []
+        if col in IDENTIFIER_COLUMNS:
+            tags.append("id")
+        if col in NFL_TARGET_COLUMNS:
+            tags.append("label")
+        if col.startswith("market_"):
+            tags.append("odds")
+        if col.startswith("injury_") or col.startswith("practice_"):
+            tags.append("injury")
+        if col.startswith("weather_"):
+            tags.append("weather")
+        if col.startswith("ps_"):
+            tags.append("pre_snap")
+        schema["columns"].append(
+            {
+                "name": col,
+                "dtype": dtype,
+                "banned": col in banned,
+                "tags": tags,
+            }
+        )
+    return schema
+
+
+def write_schema_snapshot(path, schema: Mapping[str, object]) -> None:
+    path.parent.mkdir(parents=True, exist_ok=True)
+    with open(path, "w") as fp:
+        json.dump(schema, fp, indent=2, sort_keys=True)
+
+
+__all__ = [
+    "DEFAULT_LEAK_POLICY",
+    "LeakPolicy",
+    "LeakCheckResult",
+    "evaluate_leak_prone_columns",
+    "enforce_leak_guard",
+    "build_schema_snapshot",
+    "write_schema_snapshot",
+]
diff --git a/utils/general/constants.py b/utils/general/constants.py
index d94b4260ad877484da843fa99ae2caf37e8493f4..dea87caa354d94e4a08b1762d2bd8dcd4c8caa3a
--- a/utils/general/constants.py
+++ b/utils/general/constants.py
@@ -211,7 +211,17 @@
 
 NFL_TARGET_COLUMNS: Tuple[str, ...] = (
     'anytime_td',
+    'anytime_td_offense',
+    'anytime_td_all',
+    'anytime_td_rush',
+    'anytime_td_rec',
+    'anytime_td_pass_thrown',
     'td_count',
+    'td_count_offense',
+    'td_count_all',
+    'passing_td',
+    'rushing_td_count',
+    'receiving_td_count',
     'receiving_yards',
     'rushing_yards',
     'passing_yards',


thinking
**Attempting to run tests despite missing pytest**
exec
/bin/zsh -lc 'cd /Users/jameswest/Desktop/nfl_predict && python -m pytest tests/test_data_leak_guard.py tests/test_odds_horizon_filter.py -q' in /Users/jameswest/Desktop/nfl_predict exited 127 in 709ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
zsh:1: command not found: python
file update:
diff --git a/config/training.yaml b/config/training.yaml
index 3953818d861d0410246bff132110722a3ce44007..c2b6053b488caa71f9078ff100d049f723ae1548
--- a/config/training.yaml
+++ b/config/training.yaml
@@ -476,6 +476,7 @@
   - name: 'anytime_td'
     target_col: 'anytime_td'
     label_version: 'v1_any_offense'
+    odds_horizon: 'cutoff'  # Restrict odds features to the decision-time snapshot
     task_type: 'classification'
     input_predictions:
       - 'availability_active'
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 5ba68e8bf1acd3a789a76a8857674e6f6433017b..0210d5b7e7ed60a8de7a126d64f5ed76326474c8
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -14,7 +14,7 @@
 
 import logging
 import os
-from datetime import date, timedelta
+from datetime import date, datetime, timedelta
 from typing import Sequence
 
 import polars as pl
@@ -37,6 +37,12 @@
     add_offense_context_features_training,
     _append_offense_context_columns,
 )
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    build_schema_snapshot,
+    enforce_leak_guard,
+    write_schema_snapshot,
+)
 from utils.feature.weather_features import (
     add_weather_forecast_features_training,
     append_weather_context_flags,
@@ -931,6 +937,32 @@
     if market_exprs:
         df_player_game_all = df_player_game_all.with_columns(market_exprs)
     
+    # Leak guard + schema snapshot before persisting
+    spec = get_label_spec(label_version)
+    allow_exact = {spec.primary, *spec.labels.keys(), *spec.aliases.keys()}
+    df_player_game_all, leak_result = enforce_leak_guard(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_exact=allow_exact,
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=True,
+    )
+
+    schema = build_schema_snapshot(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        metadata={
+            "cutoff_label": cutoff_label,
+            "label_version": spec.name,
+        },
+        banned=leak_result.banned,
+    )
+    schema_dir = FEATURE_AUDIT_DIR / "schema" / "anytime_td"
+    schema_path = schema_dir / f"{cutoff_label}_{datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')}.json"
+    write_schema_snapshot(schema_path, schema)
+    logging.info("    Schema snapshot written → %s", schema_path)
+
     # Write final feature matrix
     df_player_game_all = df_player_game_all.with_columns(
         pl.lit(current_cutoff_hours).cast(pl.Float32).alias("decision_horizon_hours")
@@ -951,7 +983,6 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    spec = get_label_spec(label_version)
     label_candidates = {spec.primary, "anytime_td"}
     for label_col in label_candidates:
         if label_col in df_player_game_all.columns:
diff --git a/pipeline/train.py b/pipeline/train.py
index fe70207dcdf25d209ee3ad55080b7ce826347c44..7c220514d006a3d4815d65a8af9ec7551ccf587e
--- a/pipeline/train.py
+++ b/pipeline/train.py
@@ -4,6 +4,7 @@
 import sys
 import logging
 import math
+import re
 
 
 # Move logging to top and remove global thread pinning
@@ -98,6 +99,7 @@
     fit_team_conformal_sums,
     composite_sum_interval,
 )
+from utils.feature.leak_guard import DEFAULT_LEAK_POLICY, enforce_leak_guard
 from utils.feature.targets import require_target_column
 
 # Ignore specific, noisy warnings from dependencies
@@ -793,6 +795,57 @@
             )
         return df
 
+    @staticmethod
+    def _filter_odds_snapshot_columns(df: pd.DataFrame, horizon_key: str | None) -> pd.DataFrame:
+        """Keep a single odds snapshot horizon (drop other suffixes)."""
+        if df is None or df.empty or not horizon_key:
+            return df
+
+        normalized = str(horizon_key).strip().lower()
+        horizon_map = {
+            "cutoff": "",
+            "default": "",
+            "": "",
+            "2h": "_2h",
+            "h120m": "_2h",
+            "6h": "_6h",
+            "h360m": "_6h",
+            "24h": "_24h",
+            "h1440m": "_24h",
+            "open": "_open",
+        }
+        allowed_suffix = horizon_map.get(normalized, normalized)
+        if allowed_suffix and not allowed_suffix.startswith("_"):
+            allowed_suffix = f"_{allowed_suffix.lstrip('_')}"
+
+        horizon_re = re.compile(r"^(?P<base>.+)(?P<suffix>_2h|_6h|_24h|_open)$")
+        suffixes_seen: dict[str, set[str]] = {}
+        for col in df.columns:
+            match = horizon_re.match(col)
+            if match:
+                suffixes_seen.setdefault(match.group("base"), set()).add(match.group("suffix"))
+
+        drop_cols: list[str] = []
+        for col in df.columns:
+            match = horizon_re.match(col)
+            if match:
+                suffix = match.group("suffix")
+                if suffix != allowed_suffix:
+                    drop_cols.append(col)
+            else:
+                base = col
+                if base in suffixes_seen and allowed_suffix:
+                    drop_cols.append(col)
+
+        if drop_cols:
+            df = df.drop(columns=drop_cols, errors="ignore")
+            logger.info(
+                "Removed %d odds snapshot columns outside horizon '%s'.",
+                len(drop_cols),
+                horizon_key,
+            )
+        return df
+
     def _ensure_player_game_actuals(self) -> pd.DataFrame:
         if self._player_game_actuals is not None:
             return self._player_game_actuals
@@ -2315,7 +2368,34 @@
                             df_problem[col] = df_problem[col].fillna(df_problem[col].mean())
 
                 df_problem = self._inject_composed_features(df_problem)
-            
+
+            odds_horizon = problem_copy.get("odds_horizon")
+            if odds_horizon:
+                df_problem = self._filter_odds_snapshot_columns(df_problem, odds_horizon)
+
+            # Leak guard on the problem-scoped frame
+            allow_prefixes = tuple(problem_copy.get('feature_prefixes_to_include') or [])
+            allow_exact = set(problem_copy.get('other_features_to_include') or [])
+            allow_exact.update(input_preds or [])
+            if self.target_col:
+                allow_exact.add(self.target_col)
+            df_problem, leak_info = enforce_leak_guard(
+                df_problem,
+                policy=DEFAULT_LEAK_POLICY,
+                allow_prefixes=allow_prefixes,
+                allow_exact=allow_exact,
+                drop_banned=True,
+                drop_non_allowlisted=False,
+                raise_on_banned=True,
+            )
+            if leak_info.dropped:
+                logger.info(
+                    "Dropped %d leak-prone columns for %s: %s",
+                    len(leak_info.dropped),
+                    problem_name,
+                    sorted(leak_info.dropped),
+                )
+
             self._normalize_datetime_like_columns(df_problem, problem_name)
             df_problem[self.time_col] = pd.to_datetime(df_problem[self.time_col])
             sort_cols = [self.time_col]
diff --git a/tests/test_data_leak_guard.py b/tests/test_data_leak_guard.py
index 8061f2760c0898aaeda29026859e1b9ff5644ba4..3e56665921db89ea523bbdb205d1bb90c21893df
--- a/tests/test_data_leak_guard.py
+++ b/tests/test_data_leak_guard.py
@@ -3,6 +3,14 @@
 import yaml
 from pathlib import Path
 
+import polars as pl
+
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    enforce_leak_guard,
+    evaluate_leak_prone_columns,
+)
+
 
 PROJECT_ROOT = Path(__file__).resolve().parents[1]
 TRAINING_CONFIG = PROJECT_ROOT / "config" / "training.yaml"
@@ -48,3 +56,41 @@
     )
 
 
+def test_leak_guard_flags_pattern_columns():
+    cols = [
+        "market_anytime_td_prob",
+        "final_score",
+        "postgame_anytime_td",
+        "actual_td_count",
+        "safe_feature",
+    ]
+    result = evaluate_leak_prone_columns(cols, policy=DEFAULT_LEAK_POLICY)
+    assert set(result.banned.keys()) == {"final_score", "postgame_anytime_td", "actual_td_count"}
+    assert "safe_feature" in result.kept
+    assert "market_anytime_td_prob" in result.kept
+
+
+def test_enforce_leak_guard_drops_banned_and_keeps_allowlisted():
+    df = pl.DataFrame(
+        {
+            "game_id": ["g1", "g2"],
+            "safe_feature": [1.0, 2.0],
+            "postgame_anytime_td": [1, 0],
+            "final_score": [30, 24],
+        }
+    )
+    cleaned, info = enforce_leak_guard(
+        df,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_prefixes=("safe_",),
+        allow_exact=("game_id",),
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=False,
+    )
+    assert "postgame_anytime_td" not in cleaned.columns
+    assert "final_score" not in cleaned.columns
+    assert "safe_feature" in cleaned.columns
+    assert "game_id" in cleaned.columns
+    assert set(info.dropped) == {"postgame_anytime_td", "final_score"}
+
diff --git a/tests/test_odds_horizon_filter.py b/tests/test_odds_horizon_filter.py
new file mode 100644
index 0000000000000000000000000000000000000000..70e9c681f63972bbb6e70008e286cf13f6881853
--- /dev/null
+++ b/tests/test_odds_horizon_filter.py
@@ -0,0 +1,35 @@
+from __future__ import annotations
+
+import pandas as pd
+import pytest
+
+train_module = pytest.importorskip("pipeline.train")
+ModelTrainer = train_module.ModelTrainer
+
+
+def test_filter_odds_snapshot_columns_cutoff_keeps_base_only():
+    df = pd.DataFrame(
+        {
+            "market_anytime_td_prob": [0.1, 0.2],
+            "market_anytime_td_prob_2h": [0.15, 0.25],
+            "market_anytime_td_prob_6h": [0.2, 0.3],
+            "other_feature": [1, 2],
+        }
+    )
+    filtered = ModelTrainer._filter_odds_snapshot_columns(df.copy(), "cutoff")
+    assert "market_anytime_td_prob" in filtered.columns
+    assert "market_anytime_td_prob_2h" not in filtered.columns
+    assert "market_anytime_td_prob_6h" not in filtered.columns
+    assert "other_feature" in filtered.columns
+
+
+def test_filter_odds_snapshot_columns_specific_suffix():
+    df = pd.DataFrame(
+        {
+            "market_anytime_td_prob": [0.1, 0.2],
+            "market_anytime_td_prob_2h": [0.15, 0.25],
+            "market_anytime_td_prob_6h": [0.2, 0.3],
+        }
+    )
+    filtered = ModelTrainer._filter_odds_snapshot_columns(df.copy(), "6h")
+    assert list(filtered.columns) == ["market_anytime_td_prob_6h"]
diff --git a/utils/feature/leak_guard.py b/utils/feature/leak_guard.py
new file mode 100644
index 0000000000000000000000000000000000000000..9faf8cfffc436e0934b2f410aaf252e52f4f95df
--- /dev/null
+++ b/utils/feature/leak_guard.py
@@ -0,0 +1,273 @@
+"""Leak guardrails for feature matrices.
+
+This module centralizes pattern-based leak detection so both feature assembly
+and training can fail fast when post-outcome columns sneak into the data.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+from datetime import datetime
+import json
+import re
+from typing import Iterable, Mapping, Sequence
+
+import polars as pl
+
+from utils.general.constants import IDENTIFIER_COLUMNS, LEAK_PRONE_COLUMNS, NFL_TARGET_COLUMNS
+
+try:  # Optional dependency when imported from training (pandas path)
+    import pandas as pd  # type: ignore
+except Exception:  # pragma: no cover - optional dependency
+    pd = None
+
+
+@dataclass(frozen=True)
+class LeakPolicy:
+    version: str
+    banned_exact: set[str]
+    banned_prefixes: tuple[str, ...]
+    banned_suffixes: tuple[str, ...]
+    banned_regex: tuple[tuple[re.Pattern[str], str], ...]
+    description: str = ""
+
+
+@dataclass
+class LeakCheckResult:
+    policy_version: str
+    banned: dict[str, str]
+    kept: list[str]
+    dropped: list[str]
+    allowlist_kept: list[str]
+
+
+# Core policy tuned for anytime-TD style problems (can be extended per-problem).
+_BASE_BANNED_EXACT = set(LEAK_PRONE_COLUMNS) | {
+    "final_score",
+    "final_total",
+    "points_scored",
+    "actual_td_count",
+    "actual_anytime_td",
+    "postgame_anytime_td",
+    "postgame_td_count",
+}
+_BASE_BANNED_PREFIXES = (
+    "postgame_",
+    "post_game_",
+    "post_",
+    "live_",
+    "actual_",
+    "realized_",
+    "final_",
+    "postmatch_",
+)
+_BASE_BANNED_SUFFIXES = (
+    "_post",
+    "_postgame",
+    "_final",
+    "_fullgame",
+    "_actual",
+)
+_BASE_BANNED_REGEX: tuple[tuple[re.Pattern[str], str], ...] = (
+    (re.compile(r".*post.?game.*", flags=re.IGNORECASE), "postgame marker"),
+    (re.compile(r".*final_score.*", flags=re.IGNORECASE), "final score"),
+    (re.compile(r".*actual.*td.*", flags=re.IGNORECASE), "actual TD total"),
+    (re.compile(r".*anytime_td.*(post|final|actual).*", flags=re.IGNORECASE), "post-decision anytime TD"),
+    (re.compile(r".*fullgame.*", flags=re.IGNORECASE), "full game cumulative value"),
+)
+
+DEFAULT_LEAK_POLICY = LeakPolicy(
+    version="v1",
+    description="Core post-outcome leak guard for NFL anytime TD features.",
+    banned_exact=_BASE_BANNED_EXACT,
+    banned_prefixes=_BASE_BANNED_PREFIXES,
+    banned_suffixes=_BASE_BANNED_SUFFIXES,
+    banned_regex=_BASE_BANNED_REGEX,
+)
+
+
+def _ensure_sequence(value: Sequence[str] | str | None) -> tuple[str, ...]:
+    if value is None:
+        return ()
+    if isinstance(value, str):
+        return (value,)
+    return tuple(value)
+
+
+def evaluate_leak_prone_columns(
+    columns: Iterable[str],
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+) -> LeakCheckResult:
+    """Identify leak-prone columns using the configured policy."""
+
+    banned: dict[str, str] = {}
+    columns_list = list(columns)
+    for col in columns_list:
+        if col in policy.banned_exact:
+            banned[col] = "exact"
+            continue
+        for prefix in policy.banned_prefixes:
+            if col.startswith(prefix):
+                banned[col] = f"prefix:{prefix}"
+                break
+        if col in banned:
+            continue
+        for suffix in policy.banned_suffixes:
+            if col.endswith(suffix):
+                banned[col] = f"suffix:{suffix}"
+                break
+        if col in banned:
+            continue
+        for pattern, reason in policy.banned_regex:
+            if pattern.match(col):
+                banned[col] = reason
+                break
+
+    kept = [c for c in columns_list if c not in banned]
+    return LeakCheckResult(
+        policy_version=policy.version,
+        banned=banned,
+        kept=kept,
+        dropped=[],
+        allowlist_kept=[],
+    )
+
+
+def enforce_leak_guard(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    allow_prefixes: Sequence[str] | str | None = None,
+    allow_exact: Sequence[str] | str | None = None,
+    drop_banned: bool = True,
+    drop_non_allowlisted: bool = False,
+    raise_on_banned: bool = True,
+) -> tuple[pl.DataFrame | "pd.DataFrame", LeakCheckResult]:
+    """Apply leak guardrails to a feature frame.
+
+    Parameters
+    ----------
+    df : DataFrame
+        Polars or pandas DataFrame.
+    policy : LeakPolicy
+        Leak policy to apply.
+    allow_prefixes : Sequence[str] | str | None
+        Optional prefixes that define the allowed feature surface for a problem.
+    allow_exact : Sequence[str] | str | None
+        Explicitly allowed columns (e.g., identifiers).
+    drop_banned : bool
+        If True, drop any banned columns automatically.
+    drop_non_allowlisted : bool
+        If True, drop columns that are not covered by allow_prefixes/allow_exact/identifiers/targets.
+    raise_on_banned : bool
+        If True, raise when banned columns are detected (after optional drop).
+    """
+
+    result = evaluate_leak_prone_columns(df.columns, policy=policy)
+    dropped: list[str] = []
+
+    allow_prefixes = _ensure_sequence(allow_prefixes)
+    allow_exact = set(_ensure_sequence(allow_exact))
+    allow_exact.update({col for col in IDENTIFIER_COLUMNS if col in df.columns})
+    allow_exact.update({col for col in NFL_TARGET_COLUMNS if col in df.columns})
+
+    # Permit allowlisted columns even if they match a banned rule (e.g., labels)
+    banned = {col: reason for col, reason in result.banned.items() if col not in allow_exact}
+
+    if banned and drop_banned:
+        df = df.drop(list(banned.keys()))
+        dropped.extend(banned.keys())
+
+    if banned and raise_on_banned:
+        raise ValueError(f"Leak-prone columns detected: {sorted(banned.items())}")
+
+    allowlist_cols: set[str] = set()
+    if allow_prefixes:
+        allowlist_cols.update({c for c in df.columns if c.startswith(allow_prefixes)})
+    allowlist_cols.update({c for c in allow_exact if c in df.columns})
+
+    if drop_non_allowlisted and allowlist_cols:
+        drop_candidates = [c for c in df.columns if c not in allowlist_cols]
+        if drop_candidates:
+            df = df.drop(drop_candidates)
+            dropped.extend(drop_candidates)
+
+    if drop_non_allowlisted and not allowlist_cols:
+        raise ValueError("No allowlisted columns remain after applying leak guard allowlist.")
+
+    # Store adjusted banned info on the result
+    result.banned = banned
+    result.dropped = dropped
+    result.kept = [c for c in df.columns]
+    result.allowlist_kept = sorted(list(allowlist_cols)) if allowlist_cols else []
+    return df, result
+
+
+def build_schema_snapshot(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    metadata: Mapping[str, object] | None = None,
+    banned: Mapping[str, str] | None = None,
+) -> dict:
+    """Render a schema snapshot describing each column and whether it was flagged."""
+
+    banned = banned or {}
+    meta = {
+        "generated_at_utc": datetime.utcnow().isoformat(),
+        "policy_version": policy.version,
+    }
+    meta.update(metadata or {})
+
+    # Extract columns / dtypes
+    if isinstance(df, pl.DataFrame):
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+    else:  # pandas or pandas-like
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+
+    schema = {
+        "metadata": meta,
+        "columns": [],
+    }
+
+    for col, dtype in cols_and_dtypes:
+        tags: list[str] = []
+        if col in IDENTIFIER_COLUMNS:
+            tags.append("id")
+        if col in NFL_TARGET_COLUMNS:
+            tags.append("label")
+        if col.startswith("market_"):
+            tags.append("odds")
+        if col.startswith("injury_") or col.startswith("practice_"):
+            tags.append("injury")
+        if col.startswith("weather_"):
+            tags.append("weather")
+        if col.startswith("ps_"):
+            tags.append("pre_snap")
+        schema["columns"].append(
+            {
+                "name": col,
+                "dtype": dtype,
+                "banned": col in banned,
+                "tags": tags,
+            }
+        )
+    return schema
+
+
+def write_schema_snapshot(path, schema: Mapping[str, object]) -> None:
+    path.parent.mkdir(parents=True, exist_ok=True)
+    with open(path, "w") as fp:
+        json.dump(schema, fp, indent=2, sort_keys=True)
+
+
+__all__ = [
+    "DEFAULT_LEAK_POLICY",
+    "LeakPolicy",
+    "LeakCheckResult",
+    "evaluate_leak_prone_columns",
+    "enforce_leak_guard",
+    "build_schema_snapshot",
+    "write_schema_snapshot",
+]
diff --git a/utils/general/constants.py b/utils/general/constants.py
index d94b4260ad877484da843fa99ae2caf37e8493f4..dea87caa354d94e4a08b1762d2bd8dcd4c8caa3a
--- a/utils/general/constants.py
+++ b/utils/general/constants.py
@@ -211,7 +211,17 @@
 
 NFL_TARGET_COLUMNS: Tuple[str, ...] = (
     'anytime_td',
+    'anytime_td_offense',
+    'anytime_td_all',
+    'anytime_td_rush',
+    'anytime_td_rec',
+    'anytime_td_pass_thrown',
     'td_count',
+    'td_count_offense',
+    'td_count_all',
+    'passing_td',
+    'rushing_td_count',
+    'receiving_td_count',
     'receiving_yards',
     'rushing_yards',
     'passing_yards',


thinking
**Trying pytest with python3**
exec
/bin/zsh -lc 'cd /Users/jameswest/Desktop/nfl_predict && python3 -m pytest tests/test_data_leak_guard.py tests/test_odds_horizon_filter.py -q' in /Users/jameswest/Desktop/nfl_predict exited 1 in 722ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
/opt/homebrew/opt/python@3.13/bin/python3.13: No module named pytest
file update:
diff --git a/config/training.yaml b/config/training.yaml
index 3953818d861d0410246bff132110722a3ce44007..c2b6053b488caa71f9078ff100d049f723ae1548
--- a/config/training.yaml
+++ b/config/training.yaml
@@ -476,6 +476,7 @@
   - name: 'anytime_td'
     target_col: 'anytime_td'
     label_version: 'v1_any_offense'
+    odds_horizon: 'cutoff'  # Restrict odds features to the decision-time snapshot
     task_type: 'classification'
     input_predictions:
       - 'availability_active'
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 5ba68e8bf1acd3a789a76a8857674e6f6433017b..0210d5b7e7ed60a8de7a126d64f5ed76326474c8
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -14,7 +14,7 @@
 
 import logging
 import os
-from datetime import date, timedelta
+from datetime import date, datetime, timedelta
 from typing import Sequence
 
 import polars as pl
@@ -37,6 +37,12 @@
     add_offense_context_features_training,
     _append_offense_context_columns,
 )
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    build_schema_snapshot,
+    enforce_leak_guard,
+    write_schema_snapshot,
+)
 from utils.feature.weather_features import (
     add_weather_forecast_features_training,
     append_weather_context_flags,
@@ -931,6 +937,32 @@
     if market_exprs:
         df_player_game_all = df_player_game_all.with_columns(market_exprs)
     
+    # Leak guard + schema snapshot before persisting
+    spec = get_label_spec(label_version)
+    allow_exact = {spec.primary, *spec.labels.keys(), *spec.aliases.keys()}
+    df_player_game_all, leak_result = enforce_leak_guard(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_exact=allow_exact,
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=True,
+    )
+
+    schema = build_schema_snapshot(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        metadata={
+            "cutoff_label": cutoff_label,
+            "label_version": spec.name,
+        },
+        banned=leak_result.banned,
+    )
+    schema_dir = FEATURE_AUDIT_DIR / "schema" / "anytime_td"
+    schema_path = schema_dir / f"{cutoff_label}_{datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')}.json"
+    write_schema_snapshot(schema_path, schema)
+    logging.info("    Schema snapshot written → %s", schema_path)
+
     # Write final feature matrix
     df_player_game_all = df_player_game_all.with_columns(
         pl.lit(current_cutoff_hours).cast(pl.Float32).alias("decision_horizon_hours")
@@ -951,7 +983,6 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    spec = get_label_spec(label_version)
     label_candidates = {spec.primary, "anytime_td"}
     for label_col in label_candidates:
         if label_col in df_player_game_all.columns:
diff --git a/pipeline/train.py b/pipeline/train.py
index fe70207dcdf25d209ee3ad55080b7ce826347c44..7c220514d006a3d4815d65a8af9ec7551ccf587e
--- a/pipeline/train.py
+++ b/pipeline/train.py
@@ -4,6 +4,7 @@
 import sys
 import logging
 import math
+import re
 
 
 # Move logging to top and remove global thread pinning
@@ -98,6 +99,7 @@
     fit_team_conformal_sums,
     composite_sum_interval,
 )
+from utils.feature.leak_guard import DEFAULT_LEAK_POLICY, enforce_leak_guard
 from utils.feature.targets import require_target_column
 
 # Ignore specific, noisy warnings from dependencies
@@ -793,6 +795,57 @@
             )
         return df
 
+    @staticmethod
+    def _filter_odds_snapshot_columns(df: pd.DataFrame, horizon_key: str | None) -> pd.DataFrame:
+        """Keep a single odds snapshot horizon (drop other suffixes)."""
+        if df is None or df.empty or not horizon_key:
+            return df
+
+        normalized = str(horizon_key).strip().lower()
+        horizon_map = {
+            "cutoff": "",
+            "default": "",
+            "": "",
+            "2h": "_2h",
+            "h120m": "_2h",
+            "6h": "_6h",
+            "h360m": "_6h",
+            "24h": "_24h",
+            "h1440m": "_24h",
+            "open": "_open",
+        }
+        allowed_suffix = horizon_map.get(normalized, normalized)
+        if allowed_suffix and not allowed_suffix.startswith("_"):
+            allowed_suffix = f"_{allowed_suffix.lstrip('_')}"
+
+        horizon_re = re.compile(r"^(?P<base>.+)(?P<suffix>_2h|_6h|_24h|_open)$")
+        suffixes_seen: dict[str, set[str]] = {}
+        for col in df.columns:
+            match = horizon_re.match(col)
+            if match:
+                suffixes_seen.setdefault(match.group("base"), set()).add(match.group("suffix"))
+
+        drop_cols: list[str] = []
+        for col in df.columns:
+            match = horizon_re.match(col)
+            if match:
+                suffix = match.group("suffix")
+                if suffix != allowed_suffix:
+                    drop_cols.append(col)
+            else:
+                base = col
+                if base in suffixes_seen and allowed_suffix:
+                    drop_cols.append(col)
+
+        if drop_cols:
+            df = df.drop(columns=drop_cols, errors="ignore")
+            logger.info(
+                "Removed %d odds snapshot columns outside horizon '%s'.",
+                len(drop_cols),
+                horizon_key,
+            )
+        return df
+
     def _ensure_player_game_actuals(self) -> pd.DataFrame:
         if self._player_game_actuals is not None:
             return self._player_game_actuals
@@ -2315,7 +2368,34 @@
                             df_problem[col] = df_problem[col].fillna(df_problem[col].mean())
 
                 df_problem = self._inject_composed_features(df_problem)
-            
+
+            odds_horizon = problem_copy.get("odds_horizon")
+            if odds_horizon:
+                df_problem = self._filter_odds_snapshot_columns(df_problem, odds_horizon)
+
+            # Leak guard on the problem-scoped frame
+            allow_prefixes = tuple(problem_copy.get('feature_prefixes_to_include') or [])
+            allow_exact = set(problem_copy.get('other_features_to_include') or [])
+            allow_exact.update(input_preds or [])
+            if self.target_col:
+                allow_exact.add(self.target_col)
+            df_problem, leak_info = enforce_leak_guard(
+                df_problem,
+                policy=DEFAULT_LEAK_POLICY,
+                allow_prefixes=allow_prefixes,
+                allow_exact=allow_exact,
+                drop_banned=True,
+                drop_non_allowlisted=False,
+                raise_on_banned=True,
+            )
+            if leak_info.dropped:
+                logger.info(
+                    "Dropped %d leak-prone columns for %s: %s",
+                    len(leak_info.dropped),
+                    problem_name,
+                    sorted(leak_info.dropped),
+                )
+
             self._normalize_datetime_like_columns(df_problem, problem_name)
             df_problem[self.time_col] = pd.to_datetime(df_problem[self.time_col])
             sort_cols = [self.time_col]
diff --git a/tests/test_data_leak_guard.py b/tests/test_data_leak_guard.py
index 8061f2760c0898aaeda29026859e1b9ff5644ba4..3e56665921db89ea523bbdb205d1bb90c21893df
--- a/tests/test_data_leak_guard.py
+++ b/tests/test_data_leak_guard.py
@@ -3,6 +3,14 @@
 import yaml
 from pathlib import Path
 
+import polars as pl
+
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    enforce_leak_guard,
+    evaluate_leak_prone_columns,
+)
+
 
 PROJECT_ROOT = Path(__file__).resolve().parents[1]
 TRAINING_CONFIG = PROJECT_ROOT / "config" / "training.yaml"
@@ -48,3 +56,41 @@
     )
 
 
+def test_leak_guard_flags_pattern_columns():
+    cols = [
+        "market_anytime_td_prob",
+        "final_score",
+        "postgame_anytime_td",
+        "actual_td_count",
+        "safe_feature",
+    ]
+    result = evaluate_leak_prone_columns(cols, policy=DEFAULT_LEAK_POLICY)
+    assert set(result.banned.keys()) == {"final_score", "postgame_anytime_td", "actual_td_count"}
+    assert "safe_feature" in result.kept
+    assert "market_anytime_td_prob" in result.kept
+
+
+def test_enforce_leak_guard_drops_banned_and_keeps_allowlisted():
+    df = pl.DataFrame(
+        {
+            "game_id": ["g1", "g2"],
+            "safe_feature": [1.0, 2.0],
+            "postgame_anytime_td": [1, 0],
+            "final_score": [30, 24],
+        }
+    )
+    cleaned, info = enforce_leak_guard(
+        df,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_prefixes=("safe_",),
+        allow_exact=("game_id",),
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=False,
+    )
+    assert "postgame_anytime_td" not in cleaned.columns
+    assert "final_score" not in cleaned.columns
+    assert "safe_feature" in cleaned.columns
+    assert "game_id" in cleaned.columns
+    assert set(info.dropped) == {"postgame_anytime_td", "final_score"}
+
diff --git a/tests/test_odds_horizon_filter.py b/tests/test_odds_horizon_filter.py
new file mode 100644
index 0000000000000000000000000000000000000000..70e9c681f63972bbb6e70008e286cf13f6881853
--- /dev/null
+++ b/tests/test_odds_horizon_filter.py
@@ -0,0 +1,35 @@
+from __future__ import annotations
+
+import pandas as pd
+import pytest
+
+train_module = pytest.importorskip("pipeline.train")
+ModelTrainer = train_module.ModelTrainer
+
+
+def test_filter_odds_snapshot_columns_cutoff_keeps_base_only():
+    df = pd.DataFrame(
+        {
+            "market_anytime_td_prob": [0.1, 0.2],
+            "market_anytime_td_prob_2h": [0.15, 0.25],
+            "market_anytime_td_prob_6h": [0.2, 0.3],
+            "other_feature": [1, 2],
+        }
+    )
+    filtered = ModelTrainer._filter_odds_snapshot_columns(df.copy(), "cutoff")
+    assert "market_anytime_td_prob" in filtered.columns
+    assert "market_anytime_td_prob_2h" not in filtered.columns
+    assert "market_anytime_td_prob_6h" not in filtered.columns
+    assert "other_feature" in filtered.columns
+
+
+def test_filter_odds_snapshot_columns_specific_suffix():
+    df = pd.DataFrame(
+        {
+            "market_anytime_td_prob": [0.1, 0.2],
+            "market_anytime_td_prob_2h": [0.15, 0.25],
+            "market_anytime_td_prob_6h": [0.2, 0.3],
+        }
+    )
+    filtered = ModelTrainer._filter_odds_snapshot_columns(df.copy(), "6h")
+    assert list(filtered.columns) == ["market_anytime_td_prob_6h"]
diff --git a/utils/feature/leak_guard.py b/utils/feature/leak_guard.py
new file mode 100644
index 0000000000000000000000000000000000000000..9faf8cfffc436e0934b2f410aaf252e52f4f95df
--- /dev/null
+++ b/utils/feature/leak_guard.py
@@ -0,0 +1,273 @@
+"""Leak guardrails for feature matrices.
+
+This module centralizes pattern-based leak detection so both feature assembly
+and training can fail fast when post-outcome columns sneak into the data.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+from datetime import datetime
+import json
+import re
+from typing import Iterable, Mapping, Sequence
+
+import polars as pl
+
+from utils.general.constants import IDENTIFIER_COLUMNS, LEAK_PRONE_COLUMNS, NFL_TARGET_COLUMNS
+
+try:  # Optional dependency when imported from training (pandas path)
+    import pandas as pd  # type: ignore
+except Exception:  # pragma: no cover - optional dependency
+    pd = None
+
+
+@dataclass(frozen=True)
+class LeakPolicy:
+    version: str
+    banned_exact: set[str]
+    banned_prefixes: tuple[str, ...]
+    banned_suffixes: tuple[str, ...]
+    banned_regex: tuple[tuple[re.Pattern[str], str], ...]
+    description: str = ""
+
+
+@dataclass
+class LeakCheckResult:
+    policy_version: str
+    banned: dict[str, str]
+    kept: list[str]
+    dropped: list[str]
+    allowlist_kept: list[str]
+
+
+# Core policy tuned for anytime-TD style problems (can be extended per-problem).
+_BASE_BANNED_EXACT = set(LEAK_PRONE_COLUMNS) | {
+    "final_score",
+    "final_total",
+    "points_scored",
+    "actual_td_count",
+    "actual_anytime_td",
+    "postgame_anytime_td",
+    "postgame_td_count",
+}
+_BASE_BANNED_PREFIXES = (
+    "postgame_",
+    "post_game_",
+    "post_",
+    "live_",
+    "actual_",
+    "realized_",
+    "final_",
+    "postmatch_",
+)
+_BASE_BANNED_SUFFIXES = (
+    "_post",
+    "_postgame",
+    "_final",
+    "_fullgame",
+    "_actual",
+)
+_BASE_BANNED_REGEX: tuple[tuple[re.Pattern[str], str], ...] = (
+    (re.compile(r".*post.?game.*", flags=re.IGNORECASE), "postgame marker"),
+    (re.compile(r".*final_score.*", flags=re.IGNORECASE), "final score"),
+    (re.compile(r".*actual.*td.*", flags=re.IGNORECASE), "actual TD total"),
+    (re.compile(r".*anytime_td.*(post|final|actual).*", flags=re.IGNORECASE), "post-decision anytime TD"),
+    (re.compile(r".*fullgame.*", flags=re.IGNORECASE), "full game cumulative value"),
+)
+
+DEFAULT_LEAK_POLICY = LeakPolicy(
+    version="v1",
+    description="Core post-outcome leak guard for NFL anytime TD features.",
+    banned_exact=_BASE_BANNED_EXACT,
+    banned_prefixes=_BASE_BANNED_PREFIXES,
+    banned_suffixes=_BASE_BANNED_SUFFIXES,
+    banned_regex=_BASE_BANNED_REGEX,
+)
+
+
+def _ensure_sequence(value: Sequence[str] | str | None) -> tuple[str, ...]:
+    if value is None:
+        return ()
+    if isinstance(value, str):
+        return (value,)
+    return tuple(value)
+
+
+def evaluate_leak_prone_columns(
+    columns: Iterable[str],
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+) -> LeakCheckResult:
+    """Identify leak-prone columns using the configured policy."""
+
+    banned: dict[str, str] = {}
+    columns_list = list(columns)
+    for col in columns_list:
+        if col in policy.banned_exact:
+            banned[col] = "exact"
+            continue
+        for prefix in policy.banned_prefixes:
+            if col.startswith(prefix):
+                banned[col] = f"prefix:{prefix}"
+                break
+        if col in banned:
+            continue
+        for suffix in policy.banned_suffixes:
+            if col.endswith(suffix):
+                banned[col] = f"suffix:{suffix}"
+                break
+        if col in banned:
+            continue
+        for pattern, reason in policy.banned_regex:
+            if pattern.match(col):
+                banned[col] = reason
+                break
+
+    kept = [c for c in columns_list if c not in banned]
+    return LeakCheckResult(
+        policy_version=policy.version,
+        banned=banned,
+        kept=kept,
+        dropped=[],
+        allowlist_kept=[],
+    )
+
+
+def enforce_leak_guard(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    allow_prefixes: Sequence[str] | str | None = None,
+    allow_exact: Sequence[str] | str | None = None,
+    drop_banned: bool = True,
+    drop_non_allowlisted: bool = False,
+    raise_on_banned: bool = True,
+) -> tuple[pl.DataFrame | "pd.DataFrame", LeakCheckResult]:
+    """Apply leak guardrails to a feature frame.
+
+    Parameters
+    ----------
+    df : DataFrame
+        Polars or pandas DataFrame.
+    policy : LeakPolicy
+        Leak policy to apply.
+    allow_prefixes : Sequence[str] | str | None
+        Optional prefixes that define the allowed feature surface for a problem.
+    allow_exact : Sequence[str] | str | None
+        Explicitly allowed columns (e.g., identifiers).
+    drop_banned : bool
+        If True, drop any banned columns automatically.
+    drop_non_allowlisted : bool
+        If True, drop columns that are not covered by allow_prefixes/allow_exact/identifiers/targets.
+    raise_on_banned : bool
+        If True, raise when banned columns are detected (after optional drop).
+    """
+
+    result = evaluate_leak_prone_columns(df.columns, policy=policy)
+    dropped: list[str] = []
+
+    allow_prefixes = _ensure_sequence(allow_prefixes)
+    allow_exact = set(_ensure_sequence(allow_exact))
+    allow_exact.update({col for col in IDENTIFIER_COLUMNS if col in df.columns})
+    allow_exact.update({col for col in NFL_TARGET_COLUMNS if col in df.columns})
+
+    # Permit allowlisted columns even if they match a banned rule (e.g., labels)
+    banned = {col: reason for col, reason in result.banned.items() if col not in allow_exact}
+
+    if banned and drop_banned:
+        df = df.drop(list(banned.keys()))
+        dropped.extend(banned.keys())
+
+    if banned and raise_on_banned:
+        raise ValueError(f"Leak-prone columns detected: {sorted(banned.items())}")
+
+    allowlist_cols: set[str] = set()
+    if allow_prefixes:
+        allowlist_cols.update({c for c in df.columns if c.startswith(allow_prefixes)})
+    allowlist_cols.update({c for c in allow_exact if c in df.columns})
+
+    if drop_non_allowlisted and allowlist_cols:
+        drop_candidates = [c for c in df.columns if c not in allowlist_cols]
+        if drop_candidates:
+            df = df.drop(drop_candidates)
+            dropped.extend(drop_candidates)
+
+    if drop_non_allowlisted and not allowlist_cols:
+        raise ValueError("No allowlisted columns remain after applying leak guard allowlist.")
+
+    # Store adjusted banned info on the result
+    result.banned = banned
+    result.dropped = dropped
+    result.kept = [c for c in df.columns]
+    result.allowlist_kept = sorted(list(allowlist_cols)) if allowlist_cols else []
+    return df, result
+
+
+def build_schema_snapshot(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    metadata: Mapping[str, object] | None = None,
+    banned: Mapping[str, str] | None = None,
+) -> dict:
+    """Render a schema snapshot describing each column and whether it was flagged."""
+
+    banned = banned or {}
+    meta = {
+        "generated_at_utc": datetime.utcnow().isoformat(),
+        "policy_version": policy.version,
+    }
+    meta.update(metadata or {})
+
+    # Extract columns / dtypes
+    if isinstance(df, pl.DataFrame):
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+    else:  # pandas or pandas-like
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+
+    schema = {
+        "metadata": meta,
+        "columns": [],
+    }
+
+    for col, dtype in cols_and_dtypes:
+        tags: list[str] = []
+        if col in IDENTIFIER_COLUMNS:
+            tags.append("id")
+        if col in NFL_TARGET_COLUMNS:
+            tags.append("label")
+        if col.startswith("market_"):
+            tags.append("odds")
+        if col.startswith("injury_") or col.startswith("practice_"):
+            tags.append("injury")
+        if col.startswith("weather_"):
+            tags.append("weather")
+        if col.startswith("ps_"):
+            tags.append("pre_snap")
+        schema["columns"].append(
+            {
+                "name": col,
+                "dtype": dtype,
+                "banned": col in banned,
+                "tags": tags,
+            }
+        )
+    return schema
+
+
+def write_schema_snapshot(path, schema: Mapping[str, object]) -> None:
+    path.parent.mkdir(parents=True, exist_ok=True)
+    with open(path, "w") as fp:
+        json.dump(schema, fp, indent=2, sort_keys=True)
+
+
+__all__ = [
+    "DEFAULT_LEAK_POLICY",
+    "LeakPolicy",
+    "LeakCheckResult",
+    "evaluate_leak_prone_columns",
+    "enforce_leak_guard",
+    "build_schema_snapshot",
+    "write_schema_snapshot",
+]
diff --git a/utils/general/constants.py b/utils/general/constants.py
index d94b4260ad877484da843fa99ae2caf37e8493f4..dea87caa354d94e4a08b1762d2bd8dcd4c8caa3a
--- a/utils/general/constants.py
+++ b/utils/general/constants.py
@@ -211,7 +211,17 @@
 
 NFL_TARGET_COLUMNS: Tuple[str, ...] = (
     'anytime_td',
+    'anytime_td_offense',
+    'anytime_td_all',
+    'anytime_td_rush',
+    'anytime_td_rec',
+    'anytime_td_pass_thrown',
     'td_count',
+    'td_count_offense',
+    'td_count_all',
+    'passing_td',
+    'rushing_td_count',
+    'receiving_td_count',
     'receiving_yards',
     'rushing_yards',
     'passing_yards',


thinking
**Handling missing pytest and updating plan**
Plan update
  ✓ Add structured leak-guard policy helper and integrate into feature/train pipelines with schema snapshots.
  → Align odds features to decision-time horizons from config and add assertions/logging.
  • Expand tests for leak patterns and odds snapshot selection; document new config knobs briefly.
file update:
diff --git a/config/training.yaml b/config/training.yaml
index 3953818d861d0410246bff132110722a3ce44007..c2b6053b488caa71f9078ff100d049f723ae1548
--- a/config/training.yaml
+++ b/config/training.yaml
@@ -476,6 +476,7 @@
   - name: 'anytime_td'
     target_col: 'anytime_td'
     label_version: 'v1_any_offense'
+    odds_horizon: 'cutoff'  # Restrict odds features to the decision-time snapshot
     task_type: 'classification'
     input_predictions:
       - 'availability_active'
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 5ba68e8bf1acd3a789a76a8857674e6f6433017b..0210d5b7e7ed60a8de7a126d64f5ed76326474c8
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -14,7 +14,7 @@
 
 import logging
 import os
-from datetime import date, timedelta
+from datetime import date, datetime, timedelta
 from typing import Sequence
 
 import polars as pl
@@ -37,6 +37,12 @@
     add_offense_context_features_training,
     _append_offense_context_columns,
 )
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    build_schema_snapshot,
+    enforce_leak_guard,
+    write_schema_snapshot,
+)
 from utils.feature.weather_features import (
     add_weather_forecast_features_training,
     append_weather_context_flags,
@@ -931,6 +937,32 @@
     if market_exprs:
         df_player_game_all = df_player_game_all.with_columns(market_exprs)
     
+    # Leak guard + schema snapshot before persisting
+    spec = get_label_spec(label_version)
+    allow_exact = {spec.primary, *spec.labels.keys(), *spec.aliases.keys()}
+    df_player_game_all, leak_result = enforce_leak_guard(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_exact=allow_exact,
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=True,
+    )
+
+    schema = build_schema_snapshot(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        metadata={
+            "cutoff_label": cutoff_label,
+            "label_version": spec.name,
+        },
+        banned=leak_result.banned,
+    )
+    schema_dir = FEATURE_AUDIT_DIR / "schema" / "anytime_td"
+    schema_path = schema_dir / f"{cutoff_label}_{datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')}.json"
+    write_schema_snapshot(schema_path, schema)
+    logging.info("    Schema snapshot written → %s", schema_path)
+
     # Write final feature matrix
     df_player_game_all = df_player_game_all.with_columns(
         pl.lit(current_cutoff_hours).cast(pl.Float32).alias("decision_horizon_hours")
@@ -951,7 +983,6 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    spec = get_label_spec(label_version)
     label_candidates = {spec.primary, "anytime_td"}
     for label_col in label_candidates:
         if label_col in df_player_game_all.columns:
diff --git a/pipeline/train.py b/pipeline/train.py
index fe70207dcdf25d209ee3ad55080b7ce826347c44..7c220514d006a3d4815d65a8af9ec7551ccf587e
--- a/pipeline/train.py
+++ b/pipeline/train.py
@@ -4,6 +4,7 @@
 import sys
 import logging
 import math
+import re
 
 
 # Move logging to top and remove global thread pinning
@@ -98,6 +99,7 @@
     fit_team_conformal_sums,
     composite_sum_interval,
 )
+from utils.feature.leak_guard import DEFAULT_LEAK_POLICY, enforce_leak_guard
 from utils.feature.targets import require_target_column
 
 # Ignore specific, noisy warnings from dependencies
@@ -793,6 +795,57 @@
             )
         return df
 
+    @staticmethod
+    def _filter_odds_snapshot_columns(df: pd.DataFrame, horizon_key: str | None) -> pd.DataFrame:
+        """Keep a single odds snapshot horizon (drop other suffixes)."""
+        if df is None or df.empty or not horizon_key:
+            return df
+
+        normalized = str(horizon_key).strip().lower()
+        horizon_map = {
+            "cutoff": "",
+            "default": "",
+            "": "",
+            "2h": "_2h",
+            "h120m": "_2h",
+            "6h": "_6h",
+            "h360m": "_6h",
+            "24h": "_24h",
+            "h1440m": "_24h",
+            "open": "_open",
+        }
+        allowed_suffix = horizon_map.get(normalized, normalized)
+        if allowed_suffix and not allowed_suffix.startswith("_"):
+            allowed_suffix = f"_{allowed_suffix.lstrip('_')}"
+
+        horizon_re = re.compile(r"^(?P<base>.+)(?P<suffix>_2h|_6h|_24h|_open)$")
+        suffixes_seen: dict[str, set[str]] = {}
+        for col in df.columns:
+            match = horizon_re.match(col)
+            if match:
+                suffixes_seen.setdefault(match.group("base"), set()).add(match.group("suffix"))
+
+        drop_cols: list[str] = []
+        for col in df.columns:
+            match = horizon_re.match(col)
+            if match:
+                suffix = match.group("suffix")
+                if suffix != allowed_suffix:
+                    drop_cols.append(col)
+            else:
+                base = col
+                if base in suffixes_seen and allowed_suffix:
+                    drop_cols.append(col)
+
+        if drop_cols:
+            df = df.drop(columns=drop_cols, errors="ignore")
+            logger.info(
+                "Removed %d odds snapshot columns outside horizon '%s'.",
+                len(drop_cols),
+                horizon_key,
+            )
+        return df
+
     def _ensure_player_game_actuals(self) -> pd.DataFrame:
         if self._player_game_actuals is not None:
             return self._player_game_actuals
@@ -2315,7 +2368,34 @@
                             df_problem[col] = df_problem[col].fillna(df_problem[col].mean())
 
                 df_problem = self._inject_composed_features(df_problem)
-            
+
+            odds_horizon = problem_copy.get("odds_horizon")
+            if odds_horizon:
+                df_problem = self._filter_odds_snapshot_columns(df_problem, odds_horizon)
+
+            # Leak guard on the problem-scoped frame
+            allow_prefixes = tuple(problem_copy.get('feature_prefixes_to_include') or [])
+            allow_exact = set(problem_copy.get('other_features_to_include') or [])
+            allow_exact.update(input_preds or [])
+            if self.target_col:
+                allow_exact.add(self.target_col)
+            df_problem, leak_info = enforce_leak_guard(
+                df_problem,
+                policy=DEFAULT_LEAK_POLICY,
+                allow_prefixes=allow_prefixes,
+                allow_exact=allow_exact,
+                drop_banned=True,
+                drop_non_allowlisted=False,
+                raise_on_banned=True,
+            )
+            if leak_info.dropped:
+                logger.info(
+                    "Dropped %d leak-prone columns for %s: %s",
+                    len(leak_info.dropped),
+                    problem_name,
+                    sorted(leak_info.dropped),
+                )
+
             self._normalize_datetime_like_columns(df_problem, problem_name)
             df_problem[self.time_col] = pd.to_datetime(df_problem[self.time_col])
             sort_cols = [self.time_col]
diff --git a/tests/test_data_leak_guard.py b/tests/test_data_leak_guard.py
index 8061f2760c0898aaeda29026859e1b9ff5644ba4..3e56665921db89ea523bbdb205d1bb90c21893df
--- a/tests/test_data_leak_guard.py
+++ b/tests/test_data_leak_guard.py
@@ -3,6 +3,14 @@
 import yaml
 from pathlib import Path
 
+import polars as pl
+
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    enforce_leak_guard,
+    evaluate_leak_prone_columns,
+)
+
 
 PROJECT_ROOT = Path(__file__).resolve().parents[1]
 TRAINING_CONFIG = PROJECT_ROOT / "config" / "training.yaml"
@@ -48,3 +56,41 @@
     )
 
 
+def test_leak_guard_flags_pattern_columns():
+    cols = [
+        "market_anytime_td_prob",
+        "final_score",
+        "postgame_anytime_td",
+        "actual_td_count",
+        "safe_feature",
+    ]
+    result = evaluate_leak_prone_columns(cols, policy=DEFAULT_LEAK_POLICY)
+    assert set(result.banned.keys()) == {"final_score", "postgame_anytime_td", "actual_td_count"}
+    assert "safe_feature" in result.kept
+    assert "market_anytime_td_prob" in result.kept
+
+
+def test_enforce_leak_guard_drops_banned_and_keeps_allowlisted():
+    df = pl.DataFrame(
+        {
+            "game_id": ["g1", "g2"],
+            "safe_feature": [1.0, 2.0],
+            "postgame_anytime_td": [1, 0],
+            "final_score": [30, 24],
+        }
+    )
+    cleaned, info = enforce_leak_guard(
+        df,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_prefixes=("safe_",),
+        allow_exact=("game_id",),
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=False,
+    )
+    assert "postgame_anytime_td" not in cleaned.columns
+    assert "final_score" not in cleaned.columns
+    assert "safe_feature" in cleaned.columns
+    assert "game_id" in cleaned.columns
+    assert set(info.dropped) == {"postgame_anytime_td", "final_score"}
+
diff --git a/tests/test_odds_horizon_filter.py b/tests/test_odds_horizon_filter.py
new file mode 100644
index 0000000000000000000000000000000000000000..70e9c681f63972bbb6e70008e286cf13f6881853
--- /dev/null
+++ b/tests/test_odds_horizon_filter.py
@@ -0,0 +1,35 @@
+from __future__ import annotations
+
+import pandas as pd
+import pytest
+
+train_module = pytest.importorskip("pipeline.train")
+ModelTrainer = train_module.ModelTrainer
+
+
+def test_filter_odds_snapshot_columns_cutoff_keeps_base_only():
+    df = pd.DataFrame(
+        {
+            "market_anytime_td_prob": [0.1, 0.2],
+            "market_anytime_td_prob_2h": [0.15, 0.25],
+            "market_anytime_td_prob_6h": [0.2, 0.3],
+            "other_feature": [1, 2],
+        }
+    )
+    filtered = ModelTrainer._filter_odds_snapshot_columns(df.copy(), "cutoff")
+    assert "market_anytime_td_prob" in filtered.columns
+    assert "market_anytime_td_prob_2h" not in filtered.columns
+    assert "market_anytime_td_prob_6h" not in filtered.columns
+    assert "other_feature" in filtered.columns
+
+
+def test_filter_odds_snapshot_columns_specific_suffix():
+    df = pd.DataFrame(
+        {
+            "market_anytime_td_prob": [0.1, 0.2],
+            "market_anytime_td_prob_2h": [0.15, 0.25],
+            "market_anytime_td_prob_6h": [0.2, 0.3],
+        }
+    )
+    filtered = ModelTrainer._filter_odds_snapshot_columns(df.copy(), "6h")
+    assert list(filtered.columns) == ["market_anytime_td_prob_6h"]
diff --git a/utils/feature/leak_guard.py b/utils/feature/leak_guard.py
new file mode 100644
index 0000000000000000000000000000000000000000..9faf8cfffc436e0934b2f410aaf252e52f4f95df
--- /dev/null
+++ b/utils/feature/leak_guard.py
@@ -0,0 +1,273 @@
+"""Leak guardrails for feature matrices.
+
+This module centralizes pattern-based leak detection so both feature assembly
+and training can fail fast when post-outcome columns sneak into the data.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+from datetime import datetime
+import json
+import re
+from typing import Iterable, Mapping, Sequence
+
+import polars as pl
+
+from utils.general.constants import IDENTIFIER_COLUMNS, LEAK_PRONE_COLUMNS, NFL_TARGET_COLUMNS
+
+try:  # Optional dependency when imported from training (pandas path)
+    import pandas as pd  # type: ignore
+except Exception:  # pragma: no cover - optional dependency
+    pd = None
+
+
+@dataclass(frozen=True)
+class LeakPolicy:
+    version: str
+    banned_exact: set[str]
+    banned_prefixes: tuple[str, ...]
+    banned_suffixes: tuple[str, ...]
+    banned_regex: tuple[tuple[re.Pattern[str], str], ...]
+    description: str = ""
+
+
+@dataclass
+class LeakCheckResult:
+    policy_version: str
+    banned: dict[str, str]
+    kept: list[str]
+    dropped: list[str]
+    allowlist_kept: list[str]
+
+
+# Core policy tuned for anytime-TD style problems (can be extended per-problem).
+_BASE_BANNED_EXACT = set(LEAK_PRONE_COLUMNS) | {
+    "final_score",
+    "final_total",
+    "points_scored",
+    "actual_td_count",
+    "actual_anytime_td",
+    "postgame_anytime_td",
+    "postgame_td_count",
+}
+_BASE_BANNED_PREFIXES = (
+    "postgame_",
+    "post_game_",
+    "post_",
+    "live_",
+    "actual_",
+    "realized_",
+    "final_",
+    "postmatch_",
+)
+_BASE_BANNED_SUFFIXES = (
+    "_post",
+    "_postgame",
+    "_final",
+    "_fullgame",
+    "_actual",
+)
+_BASE_BANNED_REGEX: tuple[tuple[re.Pattern[str], str], ...] = (
+    (re.compile(r".*post.?game.*", flags=re.IGNORECASE), "postgame marker"),
+    (re.compile(r".*final_score.*", flags=re.IGNORECASE), "final score"),
+    (re.compile(r".*actual.*td.*", flags=re.IGNORECASE), "actual TD total"),
+    (re.compile(r".*anytime_td.*(post|final|actual).*", flags=re.IGNORECASE), "post-decision anytime TD"),
+    (re.compile(r".*fullgame.*", flags=re.IGNORECASE), "full game cumulative value"),
+)
+
+DEFAULT_LEAK_POLICY = LeakPolicy(
+    version="v1",
+    description="Core post-outcome leak guard for NFL anytime TD features.",
+    banned_exact=_BASE_BANNED_EXACT,
+    banned_prefixes=_BASE_BANNED_PREFIXES,
+    banned_suffixes=_BASE_BANNED_SUFFIXES,
+    banned_regex=_BASE_BANNED_REGEX,
+)
+
+
+def _ensure_sequence(value: Sequence[str] | str | None) -> tuple[str, ...]:
+    if value is None:
+        return ()
+    if isinstance(value, str):
+        return (value,)
+    return tuple(value)
+
+
+def evaluate_leak_prone_columns(
+    columns: Iterable[str],
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+) -> LeakCheckResult:
+    """Identify leak-prone columns using the configured policy."""
+
+    banned: dict[str, str] = {}
+    columns_list = list(columns)
+    for col in columns_list:
+        if col in policy.banned_exact:
+            banned[col] = "exact"
+            continue
+        for prefix in policy.banned_prefixes:
+            if col.startswith(prefix):
+                banned[col] = f"prefix:{prefix}"
+                break
+        if col in banned:
+            continue
+        for suffix in policy.banned_suffixes:
+            if col.endswith(suffix):
+                banned[col] = f"suffix:{suffix}"
+                break
+        if col in banned:
+            continue
+        for pattern, reason in policy.banned_regex:
+            if pattern.match(col):
+                banned[col] = reason
+                break
+
+    kept = [c for c in columns_list if c not in banned]
+    return LeakCheckResult(
+        policy_version=policy.version,
+        banned=banned,
+        kept=kept,
+        dropped=[],
+        allowlist_kept=[],
+    )
+
+
+def enforce_leak_guard(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    allow_prefixes: Sequence[str] | str | None = None,
+    allow_exact: Sequence[str] | str | None = None,
+    drop_banned: bool = True,
+    drop_non_allowlisted: bool = False,
+    raise_on_banned: bool = True,
+) -> tuple[pl.DataFrame | "pd.DataFrame", LeakCheckResult]:
+    """Apply leak guardrails to a feature frame.
+
+    Parameters
+    ----------
+    df : DataFrame
+        Polars or pandas DataFrame.
+    policy : LeakPolicy
+        Leak policy to apply.
+    allow_prefixes : Sequence[str] | str | None
+        Optional prefixes that define the allowed feature surface for a problem.
+    allow_exact : Sequence[str] | str | None
+        Explicitly allowed columns (e.g., identifiers).
+    drop_banned : bool
+        If True, drop any banned columns automatically.
+    drop_non_allowlisted : bool
+        If True, drop columns that are not covered by allow_prefixes/allow_exact/identifiers/targets.
+    raise_on_banned : bool
+        If True, raise when banned columns are detected (after optional drop).
+    """
+
+    result = evaluate_leak_prone_columns(df.columns, policy=policy)
+    dropped: list[str] = []
+
+    allow_prefixes = _ensure_sequence(allow_prefixes)
+    allow_exact = set(_ensure_sequence(allow_exact))
+    allow_exact.update({col for col in IDENTIFIER_COLUMNS if col in df.columns})
+    allow_exact.update({col for col in NFL_TARGET_COLUMNS if col in df.columns})
+
+    # Permit allowlisted columns even if they match a banned rule (e.g., labels)
+    banned = {col: reason for col, reason in result.banned.items() if col not in allow_exact}
+
+    if banned and drop_banned:
+        df = df.drop(list(banned.keys()))
+        dropped.extend(banned.keys())
+
+    if banned and raise_on_banned:
+        raise ValueError(f"Leak-prone columns detected: {sorted(banned.items())}")
+
+    allowlist_cols: set[str] = set()
+    if allow_prefixes:
+        allowlist_cols.update({c for c in df.columns if c.startswith(allow_prefixes)})
+    allowlist_cols.update({c for c in allow_exact if c in df.columns})
+
+    if drop_non_allowlisted and allowlist_cols:
+        drop_candidates = [c for c in df.columns if c not in allowlist_cols]
+        if drop_candidates:
+            df = df.drop(drop_candidates)
+            dropped.extend(drop_candidates)
+
+    if drop_non_allowlisted and not allowlist_cols:
+        raise ValueError("No allowlisted columns remain after applying leak guard allowlist.")
+
+    # Store adjusted banned info on the result
+    result.banned = banned
+    result.dropped = dropped
+    result.kept = [c for c in df.columns]
+    result.allowlist_kept = sorted(list(allowlist_cols)) if allowlist_cols else []
+    return df, result
+
+
+def build_schema_snapshot(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    metadata: Mapping[str, object] | None = None,
+    banned: Mapping[str, str] | None = None,
+) -> dict:
+    """Render a schema snapshot describing each column and whether it was flagged."""
+
+    banned = banned or {}
+    meta = {
+        "generated_at_utc": datetime.utcnow().isoformat(),
+        "policy_version": policy.version,
+    }
+    meta.update(metadata or {})
+
+    # Extract columns / dtypes
+    if isinstance(df, pl.DataFrame):
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+    else:  # pandas or pandas-like
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+
+    schema = {
+        "metadata": meta,
+        "columns": [],
+    }
+
+    for col, dtype in cols_and_dtypes:
+        tags: list[str] = []
+        if col in IDENTIFIER_COLUMNS:
+            tags.append("id")
+        if col in NFL_TARGET_COLUMNS:
+            tags.append("label")
+        if col.startswith("market_"):
+            tags.append("odds")
+        if col.startswith("injury_") or col.startswith("practice_"):
+            tags.append("injury")
+        if col.startswith("weather_"):
+            tags.append("weather")
+        if col.startswith("ps_"):
+            tags.append("pre_snap")
+        schema["columns"].append(
+            {
+                "name": col,
+                "dtype": dtype,
+                "banned": col in banned,
+                "tags": tags,
+            }
+        )
+    return schema
+
+
+def write_schema_snapshot(path, schema: Mapping[str, object]) -> None:
+    path.parent.mkdir(parents=True, exist_ok=True)
+    with open(path, "w") as fp:
+        json.dump(schema, fp, indent=2, sort_keys=True)
+
+
+__all__ = [
+    "DEFAULT_LEAK_POLICY",
+    "LeakPolicy",
+    "LeakCheckResult",
+    "evaluate_leak_prone_columns",
+    "enforce_leak_guard",
+    "build_schema_snapshot",
+    "write_schema_snapshot",
+]
diff --git a/utils/general/constants.py b/utils/general/constants.py
index d94b4260ad877484da843fa99ae2caf37e8493f4..dea87caa354d94e4a08b1762d2bd8dcd4c8caa3a
--- a/utils/general/constants.py
+++ b/utils/general/constants.py
@@ -211,7 +211,17 @@
 
 NFL_TARGET_COLUMNS: Tuple[str, ...] = (
     'anytime_td',
+    'anytime_td_offense',
+    'anytime_td_all',
+    'anytime_td_rush',
+    'anytime_td_rec',
+    'anytime_td_pass_thrown',
     'td_count',
+    'td_count_offense',
+    'td_count_all',
+    'passing_td',
+    'rushing_td_count',
+    'receiving_td_count',
     'receiving_yards',
     'rushing_yards',
     'passing_yards',


thinking
**Evaluating test completion and doc updates**
exec
/bin/zsh -lc "cd /Users/jameswest/Desktop/nfl_predict && sed -n '1,200p' docs/pre_snap_semantics.md" in /Users/jameswest/Desktop/nfl_predict succeeded in 749ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
Pre-Snap Feature Semantics
==========================

Scope of the namespaces added in the Tier-2 pass to keep train vs. inference aligned:

- `ps_game_*`: realized same-game pre-snap stats (labels/diagnostics only).
- `ps_hist_*`: historical projections derived from rolling windows and shifted one game; these are the only pre-snap inputs consumed by models.
- `ps_tracking_*` (base columns) and `ps_hist_tracking_*` (shifted): coverage signals describing whether tracking data exists and whether a baseline was used.
- `ps_baseline_source`: string diagnostic used at inference (`actual`, `baseline`, `none`).

Coverage signals
----------------
- `ps_tracking_team_dropbacks`: copy of `ps_team_dropbacks` for coverage; not a feature input but rolled into `ps_hist_tracking_team_dropbacks_*`.
- `ps_tracking_has_game_data`: 1 if either dropbacks or touches were observed for the player; shifted into `ps_hist_tracking_has_game_data_*` for modeling.
- `ps_tracking_has_actual`: row-level flag derived during prediction to indicate that true tracking features were present.
- `ps_tracking_used_baseline`: row-level flag indicating a carry-forward baseline fill was applied.
- `ps_baseline_source`: qualitative source indicator, never used as a model feature.

Scripted play heuristic
file update:
diff --git a/config/training.yaml b/config/training.yaml
index 3953818d861d0410246bff132110722a3ce44007..c2b6053b488caa71f9078ff100d049f723ae1548
--- a/config/training.yaml
+++ b/config/training.yaml
@@ -476,6 +476,7 @@
   - name: 'anytime_td'
     target_col: 'anytime_td'
     label_version: 'v1_any_offense'
+    odds_horizon: 'cutoff'  # Restrict odds features to the decision-time snapshot
     task_type: 'classification'
     input_predictions:
       - 'availability_active'
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 5ba68e8bf1acd3a789a76a8857674e6f6433017b..0210d5b7e7ed60a8de7a126d64f5ed76326474c8
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -14,7 +14,7 @@
 
 import logging
 import os
-from datetime import date, timedelta
+from datetime import date, datetime, timedelta
 from typing import Sequence
 
 import polars as pl
@@ -37,6 +37,12 @@
     add_offense_context_features_training,
     _append_offense_context_columns,
 )
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    build_schema_snapshot,
+    enforce_leak_guard,
+    write_schema_snapshot,
+)
 from utils.feature.weather_features import (
     add_weather_forecast_features_training,
     append_weather_context_flags,
@@ -931,6 +937,32 @@
     if market_exprs:
         df_player_game_all = df_player_game_all.with_columns(market_exprs)
     
+    # Leak guard + schema snapshot before persisting
+    spec = get_label_spec(label_version)
+    allow_exact = {spec.primary, *spec.labels.keys(), *spec.aliases.keys()}
+    df_player_game_all, leak_result = enforce_leak_guard(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_exact=allow_exact,
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=True,
+    )
+
+    schema = build_schema_snapshot(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        metadata={
+            "cutoff_label": cutoff_label,
+            "label_version": spec.name,
+        },
+        banned=leak_result.banned,
+    )
+    schema_dir = FEATURE_AUDIT_DIR / "schema" / "anytime_td"
+    schema_path = schema_dir / f"{cutoff_label}_{datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')}.json"
+    write_schema_snapshot(schema_path, schema)
+    logging.info("    Schema snapshot written → %s", schema_path)
+
     # Write final feature matrix
     df_player_game_all = df_player_game_all.with_columns(
         pl.lit(current_cutoff_hours).cast(pl.Float32).alias("decision_horizon_hours")
@@ -951,7 +983,6 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    spec = get_label_spec(label_version)
     label_candidates = {spec.primary, "anytime_td"}
     for label_col in label_candidates:
         if label_col in df_player_game_all.columns:
diff --git a/pipeline/train.py b/pipeline/train.py
index fe70207dcdf25d209ee3ad55080b7ce826347c44..7c220514d006a3d4815d65a8af9ec7551ccf587e
--- a/pipeline/train.py
+++ b/pipeline/train.py
@@ -4,6 +4,7 @@
 import sys
 import logging
 import math
+import re
 
 
 # Move logging to top and remove global thread pinning
@@ -98,6 +99,7 @@
     fit_team_conformal_sums,
     composite_sum_interval,
 )
+from utils.feature.leak_guard import DEFAULT_LEAK_POLICY, enforce_leak_guard
 from utils.feature.targets import require_target_column
 
 # Ignore specific, noisy warnings from dependencies
@@ -793,6 +795,57 @@
             )
         return df
 
+    @staticmethod
+    def _filter_odds_snapshot_columns(df: pd.DataFrame, horizon_key: str | None) -> pd.DataFrame:
+        """Keep a single odds snapshot horizon (drop other suffixes)."""
+        if df is None or df.empty or not horizon_key:
+            return df
+
+        normalized = str(horizon_key).strip().lower()
+        horizon_map = {
+            "cutoff": "",
+            "default": "",
+            "": "",
+            "2h": "_2h",
+            "h120m": "_2h",
+            "6h": "_6h",
+            "h360m": "_6h",
+            "24h": "_24h",
+            "h1440m": "_24h",
+            "open": "_open",
+        }
+        allowed_suffix = horizon_map.get(normalized, normalized)
+        if allowed_suffix and not allowed_suffix.startswith("_"):
+            allowed_suffix = f"_{allowed_suffix.lstrip('_')}"
+
+        horizon_re = re.compile(r"^(?P<base>.+)(?P<suffix>_2h|_6h|_24h|_open)$")
+        suffixes_seen: dict[str, set[str]] = {}
+        for col in df.columns:
+            match = horizon_re.match(col)
+            if match:
+                suffixes_seen.setdefault(match.group("base"), set()).add(match.group("suffix"))
+
+        drop_cols: list[str] = []
+        for col in df.columns:
+            match = horizon_re.match(col)
+            if match:
+                suffix = match.group("suffix")
+                if suffix != allowed_suffix:
+                    drop_cols.append(col)
+            else:
+                base = col
+                if base in suffixes_seen and allowed_suffix:
+                    drop_cols.append(col)
+
+        if drop_cols:
+            df = df.drop(columns=drop_cols, errors="ignore")
+            logger.info(
+                "Removed %d odds snapshot columns outside horizon '%s'.",
+                len(drop_cols),
+                horizon_key,
+            )
+        return df
+
     def _ensure_player_game_actuals(self) -> pd.DataFrame:
         if self._player_game_actuals is not None:
             return self._player_game_actuals
@@ -2315,7 +2368,34 @@
                             df_problem[col] = df_problem[col].fillna(df_problem[col].mean())
 
                 df_problem = self._inject_composed_features(df_problem)
-            
+
+            odds_horizon = problem_copy.get("odds_horizon")
+            if odds_horizon:
+                df_problem = self._filter_odds_snapshot_columns(df_problem, odds_horizon)
+
+            # Leak guard on the problem-scoped frame
+            allow_prefixes = tuple(problem_copy.get('feature_prefixes_to_include') or [])
+            allow_exact = set(problem_copy.get('other_features_to_include') or [])
+            allow_exact.update(input_preds or [])
+            if self.target_col:
+                allow_exact.add(self.target_col)
+            df_problem, leak_info = enforce_leak_guard(
+                df_problem,
+                policy=DEFAULT_LEAK_POLICY,
+                allow_prefixes=allow_prefixes,
+                allow_exact=allow_exact,
+                drop_banned=True,
+                drop_non_allowlisted=False,
+                raise_on_banned=True,
+            )
+            if leak_info.dropped:
+                logger.info(
+                    "Dropped %d leak-prone columns for %s: %s",
+                    len(leak_info.dropped),
+                    problem_name,
+                    sorted(leak_info.dropped),
+                )
+
             self._normalize_datetime_like_columns(df_problem, problem_name)
             df_problem[self.time_col] = pd.to_datetime(df_problem[self.time_col])
             sort_cols = [self.time_col]
diff --git a/tests/test_data_leak_guard.py b/tests/test_data_leak_guard.py
index 8061f2760c0898aaeda29026859e1b9ff5644ba4..3e56665921db89ea523bbdb205d1bb90c21893df
--- a/tests/test_data_leak_guard.py
+++ b/tests/test_data_leak_guard.py
@@ -3,6 +3,14 @@
 import yaml
 from pathlib import Path
 
+import polars as pl
+
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    enforce_leak_guard,
+    evaluate_leak_prone_columns,
+)
+
 
 PROJECT_ROOT = Path(__file__).resolve().parents[1]
 TRAINING_CONFIG = PROJECT_ROOT / "config" / "training.yaml"
@@ -48,3 +56,41 @@
     )
 
 
+def test_leak_guard_flags_pattern_columns():
+    cols = [
+        "market_anytime_td_prob",
+        "final_score",
+        "postgame_anytime_td",
+        "actual_td_count",
+        "safe_feature",
+    ]
+    result = evaluate_leak_prone_columns(cols, policy=DEFAULT_LEAK_POLICY)
+    assert set(result.banned.keys()) == {"final_score", "postgame_anytime_td", "actual_td_count"}
+    assert "safe_feature" in result.kept
+    assert "market_anytime_td_prob" in result.kept
+
+
+def test_enforce_leak_guard_drops_banned_and_keeps_allowlisted():
+    df = pl.DataFrame(
+        {
+            "game_id": ["g1", "g2"],
+            "safe_feature": [1.0, 2.0],
+            "postgame_anytime_td": [1, 0],
+            "final_score": [30, 24],
+        }
+    )
+    cleaned, info = enforce_leak_guard(
+        df,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_prefixes=("safe_",),
+        allow_exact=("game_id",),
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=False,
+    )
+    assert "postgame_anytime_td" not in cleaned.columns
+    assert "final_score" not in cleaned.columns
+    assert "safe_feature" in cleaned.columns
+    assert "game_id" in cleaned.columns
+    assert set(info.dropped) == {"postgame_anytime_td", "final_score"}
+
diff --git a/tests/test_odds_horizon_filter.py b/tests/test_odds_horizon_filter.py
new file mode 100644
index 0000000000000000000000000000000000000000..70e9c681f63972bbb6e70008e286cf13f6881853
--- /dev/null
+++ b/tests/test_odds_horizon_filter.py
@@ -0,0 +1,35 @@
+from __future__ import annotations
+
+import pandas as pd
+import pytest
+
+train_module = pytest.importorskip("pipeline.train")
+ModelTrainer = train_module.ModelTrainer
+
+
+def test_filter_odds_snapshot_columns_cutoff_keeps_base_only():
+    df = pd.DataFrame(
+        {
+            "market_anytime_td_prob": [0.1, 0.2],
+            "market_anytime_td_prob_2h": [0.15, 0.25],
+            "market_anytime_td_prob_6h": [0.2, 0.3],
+            "other_feature": [1, 2],
+        }
+    )
+    filtered = ModelTrainer._filter_odds_snapshot_columns(df.copy(), "cutoff")
+    assert "market_anytime_td_prob" in filtered.columns
+    assert "market_anytime_td_prob_2h" not in filtered.columns
+    assert "market_anytime_td_prob_6h" not in filtered.columns
+    assert "other_feature" in filtered.columns
+
+
+def test_filter_odds_snapshot_columns_specific_suffix():
+    df = pd.DataFrame(
+        {
+            "market_anytime_td_prob": [0.1, 0.2],
+            "market_anytime_td_prob_2h": [0.15, 0.25],
+            "market_anytime_td_prob_6h": [0.2, 0.3],
+        }
+    )
+    filtered = ModelTrainer._filter_odds_snapshot_columns(df.copy(), "6h")
+    assert list(filtered.columns) == ["market_anytime_td_prob_6h"]
diff --git a/utils/feature/leak_guard.py b/utils/feature/leak_guard.py
new file mode 100644
index 0000000000000000000000000000000000000000..9faf8cfffc436e0934b2f410aaf252e52f4f95df
--- /dev/null
+++ b/utils/feature/leak_guard.py
@@ -0,0 +1,273 @@
+"""Leak guardrails for feature matrices.
+
+This module centralizes pattern-based leak detection so both feature assembly
+and training can fail fast when post-outcome columns sneak into the data.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+from datetime import datetime
+import json
+import re
+from typing import Iterable, Mapping, Sequence
+
+import polars as pl
+
+from utils.general.constants import IDENTIFIER_COLUMNS, LEAK_PRONE_COLUMNS, NFL_TARGET_COLUMNS
+
+try:  # Optional dependency when imported from training (pandas path)
+    import pandas as pd  # type: ignore
+except Exception:  # pragma: no cover - optional dependency
+    pd = None
+
+
+@dataclass(frozen=True)
+class LeakPolicy:
+    version: str
+    banned_exact: set[str]
+    banned_prefixes: tuple[str, ...]
+    banned_suffixes: tuple[str, ...]
+    banned_regex: tuple[tuple[re.Pattern[str], str], ...]
+    description: str = ""
+
+
+@dataclass
+class LeakCheckResult:
+    policy_version: str
+    banned: dict[str, str]
+    kept: list[str]
+    dropped: list[str]
+    allowlist_kept: list[str]
+
+
+# Core policy tuned for anytime-TD style problems (can be extended per-problem).
+_BASE_BANNED_EXACT = set(LEAK_PRONE_COLUMNS) | {
+    "final_score",
+    "final_total",
+    "points_scored",
+    "actual_td_count",
+    "actual_anytime_td",
+    "postgame_anytime_td",
+    "postgame_td_count",
+}
+_BASE_BANNED_PREFIXES = (
+    "postgame_",
+    "post_game_",
+    "post_",
+    "live_",
+    "actual_",
+    "realized_",
+    "final_",
+    "postmatch_",
+)
+_BASE_BANNED_SUFFIXES = (
+    "_post",
+    "_postgame",
+    "_final",
+    "_fullgame",
+    "_actual",
+)
+_BASE_BANNED_REGEX: tuple[tuple[re.Pattern[str], str], ...] = (
+    (re.compile(r".*post.?game.*", flags=re.IGNORECASE), "postgame marker"),
+    (re.compile(r".*final_score.*", flags=re.IGNORECASE), "final score"),
+    (re.compile(r".*actual.*td.*", flags=re.IGNORECASE), "actual TD total"),
+    (re.compile(r".*anytime_td.*(post|final|actual).*", flags=re.IGNORECASE), "post-decision anytime TD"),
+    (re.compile(r".*fullgame.*", flags=re.IGNORECASE), "full game cumulative value"),
+)
+
+DEFAULT_LEAK_POLICY = LeakPolicy(
+    version="v1",
+    description="Core post-outcome leak guard for NFL anytime TD features.",
+    banned_exact=_BASE_BANNED_EXACT,
+    banned_prefixes=_BASE_BANNED_PREFIXES,
+    banned_suffixes=_BASE_BANNED_SUFFIXES,
+    banned_regex=_BASE_BANNED_REGEX,
+)
+
+
+def _ensure_sequence(value: Sequence[str] | str | None) -> tuple[str, ...]:
+    if value is None:
+        return ()
+    if isinstance(value, str):
+        return (value,)
+    return tuple(value)
+
+
+def evaluate_leak_prone_columns(
+    columns: Iterable[str],
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+) -> LeakCheckResult:
+    """Identify leak-prone columns using the configured policy."""
+
+    banned: dict[str, str] = {}
+    columns_list = list(columns)
+    for col in columns_list:
+        if col in policy.banned_exact:
+            banned[col] = "exact"
+            continue
+        for prefix in policy.banned_prefixes:
+            if col.startswith(prefix):
+                banned[col] = f"prefix:{prefix}"
+                break
+        if col in banned:
+            continue
+        for suffix in policy.banned_suffixes:
+            if col.endswith(suffix):
+                banned[col] = f"suffix:{suffix}"
+                break
+        if col in banned:
+            continue
+        for pattern, reason in policy.banned_regex:
+            if pattern.match(col):
+                banned[col] = reason
+                break
+
+    kept = [c for c in columns_list if c not in banned]
+    return LeakCheckResult(
+        policy_version=policy.version,
+        banned=banned,
+        kept=kept,
+        dropped=[],
+        allowlist_kept=[],
+    )
+
+
+def enforce_leak_guard(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    allow_prefixes: Sequence[str] | str | None = None,
+    allow_exact: Sequence[str] | str | None = None,
+    drop_banned: bool = True,
+    drop_non_allowlisted: bool = False,
+    raise_on_banned: bool = True,
+) -> tuple[pl.DataFrame | "pd.DataFrame", LeakCheckResult]:
+    """Apply leak guardrails to a feature frame.
+
+    Parameters
+    ----------
+    df : DataFrame
+        Polars or pandas DataFrame.
+    policy : LeakPolicy
+        Leak policy to apply.
+    allow_prefixes : Sequence[str] | str | None
+        Optional prefixes that define the allowed feature surface for a problem.
+    allow_exact : Sequence[str] | str | None
+        Explicitly allowed columns (e.g., identifiers).
+    drop_banned : bool
+        If True, drop any banned columns automatically.
+    drop_non_allowlisted : bool
+        If True, drop columns that are not covered by allow_prefixes/allow_exact/identifiers/targets.
+    raise_on_banned : bool
+        If True, raise when banned columns are detected (after optional drop).
+    """
+
+    result = evaluate_leak_prone_columns(df.columns, policy=policy)
+    dropped: list[str] = []
+
+    allow_prefixes = _ensure_sequence(allow_prefixes)
+    allow_exact = set(_ensure_sequence(allow_exact))
+    allow_exact.update({col for col in IDENTIFIER_COLUMNS if col in df.columns})
+    allow_exact.update({col for col in NFL_TARGET_COLUMNS if col in df.columns})
+
+    # Permit allowlisted columns even if they match a banned rule (e.g., labels)
+    banned = {col: reason for col, reason in result.banned.items() if col not in allow_exact}
+
+    if banned and drop_banned:
+        df = df.drop(list(banned.keys()))
+        dropped.extend(banned.keys())
+
+    if banned and raise_on_banned:
+        raise ValueError(f"Leak-prone columns detected: {sorted(banned.items())}")
+
+    allowlist_cols: set[str] = set()
+    if allow_prefixes:
+        allowlist_cols.update({c for c in df.columns if c.startswith(allow_prefixes)})
+    allowlist_cols.update({c for c in allow_exact if c in df.columns})
+
+    if drop_non_allowlisted and allowlist_cols:
+        drop_candidates = [c for c in df.columns if c not in allowlist_cols]
+        if drop_candidates:
+            df = df.drop(drop_candidates)
+            dropped.extend(drop_candidates)
+
+    if drop_non_allowlisted and not allowlist_cols:
+        raise ValueError("No allowlisted columns remain after applying leak guard allowlist.")
+
+    # Store adjusted banned info on the result
+    result.banned = banned
+    result.dropped = dropped
+    result.kept = [c for c in df.columns]
+    result.allowlist_kept = sorted(list(allowlist_cols)) if allowlist_cols else []
+    return df, result
+
+
+def build_schema_snapshot(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    metadata: Mapping[str, object] | None = None,
+    banned: Mapping[str, str] | None = None,
+) -> dict:
+    """Render a schema snapshot describing each column and whether it was flagged."""
+
+    banned = banned or {}
+    meta = {
+        "generated_at_utc": datetime.utcnow().isoformat(),
+        "policy_version": policy.version,
+    }
+    meta.update(metadata or {})
+
+    # Extract columns / dtypes
+    if isinstance(df, pl.DataFrame):
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+    else:  # pandas or pandas-like
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+
+    schema = {
+        "metadata": meta,
+        "columns": [],
+    }
+
+    for col, dtype in cols_and_dtypes:
+        tags: list[str] = []
+        if col in IDENTIFIER_COLUMNS:
+            tags.append("id")
+        if col in NFL_TARGET_COLUMNS:
+            tags.append("label")
+        if col.startswith("market_"):
+            tags.append("odds")
+        if col.startswith("injury_") or col.startswith("practice_"):
+            tags.append("injury")
+        if col.startswith("weather_"):
+            tags.append("weather")
+        if col.startswith("ps_"):
+            tags.append("pre_snap")
+        schema["columns"].append(
+            {
+                "name": col,
+                "dtype": dtype,
+                "banned": col in banned,
+                "tags": tags,
+            }
+        )
+    return schema
+
+
+def write_schema_snapshot(path, schema: Mapping[str, object]) -> None:
+    path.parent.mkdir(parents=True, exist_ok=True)
+    with open(path, "w") as fp:
+        json.dump(schema, fp, indent=2, sort_keys=True)
+
+
+__all__ = [
+    "DEFAULT_LEAK_POLICY",
+    "LeakPolicy",
+    "LeakCheckResult",
+    "evaluate_leak_prone_columns",
+    "enforce_leak_guard",
+    "build_schema_snapshot",
+    "write_schema_snapshot",
+]
diff --git a/utils/general/constants.py b/utils/general/constants.py
index d94b4260ad877484da843fa99ae2caf37e8493f4..dea87caa354d94e4a08b1762d2bd8dcd4c8caa3a
--- a/utils/general/constants.py
+++ b/utils/general/constants.py
@@ -211,7 +211,17 @@
 
 NFL_TARGET_COLUMNS: Tuple[str, ...] = (
     'anytime_td',
+    'anytime_td_offense',
+    'anytime_td_all',
+    'anytime_td_rush',
+    'anytime_td_rec',
+    'anytime_td_pass_thrown',
     'td_count',
+    'td_count_offense',
+    'td_count_all',
+    'passing_td',
+    'rushing_td_count',
+    'receiving_td_count',
     'receiving_yards',
     'rushing_yards',
     'passing_yards',


thinking
**Adding note on leak guard**
file update
M /Users/jameswest/Desktop/nfl_predict/docs/pre_snap_semantics.md
@@ -31 +31,6 @@
 - Base `ps_game_*` and `ps_tracking_*` columns remain in the data for diagnostics/labeling but are blocked by `columns_to_discard` and `LEAK_PRONE_COLUMNS`.
+
+Decision-time odds snapshots
+----------------------------
+- Odds features are now filtered to a single horizon via `odds_horizon` in `config/training.yaml` (e.g., `cutoff` keeps the decision-time snapshot and drops `_2h/_6h/_24h/_open` variants).
+- Feature builds emit a schema snapshot under `audit/feature/schema/anytime_td/` capturing dtypes and any leak-guard flags for traceability.
apply_patch(auto_approved=true) exited 0 in 102ms:
Success. Updated the following files:
M docs/pre_snap_semantics.md
file update:
diff --git a/config/training.yaml b/config/training.yaml
index 3953818d861d0410246bff132110722a3ce44007..c2b6053b488caa71f9078ff100d049f723ae1548
--- a/config/training.yaml
+++ b/config/training.yaml
@@ -476,6 +476,7 @@
   - name: 'anytime_td'
     target_col: 'anytime_td'
     label_version: 'v1_any_offense'
+    odds_horizon: 'cutoff'  # Restrict odds features to the decision-time snapshot
     task_type: 'classification'
     input_predictions:
       - 'availability_active'
diff --git a/docs/pre_snap_semantics.md b/docs/pre_snap_semantics.md
index 7d58f2f5139d77b00c6c4a1df16648d0601b89ff..d5a996dffd7b8e94ca096b2872314b1c97a80049
--- a/docs/pre_snap_semantics.md
+++ b/docs/pre_snap_semantics.md
@@ -29,3 +29,8 @@
 ---------------
 - Only `ps_hist_*` features (including the `ps_hist_tracking_*` coverage rolls) are allowed as inputs via `feature_prefixes_to_include`.
 - Base `ps_game_*` and `ps_tracking_*` columns remain in the data for diagnostics/labeling but are blocked by `columns_to_discard` and `LEAK_PRONE_COLUMNS`.
+
+Decision-time odds snapshots
+----------------------------
+- Odds features are now filtered to a single horizon via `odds_horizon` in `config/training.yaml` (e.g., `cutoff` keeps the decision-time snapshot and drops `_2h/_6h/_24h/_open` variants).
+- Feature builds emit a schema snapshot under `audit/feature/schema/anytime_td/` capturing dtypes and any leak-guard flags for traceability.
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 5ba68e8bf1acd3a789a76a8857674e6f6433017b..0210d5b7e7ed60a8de7a126d64f5ed76326474c8
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -14,7 +14,7 @@
 
 import logging
 import os
-from datetime import date, timedelta
+from datetime import date, datetime, timedelta
 from typing import Sequence
 
 import polars as pl
@@ -37,6 +37,12 @@
     add_offense_context_features_training,
     _append_offense_context_columns,
 )
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    build_schema_snapshot,
+    enforce_leak_guard,
+    write_schema_snapshot,
+)
 from utils.feature.weather_features import (
     add_weather_forecast_features_training,
     append_weather_context_flags,
@@ -931,6 +937,32 @@
     if market_exprs:
         df_player_game_all = df_player_game_all.with_columns(market_exprs)
     
+    # Leak guard + schema snapshot before persisting
+    spec = get_label_spec(label_version)
+    allow_exact = {spec.primary, *spec.labels.keys(), *spec.aliases.keys()}
+    df_player_game_all, leak_result = enforce_leak_guard(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_exact=allow_exact,
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=True,
+    )
+
+    schema = build_schema_snapshot(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        metadata={
+            "cutoff_label": cutoff_label,
+            "label_version": spec.name,
+        },
+        banned=leak_result.banned,
+    )
+    schema_dir = FEATURE_AUDIT_DIR / "schema" / "anytime_td"
+    schema_path = schema_dir / f"{cutoff_label}_{datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')}.json"
+    write_schema_snapshot(schema_path, schema)
+    logging.info("    Schema snapshot written → %s", schema_path)
+
     # Write final feature matrix
     df_player_game_all = df_player_game_all.with_columns(
         pl.lit(current_cutoff_hours).cast(pl.Float32).alias("decision_horizon_hours")
@@ -951,7 +983,6 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    spec = get_label_spec(label_version)
     label_candidates = {spec.primary, "anytime_td"}
     for label_col in label_candidates:
         if label_col in df_player_game_all.columns:
diff --git a/pipeline/train.py b/pipeline/train.py
index fe70207dcdf25d209ee3ad55080b7ce826347c44..7c220514d006a3d4815d65a8af9ec7551ccf587e
--- a/pipeline/train.py
+++ b/pipeline/train.py
@@ -4,6 +4,7 @@
 import sys
 import logging
 import math
+import re
 
 
 # Move logging to top and remove global thread pinning
@@ -98,6 +99,7 @@
     fit_team_conformal_sums,
     composite_sum_interval,
 )
+from utils.feature.leak_guard import DEFAULT_LEAK_POLICY, enforce_leak_guard
 from utils.feature.targets import require_target_column
 
 # Ignore specific, noisy warnings from dependencies
@@ -793,6 +795,57 @@
             )
         return df
 
+    @staticmethod
+    def _filter_odds_snapshot_columns(df: pd.DataFrame, horizon_key: str | None) -> pd.DataFrame:
+        """Keep a single odds snapshot horizon (drop other suffixes)."""
+        if df is None or df.empty or not horizon_key:
+            return df
+
+        normalized = str(horizon_key).strip().lower()
+        horizon_map = {
+            "cutoff": "",
+            "default": "",
+            "": "",
+            "2h": "_2h",
+            "h120m": "_2h",
+            "6h": "_6h",
+            "h360m": "_6h",
+            "24h": "_24h",
+            "h1440m": "_24h",
+            "open": "_open",
+        }
+        allowed_suffix = horizon_map.get(normalized, normalized)
+        if allowed_suffix and not allowed_suffix.startswith("_"):
+            allowed_suffix = f"_{allowed_suffix.lstrip('_')}"
+
+        horizon_re = re.compile(r"^(?P<base>.+)(?P<suffix>_2h|_6h|_24h|_open)$")
+        suffixes_seen: dict[str, set[str]] = {}
+        for col in df.columns:
+            match = horizon_re.match(col)
+            if match:
+                suffixes_seen.setdefault(match.group("base"), set()).add(match.group("suffix"))
+
+        drop_cols: list[str] = []
+        for col in df.columns:
+            match = horizon_re.match(col)
+            if match:
+                suffix = match.group("suffix")
+                if suffix != allowed_suffix:
+                    drop_cols.append(col)
+            else:
+                base = col
+                if base in suffixes_seen and allowed_suffix:
+                    drop_cols.append(col)
+
+        if drop_cols:
+            df = df.drop(columns=drop_cols, errors="ignore")
+            logger.info(
+                "Removed %d odds snapshot columns outside horizon '%s'.",
+                len(drop_cols),
+                horizon_key,
+            )
+        return df
+
     def _ensure_player_game_actuals(self) -> pd.DataFrame:
         if self._player_game_actuals is not None:
             return self._player_game_actuals
@@ -2315,7 +2368,34 @@
                             df_problem[col] = df_problem[col].fillna(df_problem[col].mean())
 
                 df_problem = self._inject_composed_features(df_problem)
-            
+
+            odds_horizon = problem_copy.get("odds_horizon")
+            if odds_horizon:
+                df_problem = self._filter_odds_snapshot_columns(df_problem, odds_horizon)
+
+            # Leak guard on the problem-scoped frame
+            allow_prefixes = tuple(problem_copy.get('feature_prefixes_to_include') or [])
+            allow_exact = set(problem_copy.get('other_features_to_include') or [])
+            allow_exact.update(input_preds or [])
+            if self.target_col:
+                allow_exact.add(self.target_col)
+            df_problem, leak_info = enforce_leak_guard(
+                df_problem,
+                policy=DEFAULT_LEAK_POLICY,
+                allow_prefixes=allow_prefixes,
+                allow_exact=allow_exact,
+                drop_banned=True,
+                drop_non_allowlisted=False,
+                raise_on_banned=True,
+            )
+            if leak_info.dropped:
+                logger.info(
+                    "Dropped %d leak-prone columns for %s: %s",
+                    len(leak_info.dropped),
+                    problem_name,
+                    sorted(leak_info.dropped),
+                )
+
             self._normalize_datetime_like_columns(df_problem, problem_name)
             df_problem[self.time_col] = pd.to_datetime(df_problem[self.time_col])
             sort_cols = [self.time_col]
diff --git a/tests/test_data_leak_guard.py b/tests/test_data_leak_guard.py
index 8061f2760c0898aaeda29026859e1b9ff5644ba4..3e56665921db89ea523bbdb205d1bb90c21893df
--- a/tests/test_data_leak_guard.py
+++ b/tests/test_data_leak_guard.py
@@ -3,6 +3,14 @@
 import yaml
 from pathlib import Path
 
+import polars as pl
+
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    enforce_leak_guard,
+    evaluate_leak_prone_columns,
+)
+
 
 PROJECT_ROOT = Path(__file__).resolve().parents[1]
 TRAINING_CONFIG = PROJECT_ROOT / "config" / "training.yaml"
@@ -48,3 +56,41 @@
     )
 
 
+def test_leak_guard_flags_pattern_columns():
+    cols = [
+        "market_anytime_td_prob",
+        "final_score",
+        "postgame_anytime_td",
+        "actual_td_count",
+        "safe_feature",
+    ]
+    result = evaluate_leak_prone_columns(cols, policy=DEFAULT_LEAK_POLICY)
+    assert set(result.banned.keys()) == {"final_score", "postgame_anytime_td", "actual_td_count"}
+    assert "safe_feature" in result.kept
+    assert "market_anytime_td_prob" in result.kept
+
+
+def test_enforce_leak_guard_drops_banned_and_keeps_allowlisted():
+    df = pl.DataFrame(
+        {
+            "game_id": ["g1", "g2"],
+            "safe_feature": [1.0, 2.0],
+            "postgame_anytime_td": [1, 0],
+            "final_score": [30, 24],
+        }
+    )
+    cleaned, info = enforce_leak_guard(
+        df,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_prefixes=("safe_",),
+        allow_exact=("game_id",),
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=False,
+    )
+    assert "postgame_anytime_td" not in cleaned.columns
+    assert "final_score" not in cleaned.columns
+    assert "safe_feature" in cleaned.columns
+    assert "game_id" in cleaned.columns
+    assert set(info.dropped) == {"postgame_anytime_td", "final_score"}
+
diff --git a/tests/test_odds_horizon_filter.py b/tests/test_odds_horizon_filter.py
new file mode 100644
index 0000000000000000000000000000000000000000..70e9c681f63972bbb6e70008e286cf13f6881853
--- /dev/null
+++ b/tests/test_odds_horizon_filter.py
@@ -0,0 +1,35 @@
+from __future__ import annotations
+
+import pandas as pd
+import pytest
+
+train_module = pytest.importorskip("pipeline.train")
+ModelTrainer = train_module.ModelTrainer
+
+
+def test_filter_odds_snapshot_columns_cutoff_keeps_base_only():
+    df = pd.DataFrame(
+        {
+            "market_anytime_td_prob": [0.1, 0.2],
+            "market_anytime_td_prob_2h": [0.15, 0.25],
+            "market_anytime_td_prob_6h": [0.2, 0.3],
+            "other_feature": [1, 2],
+        }
+    )
+    filtered = ModelTrainer._filter_odds_snapshot_columns(df.copy(), "cutoff")
+    assert "market_anytime_td_prob" in filtered.columns
+    assert "market_anytime_td_prob_2h" not in filtered.columns
+    assert "market_anytime_td_prob_6h" not in filtered.columns
+    assert "other_feature" in filtered.columns
+
+
+def test_filter_odds_snapshot_columns_specific_suffix():
+    df = pd.DataFrame(
+        {
+            "market_anytime_td_prob": [0.1, 0.2],
+            "market_anytime_td_prob_2h": [0.15, 0.25],
+            "market_anytime_td_prob_6h": [0.2, 0.3],
+        }
+    )
+    filtered = ModelTrainer._filter_odds_snapshot_columns(df.copy(), "6h")
+    assert list(filtered.columns) == ["market_anytime_td_prob_6h"]
diff --git a/utils/feature/leak_guard.py b/utils/feature/leak_guard.py
new file mode 100644
index 0000000000000000000000000000000000000000..9faf8cfffc436e0934b2f410aaf252e52f4f95df
--- /dev/null
+++ b/utils/feature/leak_guard.py
@@ -0,0 +1,273 @@
+"""Leak guardrails for feature matrices.
+
+This module centralizes pattern-based leak detection so both feature assembly
+and training can fail fast when post-outcome columns sneak into the data.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+from datetime import datetime
+import json
+import re
+from typing import Iterable, Mapping, Sequence
+
+import polars as pl
+
+from utils.general.constants import IDENTIFIER_COLUMNS, LEAK_PRONE_COLUMNS, NFL_TARGET_COLUMNS
+
+try:  # Optional dependency when imported from training (pandas path)
+    import pandas as pd  # type: ignore
+except Exception:  # pragma: no cover - optional dependency
+    pd = None
+
+
+@dataclass(frozen=True)
+class LeakPolicy:
+    version: str
+    banned_exact: set[str]
+    banned_prefixes: tuple[str, ...]
+    banned_suffixes: tuple[str, ...]
+    banned_regex: tuple[tuple[re.Pattern[str], str], ...]
+    description: str = ""
+
+
+@dataclass
+class LeakCheckResult:
+    policy_version: str
+    banned: dict[str, str]
+    kept: list[str]
+    dropped: list[str]
+    allowlist_kept: list[str]
+
+
+# Core policy tuned for anytime-TD style problems (can be extended per-problem).
+_BASE_BANNED_EXACT = set(LEAK_PRONE_COLUMNS) | {
+    "final_score",
+    "final_total",
+    "points_scored",
+    "actual_td_count",
+    "actual_anytime_td",
+    "postgame_anytime_td",
+    "postgame_td_count",
+}
+_BASE_BANNED_PREFIXES = (
+    "postgame_",
+    "post_game_",
+    "post_",
+    "live_",
+    "actual_",
+    "realized_",
+    "final_",
+    "postmatch_",
+)
+_BASE_BANNED_SUFFIXES = (
+    "_post",
+    "_postgame",
+    "_final",
+    "_fullgame",
+    "_actual",
+)
+_BASE_BANNED_REGEX: tuple[tuple[re.Pattern[str], str], ...] = (
+    (re.compile(r".*post.?game.*", flags=re.IGNORECASE), "postgame marker"),
+    (re.compile(r".*final_score.*", flags=re.IGNORECASE), "final score"),
+    (re.compile(r".*actual.*td.*", flags=re.IGNORECASE), "actual TD total"),
+    (re.compile(r".*anytime_td.*(post|final|actual).*", flags=re.IGNORECASE), "post-decision anytime TD"),
+    (re.compile(r".*fullgame.*", flags=re.IGNORECASE), "full game cumulative value"),
+)
+
+DEFAULT_LEAK_POLICY = LeakPolicy(
+    version="v1",
+    description="Core post-outcome leak guard for NFL anytime TD features.",
+    banned_exact=_BASE_BANNED_EXACT,
+    banned_prefixes=_BASE_BANNED_PREFIXES,
+    banned_suffixes=_BASE_BANNED_SUFFIXES,
+    banned_regex=_BASE_BANNED_REGEX,
+)
+
+
+def _ensure_sequence(value: Sequence[str] | str | None) -> tuple[str, ...]:
+    if value is None:
+        return ()
+    if isinstance(value, str):
+        return (value,)
+    return tuple(value)
+
+
+def evaluate_leak_prone_columns(
+    columns: Iterable[str],
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+) -> LeakCheckResult:
+    """Identify leak-prone columns using the configured policy."""
+
+    banned: dict[str, str] = {}
+    columns_list = list(columns)
+    for col in columns_list:
+        if col in policy.banned_exact:
+            banned[col] = "exact"
+            continue
+        for prefix in policy.banned_prefixes:
+            if col.startswith(prefix):
+                banned[col] = f"prefix:{prefix}"
+                break
+        if col in banned:
+            continue
+        for suffix in policy.banned_suffixes:
+            if col.endswith(suffix):
+                banned[col] = f"suffix:{suffix}"
+                break
+        if col in banned:
+            continue
+        for pattern, reason in policy.banned_regex:
+            if pattern.match(col):
+                banned[col] = reason
+                break
+
+    kept = [c for c in columns_list if c not in banned]
+    return LeakCheckResult(
+        policy_version=policy.version,
+        banned=banned,
+        kept=kept,
+        dropped=[],
+        allowlist_kept=[],
+    )
+
+
+def enforce_leak_guard(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    allow_prefixes: Sequence[str] | str | None = None,
+    allow_exact: Sequence[str] | str | None = None,
+    drop_banned: bool = True,
+    drop_non_allowlisted: bool = False,
+    raise_on_banned: bool = True,
+) -> tuple[pl.DataFrame | "pd.DataFrame", LeakCheckResult]:
+    """Apply leak guardrails to a feature frame.
+
+    Parameters
+    ----------
+    df : DataFrame
+        Polars or pandas DataFrame.
+    policy : LeakPolicy
+        Leak policy to apply.
+    allow_prefixes : Sequence[str] | str | None
+        Optional prefixes that define the allowed feature surface for a problem.
+    allow_exact : Sequence[str] | str | None
+        Explicitly allowed columns (e.g., identifiers).
+    drop_banned : bool
+        If True, drop any banned columns automatically.
+    drop_non_allowlisted : bool
+        If True, drop columns that are not covered by allow_prefixes/allow_exact/identifiers/targets.
+    raise_on_banned : bool
+        If True, raise when banned columns are detected (after optional drop).
+    """
+
+    result = evaluate_leak_prone_columns(df.columns, policy=policy)
+    dropped: list[str] = []
+
+    allow_prefixes = _ensure_sequence(allow_prefixes)
+    allow_exact = set(_ensure_sequence(allow_exact))
+    allow_exact.update({col for col in IDENTIFIER_COLUMNS if col in df.columns})
+    allow_exact.update({col for col in NFL_TARGET_COLUMNS if col in df.columns})
+
+    # Permit allowlisted columns even if they match a banned rule (e.g., labels)
+    banned = {col: reason for col, reason in result.banned.items() if col not in allow_exact}
+
+    if banned and drop_banned:
+        df = df.drop(list(banned.keys()))
+        dropped.extend(banned.keys())
+
+    if banned and raise_on_banned:
+        raise ValueError(f"Leak-prone columns detected: {sorted(banned.items())}")
+
+    allowlist_cols: set[str] = set()
+    if allow_prefixes:
+        allowlist_cols.update({c for c in df.columns if c.startswith(allow_prefixes)})
+    allowlist_cols.update({c for c in allow_exact if c in df.columns})
+
+    if drop_non_allowlisted and allowlist_cols:
+        drop_candidates = [c for c in df.columns if c not in allowlist_cols]
+        if drop_candidates:
+            df = df.drop(drop_candidates)
+            dropped.extend(drop_candidates)
+
+    if drop_non_allowlisted and not allowlist_cols:
+        raise ValueError("No allowlisted columns remain after applying leak guard allowlist.")
+
+    # Store adjusted banned info on the result
+    result.banned = banned
+    result.dropped = dropped
+    result.kept = [c for c in df.columns]
+    result.allowlist_kept = sorted(list(allowlist_cols)) if allowlist_cols else []
+    return df, result
+
+
+def build_schema_snapshot(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    metadata: Mapping[str, object] | None = None,
+    banned: Mapping[str, str] | None = None,
+) -> dict:
+    """Render a schema snapshot describing each column and whether it was flagged."""
+
+    banned = banned or {}
+    meta = {
+        "generated_at_utc": datetime.utcnow().isoformat(),
+        "policy_version": policy.version,
+    }
+    meta.update(metadata or {})
+
+    # Extract columns / dtypes
+    if isinstance(df, pl.DataFrame):
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+    else:  # pandas or pandas-like
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+
+    schema = {
+        "metadata": meta,
+        "columns": [],
+    }
+
+    for col, dtype in cols_and_dtypes:
+        tags: list[str] = []
+        if col in IDENTIFIER_COLUMNS:
+            tags.append("id")
+        if col in NFL_TARGET_COLUMNS:
+            tags.append("label")
+        if col.startswith("market_"):
+            tags.append("odds")
+        if col.startswith("injury_") or col.startswith("practice_"):
+            tags.append("injury")
+        if col.startswith("weather_"):
+            tags.append("weather")
+        if col.startswith("ps_"):
+            tags.append("pre_snap")
+        schema["columns"].append(
+            {
+                "name": col,
+                "dtype": dtype,
+                "banned": col in banned,
+                "tags": tags,
+            }
+        )
+    return schema
+
+
+def write_schema_snapshot(path, schema: Mapping[str, object]) -> None:
+    path.parent.mkdir(parents=True, exist_ok=True)
+    with open(path, "w") as fp:
+        json.dump(schema, fp, indent=2, sort_keys=True)
+
+
+__all__ = [
+    "DEFAULT_LEAK_POLICY",
+    "LeakPolicy",
+    "LeakCheckResult",
+    "evaluate_leak_prone_columns",
+    "enforce_leak_guard",
+    "build_schema_snapshot",
+    "write_schema_snapshot",
+]
diff --git a/utils/general/constants.py b/utils/general/constants.py
index d94b4260ad877484da843fa99ae2caf37e8493f4..dea87caa354d94e4a08b1762d2bd8dcd4c8caa3a
--- a/utils/general/constants.py
+++ b/utils/general/constants.py
@@ -211,7 +211,17 @@
 
 NFL_TARGET_COLUMNS: Tuple[str, ...] = (
     'anytime_td',
+    'anytime_td_offense',
+    'anytime_td_all',
+    'anytime_td_rush',
+    'anytime_td_rec',
+    'anytime_td_pass_thrown',
     'td_count',
+    'td_count_offense',
+    'td_count_all',
+    'passing_td',
+    'rushing_td_count',
+    'receiving_td_count',
     'receiving_yards',
     'rushing_yards',
     'passing_yards',

file update:
diff --git a/config/training.yaml b/config/training.yaml
index 3953818d861d0410246bff132110722a3ce44007..c2b6053b488caa71f9078ff100d049f723ae1548
--- a/config/training.yaml
+++ b/config/training.yaml
@@ -476,6 +476,7 @@
   - name: 'anytime_td'
     target_col: 'anytime_td'
     label_version: 'v1_any_offense'
+    odds_horizon: 'cutoff'  # Restrict odds features to the decision-time snapshot
     task_type: 'classification'
     input_predictions:
       - 'availability_active'
diff --git a/docs/pre_snap_semantics.md b/docs/pre_snap_semantics.md
index 7d58f2f5139d77b00c6c4a1df16648d0601b89ff..d5a996dffd7b8e94ca096b2872314b1c97a80049
--- a/docs/pre_snap_semantics.md
+++ b/docs/pre_snap_semantics.md
@@ -29,3 +29,8 @@
 ---------------
 - Only `ps_hist_*` features (including the `ps_hist_tracking_*` coverage rolls) are allowed as inputs via `feature_prefixes_to_include`.
 - Base `ps_game_*` and `ps_tracking_*` columns remain in the data for diagnostics/labeling but are blocked by `columns_to_discard` and `LEAK_PRONE_COLUMNS`.
+
+Decision-time odds snapshots
+----------------------------
+- Odds features are now filtered to a single horizon via `odds_horizon` in `config/training.yaml` (e.g., `cutoff` keeps the decision-time snapshot and drops `_2h/_6h/_24h/_open` variants).
+- Feature builds emit a schema snapshot under `audit/feature/schema/anytime_td/` capturing dtypes and any leak-guard flags for traceability.
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 5ba68e8bf1acd3a789a76a8857674e6f6433017b..0210d5b7e7ed60a8de7a126d64f5ed76326474c8
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -14,7 +14,7 @@
 
 import logging
 import os
-from datetime import date, timedelta
+from datetime import date, datetime, timedelta
 from typing import Sequence
 
 import polars as pl
@@ -37,6 +37,12 @@
     add_offense_context_features_training,
     _append_offense_context_columns,
 )
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    build_schema_snapshot,
+    enforce_leak_guard,
+    write_schema_snapshot,
+)
 from utils.feature.weather_features import (
     add_weather_forecast_features_training,
     append_weather_context_flags,
@@ -931,6 +937,32 @@
     if market_exprs:
         df_player_game_all = df_player_game_all.with_columns(market_exprs)
     
+    # Leak guard + schema snapshot before persisting
+    spec = get_label_spec(label_version)
+    allow_exact = {spec.primary, *spec.labels.keys(), *spec.aliases.keys()}
+    df_player_game_all, leak_result = enforce_leak_guard(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_exact=allow_exact,
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=True,
+    )
+
+    schema = build_schema_snapshot(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        metadata={
+            "cutoff_label": cutoff_label,
+            "label_version": spec.name,
+        },
+        banned=leak_result.banned,
+    )
+    schema_dir = FEATURE_AUDIT_DIR / "schema" / "anytime_td"
+    schema_path = schema_dir / f"{cutoff_label}_{datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')}.json"
+    write_schema_snapshot(schema_path, schema)
+    logging.info("    Schema snapshot written → %s", schema_path)
+
     # Write final feature matrix
     df_player_game_all = df_player_game_all.with_columns(
         pl.lit(current_cutoff_hours).cast(pl.Float32).alias("decision_horizon_hours")
@@ -951,7 +983,6 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    spec = get_label_spec(label_version)
     label_candidates = {spec.primary, "anytime_td"}
     for label_col in label_candidates:
         if label_col in df_player_game_all.columns:
diff --git a/pipeline/train.py b/pipeline/train.py
index fe70207dcdf25d209ee3ad55080b7ce826347c44..7c220514d006a3d4815d65a8af9ec7551ccf587e
--- a/pipeline/train.py
+++ b/pipeline/train.py
@@ -4,6 +4,7 @@
 import sys
 import logging
 import math
+import re
 
 
 # Move logging to top and remove global thread pinning
@@ -98,6 +99,7 @@
     fit_team_conformal_sums,
     composite_sum_interval,
 )
+from utils.feature.leak_guard import DEFAULT_LEAK_POLICY, enforce_leak_guard
 from utils.feature.targets import require_target_column
 
 # Ignore specific, noisy warnings from dependencies
@@ -793,6 +795,57 @@
             )
         return df
 
+    @staticmethod
+    def _filter_odds_snapshot_columns(df: pd.DataFrame, horizon_key: str | None) -> pd.DataFrame:
+        """Keep a single odds snapshot horizon (drop other suffixes)."""
+        if df is None or df.empty or not horizon_key:
+            return df
+
+        normalized = str(horizon_key).strip().lower()
+        horizon_map = {
+            "cutoff": "",
+            "default": "",
+            "": "",
+            "2h": "_2h",
+            "h120m": "_2h",
+            "6h": "_6h",
+            "h360m": "_6h",
+            "24h": "_24h",
+            "h1440m": "_24h",
+            "open": "_open",
+        }
+        allowed_suffix = horizon_map.get(normalized, normalized)
+        if allowed_suffix and not allowed_suffix.startswith("_"):
+            allowed_suffix = f"_{allowed_suffix.lstrip('_')}"
+
+        horizon_re = re.compile(r"^(?P<base>.+)(?P<suffix>_2h|_6h|_24h|_open)$")
+        suffixes_seen: dict[str, set[str]] = {}
+        for col in df.columns:
+            match = horizon_re.match(col)
+            if match:
+                suffixes_seen.setdefault(match.group("base"), set()).add(match.group("suffix"))
+
+        drop_cols: list[str] = []
+        for col in df.columns:
+            match = horizon_re.match(col)
+            if match:
+                suffix = match.group("suffix")
+                if suffix != allowed_suffix:
+                    drop_cols.append(col)
+            else:
+                base = col
+                if base in suffixes_seen and allowed_suffix:
+                    drop_cols.append(col)
+
+        if drop_cols:
+            df = df.drop(columns=drop_cols, errors="ignore")
+            logger.info(
+                "Removed %d odds snapshot columns outside horizon '%s'.",
+                len(drop_cols),
+                horizon_key,
+            )
+        return df
+
     def _ensure_player_game_actuals(self) -> pd.DataFrame:
         if self._player_game_actuals is not None:
             return self._player_game_actuals
@@ -2315,7 +2368,34 @@
                             df_problem[col] = df_problem[col].fillna(df_problem[col].mean())
 
                 df_problem = self._inject_composed_features(df_problem)
-            
+
+            odds_horizon = problem_copy.get("odds_horizon")
+            if odds_horizon:
+                df_problem = self._filter_odds_snapshot_columns(df_problem, odds_horizon)
+
+            # Leak guard on the problem-scoped frame
+            allow_prefixes = tuple(problem_copy.get('feature_prefixes_to_include') or [])
+            allow_exact = set(problem_copy.get('other_features_to_include') or [])
+            allow_exact.update(input_preds or [])
+            if self.target_col:
+                allow_exact.add(self.target_col)
+            df_problem, leak_info = enforce_leak_guard(
+                df_problem,
+                policy=DEFAULT_LEAK_POLICY,
+                allow_prefixes=allow_prefixes,
+                allow_exact=allow_exact,
+                drop_banned=True,
+                drop_non_allowlisted=False,
+                raise_on_banned=True,
+            )
+            if leak_info.dropped:
+                logger.info(
+                    "Dropped %d leak-prone columns for %s: %s",
+                    len(leak_info.dropped),
+                    problem_name,
+                    sorted(leak_info.dropped),
+                )
+
             self._normalize_datetime_like_columns(df_problem, problem_name)
             df_problem[self.time_col] = pd.to_datetime(df_problem[self.time_col])
             sort_cols = [self.time_col]
diff --git a/tests/test_data_leak_guard.py b/tests/test_data_leak_guard.py
index 8061f2760c0898aaeda29026859e1b9ff5644ba4..3e56665921db89ea523bbdb205d1bb90c21893df
--- a/tests/test_data_leak_guard.py
+++ b/tests/test_data_leak_guard.py
@@ -3,6 +3,14 @@
 import yaml
 from pathlib import Path
 
+import polars as pl
+
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    enforce_leak_guard,
+    evaluate_leak_prone_columns,
+)
+
 
 PROJECT_ROOT = Path(__file__).resolve().parents[1]
 TRAINING_CONFIG = PROJECT_ROOT / "config" / "training.yaml"
@@ -48,3 +56,41 @@
     )
 
 
+def test_leak_guard_flags_pattern_columns():
+    cols = [
+        "market_anytime_td_prob",
+        "final_score",
+        "postgame_anytime_td",
+        "actual_td_count",
+        "safe_feature",
+    ]
+    result = evaluate_leak_prone_columns(cols, policy=DEFAULT_LEAK_POLICY)
+    assert set(result.banned.keys()) == {"final_score", "postgame_anytime_td", "actual_td_count"}
+    assert "safe_feature" in result.kept
+    assert "market_anytime_td_prob" in result.kept
+
+
+def test_enforce_leak_guard_drops_banned_and_keeps_allowlisted():
+    df = pl.DataFrame(
+        {
+            "game_id": ["g1", "g2"],
+            "safe_feature": [1.0, 2.0],
+            "postgame_anytime_td": [1, 0],
+            "final_score": [30, 24],
+        }
+    )
+    cleaned, info = enforce_leak_guard(
+        df,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_prefixes=("safe_",),
+        allow_exact=("game_id",),
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=False,
+    )
+    assert "postgame_anytime_td" not in cleaned.columns
+    assert "final_score" not in cleaned.columns
+    assert "safe_feature" in cleaned.columns
+    assert "game_id" in cleaned.columns
+    assert set(info.dropped) == {"postgame_anytime_td", "final_score"}
+
diff --git a/tests/test_odds_horizon_filter.py b/tests/test_odds_horizon_filter.py
new file mode 100644
index 0000000000000000000000000000000000000000..70e9c681f63972bbb6e70008e286cf13f6881853
--- /dev/null
+++ b/tests/test_odds_horizon_filter.py
@@ -0,0 +1,35 @@
+from __future__ import annotations
+
+import pandas as pd
+import pytest
+
+train_module = pytest.importorskip("pipeline.train")
+ModelTrainer = train_module.ModelTrainer
+
+
+def test_filter_odds_snapshot_columns_cutoff_keeps_base_only():
+    df = pd.DataFrame(
+        {
+            "market_anytime_td_prob": [0.1, 0.2],
+            "market_anytime_td_prob_2h": [0.15, 0.25],
+            "market_anytime_td_prob_6h": [0.2, 0.3],
+            "other_feature": [1, 2],
+        }
+    )
+    filtered = ModelTrainer._filter_odds_snapshot_columns(df.copy(), "cutoff")
+    assert "market_anytime_td_prob" in filtered.columns
+    assert "market_anytime_td_prob_2h" not in filtered.columns
+    assert "market_anytime_td_prob_6h" not in filtered.columns
+    assert "other_feature" in filtered.columns
+
+
+def test_filter_odds_snapshot_columns_specific_suffix():
+    df = pd.DataFrame(
+        {
+            "market_anytime_td_prob": [0.1, 0.2],
+            "market_anytime_td_prob_2h": [0.15, 0.25],
+            "market_anytime_td_prob_6h": [0.2, 0.3],
+        }
+    )
+    filtered = ModelTrainer._filter_odds_snapshot_columns(df.copy(), "6h")
+    assert list(filtered.columns) == ["market_anytime_td_prob_6h"]
diff --git a/utils/feature/leak_guard.py b/utils/feature/leak_guard.py
new file mode 100644
index 0000000000000000000000000000000000000000..9faf8cfffc436e0934b2f410aaf252e52f4f95df
--- /dev/null
+++ b/utils/feature/leak_guard.py
@@ -0,0 +1,273 @@
+"""Leak guardrails for feature matrices.
+
+This module centralizes pattern-based leak detection so both feature assembly
+and training can fail fast when post-outcome columns sneak into the data.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+from datetime import datetime
+import json
+import re
+from typing import Iterable, Mapping, Sequence
+
+import polars as pl
+
+from utils.general.constants import IDENTIFIER_COLUMNS, LEAK_PRONE_COLUMNS, NFL_TARGET_COLUMNS
+
+try:  # Optional dependency when imported from training (pandas path)
+    import pandas as pd  # type: ignore
+except Exception:  # pragma: no cover - optional dependency
+    pd = None
+
+
+@dataclass(frozen=True)
+class LeakPolicy:
+    version: str
+    banned_exact: set[str]
+    banned_prefixes: tuple[str, ...]
+    banned_suffixes: tuple[str, ...]
+    banned_regex: tuple[tuple[re.Pattern[str], str], ...]
+    description: str = ""
+
+
+@dataclass
+class LeakCheckResult:
+    policy_version: str
+    banned: dict[str, str]
+    kept: list[str]
+    dropped: list[str]
+    allowlist_kept: list[str]
+
+
+# Core policy tuned for anytime-TD style problems (can be extended per-problem).
+_BASE_BANNED_EXACT = set(LEAK_PRONE_COLUMNS) | {
+    "final_score",
+    "final_total",
+    "points_scored",
+    "actual_td_count",
+    "actual_anytime_td",
+    "postgame_anytime_td",
+    "postgame_td_count",
+}
+_BASE_BANNED_PREFIXES = (
+    "postgame_",
+    "post_game_",
+    "post_",
+    "live_",
+    "actual_",
+    "realized_",
+    "final_",
+    "postmatch_",
+)
+_BASE_BANNED_SUFFIXES = (
+    "_post",
+    "_postgame",
+    "_final",
+    "_fullgame",
+    "_actual",
+)
+_BASE_BANNED_REGEX: tuple[tuple[re.Pattern[str], str], ...] = (
+    (re.compile(r".*post.?game.*", flags=re.IGNORECASE), "postgame marker"),
+    (re.compile(r".*final_score.*", flags=re.IGNORECASE), "final score"),
+    (re.compile(r".*actual.*td.*", flags=re.IGNORECASE), "actual TD total"),
+    (re.compile(r".*anytime_td.*(post|final|actual).*", flags=re.IGNORECASE), "post-decision anytime TD"),
+    (re.compile(r".*fullgame.*", flags=re.IGNORECASE), "full game cumulative value"),
+)
+
+DEFAULT_LEAK_POLICY = LeakPolicy(
+    version="v1",
+    description="Core post-outcome leak guard for NFL anytime TD features.",
+    banned_exact=_BASE_BANNED_EXACT,
+    banned_prefixes=_BASE_BANNED_PREFIXES,
+    banned_suffixes=_BASE_BANNED_SUFFIXES,
+    banned_regex=_BASE_BANNED_REGEX,
+)
+
+
+def _ensure_sequence(value: Sequence[str] | str | None) -> tuple[str, ...]:
+    if value is None:
+        return ()
+    if isinstance(value, str):
+        return (value,)
+    return tuple(value)
+
+
+def evaluate_leak_prone_columns(
+    columns: Iterable[str],
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+) -> LeakCheckResult:
+    """Identify leak-prone columns using the configured policy."""
+
+    banned: dict[str, str] = {}
+    columns_list = list(columns)
+    for col in columns_list:
+        if col in policy.banned_exact:
+            banned[col] = "exact"
+            continue
+        for prefix in policy.banned_prefixes:
+            if col.startswith(prefix):
+                banned[col] = f"prefix:{prefix}"
+                break
+        if col in banned:
+            continue
+        for suffix in policy.banned_suffixes:
+            if col.endswith(suffix):
+                banned[col] = f"suffix:{suffix}"
+                break
+        if col in banned:
+            continue
+        for pattern, reason in policy.banned_regex:
+            if pattern.match(col):
+                banned[col] = reason
+                break
+
+    kept = [c for c in columns_list if c not in banned]
+    return LeakCheckResult(
+        policy_version=policy.version,
+        banned=banned,
+        kept=kept,
+        dropped=[],
+        allowlist_kept=[],
+    )
+
+
+def enforce_leak_guard(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    allow_prefixes: Sequence[str] | str | None = None,
+    allow_exact: Sequence[str] | str | None = None,
+    drop_banned: bool = True,
+    drop_non_allowlisted: bool = False,
+    raise_on_banned: bool = True,
+) -> tuple[pl.DataFrame | "pd.DataFrame", LeakCheckResult]:
+    """Apply leak guardrails to a feature frame.
+
+    Parameters
+    ----------
+    df : DataFrame
+        Polars or pandas DataFrame.
+    policy : LeakPolicy
+        Leak policy to apply.
+    allow_prefixes : Sequence[str] | str | None
+        Optional prefixes that define the allowed feature surface for a problem.
+    allow_exact : Sequence[str] | str | None
+        Explicitly allowed columns (e.g., identifiers).
+    drop_banned : bool
+        If True, drop any banned columns automatically.
+    drop_non_allowlisted : bool
+        If True, drop columns that are not covered by allow_prefixes/allow_exact/identifiers/targets.
+    raise_on_banned : bool
+        If True, raise when banned columns are detected (after optional drop).
+    """
+
+    result = evaluate_leak_prone_columns(df.columns, policy=policy)
+    dropped: list[str] = []
+
+    allow_prefixes = _ensure_sequence(allow_prefixes)
+    allow_exact = set(_ensure_sequence(allow_exact))
+    allow_exact.update({col for col in IDENTIFIER_COLUMNS if col in df.columns})
+    allow_exact.update({col for col in NFL_TARGET_COLUMNS if col in df.columns})
+
+    # Permit allowlisted columns even if they match a banned rule (e.g., labels)
+    banned = {col: reason for col, reason in result.banned.items() if col not in allow_exact}
+
+    if banned and drop_banned:
+        df = df.drop(list(banned.keys()))
+        dropped.extend(banned.keys())
+
+    if banned and raise_on_banned:
+        raise ValueError(f"Leak-prone columns detected: {sorted(banned.items())}")
+
+    allowlist_cols: set[str] = set()
+    if allow_prefixes:
+        allowlist_cols.update({c for c in df.columns if c.startswith(allow_prefixes)})
+    allowlist_cols.update({c for c in allow_exact if c in df.columns})
+
+    if drop_non_allowlisted and allowlist_cols:
+        drop_candidates = [c for c in df.columns if c not in allowlist_cols]
+        if drop_candidates:
+            df = df.drop(drop_candidates)
+            dropped.extend(drop_candidates)
+
+    if drop_non_allowlisted and not allowlist_cols:
+        raise ValueError("No allowlisted columns remain after applying leak guard allowlist.")
+
+    # Store adjusted banned info on the result
+    result.banned = banned
+    result.dropped = dropped
+    result.kept = [c for c in df.columns]
+    result.allowlist_kept = sorted(list(allowlist_cols)) if allowlist_cols else []
+    return df, result
+
+
+def build_schema_snapshot(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    metadata: Mapping[str, object] | None = None,
+    banned: Mapping[str, str] | None = None,
+) -> dict:
+    """Render a schema snapshot describing each column and whether it was flagged."""
+
+    banned = banned or {}
+    meta = {
+        "generated_at_utc": datetime.utcnow().isoformat(),
+        "policy_version": policy.version,
+    }
+    meta.update(metadata or {})
+
+    # Extract columns / dtypes
+    if isinstance(df, pl.DataFrame):
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+    else:  # pandas or pandas-like
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+
+    schema = {
+        "metadata": meta,
+        "columns": [],
+    }
+
+    for col, dtype in cols_and_dtypes:
+        tags: list[str] = []
+        if col in IDENTIFIER_COLUMNS:
+            tags.append("id")
+        if col in NFL_TARGET_COLUMNS:
+            tags.append("label")
+        if col.startswith("market_"):
+            tags.append("odds")
+        if col.startswith("injury_") or col.startswith("practice_"):
+            tags.append("injury")
+        if col.startswith("weather_"):
+            tags.append("weather")
+        if col.startswith("ps_"):
+            tags.append("pre_snap")
+        schema["columns"].append(
+            {
+                "name": col,
+                "dtype": dtype,
+                "banned": col in banned,
+                "tags": tags,
+            }
+        )
+    return schema
+
+
+def write_schema_snapshot(path, schema: Mapping[str, object]) -> None:
+    path.parent.mkdir(parents=True, exist_ok=True)
+    with open(path, "w") as fp:
+        json.dump(schema, fp, indent=2, sort_keys=True)
+
+
+__all__ = [
+    "DEFAULT_LEAK_POLICY",
+    "LeakPolicy",
+    "LeakCheckResult",
+    "evaluate_leak_prone_columns",
+    "enforce_leak_guard",
+    "build_schema_snapshot",
+    "write_schema_snapshot",
+]
diff --git a/utils/general/constants.py b/utils/general/constants.py
index d94b4260ad877484da843fa99ae2caf37e8493f4..dea87caa354d94e4a08b1762d2bd8dcd4c8caa3a
--- a/utils/general/constants.py
+++ b/utils/general/constants.py
@@ -211,7 +211,17 @@
 
 NFL_TARGET_COLUMNS: Tuple[str, ...] = (
     'anytime_td',
+    'anytime_td_offense',
+    'anytime_td_all',
+    'anytime_td_rush',
+    'anytime_td_rec',
+    'anytime_td_pass_thrown',
     'td_count',
+    'td_count_offense',
+    'td_count_all',
+    'passing_td',
+    'rushing_td_count',
+    'receiving_td_count',
     'receiving_yards',
     'rushing_yards',
     'passing_yards',


thinking
**Updating plan statuses**
Plan update
  ✓ Add structured leak-guard policy helper and integrate into feature/train pipelines with schema snapshots.
  ✓ Align odds features to decision-time horizons from config and add assertions/logging.
  ✓ Expand tests for leak patterns and odds snapshot selection; document new config knobs briefly.
file update:
diff --git a/config/training.yaml b/config/training.yaml
index 3953818d861d0410246bff132110722a3ce44007..c2b6053b488caa71f9078ff100d049f723ae1548
--- a/config/training.yaml
+++ b/config/training.yaml
@@ -476,6 +476,7 @@
   - name: 'anytime_td'
     target_col: 'anytime_td'
     label_version: 'v1_any_offense'
+    odds_horizon: 'cutoff'  # Restrict odds features to the decision-time snapshot
     task_type: 'classification'
     input_predictions:
       - 'availability_active'
diff --git a/docs/pre_snap_semantics.md b/docs/pre_snap_semantics.md
index 7d58f2f5139d77b00c6c4a1df16648d0601b89ff..d5a996dffd7b8e94ca096b2872314b1c97a80049
--- a/docs/pre_snap_semantics.md
+++ b/docs/pre_snap_semantics.md
@@ -29,3 +29,8 @@
 ---------------
 - Only `ps_hist_*` features (including the `ps_hist_tracking_*` coverage rolls) are allowed as inputs via `feature_prefixes_to_include`.
 - Base `ps_game_*` and `ps_tracking_*` columns remain in the data for diagnostics/labeling but are blocked by `columns_to_discard` and `LEAK_PRONE_COLUMNS`.
+
+Decision-time odds snapshots
+----------------------------
+- Odds features are now filtered to a single horizon via `odds_horizon` in `config/training.yaml` (e.g., `cutoff` keeps the decision-time snapshot and drops `_2h/_6h/_24h/_open` variants).
+- Feature builds emit a schema snapshot under `audit/feature/schema/anytime_td/` capturing dtypes and any leak-guard flags for traceability.
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 5ba68e8bf1acd3a789a76a8857674e6f6433017b..0210d5b7e7ed60a8de7a126d64f5ed76326474c8
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -14,7 +14,7 @@
 
 import logging
 import os
-from datetime import date, timedelta
+from datetime import date, datetime, timedelta
 from typing import Sequence
 
 import polars as pl
@@ -37,6 +37,12 @@
     add_offense_context_features_training,
     _append_offense_context_columns,
 )
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    build_schema_snapshot,
+    enforce_leak_guard,
+    write_schema_snapshot,
+)
 from utils.feature.weather_features import (
     add_weather_forecast_features_training,
     append_weather_context_flags,
@@ -931,6 +937,32 @@
     if market_exprs:
         df_player_game_all = df_player_game_all.with_columns(market_exprs)
     
+    # Leak guard + schema snapshot before persisting
+    spec = get_label_spec(label_version)
+    allow_exact = {spec.primary, *spec.labels.keys(), *spec.aliases.keys()}
+    df_player_game_all, leak_result = enforce_leak_guard(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_exact=allow_exact,
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=True,
+    )
+
+    schema = build_schema_snapshot(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        metadata={
+            "cutoff_label": cutoff_label,
+            "label_version": spec.name,
+        },
+        banned=leak_result.banned,
+    )
+    schema_dir = FEATURE_AUDIT_DIR / "schema" / "anytime_td"
+    schema_path = schema_dir / f"{cutoff_label}_{datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')}.json"
+    write_schema_snapshot(schema_path, schema)
+    logging.info("    Schema snapshot written → %s", schema_path)
+
     # Write final feature matrix
     df_player_game_all = df_player_game_all.with_columns(
         pl.lit(current_cutoff_hours).cast(pl.Float32).alias("decision_horizon_hours")
@@ -951,7 +983,6 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    spec = get_label_spec(label_version)
     label_candidates = {spec.primary, "anytime_td"}
     for label_col in label_candidates:
         if label_col in df_player_game_all.columns:
diff --git a/pipeline/train.py b/pipeline/train.py
index fe70207dcdf25d209ee3ad55080b7ce826347c44..7c220514d006a3d4815d65a8af9ec7551ccf587e
--- a/pipeline/train.py
+++ b/pipeline/train.py
@@ -4,6 +4,7 @@
 import sys
 import logging
 import math
+import re
 
 
 # Move logging to top and remove global thread pinning
@@ -98,6 +99,7 @@
     fit_team_conformal_sums,
     composite_sum_interval,
 )
+from utils.feature.leak_guard import DEFAULT_LEAK_POLICY, enforce_leak_guard
 from utils.feature.targets import require_target_column
 
 # Ignore specific, noisy warnings from dependencies
@@ -793,6 +795,57 @@
             )
         return df
 
+    @staticmethod
+    def _filter_odds_snapshot_columns(df: pd.DataFrame, horizon_key: str | None) -> pd.DataFrame:
+        """Keep a single odds snapshot horizon (drop other suffixes)."""
+        if df is None or df.empty or not horizon_key:
+            return df
+
+        normalized = str(horizon_key).strip().lower()
+        horizon_map = {
+            "cutoff": "",
+            "default": "",
+            "": "",
+            "2h": "_2h",
+            "h120m": "_2h",
+            "6h": "_6h",
+            "h360m": "_6h",
+            "24h": "_24h",
+            "h1440m": "_24h",
+            "open": "_open",
+        }
+        allowed_suffix = horizon_map.get(normalized, normalized)
+        if allowed_suffix and not allowed_suffix.startswith("_"):
+            allowed_suffix = f"_{allowed_suffix.lstrip('_')}"
+
+        horizon_re = re.compile(r"^(?P<base>.+)(?P<suffix>_2h|_6h|_24h|_open)$")
+        suffixes_seen: dict[str, set[str]] = {}
+        for col in df.columns:
+            match = horizon_re.match(col)
+            if match:
+                suffixes_seen.setdefault(match.group("base"), set()).add(match.group("suffix"))
+
+        drop_cols: list[str] = []
+        for col in df.columns:
+            match = horizon_re.match(col)
+            if match:
+                suffix = match.group("suffix")
+                if suffix != allowed_suffix:
+                    drop_cols.append(col)
+            else:
+                base = col
+                if base in suffixes_seen and allowed_suffix:
+                    drop_cols.append(col)
+
+        if drop_cols:
+            df = df.drop(columns=drop_cols, errors="ignore")
+            logger.info(
+                "Removed %d odds snapshot columns outside horizon '%s'.",
+                len(drop_cols),
+                horizon_key,
+            )
+        return df
+
     def _ensure_player_game_actuals(self) -> pd.DataFrame:
         if self._player_game_actuals is not None:
             return self._player_game_actuals
@@ -2315,7 +2368,34 @@
                             df_problem[col] = df_problem[col].fillna(df_problem[col].mean())
 
                 df_problem = self._inject_composed_features(df_problem)
-            
+
+            odds_horizon = problem_copy.get("odds_horizon")
+            if odds_horizon:
+                df_problem = self._filter_odds_snapshot_columns(df_problem, odds_horizon)
+
+            # Leak guard on the problem-scoped frame
+            allow_prefixes = tuple(problem_copy.get('feature_prefixes_to_include') or [])
+            allow_exact = set(problem_copy.get('other_features_to_include') or [])
+            allow_exact.update(input_preds or [])
+            if self.target_col:
+                allow_exact.add(self.target_col)
+            df_problem, leak_info = enforce_leak_guard(
+                df_problem,
+                policy=DEFAULT_LEAK_POLICY,
+                allow_prefixes=allow_prefixes,
+                allow_exact=allow_exact,
+                drop_banned=True,
+                drop_non_allowlisted=False,
+                raise_on_banned=True,
+            )
+            if leak_info.dropped:
+                logger.info(
+                    "Dropped %d leak-prone columns for %s: %s",
+                    len(leak_info.dropped),
+                    problem_name,
+                    sorted(leak_info.dropped),
+                )
+
             self._normalize_datetime_like_columns(df_problem, problem_name)
             df_problem[self.time_col] = pd.to_datetime(df_problem[self.time_col])
             sort_cols = [self.time_col]
diff --git a/tests/test_data_leak_guard.py b/tests/test_data_leak_guard.py
index 8061f2760c0898aaeda29026859e1b9ff5644ba4..3e56665921db89ea523bbdb205d1bb90c21893df
--- a/tests/test_data_leak_guard.py
+++ b/tests/test_data_leak_guard.py
@@ -3,6 +3,14 @@
 import yaml
 from pathlib import Path
 
+import polars as pl
+
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    enforce_leak_guard,
+    evaluate_leak_prone_columns,
+)
+
 
 PROJECT_ROOT = Path(__file__).resolve().parents[1]
 TRAINING_CONFIG = PROJECT_ROOT / "config" / "training.yaml"
@@ -48,3 +56,41 @@
     )
 
 
+def test_leak_guard_flags_pattern_columns():
+    cols = [
+        "market_anytime_td_prob",
+        "final_score",
+        "postgame_anytime_td",
+        "actual_td_count",
+        "safe_feature",
+    ]
+    result = evaluate_leak_prone_columns(cols, policy=DEFAULT_LEAK_POLICY)
+    assert set(result.banned.keys()) == {"final_score", "postgame_anytime_td", "actual_td_count"}
+    assert "safe_feature" in result.kept
+    assert "market_anytime_td_prob" in result.kept
+
+
+def test_enforce_leak_guard_drops_banned_and_keeps_allowlisted():
+    df = pl.DataFrame(
+        {
+            "game_id": ["g1", "g2"],
+            "safe_feature": [1.0, 2.0],
+            "postgame_anytime_td": [1, 0],
+            "final_score": [30, 24],
+        }
+    )
+    cleaned, info = enforce_leak_guard(
+        df,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_prefixes=("safe_",),
+        allow_exact=("game_id",),
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=False,
+    )
+    assert "postgame_anytime_td" not in cleaned.columns
+    assert "final_score" not in cleaned.columns
+    assert "safe_feature" in cleaned.columns
+    assert "game_id" in cleaned.columns
+    assert set(info.dropped) == {"postgame_anytime_td", "final_score"}
+
diff --git a/tests/test_odds_horizon_filter.py b/tests/test_odds_horizon_filter.py
new file mode 100644
index 0000000000000000000000000000000000000000..70e9c681f63972bbb6e70008e286cf13f6881853
--- /dev/null
+++ b/tests/test_odds_horizon_filter.py
@@ -0,0 +1,35 @@
+from __future__ import annotations
+
+import pandas as pd
+import pytest
+
+train_module = pytest.importorskip("pipeline.train")
+ModelTrainer = train_module.ModelTrainer
+
+
+def test_filter_odds_snapshot_columns_cutoff_keeps_base_only():
+    df = pd.DataFrame(
+        {
+            "market_anytime_td_prob": [0.1, 0.2],
+            "market_anytime_td_prob_2h": [0.15, 0.25],
+            "market_anytime_td_prob_6h": [0.2, 0.3],
+            "other_feature": [1, 2],
+        }
+    )
+    filtered = ModelTrainer._filter_odds_snapshot_columns(df.copy(), "cutoff")
+    assert "market_anytime_td_prob" in filtered.columns
+    assert "market_anytime_td_prob_2h" not in filtered.columns
+    assert "market_anytime_td_prob_6h" not in filtered.columns
+    assert "other_feature" in filtered.columns
+
+
+def test_filter_odds_snapshot_columns_specific_suffix():
+    df = pd.DataFrame(
+        {
+            "market_anytime_td_prob": [0.1, 0.2],
+            "market_anytime_td_prob_2h": [0.15, 0.25],
+            "market_anytime_td_prob_6h": [0.2, 0.3],
+        }
+    )
+    filtered = ModelTrainer._filter_odds_snapshot_columns(df.copy(), "6h")
+    assert list(filtered.columns) == ["market_anytime_td_prob_6h"]
diff --git a/utils/feature/leak_guard.py b/utils/feature/leak_guard.py
new file mode 100644
index 0000000000000000000000000000000000000000..9faf8cfffc436e0934b2f410aaf252e52f4f95df
--- /dev/null
+++ b/utils/feature/leak_guard.py
@@ -0,0 +1,273 @@
+"""Leak guardrails for feature matrices.
+
+This module centralizes pattern-based leak detection so both feature assembly
+and training can fail fast when post-outcome columns sneak into the data.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+from datetime import datetime
+import json
+import re
+from typing import Iterable, Mapping, Sequence
+
+import polars as pl
+
+from utils.general.constants import IDENTIFIER_COLUMNS, LEAK_PRONE_COLUMNS, NFL_TARGET_COLUMNS
+
+try:  # Optional dependency when imported from training (pandas path)
+    import pandas as pd  # type: ignore
+except Exception:  # pragma: no cover - optional dependency
+    pd = None
+
+
+@dataclass(frozen=True)
+class LeakPolicy:
+    version: str
+    banned_exact: set[str]
+    banned_prefixes: tuple[str, ...]
+    banned_suffixes: tuple[str, ...]
+    banned_regex: tuple[tuple[re.Pattern[str], str], ...]
+    description: str = ""
+
+
+@dataclass
+class LeakCheckResult:
+    policy_version: str
+    banned: dict[str, str]
+    kept: list[str]
+    dropped: list[str]
+    allowlist_kept: list[str]
+
+
+# Core policy tuned for anytime-TD style problems (can be extended per-problem).
+_BASE_BANNED_EXACT = set(LEAK_PRONE_COLUMNS) | {
+    "final_score",
+    "final_total",
+    "points_scored",
+    "actual_td_count",
+    "actual_anytime_td",
+    "postgame_anytime_td",
+    "postgame_td_count",
+}
+_BASE_BANNED_PREFIXES = (
+    "postgame_",
+    "post_game_",
+    "post_",
+    "live_",
+    "actual_",
+    "realized_",
+    "final_",
+    "postmatch_",
+)
+_BASE_BANNED_SUFFIXES = (
+    "_post",
+    "_postgame",
+    "_final",
+    "_fullgame",
+    "_actual",
+)
+_BASE_BANNED_REGEX: tuple[tuple[re.Pattern[str], str], ...] = (
+    (re.compile(r".*post.?game.*", flags=re.IGNORECASE), "postgame marker"),
+    (re.compile(r".*final_score.*", flags=re.IGNORECASE), "final score"),
+    (re.compile(r".*actual.*td.*", flags=re.IGNORECASE), "actual TD total"),
+    (re.compile(r".*anytime_td.*(post|final|actual).*", flags=re.IGNORECASE), "post-decision anytime TD"),
+    (re.compile(r".*fullgame.*", flags=re.IGNORECASE), "full game cumulative value"),
+)
+
+DEFAULT_LEAK_POLICY = LeakPolicy(
+    version="v1",
+    description="Core post-outcome leak guard for NFL anytime TD features.",
+    banned_exact=_BASE_BANNED_EXACT,
+    banned_prefixes=_BASE_BANNED_PREFIXES,
+    banned_suffixes=_BASE_BANNED_SUFFIXES,
+    banned_regex=_BASE_BANNED_REGEX,
+)
+
+
+def _ensure_sequence(value: Sequence[str] | str | None) -> tuple[str, ...]:
+    if value is None:
+        return ()
+    if isinstance(value, str):
+        return (value,)
+    return tuple(value)
+
+
+def evaluate_leak_prone_columns(
+    columns: Iterable[str],
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+) -> LeakCheckResult:
+    """Identify leak-prone columns using the configured policy."""
+
+    banned: dict[str, str] = {}
+    columns_list = list(columns)
+    for col in columns_list:
+        if col in policy.banned_exact:
+            banned[col] = "exact"
+            continue
+        for prefix in policy.banned_prefixes:
+            if col.startswith(prefix):
+                banned[col] = f"prefix:{prefix}"
+                break
+        if col in banned:
+            continue
+        for suffix in policy.banned_suffixes:
+            if col.endswith(suffix):
+                banned[col] = f"suffix:{suffix}"
+                break
+        if col in banned:
+            continue
+        for pattern, reason in policy.banned_regex:
+            if pattern.match(col):
+                banned[col] = reason
+                break
+
+    kept = [c for c in columns_list if c not in banned]
+    return LeakCheckResult(
+        policy_version=policy.version,
+        banned=banned,
+        kept=kept,
+        dropped=[],
+        allowlist_kept=[],
+    )
+
+
+def enforce_leak_guard(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    allow_prefixes: Sequence[str] | str | None = None,
+    allow_exact: Sequence[str] | str | None = None,
+    drop_banned: bool = True,
+    drop_non_allowlisted: bool = False,
+    raise_on_banned: bool = True,
+) -> tuple[pl.DataFrame | "pd.DataFrame", LeakCheckResult]:
+    """Apply leak guardrails to a feature frame.
+
+    Parameters
+    ----------
+    df : DataFrame
+        Polars or pandas DataFrame.
+    policy : LeakPolicy
+        Leak policy to apply.
+    allow_prefixes : Sequence[str] | str | None
+        Optional prefixes that define the allowed feature surface for a problem.
+    allow_exact : Sequence[str] | str | None
+        Explicitly allowed columns (e.g., identifiers).
+    drop_banned : bool
+        If True, drop any banned columns automatically.
+    drop_non_allowlisted : bool
+        If True, drop columns that are not covered by allow_prefixes/allow_exact/identifiers/targets.
+    raise_on_banned : bool
+        If True, raise when banned columns are detected (after optional drop).
+    """
+
+    result = evaluate_leak_prone_columns(df.columns, policy=policy)
+    dropped: list[str] = []
+
+    allow_prefixes = _ensure_sequence(allow_prefixes)
+    allow_exact = set(_ensure_sequence(allow_exact))
+    allow_exact.update({col for col in IDENTIFIER_COLUMNS if col in df.columns})
+    allow_exact.update({col for col in NFL_TARGET_COLUMNS if col in df.columns})
+
+    # Permit allowlisted columns even if they match a banned rule (e.g., labels)
+    banned = {col: reason for col, reason in result.banned.items() if col not in allow_exact}
+
+    if banned and drop_banned:
+        df = df.drop(list(banned.keys()))
+        dropped.extend(banned.keys())
+
+    if banned and raise_on_banned:
+        raise ValueError(f"Leak-prone columns detected: {sorted(banned.items())}")
+
+    allowlist_cols: set[str] = set()
+    if allow_prefixes:
+        allowlist_cols.update({c for c in df.columns if c.startswith(allow_prefixes)})
+    allowlist_cols.update({c for c in allow_exact if c in df.columns})
+
+    if drop_non_allowlisted and allowlist_cols:
+        drop_candidates = [c for c in df.columns if c not in allowlist_cols]
+        if drop_candidates:
+            df = df.drop(drop_candidates)
+            dropped.extend(drop_candidates)
+
+    if drop_non_allowlisted and not allowlist_cols:
+        raise ValueError("No allowlisted columns remain after applying leak guard allowlist.")
+
+    # Store adjusted banned info on the result
+    result.banned = banned
+    result.dropped = dropped
+    result.kept = [c for c in df.columns]
+    result.allowlist_kept = sorted(list(allowlist_cols)) if allowlist_cols else []
+    return df, result
+
+
+def build_schema_snapshot(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    metadata: Mapping[str, object] | None = None,
+    banned: Mapping[str, str] | None = None,
+) -> dict:
+    """Render a schema snapshot describing each column and whether it was flagged."""
+
+    banned = banned or {}
+    meta = {
+        "generated_at_utc": datetime.utcnow().isoformat(),
+        "policy_version": policy.version,
+    }
+    meta.update(metadata or {})
+
+    # Extract columns / dtypes
+    if isinstance(df, pl.DataFrame):
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+    else:  # pandas or pandas-like
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+
+    schema = {
+        "metadata": meta,
+        "columns": [],
+    }
+
+    for col, dtype in cols_and_dtypes:
+        tags: list[str] = []
+        if col in IDENTIFIER_COLUMNS:
+            tags.append("id")
+        if col in NFL_TARGET_COLUMNS:
+            tags.append("label")
+        if col.startswith("market_"):
+            tags.append("odds")
+        if col.startswith("injury_") or col.startswith("practice_"):
+            tags.append("injury")
+        if col.startswith("weather_"):
+            tags.append("weather")
+        if col.startswith("ps_"):
+            tags.append("pre_snap")
+        schema["columns"].append(
+            {
+                "name": col,
+                "dtype": dtype,
+                "banned": col in banned,
+                "tags": tags,
+            }
+        )
+    return schema
+
+
+def write_schema_snapshot(path, schema: Mapping[str, object]) -> None:
+    path.parent.mkdir(parents=True, exist_ok=True)
+    with open(path, "w") as fp:
+        json.dump(schema, fp, indent=2, sort_keys=True)
+
+
+__all__ = [
+    "DEFAULT_LEAK_POLICY",
+    "LeakPolicy",
+    "LeakCheckResult",
+    "evaluate_leak_prone_columns",
+    "enforce_leak_guard",
+    "build_schema_snapshot",
+    "write_schema_snapshot",
+]
diff --git a/utils/general/constants.py b/utils/general/constants.py
index d94b4260ad877484da843fa99ae2caf37e8493f4..dea87caa354d94e4a08b1762d2bd8dcd4c8caa3a
--- a/utils/general/constants.py
+++ b/utils/general/constants.py
@@ -211,7 +211,17 @@
 
 NFL_TARGET_COLUMNS: Tuple[str, ...] = (
     'anytime_td',
+    'anytime_td_offense',
+    'anytime_td_all',
+    'anytime_td_rush',
+    'anytime_td_rec',
+    'anytime_td_pass_thrown',
     'td_count',
+    'td_count_offense',
+    'td_count_all',
+    'passing_td',
+    'rushing_td_count',
+    'receiving_td_count',
     'receiving_yards',
     'rushing_yards',
     'passing_yards',


thinking
**Verifying code consistency and dependencies**

I'm making sure the code compiles cleanly, checking for any unused or missing imports, especially related to leak guard and feature guard changes. I’m confirming that banned columns and allowed exact sets are handled consistently and ensuring that JSON is imported where needed. I’ll also review test readiness and gather git status for any modifications before the final steps.
exec
/bin/zsh -lc 'cd /Users/jameswest/Desktop/nfl_predict && git status --short' in /Users/jameswest/Desktop/nfl_predict succeeded in 741ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
 M codex_meta_loop.py
 M docs/rolling_window_implementation.md
 M pipeline/feature.py
 M pipeline/predict.py
 M pipeline/train.py
 M tests/test_data_leak_guard.py
 M tests/test_training_config_features.py
 M utils/collect/visual_crossing_weather.py
 M utils/collect/weather_forecasts.py
 M utils/feature/player_game_level.py
 M utils/feature/rolling_window.py
 M utils/feature/stats.py
 M utils/feature/targets.py
 M utils/general/constants.py
 M utils/train/persist.py
?? .codex_meta_logs/
?? _tmp_can_write
?? codex_output.md
?? docs/pre_snap_semantics.md
file update:
diff --git a/config/training.yaml b/config/training.yaml
index 3953818d861d0410246bff132110722a3ce44007..c2b6053b488caa71f9078ff100d049f723ae1548
--- a/config/training.yaml
+++ b/config/training.yaml
@@ -476,6 +476,7 @@
   - name: 'anytime_td'
     target_col: 'anytime_td'
     label_version: 'v1_any_offense'
+    odds_horizon: 'cutoff'  # Restrict odds features to the decision-time snapshot
     task_type: 'classification'
     input_predictions:
       - 'availability_active'
diff --git a/docs/pre_snap_semantics.md b/docs/pre_snap_semantics.md
index 7d58f2f5139d77b00c6c4a1df16648d0601b89ff..d5a996dffd7b8e94ca096b2872314b1c97a80049
--- a/docs/pre_snap_semantics.md
+++ b/docs/pre_snap_semantics.md
@@ -29,3 +29,8 @@
 ---------------
 - Only `ps_hist_*` features (including the `ps_hist_tracking_*` coverage rolls) are allowed as inputs via `feature_prefixes_to_include`.
 - Base `ps_game_*` and `ps_tracking_*` columns remain in the data for diagnostics/labeling but are blocked by `columns_to_discard` and `LEAK_PRONE_COLUMNS`.
+
+Decision-time odds snapshots
+----------------------------
+- Odds features are now filtered to a single horizon via `odds_horizon` in `config/training.yaml` (e.g., `cutoff` keeps the decision-time snapshot and drops `_2h/_6h/_24h/_open` variants).
+- Feature builds emit a schema snapshot under `audit/feature/schema/anytime_td/` capturing dtypes and any leak-guard flags for traceability.
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 5ba68e8bf1acd3a789a76a8857674e6f6433017b..0210d5b7e7ed60a8de7a126d64f5ed76326474c8
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -14,7 +14,7 @@
 
 import logging
 import os
-from datetime import date, timedelta
+from datetime import date, datetime, timedelta
 from typing import Sequence
 
 import polars as pl
@@ -37,6 +37,12 @@
     add_offense_context_features_training,
     _append_offense_context_columns,
 )
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    build_schema_snapshot,
+    enforce_leak_guard,
+    write_schema_snapshot,
+)
 from utils.feature.weather_features import (
     add_weather_forecast_features_training,
     append_weather_context_flags,
@@ -931,6 +937,32 @@
     if market_exprs:
         df_player_game_all = df_player_game_all.with_columns(market_exprs)
     
+    # Leak guard + schema snapshot before persisting
+    spec = get_label_spec(label_version)
+    allow_exact = {spec.primary, *spec.labels.keys(), *spec.aliases.keys()}
+    df_player_game_all, leak_result = enforce_leak_guard(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_exact=allow_exact,
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=True,
+    )
+
+    schema = build_schema_snapshot(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        metadata={
+            "cutoff_label": cutoff_label,
+            "label_version": spec.name,
+        },
+        banned=leak_result.banned,
+    )
+    schema_dir = FEATURE_AUDIT_DIR / "schema" / "anytime_td"
+    schema_path = schema_dir / f"{cutoff_label}_{datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')}.json"
+    write_schema_snapshot(schema_path, schema)
+    logging.info("    Schema snapshot written → %s", schema_path)
+
     # Write final feature matrix
     df_player_game_all = df_player_game_all.with_columns(
         pl.lit(current_cutoff_hours).cast(pl.Float32).alias("decision_horizon_hours")
@@ -951,7 +983,6 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    spec = get_label_spec(label_version)
     label_candidates = {spec.primary, "anytime_td"}
     for label_col in label_candidates:
         if label_col in df_player_game_all.columns:
diff --git a/pipeline/train.py b/pipeline/train.py
index fe70207dcdf25d209ee3ad55080b7ce826347c44..7c220514d006a3d4815d65a8af9ec7551ccf587e
--- a/pipeline/train.py
+++ b/pipeline/train.py
@@ -4,6 +4,7 @@
 import sys
 import logging
 import math
+import re
 
 
 # Move logging to top and remove global thread pinning
@@ -98,6 +99,7 @@
     fit_team_conformal_sums,
     composite_sum_interval,
 )
+from utils.feature.leak_guard import DEFAULT_LEAK_POLICY, enforce_leak_guard
 from utils.feature.targets import require_target_column
 
 # Ignore specific, noisy warnings from dependencies
@@ -793,6 +795,57 @@
             )
         return df
 
+    @staticmethod
+    def _filter_odds_snapshot_columns(df: pd.DataFrame, horizon_key: str | None) -> pd.DataFrame:
+        """Keep a single odds snapshot horizon (drop other suffixes)."""
+        if df is None or df.empty or not horizon_key:
+            return df
+
+        normalized = str(horizon_key).strip().lower()
+        horizon_map = {
+            "cutoff": "",
+            "default": "",
+            "": "",
+            "2h": "_2h",
+            "h120m": "_2h",
+            "6h": "_6h",
+            "h360m": "_6h",
+            "24h": "_24h",
+            "h1440m": "_24h",
+            "open": "_open",
+        }
+        allowed_suffix = horizon_map.get(normalized, normalized)
+        if allowed_suffix and not allowed_suffix.startswith("_"):
+            allowed_suffix = f"_{allowed_suffix.lstrip('_')}"
+
+        horizon_re = re.compile(r"^(?P<base>.+)(?P<suffix>_2h|_6h|_24h|_open)$")
+        suffixes_seen: dict[str, set[str]] = {}
+        for col in df.columns:
+            match = horizon_re.match(col)
+            if match:
+                suffixes_seen.setdefault(match.group("base"), set()).add(match.group("suffix"))
+
+        drop_cols: list[str] = []
+        for col in df.columns:
+            match = horizon_re.match(col)
+            if match:
+                suffix = match.group("suffix")
+                if suffix != allowed_suffix:
+                    drop_cols.append(col)
+            else:
+                base = col
+                if base in suffixes_seen and allowed_suffix:
+                    drop_cols.append(col)
+
+        if drop_cols:
+            df = df.drop(columns=drop_cols, errors="ignore")
+            logger.info(
+                "Removed %d odds snapshot columns outside horizon '%s'.",
+                len(drop_cols),
+                horizon_key,
+            )
+        return df
+
     def _ensure_player_game_actuals(self) -> pd.DataFrame:
         if self._player_game_actuals is not None:
             return self._player_game_actuals
@@ -2315,7 +2368,34 @@
                             df_problem[col] = df_problem[col].fillna(df_problem[col].mean())
 
                 df_problem = self._inject_composed_features(df_problem)
-            
+
+            odds_horizon = problem_copy.get("odds_horizon")
+            if odds_horizon:
+                df_problem = self._filter_odds_snapshot_columns(df_problem, odds_horizon)
+
+            # Leak guard on the problem-scoped frame
+            allow_prefixes = tuple(problem_copy.get('feature_prefixes_to_include') or [])
+            allow_exact = set(problem_copy.get('other_features_to_include') or [])
+            allow_exact.update(input_preds or [])
+            if self.target_col:
+                allow_exact.add(self.target_col)
+            df_problem, leak_info = enforce_leak_guard(
+                df_problem,
+                policy=DEFAULT_LEAK_POLICY,
+                allow_prefixes=allow_prefixes,
+                allow_exact=allow_exact,
+                drop_banned=True,
+                drop_non_allowlisted=False,
+                raise_on_banned=True,
+            )
+            if leak_info.dropped:
+                logger.info(
+                    "Dropped %d leak-prone columns for %s: %s",
+                    len(leak_info.dropped),
+                    problem_name,
+                    sorted(leak_info.dropped),
+                )
+
             self._normalize_datetime_like_columns(df_problem, problem_name)
             df_problem[self.time_col] = pd.to_datetime(df_problem[self.time_col])
             sort_cols = [self.time_col]
diff --git a/tests/test_data_leak_guard.py b/tests/test_data_leak_guard.py
index 8061f2760c0898aaeda29026859e1b9ff5644ba4..3e56665921db89ea523bbdb205d1bb90c21893df
--- a/tests/test_data_leak_guard.py
+++ b/tests/test_data_leak_guard.py
@@ -3,6 +3,14 @@
 import yaml
 from pathlib import Path
 
+import polars as pl
+
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    enforce_leak_guard,
+    evaluate_leak_prone_columns,
+)
+
 
 PROJECT_ROOT = Path(__file__).resolve().parents[1]
 TRAINING_CONFIG = PROJECT_ROOT / "config" / "training.yaml"
@@ -48,3 +56,41 @@
     )
 
 
+def test_leak_guard_flags_pattern_columns():
+    cols = [
+        "market_anytime_td_prob",
+        "final_score",
+        "postgame_anytime_td",
+        "actual_td_count",
+        "safe_feature",
+    ]
+    result = evaluate_leak_prone_columns(cols, policy=DEFAULT_LEAK_POLICY)
+    assert set(result.banned.keys()) == {"final_score", "postgame_anytime_td", "actual_td_count"}
+    assert "safe_feature" in result.kept
+    assert "market_anytime_td_prob" in result.kept
+
+
+def test_enforce_leak_guard_drops_banned_and_keeps_allowlisted():
+    df = pl.DataFrame(
+        {
+            "game_id": ["g1", "g2"],
+            "safe_feature": [1.0, 2.0],
+            "postgame_anytime_td": [1, 0],
+            "final_score": [30, 24],
+        }
+    )
+    cleaned, info = enforce_leak_guard(
+        df,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_prefixes=("safe_",),
+        allow_exact=("game_id",),
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=False,
+    )
+    assert "postgame_anytime_td" not in cleaned.columns
+    assert "final_score" not in cleaned.columns
+    assert "safe_feature" in cleaned.columns
+    assert "game_id" in cleaned.columns
+    assert set(info.dropped) == {"postgame_anytime_td", "final_score"}
+
diff --git a/tests/test_odds_horizon_filter.py b/tests/test_odds_horizon_filter.py
new file mode 100644
index 0000000000000000000000000000000000000000..70e9c681f63972bbb6e70008e286cf13f6881853
--- /dev/null
+++ b/tests/test_odds_horizon_filter.py
@@ -0,0 +1,35 @@
+from __future__ import annotations
+
+import pandas as pd
+import pytest
+
+train_module = pytest.importorskip("pipeline.train")
+ModelTrainer = train_module.ModelTrainer
+
+
+def test_filter_odds_snapshot_columns_cutoff_keeps_base_only():
+    df = pd.DataFrame(
+        {
+            "market_anytime_td_prob": [0.1, 0.2],
+            "market_anytime_td_prob_2h": [0.15, 0.25],
+            "market_anytime_td_prob_6h": [0.2, 0.3],
+            "other_feature": [1, 2],
+        }
+    )
+    filtered = ModelTrainer._filter_odds_snapshot_columns(df.copy(), "cutoff")
+    assert "market_anytime_td_prob" in filtered.columns
+    assert "market_anytime_td_prob_2h" not in filtered.columns
+    assert "market_anytime_td_prob_6h" not in filtered.columns
+    assert "other_feature" in filtered.columns
+
+
+def test_filter_odds_snapshot_columns_specific_suffix():
+    df = pd.DataFrame(
+        {
+            "market_anytime_td_prob": [0.1, 0.2],
+            "market_anytime_td_prob_2h": [0.15, 0.25],
+            "market_anytime_td_prob_6h": [0.2, 0.3],
+        }
+    )
+    filtered = ModelTrainer._filter_odds_snapshot_columns(df.copy(), "6h")
+    assert list(filtered.columns) == ["market_anytime_td_prob_6h"]
diff --git a/utils/feature/leak_guard.py b/utils/feature/leak_guard.py
new file mode 100644
index 0000000000000000000000000000000000000000..9faf8cfffc436e0934b2f410aaf252e52f4f95df
--- /dev/null
+++ b/utils/feature/leak_guard.py
@@ -0,0 +1,273 @@
+"""Leak guardrails for feature matrices.
+
+This module centralizes pattern-based leak detection so both feature assembly
+and training can fail fast when post-outcome columns sneak into the data.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+from datetime import datetime
+import json
+import re
+from typing import Iterable, Mapping, Sequence
+
+import polars as pl
+
+from utils.general.constants import IDENTIFIER_COLUMNS, LEAK_PRONE_COLUMNS, NFL_TARGET_COLUMNS
+
+try:  # Optional dependency when imported from training (pandas path)
+    import pandas as pd  # type: ignore
+except Exception:  # pragma: no cover - optional dependency
+    pd = None
+
+
+@dataclass(frozen=True)
+class LeakPolicy:
+    version: str
+    banned_exact: set[str]
+    banned_prefixes: tuple[str, ...]
+    banned_suffixes: tuple[str, ...]
+    banned_regex: tuple[tuple[re.Pattern[str], str], ...]
+    description: str = ""
+
+
+@dataclass
+class LeakCheckResult:
+    policy_version: str
+    banned: dict[str, str]
+    kept: list[str]
+    dropped: list[str]
+    allowlist_kept: list[str]
+
+
+# Core policy tuned for anytime-TD style problems (can be extended per-problem).
+_BASE_BANNED_EXACT = set(LEAK_PRONE_COLUMNS) | {
+    "final_score",
+    "final_total",
+    "points_scored",
+    "actual_td_count",
+    "actual_anytime_td",
+    "postgame_anytime_td",
+    "postgame_td_count",
+}
+_BASE_BANNED_PREFIXES = (
+    "postgame_",
+    "post_game_",
+    "post_",
+    "live_",
+    "actual_",
+    "realized_",
+    "final_",
+    "postmatch_",
+)
+_BASE_BANNED_SUFFIXES = (
+    "_post",
+    "_postgame",
+    "_final",
+    "_fullgame",
+    "_actual",
+)
+_BASE_BANNED_REGEX: tuple[tuple[re.Pattern[str], str], ...] = (
+    (re.compile(r".*post.?game.*", flags=re.IGNORECASE), "postgame marker"),
+    (re.compile(r".*final_score.*", flags=re.IGNORECASE), "final score"),
+    (re.compile(r".*actual.*td.*", flags=re.IGNORECASE), "actual TD total"),
+    (re.compile(r".*anytime_td.*(post|final|actual).*", flags=re.IGNORECASE), "post-decision anytime TD"),
+    (re.compile(r".*fullgame.*", flags=re.IGNORECASE), "full game cumulative value"),
+)
+
+DEFAULT_LEAK_POLICY = LeakPolicy(
+    version="v1",
+    description="Core post-outcome leak guard for NFL anytime TD features.",
+    banned_exact=_BASE_BANNED_EXACT,
+    banned_prefixes=_BASE_BANNED_PREFIXES,
+    banned_suffixes=_BASE_BANNED_SUFFIXES,
+    banned_regex=_BASE_BANNED_REGEX,
+)
+
+
+def _ensure_sequence(value: Sequence[str] | str | None) -> tuple[str, ...]:
+    if value is None:
+        return ()
+    if isinstance(value, str):
+        return (value,)
+    return tuple(value)
+
+
+def evaluate_leak_prone_columns(
+    columns: Iterable[str],
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+) -> LeakCheckResult:
+    """Identify leak-prone columns using the configured policy."""
+
+    banned: dict[str, str] = {}
+    columns_list = list(columns)
+    for col in columns_list:
+        if col in policy.banned_exact:
+            banned[col] = "exact"
+            continue
+        for prefix in policy.banned_prefixes:
+            if col.startswith(prefix):
+                banned[col] = f"prefix:{prefix}"
+                break
+        if col in banned:
+            continue
+        for suffix in policy.banned_suffixes:
+            if col.endswith(suffix):
+                banned[col] = f"suffix:{suffix}"
+                break
+        if col in banned:
+            continue
+        for pattern, reason in policy.banned_regex:
+            if pattern.match(col):
+                banned[col] = reason
+                break
+
+    kept = [c for c in columns_list if c not in banned]
+    return LeakCheckResult(
+        policy_version=policy.version,
+        banned=banned,
+        kept=kept,
+        dropped=[],
+        allowlist_kept=[],
+    )
+
+
+def enforce_leak_guard(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    allow_prefixes: Sequence[str] | str | None = None,
+    allow_exact: Sequence[str] | str | None = None,
+    drop_banned: bool = True,
+    drop_non_allowlisted: bool = False,
+    raise_on_banned: bool = True,
+) -> tuple[pl.DataFrame | "pd.DataFrame", LeakCheckResult]:
+    """Apply leak guardrails to a feature frame.
+
+    Parameters
+    ----------
+    df : DataFrame
+        Polars or pandas DataFrame.
+    policy : LeakPolicy
+        Leak policy to apply.
+    allow_prefixes : Sequence[str] | str | None
+        Optional prefixes that define the allowed feature surface for a problem.
+    allow_exact : Sequence[str] | str | None
+        Explicitly allowed columns (e.g., identifiers).
+    drop_banned : bool
+        If True, drop any banned columns automatically.
+    drop_non_allowlisted : bool
+        If True, drop columns that are not covered by allow_prefixes/allow_exact/identifiers/targets.
+    raise_on_banned : bool
+        If True, raise when banned columns are detected (after optional drop).
+    """
+
+    result = evaluate_leak_prone_columns(df.columns, policy=policy)
+    dropped: list[str] = []
+
+    allow_prefixes = _ensure_sequence(allow_prefixes)
+    allow_exact = set(_ensure_sequence(allow_exact))
+    allow_exact.update({col for col in IDENTIFIER_COLUMNS if col in df.columns})
+    allow_exact.update({col for col in NFL_TARGET_COLUMNS if col in df.columns})
+
+    # Permit allowlisted columns even if they match a banned rule (e.g., labels)
+    banned = {col: reason for col, reason in result.banned.items() if col not in allow_exact}
+
+    if banned and drop_banned:
+        df = df.drop(list(banned.keys()))
+        dropped.extend(banned.keys())
+
+    if banned and raise_on_banned:
+        raise ValueError(f"Leak-prone columns detected: {sorted(banned.items())}")
+
+    allowlist_cols: set[str] = set()
+    if allow_prefixes:
+        allowlist_cols.update({c for c in df.columns if c.startswith(allow_prefixes)})
+    allowlist_cols.update({c for c in allow_exact if c in df.columns})
+
+    if drop_non_allowlisted and allowlist_cols:
+        drop_candidates = [c for c in df.columns if c not in allowlist_cols]
+        if drop_candidates:
+            df = df.drop(drop_candidates)
+            dropped.extend(drop_candidates)
+
+    if drop_non_allowlisted and not allowlist_cols:
+        raise ValueError("No allowlisted columns remain after applying leak guard allowlist.")
+
+    # Store adjusted banned info on the result
+    result.banned = banned
+    result.dropped = dropped
+    result.kept = [c for c in df.columns]
+    result.allowlist_kept = sorted(list(allowlist_cols)) if allowlist_cols else []
+    return df, result
+
+
+def build_schema_snapshot(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    metadata: Mapping[str, object] | None = None,
+    banned: Mapping[str, str] | None = None,
+) -> dict:
+    """Render a schema snapshot describing each column and whether it was flagged."""
+
+    banned = banned or {}
+    meta = {
+        "generated_at_utc": datetime.utcnow().isoformat(),
+        "policy_version": policy.version,
+    }
+    meta.update(metadata or {})
+
+    # Extract columns / dtypes
+    if isinstance(df, pl.DataFrame):
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+    else:  # pandas or pandas-like
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+
+    schema = {
+        "metadata": meta,
+        "columns": [],
+    }
+
+    for col, dtype in cols_and_dtypes:
+        tags: list[str] = []
+        if col in IDENTIFIER_COLUMNS:
+            tags.append("id")
+        if col in NFL_TARGET_COLUMNS:
+            tags.append("label")
+        if col.startswith("market_"):
+            tags.append("odds")
+        if col.startswith("injury_") or col.startswith("practice_"):
+            tags.append("injury")
+        if col.startswith("weather_"):
+            tags.append("weather")
+        if col.startswith("ps_"):
+            tags.append("pre_snap")
+        schema["columns"].append(
+            {
+                "name": col,
+                "dtype": dtype,
+                "banned": col in banned,
+                "tags": tags,
+            }
+        )
+    return schema
+
+
+def write_schema_snapshot(path, schema: Mapping[str, object]) -> None:
+    path.parent.mkdir(parents=True, exist_ok=True)
+    with open(path, "w") as fp:
+        json.dump(schema, fp, indent=2, sort_keys=True)
+
+
+__all__ = [
+    "DEFAULT_LEAK_POLICY",
+    "LeakPolicy",
+    "LeakCheckResult",
+    "evaluate_leak_prone_columns",
+    "enforce_leak_guard",
+    "build_schema_snapshot",
+    "write_schema_snapshot",
+]
diff --git a/utils/general/constants.py b/utils/general/constants.py
index d94b4260ad877484da843fa99ae2caf37e8493f4..dea87caa354d94e4a08b1762d2bd8dcd4c8caa3a
--- a/utils/general/constants.py
+++ b/utils/general/constants.py
@@ -211,7 +211,17 @@
 
 NFL_TARGET_COLUMNS: Tuple[str, ...] = (
     'anytime_td',
+    'anytime_td_offense',
+    'anytime_td_all',
+    'anytime_td_rush',
+    'anytime_td_rec',
+    'anytime_td_pass_thrown',
     'td_count',
+    'td_count_offense',
+    'td_count_all',
+    'passing_td',
+    'rushing_td_count',
+    'receiving_td_count',
     'receiving_yards',
     'rushing_yards',
     'passing_yards',


thinking
**Preparing detailed final summary**

I’m organizing a thorough final message that highlights key changes like the leak guard module, schema snapshots, and test additions, while noting pytest is missing so tests didn’t run. I’ll clearly mention the inability to commit due to .git permission issues and include a PROGRESS line explaining that the plan isn’t fully complete yet. This message will follow the required plain-text bullet style and suggest sensible next steps, ensuring all relevant file paths and caveats are included for clarity.
codex
- Added structured leak guard (`utils/feature/leak_guard.py`) with pattern-based banning, allowlists, schema snapshot rendering, and wired it into feature assembly (`pipeline/feature.py`) and per-problem training load (`pipeline/train.py`); feature builds now emit schema artifacts under `audit/feature/schema/anytime_td/`.
- Extended target constants to cover label variants (`utils/general/constants.py`), filtered decision-time odds to a single configured horizon via new `odds_horizon` config on the anytime TD problem (`config/training.yaml`) and `_filter_odds_snapshot_columns`, and documented the knob plus schema/audit trail in `docs/pre_snap_semantics.md`.
- Hardened leak guard testing and odds horizon selection with new cases (`tests/test_data_leak_guard.py`, `tests/test_odds_horizon_filter.py`).

Tests: python3 -m pytest tests/test_data_leak_guard.py tests/test_odds_horizon_filter.py -q (fails: pytest module not installed).

Note: Unable to stage/commit because the environment blocks writing under `.git` (cannot create index.lock or touch `.git/*`).

PROGRESS: Leak guardrails and odds-horizon filtering with tests/docs are in place; remaining plan items include decision-time injury alignment, purge-aware CV/slicing, richer football features, and broader docs/evaluation.
file update:
diff --git a/config/training.yaml b/config/training.yaml
index 3953818d861d0410246bff132110722a3ce44007..c2b6053b488caa71f9078ff100d049f723ae1548
--- a/config/training.yaml
+++ b/config/training.yaml
@@ -476,6 +476,7 @@
   - name: 'anytime_td'
     target_col: 'anytime_td'
     label_version: 'v1_any_offense'
+    odds_horizon: 'cutoff'  # Restrict odds features to the decision-time snapshot
     task_type: 'classification'
     input_predictions:
       - 'availability_active'
diff --git a/docs/pre_snap_semantics.md b/docs/pre_snap_semantics.md
index 7d58f2f5139d77b00c6c4a1df16648d0601b89ff..d5a996dffd7b8e94ca096b2872314b1c97a80049
--- a/docs/pre_snap_semantics.md
+++ b/docs/pre_snap_semantics.md
@@ -29,3 +29,8 @@
 ---------------
 - Only `ps_hist_*` features (including the `ps_hist_tracking_*` coverage rolls) are allowed as inputs via `feature_prefixes_to_include`.
 - Base `ps_game_*` and `ps_tracking_*` columns remain in the data for diagnostics/labeling but are blocked by `columns_to_discard` and `LEAK_PRONE_COLUMNS`.
+
+Decision-time odds snapshots
+----------------------------
+- Odds features are now filtered to a single horizon via `odds_horizon` in `config/training.yaml` (e.g., `cutoff` keeps the decision-time snapshot and drops `_2h/_6h/_24h/_open` variants).
+- Feature builds emit a schema snapshot under `audit/feature/schema/anytime_td/` capturing dtypes and any leak-guard flags for traceability.
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 5ba68e8bf1acd3a789a76a8857674e6f6433017b..0210d5b7e7ed60a8de7a126d64f5ed76326474c8
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -14,7 +14,7 @@
 
 import logging
 import os
-from datetime import date, timedelta
+from datetime import date, datetime, timedelta
 from typing import Sequence
 
 import polars as pl
@@ -37,6 +37,12 @@
     add_offense_context_features_training,
     _append_offense_context_columns,
 )
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    build_schema_snapshot,
+    enforce_leak_guard,
+    write_schema_snapshot,
+)
 from utils.feature.weather_features import (
     add_weather_forecast_features_training,
     append_weather_context_flags,
@@ -931,6 +937,32 @@
     if market_exprs:
         df_player_game_all = df_player_game_all.with_columns(market_exprs)
     
+    # Leak guard + schema snapshot before persisting
+    spec = get_label_spec(label_version)
+    allow_exact = {spec.primary, *spec.labels.keys(), *spec.aliases.keys()}
+    df_player_game_all, leak_result = enforce_leak_guard(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_exact=allow_exact,
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=True,
+    )
+
+    schema = build_schema_snapshot(
+        df_player_game_all,
+        policy=DEFAULT_LEAK_POLICY,
+        metadata={
+            "cutoff_label": cutoff_label,
+            "label_version": spec.name,
+        },
+        banned=leak_result.banned,
+    )
+    schema_dir = FEATURE_AUDIT_DIR / "schema" / "anytime_td"
+    schema_path = schema_dir / f"{cutoff_label}_{datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')}.json"
+    write_schema_snapshot(schema_path, schema)
+    logging.info("    Schema snapshot written → %s", schema_path)
+
     # Write final feature matrix
     df_player_game_all = df_player_game_all.with_columns(
         pl.lit(current_cutoff_hours).cast(pl.Float32).alias("decision_horizon_hours")
@@ -951,7 +983,6 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    spec = get_label_spec(label_version)
     label_candidates = {spec.primary, "anytime_td"}
     for label_col in label_candidates:
         if label_col in df_player_game_all.columns:
diff --git a/pipeline/train.py b/pipeline/train.py
index fe70207dcdf25d209ee3ad55080b7ce826347c44..7c220514d006a3d4815d65a8af9ec7551ccf587e
--- a/pipeline/train.py
+++ b/pipeline/train.py
@@ -4,6 +4,7 @@
 import sys
 import logging
 import math
+import re
 
 
 # Move logging to top and remove global thread pinning
@@ -98,6 +99,7 @@
     fit_team_conformal_sums,
     composite_sum_interval,
 )
+from utils.feature.leak_guard import DEFAULT_LEAK_POLICY, enforce_leak_guard
 from utils.feature.targets import require_target_column
 
 # Ignore specific, noisy warnings from dependencies
@@ -793,6 +795,57 @@
             )
         return df
 
+    @staticmethod
+    def _filter_odds_snapshot_columns(df: pd.DataFrame, horizon_key: str | None) -> pd.DataFrame:
+        """Keep a single odds snapshot horizon (drop other suffixes)."""
+        if df is None or df.empty or not horizon_key:
+            return df
+
+        normalized = str(horizon_key).strip().lower()
+        horizon_map = {
+            "cutoff": "",
+            "default": "",
+            "": "",
+            "2h": "_2h",
+            "h120m": "_2h",
+            "6h": "_6h",
+            "h360m": "_6h",
+            "24h": "_24h",
+            "h1440m": "_24h",
+            "open": "_open",
+        }
+        allowed_suffix = horizon_map.get(normalized, normalized)
+        if allowed_suffix and not allowed_suffix.startswith("_"):
+            allowed_suffix = f"_{allowed_suffix.lstrip('_')}"
+
+        horizon_re = re.compile(r"^(?P<base>.+)(?P<suffix>_2h|_6h|_24h|_open)$")
+        suffixes_seen: dict[str, set[str]] = {}
+        for col in df.columns:
+            match = horizon_re.match(col)
+            if match:
+                suffixes_seen.setdefault(match.group("base"), set()).add(match.group("suffix"))
+
+        drop_cols: list[str] = []
+        for col in df.columns:
+            match = horizon_re.match(col)
+            if match:
+                suffix = match.group("suffix")
+                if suffix != allowed_suffix:
+                    drop_cols.append(col)
+            else:
+                base = col
+                if base in suffixes_seen and allowed_suffix:
+                    drop_cols.append(col)
+
+        if drop_cols:
+            df = df.drop(columns=drop_cols, errors="ignore")
+            logger.info(
+                "Removed %d odds snapshot columns outside horizon '%s'.",
+                len(drop_cols),
+                horizon_key,
+            )
+        return df
+
     def _ensure_player_game_actuals(self) -> pd.DataFrame:
         if self._player_game_actuals is not None:
             return self._player_game_actuals
@@ -2315,7 +2368,34 @@
                             df_problem[col] = df_problem[col].fillna(df_problem[col].mean())
 
                 df_problem = self._inject_composed_features(df_problem)
-            
+
+            odds_horizon = problem_copy.get("odds_horizon")
+            if odds_horizon:
+                df_problem = self._filter_odds_snapshot_columns(df_problem, odds_horizon)
+
+            # Leak guard on the problem-scoped frame
+            allow_prefixes = tuple(problem_copy.get('feature_prefixes_to_include') or [])
+            allow_exact = set(problem_copy.get('other_features_to_include') or [])
+            allow_exact.update(input_preds or [])
+            if self.target_col:
+                allow_exact.add(self.target_col)
+            df_problem, leak_info = enforce_leak_guard(
+                df_problem,
+                policy=DEFAULT_LEAK_POLICY,
+                allow_prefixes=allow_prefixes,
+                allow_exact=allow_exact,
+                drop_banned=True,
+                drop_non_allowlisted=False,
+                raise_on_banned=True,
+            )
+            if leak_info.dropped:
+                logger.info(
+                    "Dropped %d leak-prone columns for %s: %s",
+                    len(leak_info.dropped),
+                    problem_name,
+                    sorted(leak_info.dropped),
+                )
+
             self._normalize_datetime_like_columns(df_problem, problem_name)
             df_problem[self.time_col] = pd.to_datetime(df_problem[self.time_col])
             sort_cols = [self.time_col]
diff --git a/tests/test_data_leak_guard.py b/tests/test_data_leak_guard.py
index 8061f2760c0898aaeda29026859e1b9ff5644ba4..3e56665921db89ea523bbdb205d1bb90c21893df
--- a/tests/test_data_leak_guard.py
+++ b/tests/test_data_leak_guard.py
@@ -3,6 +3,14 @@
 import yaml
 from pathlib import Path
 
+import polars as pl
+
+from utils.feature.leak_guard import (
+    DEFAULT_LEAK_POLICY,
+    enforce_leak_guard,
+    evaluate_leak_prone_columns,
+)
+
 
 PROJECT_ROOT = Path(__file__).resolve().parents[1]
 TRAINING_CONFIG = PROJECT_ROOT / "config" / "training.yaml"
@@ -48,3 +56,41 @@
     )
 
 
+def test_leak_guard_flags_pattern_columns():
+    cols = [
+        "market_anytime_td_prob",
+        "final_score",
+        "postgame_anytime_td",
+        "actual_td_count",
+        "safe_feature",
+    ]
+    result = evaluate_leak_prone_columns(cols, policy=DEFAULT_LEAK_POLICY)
+    assert set(result.banned.keys()) == {"final_score", "postgame_anytime_td", "actual_td_count"}
+    assert "safe_feature" in result.kept
+    assert "market_anytime_td_prob" in result.kept
+
+
+def test_enforce_leak_guard_drops_banned_and_keeps_allowlisted():
+    df = pl.DataFrame(
+        {
+            "game_id": ["g1", "g2"],
+            "safe_feature": [1.0, 2.0],
+            "postgame_anytime_td": [1, 0],
+            "final_score": [30, 24],
+        }
+    )
+    cleaned, info = enforce_leak_guard(
+        df,
+        policy=DEFAULT_LEAK_POLICY,
+        allow_prefixes=("safe_",),
+        allow_exact=("game_id",),
+        drop_banned=True,
+        drop_non_allowlisted=False,
+        raise_on_banned=False,
+    )
+    assert "postgame_anytime_td" not in cleaned.columns
+    assert "final_score" not in cleaned.columns
+    assert "safe_feature" in cleaned.columns
+    assert "game_id" in cleaned.columns
+    assert set(info.dropped) == {"postgame_anytime_td", "final_score"}
+
diff --git a/tests/test_odds_horizon_filter.py b/tests/test_odds_horizon_filter.py
new file mode 100644
index 0000000000000000000000000000000000000000..70e9c681f63972bbb6e70008e286cf13f6881853
--- /dev/null
+++ b/tests/test_odds_horizon_filter.py
@@ -0,0 +1,35 @@
+from __future__ import annotations
+
+import pandas as pd
+import pytest
+
+train_module = pytest.importorskip("pipeline.train")
+ModelTrainer = train_module.ModelTrainer
+
+
+def test_filter_odds_snapshot_columns_cutoff_keeps_base_only():
+    df = pd.DataFrame(
+        {
+            "market_anytime_td_prob": [0.1, 0.2],
+            "market_anytime_td_prob_2h": [0.15, 0.25],
+            "market_anytime_td_prob_6h": [0.2, 0.3],
+            "other_feature": [1, 2],
+        }
+    )
+    filtered = ModelTrainer._filter_odds_snapshot_columns(df.copy(), "cutoff")
+    assert "market_anytime_td_prob" in filtered.columns
+    assert "market_anytime_td_prob_2h" not in filtered.columns
+    assert "market_anytime_td_prob_6h" not in filtered.columns
+    assert "other_feature" in filtered.columns
+
+
+def test_filter_odds_snapshot_columns_specific_suffix():
+    df = pd.DataFrame(
+        {
+            "market_anytime_td_prob": [0.1, 0.2],
+            "market_anytime_td_prob_2h": [0.15, 0.25],
+            "market_anytime_td_prob_6h": [0.2, 0.3],
+        }
+    )
+    filtered = ModelTrainer._filter_odds_snapshot_columns(df.copy(), "6h")
+    assert list(filtered.columns) == ["market_anytime_td_prob_6h"]
diff --git a/utils/feature/leak_guard.py b/utils/feature/leak_guard.py
new file mode 100644
index 0000000000000000000000000000000000000000..9faf8cfffc436e0934b2f410aaf252e52f4f95df
--- /dev/null
+++ b/utils/feature/leak_guard.py
@@ -0,0 +1,273 @@
+"""Leak guardrails for feature matrices.
+
+This module centralizes pattern-based leak detection so both feature assembly
+and training can fail fast when post-outcome columns sneak into the data.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+from datetime import datetime
+import json
+import re
+from typing import Iterable, Mapping, Sequence
+
+import polars as pl
+
+from utils.general.constants import IDENTIFIER_COLUMNS, LEAK_PRONE_COLUMNS, NFL_TARGET_COLUMNS
+
+try:  # Optional dependency when imported from training (pandas path)
+    import pandas as pd  # type: ignore
+except Exception:  # pragma: no cover - optional dependency
+    pd = None
+
+
+@dataclass(frozen=True)
+class LeakPolicy:
+    version: str
+    banned_exact: set[str]
+    banned_prefixes: tuple[str, ...]
+    banned_suffixes: tuple[str, ...]
+    banned_regex: tuple[tuple[re.Pattern[str], str], ...]
+    description: str = ""
+
+
+@dataclass
+class LeakCheckResult:
+    policy_version: str
+    banned: dict[str, str]
+    kept: list[str]
+    dropped: list[str]
+    allowlist_kept: list[str]
+
+
+# Core policy tuned for anytime-TD style problems (can be extended per-problem).
+_BASE_BANNED_EXACT = set(LEAK_PRONE_COLUMNS) | {
+    "final_score",
+    "final_total",
+    "points_scored",
+    "actual_td_count",
+    "actual_anytime_td",
+    "postgame_anytime_td",
+    "postgame_td_count",
+}
+_BASE_BANNED_PREFIXES = (
+    "postgame_",
+    "post_game_",
+    "post_",
+    "live_",
+    "actual_",
+    "realized_",
+    "final_",
+    "postmatch_",
+)
+_BASE_BANNED_SUFFIXES = (
+    "_post",
+    "_postgame",
+    "_final",
+    "_fullgame",
+    "_actual",
+)
+_BASE_BANNED_REGEX: tuple[tuple[re.Pattern[str], str], ...] = (
+    (re.compile(r".*post.?game.*", flags=re.IGNORECASE), "postgame marker"),
+    (re.compile(r".*final_score.*", flags=re.IGNORECASE), "final score"),
+    (re.compile(r".*actual.*td.*", flags=re.IGNORECASE), "actual TD total"),
+    (re.compile(r".*anytime_td.*(post|final|actual).*", flags=re.IGNORECASE), "post-decision anytime TD"),
+    (re.compile(r".*fullgame.*", flags=re.IGNORECASE), "full game cumulative value"),
+)
+
+DEFAULT_LEAK_POLICY = LeakPolicy(
+    version="v1",
+    description="Core post-outcome leak guard for NFL anytime TD features.",
+    banned_exact=_BASE_BANNED_EXACT,
+    banned_prefixes=_BASE_BANNED_PREFIXES,
+    banned_suffixes=_BASE_BANNED_SUFFIXES,
+    banned_regex=_BASE_BANNED_REGEX,
+)
+
+
+def _ensure_sequence(value: Sequence[str] | str | None) -> tuple[str, ...]:
+    if value is None:
+        return ()
+    if isinstance(value, str):
+        return (value,)
+    return tuple(value)
+
+
+def evaluate_leak_prone_columns(
+    columns: Iterable[str],
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+) -> LeakCheckResult:
+    """Identify leak-prone columns using the configured policy."""
+
+    banned: dict[str, str] = {}
+    columns_list = list(columns)
+    for col in columns_list:
+        if col in policy.banned_exact:
+            banned[col] = "exact"
+            continue
+        for prefix in policy.banned_prefixes:
+            if col.startswith(prefix):
+                banned[col] = f"prefix:{prefix}"
+                break
+        if col in banned:
+            continue
+        for suffix in policy.banned_suffixes:
+            if col.endswith(suffix):
+                banned[col] = f"suffix:{suffix}"
+                break
+        if col in banned:
+            continue
+        for pattern, reason in policy.banned_regex:
+            if pattern.match(col):
+                banned[col] = reason
+                break
+
+    kept = [c for c in columns_list if c not in banned]
+    return LeakCheckResult(
+        policy_version=policy.version,
+        banned=banned,
+        kept=kept,
+        dropped=[],
+        allowlist_kept=[],
+    )
+
+
+def enforce_leak_guard(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    allow_prefixes: Sequence[str] | str | None = None,
+    allow_exact: Sequence[str] | str | None = None,
+    drop_banned: bool = True,
+    drop_non_allowlisted: bool = False,
+    raise_on_banned: bool = True,
+) -> tuple[pl.DataFrame | "pd.DataFrame", LeakCheckResult]:
+    """Apply leak guardrails to a feature frame.
+
+    Parameters
+    ----------
+    df : DataFrame
+        Polars or pandas DataFrame.
+    policy : LeakPolicy
+        Leak policy to apply.
+    allow_prefixes : Sequence[str] | str | None
+        Optional prefixes that define the allowed feature surface for a problem.
+    allow_exact : Sequence[str] | str | None
+        Explicitly allowed columns (e.g., identifiers).
+    drop_banned : bool
+        If True, drop any banned columns automatically.
+    drop_non_allowlisted : bool
+        If True, drop columns that are not covered by allow_prefixes/allow_exact/identifiers/targets.
+    raise_on_banned : bool
+        If True, raise when banned columns are detected (after optional drop).
+    """
+
+    result = evaluate_leak_prone_columns(df.columns, policy=policy)
+    dropped: list[str] = []
+
+    allow_prefixes = _ensure_sequence(allow_prefixes)
+    allow_exact = set(_ensure_sequence(allow_exact))
+    allow_exact.update({col for col in IDENTIFIER_COLUMNS if col in df.columns})
+    allow_exact.update({col for col in NFL_TARGET_COLUMNS if col in df.columns})
+
+    # Permit allowlisted columns even if they match a banned rule (e.g., labels)
+    banned = {col: reason for col, reason in result.banned.items() if col not in allow_exact}
+
+    if banned and drop_banned:
+        df = df.drop(list(banned.keys()))
+        dropped.extend(banned.keys())
+
+    if banned and raise_on_banned:
+        raise ValueError(f"Leak-prone columns detected: {sorted(banned.items())}")
+
+    allowlist_cols: set[str] = set()
+    if allow_prefixes:
+        allowlist_cols.update({c for c in df.columns if c.startswith(allow_prefixes)})
+    allowlist_cols.update({c for c in allow_exact if c in df.columns})
+
+    if drop_non_allowlisted and allowlist_cols:
+        drop_candidates = [c for c in df.columns if c not in allowlist_cols]
+        if drop_candidates:
+            df = df.drop(drop_candidates)
+            dropped.extend(drop_candidates)
+
+    if drop_non_allowlisted and not allowlist_cols:
+        raise ValueError("No allowlisted columns remain after applying leak guard allowlist.")
+
+    # Store adjusted banned info on the result
+    result.banned = banned
+    result.dropped = dropped
+    result.kept = [c for c in df.columns]
+    result.allowlist_kept = sorted(list(allowlist_cols)) if allowlist_cols else []
+    return df, result
+
+
+def build_schema_snapshot(
+    df: pl.DataFrame | "pd.DataFrame",
+    *,
+    policy: LeakPolicy = DEFAULT_LEAK_POLICY,
+    metadata: Mapping[str, object] | None = None,
+    banned: Mapping[str, str] | None = None,
+) -> dict:
+    """Render a schema snapshot describing each column and whether it was flagged."""
+
+    banned = banned or {}
+    meta = {
+        "generated_at_utc": datetime.utcnow().isoformat(),
+        "policy_version": policy.version,
+    }
+    meta.update(metadata or {})
+
+    # Extract columns / dtypes
+    if isinstance(df, pl.DataFrame):
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+    else:  # pandas or pandas-like
+        cols_and_dtypes = [(col, str(dtype)) for col, dtype in zip(df.columns, df.dtypes)]
+
+    schema = {
+        "metadata": meta,
+        "columns": [],
+    }
+
+    for col, dtype in cols_and_dtypes:
+        tags: list[str] = []
+        if col in IDENTIFIER_COLUMNS:
+            tags.append("id")
+        if col in NFL_TARGET_COLUMNS:
+            tags.append("label")
+        if col.startswith("market_"):
+            tags.append("odds")
+        if col.startswith("injury_") or col.startswith("practice_"):
+            tags.append("injury")
+        if col.startswith("weather_"):
+            tags.append("weather")
+        if col.startswith("ps_"):
+            tags.append("pre_snap")
+        schema["columns"].append(
+            {
+                "name": col,
+                "dtype": dtype,
+                "banned": col in banned,
+                "tags": tags,
+            }
+        )
+    return schema
+
+
+def write_schema_snapshot(path, schema: Mapping[str, object]) -> None:
+    path.parent.mkdir(parents=True, exist_ok=True)
+    with open(path, "w") as fp:
+        json.dump(schema, fp, indent=2, sort_keys=True)
+
+
+__all__ = [
+    "DEFAULT_LEAK_POLICY",
+    "LeakPolicy",
+    "LeakCheckResult",
+    "evaluate_leak_prone_columns",
+    "enforce_leak_guard",
+    "build_schema_snapshot",
+    "write_schema_snapshot",
+]
diff --git a/utils/general/constants.py b/utils/general/constants.py
index d94b4260ad877484da843fa99ae2caf37e8493f4..dea87caa354d94e4a08b1762d2bd8dcd4c8caa3a
--- a/utils/general/constants.py
+++ b/utils/general/constants.py
@@ -211,7 +211,17 @@
 
 NFL_TARGET_COLUMNS: Tuple[str, ...] = (
     'anytime_td',
+    'anytime_td_offense',
+    'anytime_td_all',
+    'anytime_td_rush',
+    'anytime_td_rec',
+    'anytime_td_pass_thrown',
     'td_count',
+    'td_count_offense',
+    'td_count_all',
+    'passing_td',
+    'rushing_td_count',
+    'receiving_td_count',
     'receiving_yards',
     'rushing_yards',
     'passing_yards',

tokens used
211,723
- Added structured leak guard (`utils/feature/leak_guard.py`) with pattern-based banning, allowlists, schema snapshot rendering, and wired it into feature assembly (`pipeline/feature.py`) and per-problem training load (`pipeline/train.py`); feature builds now emit schema artifacts under `audit/feature/schema/anytime_td/`.
- Extended target constants to cover label variants (`utils/general/constants.py`), filtered decision-time odds to a single configured horizon via new `odds_horizon` config on the anytime TD problem (`config/training.yaml`) and `_filter_odds_snapshot_columns`, and documented the knob plus schema/audit trail in `docs/pre_snap_semantics.md`.
- Hardened leak guard testing and odds horizon selection with new cases (`tests/test_data_leak_guard.py`, `tests/test_odds_horizon_filter.py`).

Tests: python3 -m pytest tests/test_data_leak_guard.py tests/test_odds_horizon_filter.py -q (fails: pytest module not installed).

Note: Unable to stage/commit because the environment blocks writing under `.git` (cannot create index.lock or touch `.git/*`).

PROGRESS: Leak guardrails and odds-horizon filtering with tests/docs are in place; remaining plan items include decision-time injury alignment, purge-aware CV/slicing, richer football features, and broader docs/evaluation.
