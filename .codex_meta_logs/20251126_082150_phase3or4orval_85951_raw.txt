OpenAI Codex v0.63.0 (research preview)
--------
workdir: /Users/jameswest/Desktop/nfl_predict
model: gpt-5.1-codex-max
provider: openai
approval: never
sandbox: workspace-write [workdir, /tmp, $TMPDIR]
reasoning effort: none
reasoning summaries: auto
session id: 019ac0f8-9eef-7241-8384-b4a416b9f251
--------
user
Okay, great. Please work like an agent and implement the following plan in this repository.

    Here is the plan:

    <BEGIN_PLAN_START>
    **Overall Priorities**

- **P0 – Correctness & leakage:** Fix label semantics, explicit target wiring, strict leak guardrails, and decision-time realism for odds/injuries. These are mandatory before trusting any new metrics.
- **P1 – Evaluation & CV:** Add purge-aware CV, odds-free baselines, and slice-level evaluation so we can see where the model is actually good or leaking.
- **P2 – Football-grounded features:** Layer in richer TD-mechanism features (red-zone roles, goal-line usage, hurry-up, etc.) once P0/P1 are solid.
- **P3 – Cleanup & ergonomics:** Remove MLB cruft, canonicalize IDs, wire feature tuning, and upgrade docs/monitoring/CI.

Below is a detailed, implementation-ready plan organized by theme and priority.

---

**1. Labels & Target Semantics (P0)**

Goals: precisely define what “anytime TD” means; capture variants (offense-only, by TD type); make configuration- and version-controlled.

- **1.1 Design label variants and semantics**
  - Define a small, explicit set of label types:
    - `anytime_td_all`: player scores any TD (rushing/receiving/passing/return) on any side of the ball.
    - `anytime_td_offense`: only offensive TDs (rushing/receiving/passing credited to offensive players).
    - `anytime_td_rush`, `anytime_td_rec`, `anytime_td_pass_thrown`: type-specific labels.
    - Optionally `anytime_td_redzone` (TD originating from inside opponent 20), `anytime_td_goal_to_go` (inside 10 or 5) for future experiments.
  - Decide and document how to treat edge cases:
    - TD via laterals, fumble recoveries, fake punts/FGs, pick-sixes for offensive players, 2-point conversions, penalties nullifying TDs.
    - Multi-TD games (label is still binary; separate count label can be added if useful).
  - Produce a short design note listing:
    - Exact inclusion/exclusion rules per label.
    - Required input columns and which upstream tables they come from.

- **1.2 Implement label generation with versioning**
  - In `utils/feature/player_game_level.py`:
    - Refactor current `anytime_td` computation into a reusable helper, e.g. `_compute_td_labels(row, label_cfg)`, that can output multiple label columns.
    - Introduce a small `LabelConfig` structure or dict that encodes which TD types to include and whether to restrict to offensive plays.
  - Add a new module or function (e.g. `utils/feature/labels.py`) that:
    - Defines label “versions” (e.g. `v1_any_offense`, `v2_any_all`, etc.) as combinations of rules.
    - Provides a function `get_label_spec(version_name)` that returns both:
      - Column name(s) to be produced.
      - Rules to feed into `_compute_td_labels`.
  - Add a `label_version` field in `config/training.yaml` under the relevant problem:
    - E.g. `labels: { version: v1_any_offense, target_col: anytime_td_offense }`.
    - Allow multiple label columns per run for multi-task experiments, but keep initial scope simple (one primary target).

- **1.3 Explicit target wiring in training and feature code**
  - In `utils/feature/targets.py`:
    - Replace hardcoded `anytime_td` with logic that:
      - Reads `target_col` (and possibly `label_version`) from config.
      - Ensures the column exists in the assembled feature frame before training.
      - Raises a clear error if the configured target is missing or NaN-heavy.
  - In `pipeline/train.py`:
    - Make `target_col` mandatory in the training section.
    - Assert that only label columns from the configured version are passed into `y`.
    - Optionally log label prevalence and positive rate per run.

- **1.4 Label audit tests and fixtures**
  - Add a very small synthetic dataset (e.g. CSV or in-memory DataFrame) with carefully constructed plays:
    - Simple rushing TD, receiving TD, passing-TD-thrower, defensive player scoring off turnover, special teams TD, nullified TD, etc.
  - Create unit tests (under `tests/labels/` or similar) that:
    - Run label generation for each version.
    - Assert expected 0/1 labels per player-game for each scenario.
  - Add a basic “label sanity” script/notebook to:
    - Show positive rate by position, team, and season.
    - Flag obviously inconsistent patterns (e.g. kickers with many positive labels, players labeled positive with 0 snaps).

- **Risks / Pitfalls**
  - Backward compatibility: old runs will have old semantics; plan to tag runs with `label_version` for clarity.
  - Label proliferation: keep to a small, curated set of versions to avoid confusion and combinatorial explosion.

---

**2. Leakage Guardrails & Schema Tracking (P0)**

Goals: systematically prevent data leakage, make prohibited columns/config leaks fail loudly, and track feature schemas per run.

- **2.1 Expand and structure leak-prone column policies**
  - Replace simple `LEAK_PRONE_COLUMNS` list with structured policies:
    - Patterns (e.g. `*_tds`, `points_scored`, `final_score`, `postgame_*`).
    - Time-suffix patterns that are clearly post-outcome (e.g. `_fullgame`, `_final`).
    - Direct target relatives (`anytime_td`, `*_touchdowns`, `*_td_share` after the game).
  - Define per-problem allowlists:
    - E.g. for `anytime_td`, only allow feature prefixes that are plausible pregame or pre-decision (odds, depth chart, usage history).
  - Implement a helper (e.g. `utils/feature/leak_guard.py`) that:
    - Given a features DataFrame and problem config, returns:
      - Allowed columns.
      - Banned columns (with reasons).
    - Raises if any banned column is present or if no allowed features remain.

- **2.2 Integrate guardrails into the feature pipeline**
  - In `pipeline/feature.py` (or wherever feature assembly occurs):
    - After all joins/engineering, but before saving:
      - Compute and log lists of (a) all columns, (b) banned candidates, (c) final kept columns.
      - Drop any non-whitelisted columns and assert that nothing on the banned list makes it into the final dataset.
  - In `pipeline/train.py`:
    - Before fitting the model:
      - Run a guardrail check again on `X_train`/`X_valid` to catch any path where features were loaded from disk without going through assembly guardrails.

- **2.3 Schema snapshot artifacts**
  - For each feature build run:
    - Write a schema artifact that includes for each column:
      - `name`, `dtype`, `source_table`, `tags` (e.g. `odds`, `injury`, `rolling_usage`, `postgame_risk`), and whether it passed guardrails.
    - Save as `output/schema/anytime_td/<model>/<timestamp>_schema.json` (or YAML).
  - Use `label_version`, `feature_version`, and `leak_policy_version` fields in the artifact metadata for long-term traceability.

- **2.4 Leak tests**
  - Extend `tests/test_data_leak_guard.py`:
    - Add pattern-based cases:
      - Simulate columns like `final_score`, `postgame_anytime_td`, `actual_td_count`, etc., and assert they are banned.
    - Add a test that:
      - Mocks a feature DataFrame including both allowed and banned columns, runs guardrail, and checks:
        - Banned columns are dropped or cause failure (depending on desired behavior).
        - At least one allowed feature remains.
  - Add one integration-style test:
    - Create a tiny toy pipeline call that produces features.
    - Assert that the saved schema artifact matches expectations and has no leak-prone columns.

- **Risks / Pitfalls**
  - Over-aggressive banning could drop genuinely useful but safe features; start with a strict core list and allow opt-in overrides via config for expert-level use.
  - Need to keep pattern-based rules in sync with naming conventions as features evolve.

---

**3. Decision-Time Realism: Odds & Injuries (P0)**

Goals: ensure that odds and injury data respect a defined as-of time (e.g. 90 minutes before kick), and that only features available at decision time are used.

- **3.1 Represent as-of timestamps and horizons**
  - Establish a standard as-of representation:
    - For odds: `market_anytime_td_{horizon}_*` where `horizon` encodes offset (e.g. `h090m`).
    - For injuries: snapshot types like `inactives_90m`, `practice_report`, `final_inactives`.
  - In `config/training.yaml`:
    - Add fields under the anytime TD problem:
      - `decision_cutoff_minutes_before_kick: 90`
      - `odds_horizon: h090m`
      - `injury_snapshot: inactives_90m` (or `latest_before_cutoff`).

- **3.2 Odds feature alignment**
  - In `utils/feature/player_game_level.py` where `market_anytime_td_*` features are built:
    - Ensure multiple snapshots are either:
      - Materialized with an explicit horizon suffix, or
      - Filtered down to only the snapshot that matches `odds_horizon`.
  - In the feature selection step:
    - Only include columns with the configured horizon suffix for odds features.
    - Optionally add a `use_odds_features: true/false` flag in training config to run:
      - Baseline without odds (P1).
      - Full model with odds.

- **3.3 Injury and depth chart features**
  - For injury features:
    - Ensure each injury record has a timestamp or report type that can be compared to game kickoff.
    - In the join logic:
      - Filter to records with `report_time <= decision_time`.
      - If multiple, choose the most recent pre-cutoff record per player-game.
  - For depth chart/snap expectation features:
    - Use only historical games and pregame reports up to the previous game; never use actual snaps or usage from the current game.
    - Tag these features as `pre_decision` in schema artifacts.

- **3.4 Decision-time assertions and tests**
  - In the odds/injury join code:
    - Add assertions that:
      - No record with timestamp > decision time is included.
      - At least one record exists for games where data should be available; log missing coverage.
  - Add tests that:
    - Build a tiny dataset with:
      - A pre-cutoff odds snapshot and a post-cutoff snapshot.
      - Multiple injury reports per player (limited and then full participant closer to game).
    - Verify that:
      - Only the correct horizon/snapshot is included.
      - Changing `decision_cutoff_minutes_before_kick` or `odds_horizon` changes which columns appear.

- **Risks / Pitfalls**
  - Historical data may lack fine-grained timestamps for some sources; define conservative assumptions (e.g. treat unknown-time injury reports as post-cutoff unless known safe) and document them.
  - Misconfigured horizons can silently eliminate odds data; add logging that counts how many games/players have odds at the chosen horizon.

---

**4. Cross-Validation & Purge Leakage (P1 but important)**

Goals: prevent leakage via time and groups, especially with rolling features, and make CV reflect real deployment.

- **4.1 Formalize time and group keys**
  - Decide on standard split keys:
    - `group_col`: `game_id` or `game_id + team` depending on how data is structured.
    - `time_col`: kickoff datetime (not just season/week, if available).
  - Add fields to `config/training.yaml`:
    - `time_col`, `group_col`.
    - `purge_window_days` or `purge_window_games`.
    - Optional `embargo_days` separating train and validation.

- **4.2 Implement PurgedGroupTimeSeriesSplit**
  - Encapsulate the splitting logic in a helper (e.g. `utils/cv/purged_group_tscv.py`):
    - Wrap existing PurgedGroupTimeSeriesSplit or implement equivalent.
    - Inputs: time, group, purge window, embargo.
    - Output: list of `(train_idx, valid_idx)` pairs.
  - In `pipeline/train.py`:
    - Use this helper whenever CV is configured for time-series problems.
    - Ensure folds are monotone in time and respect group boundaries.

- **4.3 Align purge window with rolling windows**
  - Determine the maximum lookback window used for rolling features (e.g. last 5 games, last 8 weeks).
  - Set `purge_window` to at least that lookback window in terms of time or game count:
    - If using last 4 weeks of stats, purge at least 4 weeks before each validation window.
  - Document this relationship in the config and docs so future feature changes adjust purge accordingly.

- **4.4 Tests for leakage via CV**
  - Add tests that:
    - Construct a small timeline with player-game rows, e.g. 10 games.
    - Use fake rolling stats that depend on latest game to simulate potential leakage.
    - Run PurgedGroupTimeSeriesSplit and assert:
      - No validation rows share `game_id` or time window overlap with training rows inside the purge window.
      - The earliest training date in a fold is at least `purge_window` before the earliest validation date in that fold.

- **Risks / Pitfalls**
  - Larger purge windows can reduce effective training size; monitor fold sizes and adjust number of folds or lookback windows accordingly.
  - Mis-specified `time_col` (e.g. using data ingestion time instead of game time) can give misleading splits.

---

**5. Football-Grounded Feature Engineering (P2)**

Goals: add features that directly reflect the mechanisms by which TDs occur: red-zone roles, goal-line roles, hurry-up usage, designed touches, etc.

- **5.1 Red-zone and goal-line usage**
  - From play-by-play / drive data:
    - Compute per-player rates and shares:
      - Inside-20, inside-10, inside-5 carries and targets.
      - Goal-to-go carries/targets.
      - Draw a distinction between passing TDs and rush TDs.
    - Aggregate at season-to-date and recent window (last 3–5 games).
  - In `utils/feature/player_game_level.py` (or new dedicated module):
    - Add features such as:
      - `rz_carry_share_season`, `rz_target_share_season`.
      - `goal_line_carry_share_recent`, `goal_line_target_share_recent`.
      - Binary flags like `primary_goal_line_back`, `primary_rz_receiver` based on quantile thresholds within team.

- **5.2 2-minute and hurry-up roles**
  - Identify 2-minute / hurry-up situations:
    - Last 2 minutes of each half.
    - Situations where offense is down by more than one score late in game.
  - Compute per-player:
    - Snap share or target share in these situations.
    - TDs scored in hurry-up vs normal situations.
  - Add features:
    - `two_minute_snap_share`, `hurry_up_target_share`, etc.
    - Flags for “two-minute back” or “hurry-up slot WR”.

- **5.3 Alignment and route role features (if data available)**
  - If route/alignments exist:
    - Rate at which a player:
      - Lines up in the slot vs outside vs backfield vs inline TE in the red zone.
      - Runs routes in the end zone / inside 10.
  - Features:
    - `rz_slot_route_share`, `rz_inline_te_route_share`, `end_zone_target_share`.
    - Flags like `primary_end_zone_target`.

- **5.4 QB-specific TD mechanisms**
  - For QBs:
    - Designed rush attempts inside 10 / 5.
    - Scramble TD rates relative to dropbacks.
    - RZ pass vs scramble tendencies.
  - Features:
    - `qb_rz_rush_share`, `qb_scramble_td_rate`, `qb_rz_pass_td_rate`.

- **5.5 Running backs & TEs vs WRs**
  - Add position-specific feature templates:
    - For RBs: early-down vs short-yardage usage; RZ carries; screen target share.
    - For TEs: red-zone target share, end-zone target share, block vs route ratio.
    - For WRs: deep target share vs red-zone target share; contested catch targets near end zone.

- **5.6 Risk-aware implementation**
  - Tag all new features with:
    - `source` (drive/play-by-play), `time_window` (season vs last N games), and `situation` (red_zone, hurry_up).
  - Ensure they are built strictly from past games only; no use of current-game outcomes.
  - Add a small suite of unit tests for feature aggregation logic using synthetic play data.

- **Risks / Pitfalls**
  - Data quality: mis-tagged field position or missing drives could bias red-zone features; add sanity checks (e.g. team total sums of red-zone carries roughly match play counts).
  - Overfitting: many niche situational features; use regularization and monitor importance to prune low-value features later.

---

**6. Team Context & Scoring Environment (P2)**

Goals: connect player TD propensity to team scoring expectations and game environment.

- **6.1 Improve team scoring features**
  - From betting lines and historical scoring:
    - Compute `team_implied_total` and `opp_implied_total` from spreads and totals if not already robustly done.
    - Compute league-average implied total per season/week to create normalized features:
      - `team_implied_total_z_score`.
  - Add features that tie player usage to team context:
    - `team_implied_td_count ≈ team_implied_total / 7`.
    - Player share features:
      - `player_rush_td_share_recent * team_implied_td_count`.
      - `player_rec_td_share_recent * team_implied_td_count`.

- **6.2 Game environment features**
  - Compute:
    - Pace (plays per game, situation-adjusted if possible).
    - Run/pass rate, particularly in red zone.
    - Weather and stadium type (indoors/outdoors, surface) if available.
  - Add features:
    - `fast_pace_flag`, `run_heavy_rz_flag`, `indoor_flag`, `good_weather_flag`.

- **6.3 Calibration and interaction*
  - Later (P3): consider modeling team-level TD expectations separately and feeding them as a feature or constraint into the player-level model.
  - For now, ensure:
    - Team context variables are present and not collinear with straightforward derived totals.

- **Risks / Pitfalls**
  - Team implied totals are odds-derived and may overlap conceptually with player-specific odds; track both but be careful about double-counting odds information in leak analyses.
  - Environment features can be noisy; monitor importance and prune if they add little.

---

**7. Cleanup of Legacy / Dead Paths (P0–P3 depending on impact)**

Goals: remove MLB remnants and dead code that confuse maintenance and hide bugs.

- **7.1 Canonicalize game identifiers**
  - Decide on canonical ID (likely `game_id`).
  - Sweep code for `game_pk` and other MLB-centric IDs:
    - In `pipeline/train.py`, calibration/conformal code, and any schema definitions.
  - Plan:
    - Introduce a small mapping function (e.g. `canonical_game_id`) if necessary.
    - Migrate any remaining MLB references in NFL paths to the canonical ID.

- **7.2 Remove MLB-specific artifacts from NFL pipeline**
  - Identify MLB-only references:
    - `inning_topbot`, `statcast`, `pitcher_id`, etc.
  - For NFL-specific code paths:
    - Strip out MLB-only parameters and data paths.
    - Update docs and tests to only reference NFL-oriented concepts.
  - Keep MLB code only if there is a separate MLB pipeline clearly separated by directory or namespace; otherwise archive or remove.

- **7.3 Fix or deprecate `tune_features` CLI**
  - Decide on intended behavior:
    - Either wire it to an actual feature search (e.g. toggling feature groups, evaluating metrics) or explicitly remove/deprecate it to avoid confusion.
  - If keeping:
    - Make it call the main pipeline with different feature set configurations.
    - Add minimal documentation in `docs/` explaining how to use it and its limitations.

- **7.4 Remove commented stubs like `snap_zero_usage_stub`**
  - If the concept is still valuable:
    - Either implement properly (e.g. “zero-usage but active players” flag) with tests, or explicitly move to a tracked TODO in documentation.
  - Remove commented-out code to keep the feature module readable.

- **7.5 Documentation cleanup**
  - Move MLB-specific docs (`docs/Rolling.md`, `docs/statcast_glossary.md`) to:
    - A clearly-labeled MLB section, or
    - A deprecated folder if not relevant.
  - Add a short note in any shared docs clarifying which parts are NFL vs MLB.

- **Risks / Pitfalls**
  - Some code may be shared between sports; be careful not to break generic utilities while removing MLB-specific logic.
  - Ensure tests covering MLB paths (if any) are either updated or clearly separated.

---

**8. Documentation & Monitoring (P1)**

Goals: capture label/feature/leak rules in living docs and set up monitoring that can be automated.

- **8.1 Label and pipeline documentation**
  - Create `docs/anytime_td_pipeline.md` containing:
    - High-level overview of the anytime TD problem.
    - Label semantics, versions, and their exact definitions.
    - Major feature groups and their intended football meaning.
    - Leak guardrail rules and example banned columns.
    - Configuration fields specific to anytime TD (label_version, odds_horizon, purge_window, etc.).
  - Include a short “How to add new features safely” section:
    - Steps to add new features, tag them, and run leak and label tests.

- **8.2 Evaluation and slicing**
  - Extend evaluation to produce:
    - Metrics by position (QB/RB/WR/TE/other).
    - Metrics by role flags (goal-line back, primary red-zone target).
    - Metrics by odds buckets (e.g. implied anytime TD probability deciles).
    - Metrics by team implied total buckets.
  - Add outputs to `output/metrics/anytime_td/...`:
    - E.g. `metrics_by_position.csv`, `metrics_by_odds_bucket.csv`.

- **8.3 Odds-free baseline and benchmarks**
  - Add an odds-free model config:
    - Same labels and non-odds features only.
  - Track its metrics alongside the full model in:
    - `output/metrics/cutoff_backtest_summary.csv`.
  - Use this baseline to detect suspicious jumps when odds are added; large improvements may indicate misuse of post-decision data.

- **8.4 CI / smoke tests**
  - Add a lightweight CI test (using a small subset of games) that:
    - Runs feature assembly for a small date range.
    - Runs training for 1–2 folds.
    - Confirms:
      - No leak guardrail violations.
      - Labels are generated and have reasonable prevalence.
      - Model trains successfully and produces artifacts.
  - Ensure these tests do not depend on external network I/O to avoid flakiness.

- **Risks / Pitfalls**
  - Overly heavy CI can become slow; keep smoke tests tiny and separate from full offline backtests.
  - Slicing metrics produce many files; keep a clear naming scheme and document where to find them.

---

**9. Implementation & Rollout Strategy**

- **Phase P0: Safety and semantic correctness**
  - Implement label versioning and target wiring.
  - Set up leak guardrails and schema snapshots.
  - Enforce decision-time realism for odds and injuries.
  - Clean the most egregious MLB cruft in NFL paths and canonicalize `game_id`.
  - Run a small backtest (once network and runtime constraints allow) to ensure metrics are reasonable and no guardrail violations occur.

- **Phase P1: CV, baselines, and richer evaluation**
  - Introduce purge-aware time-series CV.
  - Add odds-free baseline config and evaluation.
  - Implement evaluation slices by position/role/odds bucket.
  - Write core docs for labels and leak policies; add CI smoke tests.

- **Phase P2: Football-grounded feature expansion**
  - Add red-zone and goal-line usage features, hurry-up roles, and position-specific TD mechanisms.
  - Integrate team context and scoring environment features.
  - Retrain and evaluate; compare improvements vs odds-free and full models while monitoring for new leak risks.

- **Phase P3: Ergonomics and tuning**
  - Finalize cleanup of dead CLIs and MLB docs in NFL scope.
  - Decide on and implement `tune_features` functionality or deprecate it.
  - Iterate on documentation, examples, and notebooks for future contributors.

If you’d like, the next step can be to pick a single P0 theme (e.g. label versioning + target wiring) and I can outline concrete code changes per file for that slice.
    <END_PLAN_END>

    Repository + Git requirements:

    - This repo is under git. At the very beginning of THIS RUN, before editing any files:
        1) Run `git status` to inspect the current state.
        2) If there are uncommitted changes from previous runs, stage and commit them with a concise
           message like `codex: iteration checkpoint` (or a slightly more descriptive variant).
        3) If a remote named `origin` exists and authentication allows, run `git push` so that the
           current state is saved remotely. If push fails due to auth or remote issues, continue with
           local commits only, but do NOT delete history.
        4) Only after ensuring there is a clean commit of the current state should you begin making
           new edits in this run.

    - During this run:
        * Make coherent, incremental commits as you reach logical checkpoints.
        * If you realize that your changes have badly broken the project and you cannot fix them
          cleanly within this run, you may revert to the last good commit (for example, using
          `git reset --hard HEAD` or `git checkout .`), then proceed more conservatively.

    Your tools allow you to:
    - Inspect files in this repo.
    - Edit files.
    - Run shell commands/tests as needed (e.g. project-specific tests, evaluations, or scripts).
    - Use git commands to create commits and, if possible, push them.

    Your goal in THIS RUN:
    - Implement as much of the plan as you reasonably can with high quality.
    - Prioritize correctness, alignment with football reality, and improved model performance
      over speed.
    - Run whatever tests or checks are appropriate to validate your changes.

    At the end of THIS RUN:
    - Give a concise update on your progress.
    - If the ENTIRE plan is fully implemented and validated, include a line with EXACTLY:
        The plan is completely implemented
      (case and spacing exactly as written).
    - If the plan is NOT fully implemented, include a concise progress summary starting with:
        PROGRESS:
      followed by a short description of what you accomplished and what remains.

    Take your time and implement the richest / most complete solution for the pieces you touch in this run.

mcp startup: no servers
warning: Repository snapshot encountered large untracked directories: .codex_meta_logs (883 files). This can slow Codex; consider adding these paths to .gitignore or disabling undo in your config.

thinking
**Checking git status**
exec
/bin/zsh -lc 'cd /Users/jameswest/Desktop/nfl_predict && git status --short' in /Users/jameswest/Desktop/nfl_predict succeeded in 847ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
 M codex_meta_loop.py
 M docs/rolling_window_implementation.md
 M pipeline/feature.py
 M pipeline/predict.py
 M pipeline/train.py
 M tests/test_training_config_features.py
 M utils/collect/visual_crossing_weather.py
 M utils/collect/weather_forecasts.py
 M utils/feature/player_game_level.py
 M utils/feature/rolling_window.py
 M utils/feature/stats.py
 M utils/general/constants.py
 M utils/train/persist.py
?? .codex_meta_logs/
?? _tmp_can_write
?? codex_output.md
?? docs/pre_snap_semantics.md
?? testfile
?? tests/test_predict_probabilities.py

thinking
**Preparing to commit existing changes**
exec
/bin/zsh -lc 'cd /Users/jameswest/Desktop/nfl_predict && git remote -v' in /Users/jameswest/Desktop/nfl_predict succeeded in 793ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
origin	git@github.com:jameswest25/nfl_predict.git (fetch)
origin	git@github.com:jameswest25/nfl_predict.git (push)

thinking
**Preparing commit before push**
exec
/bin/zsh -lc 'cd /Users/jameswest/Desktop/nfl_predict && git add -A' in /Users/jameswest/Desktop/nfl_predict exited 128 in 783ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
fatal: Unable to create '/Users/jameswest/Desktop/nfl_predict/.git/index.lock': Operation not permitted

thinking
**Checking for existing git lock file**
exec
/bin/zsh -lc 'cd /Users/jameswest/Desktop/nfl_predict && ls .git/index.lock' in /Users/jameswest/Desktop/nfl_predict exited 1 in 689ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
ls: .git/index.lock: No such file or directory

thinking
**Considering permission issues**
exec
/bin/zsh -lc 'cd /Users/jameswest/Desktop/nfl_predict && git add -A' in /Users/jameswest/Desktop/nfl_predict exited 128 in 736ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
fatal: Unable to create '/Users/jameswest/Desktop/nfl_predict/.git/index.lock': Operation not permitted

thinking
**Investigating .git permission issues**
exec
/bin/zsh -lc 'cd /Users/jameswest/Desktop/nfl_predict && ls -ld .git' in /Users/jameswest/Desktop/nfl_predict succeeded in 731ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
drwxr-xr-x  13 jameswest  staff  416 Nov 26 08:21 .git

thinking
**Investigating file write permissions**
exec
/bin/zsh -lc 'cd /Users/jameswest/Desktop/nfl_predict && echo hi > tmp_write_test' in /Users/jameswest/Desktop/nfl_predict succeeded in 707ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted

thinking
**Investigating .git permission issues**
exec
/bin/zsh -lc 'cd /Users/jameswest/Desktop/nfl_predict && touch .git/tmp_test' in /Users/jameswest/Desktop/nfl_predict exited 1 in 729ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
touch: .git/tmp_test: Operation not permitted

thinking
**Investigating .git write restrictions**
exec
/bin/zsh -lc 'cd /Users/jameswest/Desktop/nfl_predict && ls -le .git' in /Users/jameswest/Desktop/nfl_predict succeeded in 736ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
total 72
-rw-r--r--    1 jameswest  staff     18 Nov 26 01:04 COMMIT_EDITMSG
-rw-r--r--    1 jameswest  staff     21 Nov 25 22:42 HEAD
-rw-r--r--    1 jameswest  staff     41 Nov 25 22:50 ORIG_HEAD
-rw-r--r--    1 jameswest  staff    308 Nov 25 22:58 config
-rw-r--r--    1 jameswest  staff     73 Nov 25 22:42 description
drwxr-xr-x   15 jameswest  staff    480 Nov 25 22:42 hooks
-rw-r--r--    1 jameswest  staff  13040 Nov 26 01:04 index
drwxr-xr-x    3 jameswest  staff     96 Nov 25 22:42 info
drwxr-xr-x    4 jameswest  staff    128 Nov 25 22:45 logs
drwxr-xr-x  260 jameswest  staff   8320 Nov 26 03:43 objects
drwxr-xr-x    5 jameswest  staff    160 Nov 25 22:58 refs

thinking
**Checking Git directory flags**
exec
/bin/zsh -lc 'cd /Users/jameswest/Desktop/nfl_predict && ls -lO .git' in /Users/jameswest/Desktop/nfl_predict succeeded in 733ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
total 72
-rw-r--r--    1 jameswest  staff  -    18 Nov 26 01:04 COMMIT_EDITMSG
-rw-r--r--    1 jameswest  staff  -    21 Nov 25 22:42 HEAD
-rw-r--r--    1 jameswest  staff  -    41 Nov 25 22:50 ORIG_HEAD
-rw-r--r--    1 jameswest  staff  -   308 Nov 25 22:58 config
-rw-r--r--    1 jameswest  staff  -    73 Nov 25 22:42 description
drwxr-xr-x   15 jameswest  staff  -   480 Nov 25 22:42 hooks
-rw-r--r--    1 jameswest  staff  - 13040 Nov 26 01:04 index
drwxr-xr-x    3 jameswest  staff  -    96 Nov 25 22:42 info
drwxr-xr-x    4 jameswest  staff  -   128 Nov 25 22:45 logs
drwxr-xr-x  260 jameswest  staff  -  8320 Nov 26 03:43 objects
drwxr-xr-x    5 jameswest  staff  -   160 Nov 25 22:58 refs

thinking
**Investigating .git write restrictions**

I'm exploring why writes to the .git directory fail, considering possible filesystem virtualizations or sandbox policies blocking modifications. Since staging requires creating index.lock, which isn't permitted, I’m thinking about workarounds like setting GIT_INDEX_FILE to a writable path outside .git to stage changes, though committing might still fail due to restrictions on writing to .git/objects. I'll keep these constraints in mind and consider alerting the user if commits aren't possible.

thinking
**Checking temporary file handling**
exec
/bin/zsh -lc 'cd /Users/jameswest/Desktop/nfl_predict && touch .git/objects/tmp_test' in /Users/jameswest/Desktop/nfl_predict exited 1 in 743ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
touch: .git/objects/tmp_test: Operation not permitted

thinking
**Assessing commit limitations and planning partial work**

I see that I can't write to the .git directory, so committing any changes is impossible in this environment. Since committing is required before edits but unfeasible now, I’ll have to proceed cautiously—informing the user about this limitation later, but still working on implementing a scoped subset of the plan. I want to explore the repo structure and inspect existing modifications carefully so I don’t overwrite anything important, focusing on partial features like label versioning, target wiring, and guard skeleton to keep the scope manageable.
exec
/bin/zsh -lc 'cd /Users/jameswest/Desktop/nfl_predict && ls' in /Users/jameswest/Desktop/nfl_predict succeeded in 746ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
README.md
__pycache__
_tmp_can_write
audit
cache
codex_meta_loop.py
codex_output.md
config
data
docs
logs
main.py
output
pipeline
pyproject.toml
requirements.txt
scripts
testfile
tests
exec
/bin/zsh -lc 'cd /Users/jameswest/Desktop/nfl_predict && ls config' in /Users/jameswest/Desktop/nfl_predict succeeded in 731ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
config.yaml
training.yaml

thinking
**Checking current training configuration**
exec
/bin/zsh -lc "cd /Users/jameswest/Desktop/nfl_predict && sed -n '1,200p' config/training.yaml" in /Users/jameswest/Desktop/nfl_predict succeeded in 728ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
# config/training.yaml
# Configuration for the model training pipeline (pipeline/train.py)
# NFL Player Prediction Targets

# --- Data I/O ---
data:
  raw_pbp_dir: 'data/raw/pbp_by_day'  # NFL play-by-play raw data
  feature_matrix_path: 'data/processed/final/processed.parquet'  # NFL feature matrix
  
  # Directory to save trained model artifacts (models and feature lists).
  model_output_dir: 'output/models'
  
  # Directory to save evaluation reports and metrics.
  metrics_output_dir: 'output/metrics/'

# =============================================================================
# SHARED COLUMN DEFINITIONS (using YAML anchors to avoid duplication)
# =============================================================================
# These columns leak same-game outcomes and must be excluded from training.

thinking
**Continuing to review large file near problem section**
exec
/bin/zsh -lc 'cd /Users/jameswest/Desktop/nfl_predict && rg "anytime" -n config/training.yaml' in /Users/jameswest/Desktop/nfl_predict succeeded in 772ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
476:  - name: 'anytime_td'
477:    target_col: 'anytime_td'
666:    - 'anytime_td'
exec
/bin/zsh -lc "cd /Users/jameswest/Desktop/nfl_predict && sed -n '440,540p' config/training.yaml" in /Users/jameswest/Desktop/nfl_predict succeeded in 731ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
      - 'availability_snapshare'
      - 'usage_targets'
      - 'usage_carries'
      - 'efficiency_rec_yards'
      - 'efficiency_rush_yards'
    feature_prefixes_to_include:
      - 'pred_'
      - 'expected_'
      - 'opp_def_'
      - 'red_zone_'
      - 'goal_to_go_'
      - 'off_ctx_'
      - 'qb_profile_'
      - 'drive_hist_'
      - 'weather_'
      - 'travel_'
    other_features_to_include:
      - 'week'
      - 'season'

thinking
**Reviewing training config and integration plan**
exec
/bin/zsh -lc "cd /Users/jameswest/Desktop/nfl_predict && sed -n '1,200p' utils/feature/player_game_level.py" in /Users/jameswest/Desktop/nfl_predict succeeded in 735ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
"""Player-game level aggregation for NFL predictions.

Aggregates play-by-play data to player-game level for all skill positions.
Each player gets one row per game with their total stats.

Target columns created:
- anytime_td (binary): Did player score a TD (receiving or rushing)?
- td_count (int): Number of TDs scored (receiving + rushing)
- passing_td (int): Number of passing TDs (for QBs)
- receiving_yards (float): Total receiving yards
- rushing_yards (float): Total rushing yards
- passing_yards (float): Total passing yards
"""

from __future__ import annotations

from pathlib import Path
from datetime import date
import datetime as dt

thinking
**Searching for label computation**
exec
/bin/zsh -lc 'cd /Users/jameswest/Desktop/nfl_predict && rg "anytime_td" utils/feature/player_game_level.py' in /Users/jameswest/Desktop/nfl_predict succeeded in 746ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
- anytime_td (binary): Did player score a TD (receiving or rushing)?
    "market_anytime_td_prob",
    "market_anytime_td_consensus",
    "market_anytime_td_spread",
    "market_anytime_td_book_count",
    "market_anytime_td_prob_2h",
    "market_anytime_td_consensus_2h",
    "market_anytime_td_spread_2h",
    "market_anytime_td_book_count_2h",
    "market_anytime_td_prob_6h",
    "market_anytime_td_consensus_6h",
    "market_anytime_td_spread_6h",
    "market_anytime_td_book_count_6h",
    "market_anytime_td_prob_24h",
    "market_anytime_td_consensus_24h",
    "market_anytime_td_spread_24h",
    "market_anytime_td_book_count_24h",
    "market_anytime_td_prob_open",
    "market_anytime_td_consensus_open",

thinking
**Inspecting code near label compute**
exec
/bin/zsh -lc "cd /Users/jameswest/Desktop/nfl_predict && sed -n '820,980p' utils/feature/player_game_level.py" in /Users/jameswest/Desktop/nfl_predict succeeded in 742ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
                pl.col("snapshot_ts").alias("snapshot_ts_snap"),
                pl.col("status").alias("status_snap"),
                pl.col("status_abbr").alias("status_abbr_snap"),
                pl.col("status_detail").alias("status_detail_snap"),
                pl.col("depth_chart_order").alias("depth_chart_order_snap"),
            ]
        )
        roster_game = roster_game.join(
            snapshot_pl,
            on=["game_id", "player_id"],
            how="left",
        )
        roster_game = roster_game.with_columns(
            pl.when(
                pl.col("snapshot_ts_snap").is_not_null()
                & pl.col("_decision_cutoff_ts").is_not_null()
                & (pl.col("snapshot_ts_snap") <= pl.col("_decision_cutoff_ts"))
            )
            .then(pl.col("snapshot_ts_snap"))

thinking
**Searching for touchdown label computation**
exec
/bin/zsh -lc 'cd /Users/jameswest/Desktop/nfl_predict && rg "_total_touchdowns" -n utils/feature/player_game_level.py' in /Users/jameswest/Desktop/nfl_predict succeeded in 710ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
3443:        .alias("_total_touchdowns")
3447:        (pl.col("_total_touchdowns") > 0).cast(pl.Int8).alias("anytime_td"),
3448:        pl.col("_total_touchdowns").alias("td_count"),
3449:    ]).drop("_total_touchdowns")

thinking
**Checking context near line 3440**
exec
/bin/zsh -lc "cd /Users/jameswest/Desktop/nfl_predict && sed -n '3400,3485p' utils/feature/player_game_level.py" in /Users/jameswest/Desktop/nfl_predict succeeded in 736ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
            # Sum TD counts
            pl.col("passing_td").fill_null(0).sum().alias("passing_td"),
            pl.col("rushing_td_count").fill_null(0).sum().alias("rushing_td_count"),
            pl.col("receiving_td_count").fill_null(0).sum().alias("receiving_td_count"),
            pl.col("touchdowns").fill_null(0).sum().alias("touchdowns"),
            
            # Team context (take first, should be same)
            pl.col("team").first().alias("team"),
            pl.col("opponent").first().alias("opponent"),
            *_metadata_exprs(df),
        ])
    )
    
    # Fill nulls with 0 for numeric columns
    numeric_cols = [
        "passing_yards", "rushing_yards", "receiving_yards",
        "pass_attempt", "completion", "carry", "target", "reception",
        "passing_td", "rushing_td_count", "receiving_td_count", "touchdowns",
        "td_count", "red_zone_target", "red_zone_carry", "goal_to_go_target", "goal_to_go_carry"

thinking
**Planning label computation refactor**
exec
/bin/zsh -lc "cd /Users/jameswest/Desktop/nfl_predict && sed -n '1,200p' utils/feature/targets.py" in /Users/jameswest/Desktop/nfl_predict succeeded in 726ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
"""Target column validation for NFL player prediction models.

Target columns are created in utils/feature/player_game_level.py during aggregation.
This module validates that required targets exist and have correct dtypes.
"""

import polars as pl
import logging

logger = logging.getLogger(__name__)


# Expected target columns and their types
NFL_TARGET_SCHEMA = {
    # Binary classification targets
    "anytime_td": pl.Int8,  # Primary MVP target: did player score a TD?
    
    # Count/regression targets
    "td_count": pl.Int64,  # Number of TDs scored (receiving + rushing)

thinking
**Checking pipeline train.py for target usage**
exec
/bin/zsh -lc "cd /Users/jameswest/Desktop/nfl_predict && sed -n '1,200p' pipeline/train.py" in /Users/jameswest/Desktop/nfl_predict succeeded in 747ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
import os
import random
import inspect
import sys
import logging
import math


# Move logging to top and remove global thread pinning
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# Add project root to sys.path to allow module imports when running as script
sys.path.append(os.getcwd())

import pandas as pd
import numpy as np
import yaml
import joblib
import optuna

thinking
**Searching for target_col usage in training script**
exec
/bin/zsh -lc 'cd /Users/jameswest/Desktop/nfl_predict && rg "target_col" -n pipeline/train.py' in /Users/jameswest/Desktop/nfl_predict succeeded in 747ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
261:        self.target_col = None
691:            df = self._derive_target_column(
693:                target_col=problem_config["target_col"],
725:    def _derive_target_column(
728:        target_col: str,
740:                  raise ValueError(f"Cannot derive {target_col} from game_by_week (missing source or data).")
748:             merged.rename(columns={source_col: target_col}, inplace=True)
751:             merged = merged[merged[target_col].notna()].reset_index(drop=True)
778:        df[target_col] = (
784:        df = df[df[target_col].notna()].reset_index(drop=True)
912:        X, y = transform_with_artifacts(df, artifacts, self.target_col)
973:            target_col=self.target_col,
982:        if self.target_col not in df_train.columns:
993:        targets = pd.to_numeric(df_train[self.target_col], errors="coerce").fillna(0.0)
998:                self.target_col: targets,
1014:        actual = grouped[self.target_col].sum()
2165:            self.target_col = problem_copy['target_col']
2177:                target_load_cols.append(self.target_col)
2317:            if self.target_col and self.target_col in df_problem.columns:

thinking
**Examining functions near target**
exec
/bin/zsh -lc "cd /Users/jameswest/Desktop/nfl_predict && sed -n '650,840p' pipeline/train.py" in /Users/jameswest/Desktop/nfl_predict succeeded in 726ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted

        _combine_rz("expected_rz_opportunities", "team_based_rz_opportunities", "expected_rz_opportunities")
        _combine_rz("expected_rz_opportunities_raw", "team_based_rz_opportunities_raw", "expected_rz_opportunities_raw")

        if "expected_rz_targets" in df.columns and "expected_rz_carries" in df.columns:
            df["expected_rz_opportunities"] = df["expected_rz_targets"] + df["expected_rz_carries"]
        if "expected_rz_targets_raw" in df.columns and "expected_rz_carries_raw" in df.columns:
            df["expected_rz_opportunities_raw"] = df["expected_rz_targets_raw"] + df["expected_rz_carries_raw"]

        if "pred_efficiency_tds" in df.columns and "expected_rz_opportunities" in df.columns:
            df["expected_rz_td_signal"] = df["pred_efficiency_tds"] * df["expected_rz_opportunities"]
        if "pred_efficiency_tds" in df.columns and "expected_rz_opportunities_raw" in df.columns:
            df["expected_rz_td_signal_raw"] = df["pred_efficiency_tds"] * df["expected_rz_opportunities_raw"]

        if "pred_efficiency_rec_yards" in df.columns:
            df["expected_receiving_yards"] = (
                pd.to_numeric(df["pred_efficiency_rec_yards"], errors="coerce")
                .clip(lower=0.0)
            )

thinking
**Planning label config updates**

I'm mapping out how to introduce new label specs and integrate them into the training config and label computation while keeping changes minimal and focused on P0 label semantics and target wiring. I'll add a label spec module, adjust label computation in player_game_level, and carefully update training.yaml to include label versions and target columns without breaking existing functionality. Testing impact needs checking too.

thinking
**Evaluating target column strategies**
exec
/bin/zsh -lc 'cd /Users/jameswest/Desktop/nfl_predict && rg "anytime_td"' in /Users/jameswest/Desktop/nfl_predict succeeded in 779ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
main.py:4. Train: Train models on player targets (anytime_td, yards, etc.)
pipeline/train.py:    parser.add_argument('--problem', type=str, default='anytime_td', help="The problem to optimize for during tuning.")
utils/feature/targets.py:    "anytime_td": pl.Int8,  # Primary MVP target: did player score a TD?
docs/predict.md:  - Latest model + artifacts from `output/models/anytime_td/xgboost/<timestamp>/`.
docs/predict.md:  - Inference artifacts (`output/models/inference_artifacts_anytime_td.joblib`) for frozen feature order + categorical levels.
docs/predict.md:  - CSV under `output/predictions/anytime_td_predictions_<start>_<end>.csv` with one row per player/game.
docs/predict.md:- **Model threshold** – Pulled from `output/metrics/anytime_td/xgboost/<timestamp>/metrics.yaml`.
tests/test_data_leak_guard.py:def test_anytime_td_feature_list_has_no_banned_columns():
tests/test_data_leak_guard.py:    anytime_td = _load_training_problem("anytime_td")
tests/test_data_leak_guard.py:    other_features = set(anytime_td.get("other_features_to_include", []))
tests/test_data_leak_guard.py:        "Leak-prone columns found in anytime_td feature list: "
tests/test_data_leak_guard.py:def test_anytime_td_prefixes_do_not_cover_banned_columns():
tests/test_data_leak_guard.py:    anytime_td = _load_training_problem("anytime_td")
tests/test_data_leak_guard.py:    prefixes = [str(p) for p in anytime_td.get("feature_prefixes_to_include", []) or []]
scripts/eval/odds_backtest.py:        --score-column market_anytime_td_prob \
scripts/eval/odds_backtest.py:        default="market_anytime_td_prob",
scripts/eval/odds_backtest.py:        default="anytime_td",
scripts/backtest/run_backtest.py:        default="anytime_td",
scripts/backtest/run_backtest.py:        help="Target column (default: anytime_td).",

thinking
**Planning label versioning system**

I'm considering adding a flexible label versioning system by keeping the existing `anytime_td` column for compatibility while introducing new columns and configs for label versions; I'll design minimal yet precise label specs, update relevant modules to compute and validate these labels, and add targeted tests without disrupting existing code.

thinking
**Analyzing touchdown data availability**

thinking
**Designing touchdown label specifications**
exec
/bin/zsh -lc 'cd /Users/jameswest/Desktop/nfl_predict && rg "player_game_level" -n pipeline/feature.py' in /Users/jameswest/Desktop/nfl_predict succeeded in 752ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
9:3. **build_player_game_level**  – aggregate per game and join context
27:from utils.feature.player_game_level import build_player_game_level
297:            build_player_game_level(start_date=cur, end_date=chunk_end)
exec
/bin/zsh -lc "cd /Users/jameswest/Desktop/nfl_predict && sed -n '1,200p' pipeline/feature.py" in /Users/jameswest/Desktop/nfl_predict succeeded in 734ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
from __future__ import annotations

"""Feature pipeline orchestrator for NFL player-level predictions.

Stages
------
1. **build_play_level**         – derive cleaned play-level slices
2. **build_player_drive_level** – aggregate per drive
3. **build_player_game_level**  – aggregate per game and join context

This wrapper triggers each stage, optionally enforces a schema after each
write, and returns the final game-level DataFrame for downstream usage.
"""

import logging
import os
from datetime import date, timedelta
from typing import Sequence


thinking
**Searching for validate_target_columns usage**
exec
/bin/zsh -lc 'cd /Users/jameswest/Desktop/nfl_predict && rg "validate_target_columns" -n pipeline/feature.py' in /Users/jameswest/Desktop/nfl_predict succeeded in 734ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
29:from utils.feature.targets import validate_target_columns
815:    df_player_game_all = validate_target_columns(df_player_game_all, strict=False)
exec
/bin/zsh -lc "cd /Users/jameswest/Desktop/nfl_predict && sed -n '760,840p' pipeline/feature.py" in /Users/jameswest/Desktop/nfl_predict succeeded in 707ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted

    logging.info("Enriching odds features (NFL)...")
    rows_before_odds = df_player_game_all.height
    df_player_game_all = add_nfl_odds_features_to_df(
        df_player_game_all,
        player_col="player_name",
        allow_schedule_fallback=False,
        drop_schedule_rows=True,
    )

    rows_after_odds = df_player_game_all.height
    logging.info(
        "Odds features attached; retained %d/%d rows (%.2f%%) with pre-cutoff snapshots",
        rows_after_odds,
        rows_before_odds,
        (rows_after_odds / rows_before_odds * 100.0) if rows_before_odds else 0.0,
    )
    if "odds_schedule_fallback" not in df_player_game_all.columns:
        df_player_game_all = df_player_game_all.with_columns(

thinking
**Planning label version integration**
exec
/bin/zsh -lc 'cd /Users/jameswest/Desktop/nfl_predict && rg "def build_player_game_level" -n utils/feature/player_game_level.py' in /Users/jameswest/Desktop/nfl_predict succeeded in 735ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
1585:def build_player_game_level(*, start_date: date, end_date: date) -> None:
exec
/bin/zsh -lc "cd /Users/jameswest/Desktop/nfl_predict && sed -n '1550,1680p' utils/feature/player_game_level.py" in /Users/jameswest/Desktop/nfl_predict succeeded in 753ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
            pl.col("season").cast(pl.Int32),
            pl.col("week").cast(pl.Int32),
            pl.col("team").cast(pl.Utf8),
        ]
    )
    float_cols = [
        col
        for col, dtype in df.schema.items()
        if col.startswith("travel_")
        and col
        not in {
            "travel_short_week_flag",
            "travel_long_rest_flag",
            "travel_bye_week_flag",
            "travel_west_to_east_early_flag",
            "travel_east_to_west_late_flag",
        }
        and dtype in (pl.Float64, pl.Float32, pl.Int64, pl.Int32, pl.UInt64, pl.UInt32)
    ]

thinking
**Adding optional label version argument**
exec
/bin/zsh -lc 'cd /Users/jameswest/Desktop/nfl_predict && rg "training" pipeline/feature.py' in /Users/jameswest/Desktop/nfl_predict succeeded in 748ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
    add_offense_context_features_training,
    add_weather_forecast_features_training,
    # This is what training will use
    df_player_game_all = add_offense_context_features_training(
        df_player_game_all = add_weather_forecast_features_training(
    # training configuration, so we avoid dropping them here to retain label availability.

thinking
**Inspecting build_feature_matrix function**
exec
/bin/zsh -lc 'cd /Users/jameswest/Desktop/nfl_predict && rg "def build_feature_matrix" -n pipeline/feature.py' in /Users/jameswest/Desktop/nfl_predict succeeded in 748ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
960:def build_feature_matrix(
exec
/bin/zsh -lc "cd /Users/jameswest/Desktop/nfl_predict && sed -n '940,1080p' pipeline/feature.py" in /Users/jameswest/Desktop/nfl_predict succeeded in 760ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
        primary_output.parent.mkdir(parents=True, exist_ok=True)
        df_player_game_all.write_parquet(primary_output, compression="zstd")

    logging.info("✅  Final feature matrix (%s cutoff) written → %s", cutoff_label, target_output_path)
    if primary_output != target_output_path:
        logging.info("    Primary feature matrix updated → %s", primary_output)
    logging.info("    Rows: %d, Columns: %d", len(df_player_game_all), len(df_player_game_all.columns))
    logging.info("    Date range: %s to %s", 
                 df_player_game_all["game_date"].min(), 
                 df_player_game_all["game_date"].max())
    
    # Log target distribution for anytime_td
    if "anytime_td" in df_player_game_all.columns:
        td_count = df_player_game_all["anytime_td"].sum()
        td_rate = td_count / len(df_player_game_all) * 100
        logging.info("    Anytime TD rate: %.2f%% (%d/%d)", td_rate, td_count, len(df_player_game_all))
    
    return df_player_game_all


thinking
**Investigating feature matrix function**
exec
/bin/zsh -lc 'cd /Users/jameswest/Desktop/nfl_predict && rg "_build_feature_matrix_internal" -n -g"pipeline/feature.py"' in /Users/jameswest/Desktop/nfl_predict succeeded in 833ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
pipeline/feature.py:226:def _build_feature_matrix_internal(
pipeline/feature.py:986:            df = _build_feature_matrix_internal(
exec
/bin/zsh -lc "cd /Users/jameswest/Desktop/nfl_predict && sed -n '200,340p' pipeline/feature.py" in /Users/jameswest/Desktop/nfl_predict succeeded in 751ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
        + [_l3_name(col) for col in numeric_cols]
    )
    feature_cols.extend(rate_feature_names)
    feature_cols = list(dict.fromkeys(feature_cols))

    drive_features = drive_features.select(
        [
            "season",
            "week",
            "game_id",
            "team",
            "player_id",
            "game_date",
            "data_as_of",
            *feature_cols,
        ]
    )

    return drive_features.with_columns(

thinking
**Planning label version parameter integration**

thinking
**Designing label specification structure**

thinking
**Designing touchdown expression computations**

thinking
**Reviewing touchdown counting logic**
exec
/bin/zsh -lc 'cd /Users/jameswest/Desktop/nfl_predict && rg "_aggregate_passers" -n utils/feature/player_game_level.py' in /Users/jameswest/Desktop/nfl_predict succeeded in 773ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
1657:    passer_stats = _aggregate_passers(df)
3200:def _aggregate_passers(df: pl.DataFrame) -> pl.DataFrame:
exec
/bin/zsh -lc "cd /Users/jameswest/Desktop/nfl_predict && sed -n '3170,3330p' utils/feature/player_game_level.py" in /Users/jameswest/Desktop/nfl_predict succeeded in 739ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted

    df = df.with_columns(
        pl.when(fallback_expr)
        .then(pl.lit("heuristic"))
        .otherwise(pl.lit("model"))
        .alias("injury_inactive_probability_source")
        )

    df = df.with_columns(
        pl.when(fallback_expr)
        .then(heuristic_prob)
        .otherwise(pl.col(MODEL_PROB_COL))
        .alias("injury_inactive_probability")
    )

    df = df.with_columns(
        [
            pl.when(fallback_expr)
            .then(pl.col("injury_inactive_probability"))
exec
/bin/zsh -lc "cd /Users/jameswest/Desktop/nfl_predict && sed -n '3330,3470p' utils/feature/player_game_level.py" in /Users/jameswest/Desktop/nfl_predict succeeded in 742ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
            pl.col("target").fill_null(0).sum().cast(pl.Int64).alias("target"),
            pl.col("reception").fill_null(0).sum().cast(pl.Int64).alias("reception"),
            pl.when(pl.col("pass_touchdown") == 1).then(1).otherwise(0).sum().cast(pl.Int64).alias("receiving_td_count"),
            pl.col("red_zone_target").fill_null(0).sum().cast(pl.Int64).alias("red_zone_target"),
            pl.col("goal_to_go_target").fill_null(0).sum().cast(pl.Int64).alias("goal_to_go_target"),
            
            # Initialize other stats to 0
            pl.lit(0.0).cast(pl.Float64).alias("passing_yards"),
            pl.lit(0).cast(pl.Int64).alias("pass_attempt"),
            pl.lit(0).cast(pl.Int64).alias("completion"),
            pl.lit(0).cast(pl.Int64).alias("passing_td"),
            pl.lit(0.0).cast(pl.Float64).alias("rushing_yards"),
            pl.lit(0).cast(pl.Int64).alias("carry"),
            pl.lit(0).cast(pl.Int64).alias("rushing_td_count"),
            pl.lit(0).cast(pl.Int64).alias("red_zone_carry"),
            pl.lit(0).cast(pl.Int64).alias("goal_to_go_carry"),
            
            # Touchdowns
            pl.when(pl.col("touchdown_player_id") == pl.col("receiver_player_id"))

thinking
**Planning label computation refactor**

I'm thinking about consolidating label calculations into a new helper called `_compute_td_labels`, to be called during the merging step for consistency. This will involve creating a new utility module to hold label specifications and rules, possibly using dataclasses to define label versions and their settings. This way, aggregators won’t redundantly compute labels early on, and the final merged dataframe will have reliable, unified label columns.

thinking
**Designing label specs and tests**

I’m planning functions to get label specs by version and to compute label columns in a polars DataFrame, handling aliases and minimal required columns. I want to define a global constant for required base columns and add tests with small synthetic datasets covering typical touchdown scenarios, using polars and pytest conventions while checking existing test styles for guidance.
exec
/bin/zsh -lc "cd /Users/jameswest/Desktop/nfl_predict && sed -n '1,200p' tests/test_data_leak_guard.py" in /Users/jameswest/Desktop/nfl_predict succeeded in 742ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
from __future__ import annotations

import yaml
from pathlib import Path


PROJECT_ROOT = Path(__file__).resolve().parents[1]
TRAINING_CONFIG = PROJECT_ROOT / "config" / "training.yaml"
BANNED_FEATURES = {
    "status",
    "injury_game_status",
    "injury_is_inactive_designation",
    "injury_is_inactive_prob",
    "touchdown_player_id",
}


def _load_training_problem(name: str) -> dict:
    with TRAINING_CONFIG.open("r") as fp:

thinking
**Planning label version integration**

thinking
**Planning label version integration**

I'm thinking about adding a nested `labels` field with version and target inside the problem config to handle label versions more flexibly. This will require updating the training pipeline and utilities to recognize and verify these new label specs, especially ensuring the target column's presence. I'll explore where in the training code problem configs are processed to insert these checks and keep changes minimal but effective.
exec
/bin/zsh -lc 'cd /Users/jameswest/Desktop/nfl_predict && rg "problems_to_run" -n pipeline/train.py' in /Users/jameswest/Desktop/nfl_predict exited 1 in 761ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted

thinking
**Searching for configuration usage**
exec
/bin/zsh -lc 'cd /Users/jameswest/Desktop/nfl_predict && rg "problems" pipeline/train.py' in /Users/jameswest/Desktop/nfl_predict succeeded in 704ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
        if "problems" in overrides and overrides["problems"]:
            self.config["problems"] = [p for p in self.config["problems"] if p["name"] in set(overrides["problems"])]
        self.problems = self.config['problems']
        # Store predictions + merge keys for downstream problems
        """Prepare team total adjustment configuration for classification problems."""
        """Execute the full training pipeline for all defined problems."""
        for problem in self.problems:
            # Check if this problem requires input predictions from previous problems
        # --- NEW: build composite & team conformal sum artifacts after all problems trained ---
                for p in self.problems:
    problem_config = next((p for p in base_trainer.config['problems'] if p['name'] == problem_name), None)
    parser.add_argument('--problems', type=str, default='', help="Comma-separated subset of problems to run.")
                "problems": [p.strip() for p in args.problems.split(",") if p.strip()] if args.problems else None,

thinking
**Extracting main training run section**
exec
/bin/zsh -lc "cd /Users/jameswest/Desktop/nfl_predict && sed -n '2100,2340p' pipeline/train.py" in /Users/jameswest/Desktop/nfl_predict succeeded in 703ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
                else:
                    return model.steps[-1][1]
        except Exception:
            pass

        # 3) Our custom calibration wrappers
        try:
            if isinstance(model, (IsotonicCalibratedModel, BetaCalibratedModel, HistogramBinningCalibratedModel)):
                return model.base_estimator
        except Exception:
            pass

        try:
            if isinstance(model, (IsotonicMeanCalibratedRegressor, SplitConformalRegressor)):
                return model.base_estimator
        except Exception:
            pass

        # 4) SelectiveClassifier – return the base estimator

thinking
**Planning target column validation and label version support**

I'm thinking through adding robust checks for the target column's existence and validity when loading problem data, possibly via a new helper in `utils/feature/targets.py`. I want to incorporate label version info from config, update training config accordingly, and ensure errors raise clearly if targets are missing or invalid. I'll also consider adding focused tests for label logic to keep verification manageable.

thinking
**Analyzing touchdown label aggregation**

thinking
**Defining touchdown count expressions**

thinking
**Designing label summation expressions**

thinking
**Planning touchdown label computations**

thinking
**Updating label specification and target column handling**

I'm planning updates to label handling by adding fallback defaults and versioning support in the config and pipeline. I'll enhance `ensure_target_column` logic to verify column presence and aliasing, add validation functions, and update the trainer to log label version use. This way, the data targets will be properly aligned with label specs, preventing missing or misnamed columns during training.

thinking
**Planning label computation updates**

thinking
**Planning label computation integration**
exec
/bin/zsh -lc "cd /Users/jameswest/Desktop/nfl_predict && sed -n '1680,1880p' utils/feature/player_game_level.py" in /Users/jameswest/Desktop/nfl_predict succeeded in 843ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
    
    # Merge rows where same player had multiple roles in same game
    # (e.g., QB who also rushed, WR who also rushed)
    df_merged = _merge_multi_role_players(df_all)

    df_merged = _append_zero_usage_players(df_merged, seasons_in_window)
    
    pre_snap_usage = _compute_pre_snap_usage(df)
    if not pre_snap_usage.is_empty():
        df_merged = df_merged.join(
            pre_snap_usage, on=["season", "week", "team", "player_id"], how="left"
        )
    for col in PRE_SNAP_BASE_COLUMNS:
        if col in df_merged.columns:
            df_merged = df_merged.with_columns(
                pl.col(col).fill_null(0).cast(pl.Float32).alias(col)
            )
        else:
            df_merged = df_merged.with_columns(

thinking
**Updating function signatures and config for label versions**

thinking
**Enhancing target validation and label version handling**

I'm adding logger warnings and calling require_target in ModelTrainer.run to ensure target columns are validated before dropping nulls. I plan to import the needed validation functions and update pipeline and feature building code to handle label versions, aiming to align features generated with training config targets by passing an optional label_version parameter through build_feature_matrix and related calls, defaulting to keep compatibility.

thinking
**Planning feature_matrix updates**

I’m sorting out how to add an optional label_version parameter to feature_matrix and its internals without breaking existing code. I need to check main entry points for call sites, decide whether to tie label_version to configs, and consider adding new label-related functions and schema columns carefully. Testing strategies and patching rules are also on my mind to keep changes contained and manageable.

thinking
**Planning label schema updates and patching**

I'm figuring out how to add new label columns with proper data types to the NFL_TARGET_SCHEMA, aiming to keep changes minimal and safe by adding a helper function for requiring target columns, updating training configs, and adding tests. I want to patch new files carefully without overwriting user changes, applying patches sequentially and reading existing modifications to avoid conflicts.
file update
A /Users/jameswest/Desktop/nfl_predict/utils/feature/labels.py
"""Label semantics and versioning for NFL player-level targets.

This module centralizes anytime-TD label definitions so that:
- Semantics are explicit and versioned.
- Training can request a specific label column per problem.
- Feature generation can emit multiple label variants for analysis.
"""

from __future__ import annotations

from dataclasses import dataclass, field
from typing import Dict, Iterable, Mapping

import polars as pl


@dataclass(frozen=True)
class LabelRules:
    """Rules controlling which TD components count toward a label."""

    include_rush: bool = True
    include_rec: bool = True
    include_pass_thrown: bool = True  # credit passers for thrown TDs
    include_other: bool = False  # fumble returns, defensive/special teams if present


@dataclass(frozen=True)
class LabelSpec:
    """Container describing a label version."""

    name: str
    primary: str
    labels: Mapping[str, LabelRules]
    aliases: Mapping[str, str] = field(default_factory=dict)

    @property
    def all_columns(self) -> set[str]:
        cols = set(self.labels.keys())
        cols.update(self.aliases.keys())
        return cols


DEFAULT_LABEL_VERSION = "v1_any_offense"


LABEL_VERSIONS: Dict[str, LabelSpec] = {
    "v1_any_offense": LabelSpec(
        name="v1_any_offense",
        primary="anytime_td_offense",
        labels={
            "anytime_td_offense": LabelRules(include_other=False),
            "anytime_td_rush": LabelRules(include_rush=True, include_rec=False, include_pass_thrown=False, include_other=False),
            "anytime_td_rec": LabelRules(include_rush=False, include_rec=True, include_pass_thrown=False, include_other=False),
            "anytime_td_pass_thrown": LabelRules(include_rush=False, include_rec=False, include_pass_thrown=True, include_other=False),
            "anytime_td_all": LabelRules(include_other=True),
        },
        aliases={
            # Maintain legacy column name as an alias to the offense-only label.
            "anytime_td": "anytime_td_offense",
            # Keep td_count pointing to the offense definition for backward compatibility.
            "td_count": "td_count_offense",
        },
    ),
    "v1_any_all": LabelSpec(
        name="v1_any_all",
        primary="anytime_td_all",
        labels={
            "anytime_td_all": LabelRules(include_other=True),
            "anytime_td_offense": LabelRules(include_other=False),
            "anytime_td_rush": LabelRules(include_rush=True, include_rec=False, include_pass_thrown=False, include_other=False),
            "anytime_td_rec": LabelRules(include_rush=False, include_rec=True, include_pass_thrown=False, include_other=False),
            "anytime_td_pass_thrown": LabelRules(include_rush=False, include_rec=False, include_pass_thrown=True, include_other=False),
        },
        aliases={
            "anytime_td": "anytime_td_all",
            "td_count": "td_count_all",
        },
    ),
}


def get_label_spec(version: str | None) -> LabelSpec:
    """Return a concrete LabelSpec for the requested version (or default)."""

    version = version or DEFAULT_LABEL_VERSION
    if version not in LABEL_VERSIONS:
        raise ValueError(
            f"Unknown label_version '{version}'. "
            f"Available: {sorted(LABEL_VERSIONS.keys())}"
        )
    return LABEL_VERSIONS[version]


def _sum_expr(exprs: Iterable[pl.Expr]) -> pl.Expr:
    exprs = list(exprs)
    if not exprs:
        return pl.lit(0).cast(pl.Int64)
    acc = exprs[0]
    for expr in exprs[1:]:
        acc = acc + expr
    return acc


def compute_td_labels(df: pl.DataFrame, *, version: str | None = None) -> pl.DataFrame:
    """Compute TD label columns according to a label version.

    Parameters
    ----------
    df : pl.DataFrame
        Player-game frame containing touchdown components.
    version : str | None
        Label version identifier. Defaults to DEFAULT_LABEL_VERSION.
    """

    spec = get_label_spec(version)
    rush = pl.col("rushing_td_count").fill_null(0).cast(pl.Int64)
    rec = pl.col("receiving_td_count").fill_null(0).cast(pl.Int64)
    passing = pl.col("passing_td").fill_null(0).cast(pl.Int64)
    reported_total = pl.col("touchdowns").fill_null(0).cast(pl.Int64)

    offense_total = _sum_expr([rush, rec, passing]).alias("_td_offense_total")
    other_total = (reported_total - offense_total).clip_min(0).alias("_td_other_total")
    all_total = (offense_total + other_total).alias("_td_all_total")

    totals_exprs = [
        offense_total,
        other_total,
        all_total,
    ]

    label_exprs: list[pl.Expr] = [
        pl.col("_td_offense_total").alias("td_count_offense"),
        pl.col("_td_all_total").alias("td_count_all"),
    ]

    for label_name, rules in spec.labels.items():
        parts: list[pl.Expr] = []
        if rules.include_rush:
            parts.append(rush)
        if rules.include_rec:
            parts.append(rec)
        if rules.include_pass_thrown:
            parts.append(passing)
        if rules.include_other:
            parts.append(pl.col("_td_other_total"))
        total_expr = _sum_expr(parts)
        label_exprs.append((total_expr > 0).cast(pl.Int8).alias(label_name))

    # Canonical counts for compatibility
    if "td_count" not in df.columns:
        # Fill td_count using the alias mapping; default to offense count.
        target_alias = spec.aliases.get("td_count") or "td_count_offense"
        label_exprs.append(pl.col(target_alias).alias("td_count"))

    df = df.with_columns(totals_exprs).with_columns(label_exprs)

    # Resolve aliases (e.g., anytime_td -> anytime_td_offense)
    if spec.aliases:
        alias_exprs = []
        for alias_name, source_name in spec.aliases.items():
            if source_name in df.columns:
                alias_exprs.append(pl.col(source_name).alias(alias_name))
        if alias_exprs:
            df = df.with_columns(alias_exprs)

    drop_cols = [col for col in ("_td_offense_total", "_td_other_total", "_td_all_total") if col in df.columns]
    if drop_cols:
        df = df.drop(drop_cols)
    return df
apply_patch(auto_approved=true) exited 0 in 68ms:
Success. Updated the following files:
A utils/feature/labels.py
file update:
diff --git a/utils/feature/labels.py b/utils/feature/labels.py
new file mode 100644
index 0000000000000000000000000000000000000000..b34571f04254cd7bceb9363a190ee7d305852bd5
--- /dev/null
+++ b/utils/feature/labels.py
@@ -0,0 +1,169 @@
+"""Label semantics and versioning for NFL player-level targets.
+
+This module centralizes anytime-TD label definitions so that:
+- Semantics are explicit and versioned.
+- Training can request a specific label column per problem.
+- Feature generation can emit multiple label variants for analysis.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass, field
+from typing import Dict, Iterable, Mapping
+
+import polars as pl
+
+
+@dataclass(frozen=True)
+class LabelRules:
+    """Rules controlling which TD components count toward a label."""
+
+    include_rush: bool = True
+    include_rec: bool = True
+    include_pass_thrown: bool = True  # credit passers for thrown TDs
+    include_other: bool = False  # fumble returns, defensive/special teams if present
+
+
+@dataclass(frozen=True)
+class LabelSpec:
+    """Container describing a label version."""
+
+    name: str
+    primary: str
+    labels: Mapping[str, LabelRules]
+    aliases: Mapping[str, str] = field(default_factory=dict)
+
+    @property
+    def all_columns(self) -> set[str]:
+        cols = set(self.labels.keys())
+        cols.update(self.aliases.keys())
+        return cols
+
+
+DEFAULT_LABEL_VERSION = "v1_any_offense"
+
+
+LABEL_VERSIONS: Dict[str, LabelSpec] = {
+    "v1_any_offense": LabelSpec(
+        name="v1_any_offense",
+        primary="anytime_td_offense",
+        labels={
+            "anytime_td_offense": LabelRules(include_other=False),
+            "anytime_td_rush": LabelRules(include_rush=True, include_rec=False, include_pass_thrown=False, include_other=False),
+            "anytime_td_rec": LabelRules(include_rush=False, include_rec=True, include_pass_thrown=False, include_other=False),
+            "anytime_td_pass_thrown": LabelRules(include_rush=False, include_rec=False, include_pass_thrown=True, include_other=False),
+            "anytime_td_all": LabelRules(include_other=True),
+        },
+        aliases={
+            # Maintain legacy column name as an alias to the offense-only label.
+            "anytime_td": "anytime_td_offense",
+            # Keep td_count pointing to the offense definition for backward compatibility.
+            "td_count": "td_count_offense",
+        },
+    ),
+    "v1_any_all": LabelSpec(
+        name="v1_any_all",
+        primary="anytime_td_all",
+        labels={
+            "anytime_td_all": LabelRules(include_other=True),
+            "anytime_td_offense": LabelRules(include_other=False),
+            "anytime_td_rush": LabelRules(include_rush=True, include_rec=False, include_pass_thrown=False, include_other=False),
+            "anytime_td_rec": LabelRules(include_rush=False, include_rec=True, include_pass_thrown=False, include_other=False),
+            "anytime_td_pass_thrown": LabelRules(include_rush=False, include_rec=False, include_pass_thrown=True, include_other=False),
+        },
+        aliases={
+            "anytime_td": "anytime_td_all",
+            "td_count": "td_count_all",
+        },
+    ),
+}
+
+
+def get_label_spec(version: str | None) -> LabelSpec:
+    """Return a concrete LabelSpec for the requested version (or default)."""
+
+    version = version or DEFAULT_LABEL_VERSION
+    if version not in LABEL_VERSIONS:
+        raise ValueError(
+            f"Unknown label_version '{version}'. "
+            f"Available: {sorted(LABEL_VERSIONS.keys())}"
+        )
+    return LABEL_VERSIONS[version]
+
+
+def _sum_expr(exprs: Iterable[pl.Expr]) -> pl.Expr:
+    exprs = list(exprs)
+    if not exprs:
+        return pl.lit(0).cast(pl.Int64)
+    acc = exprs[0]
+    for expr in exprs[1:]:
+        acc = acc + expr
+    return acc
+
+
+def compute_td_labels(df: pl.DataFrame, *, version: str | None = None) -> pl.DataFrame:
+    """Compute TD label columns according to a label version.
+
+    Parameters
+    ----------
+    df : pl.DataFrame
+        Player-game frame containing touchdown components.
+    version : str | None
+        Label version identifier. Defaults to DEFAULT_LABEL_VERSION.
+    """
+
+    spec = get_label_spec(version)
+    rush = pl.col("rushing_td_count").fill_null(0).cast(pl.Int64)
+    rec = pl.col("receiving_td_count").fill_null(0).cast(pl.Int64)
+    passing = pl.col("passing_td").fill_null(0).cast(pl.Int64)
+    reported_total = pl.col("touchdowns").fill_null(0).cast(pl.Int64)
+
+    offense_total = _sum_expr([rush, rec, passing]).alias("_td_offense_total")
+    other_total = (reported_total - offense_total).clip_min(0).alias("_td_other_total")
+    all_total = (offense_total + other_total).alias("_td_all_total")
+
+    totals_exprs = [
+        offense_total,
+        other_total,
+        all_total,
+    ]
+
+    label_exprs: list[pl.Expr] = [
+        pl.col("_td_offense_total").alias("td_count_offense"),
+        pl.col("_td_all_total").alias("td_count_all"),
+    ]
+
+    for label_name, rules in spec.labels.items():
+        parts: list[pl.Expr] = []
+        if rules.include_rush:
+            parts.append(rush)
+        if rules.include_rec:
+            parts.append(rec)
+        if rules.include_pass_thrown:
+            parts.append(passing)
+        if rules.include_other:
+            parts.append(pl.col("_td_other_total"))
+        total_expr = _sum_expr(parts)
+        label_exprs.append((total_expr > 0).cast(pl.Int8).alias(label_name))
+
+    # Canonical counts for compatibility
+    if "td_count" not in df.columns:
+        # Fill td_count using the alias mapping; default to offense count.
+        target_alias = spec.aliases.get("td_count") or "td_count_offense"
+        label_exprs.append(pl.col(target_alias).alias("td_count"))
+
+    df = df.with_columns(totals_exprs).with_columns(label_exprs)
+
+    # Resolve aliases (e.g., anytime_td -> anytime_td_offense)
+    if spec.aliases:
+        alias_exprs = []
+        for alias_name, source_name in spec.aliases.items():
+            if source_name in df.columns:
+                alias_exprs.append(pl.col(source_name).alias(alias_name))
+        if alias_exprs:
+            df = df.with_columns(alias_exprs)
+
+    drop_cols = [col for col in ("_td_offense_total", "_td_other_total", "_td_all_total") if col in df.columns]
+    if drop_cols:
+        df = df.drop(drop_cols)
+    return df

file update:
diff --git a/utils/feature/labels.py b/utils/feature/labels.py
new file mode 100644
index 0000000000000000000000000000000000000000..b34571f04254cd7bceb9363a190ee7d305852bd5
--- /dev/null
+++ b/utils/feature/labels.py
@@ -0,0 +1,169 @@
+"""Label semantics and versioning for NFL player-level targets.
+
+This module centralizes anytime-TD label definitions so that:
+- Semantics are explicit and versioned.
+- Training can request a specific label column per problem.
+- Feature generation can emit multiple label variants for analysis.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass, field
+from typing import Dict, Iterable, Mapping
+
+import polars as pl
+
+
+@dataclass(frozen=True)
+class LabelRules:
+    """Rules controlling which TD components count toward a label."""
+
+    include_rush: bool = True
+    include_rec: bool = True
+    include_pass_thrown: bool = True  # credit passers for thrown TDs
+    include_other: bool = False  # fumble returns, defensive/special teams if present
+
+
+@dataclass(frozen=True)
+class LabelSpec:
+    """Container describing a label version."""
+
+    name: str
+    primary: str
+    labels: Mapping[str, LabelRules]
+    aliases: Mapping[str, str] = field(default_factory=dict)
+
+    @property
+    def all_columns(self) -> set[str]:
+        cols = set(self.labels.keys())
+        cols.update(self.aliases.keys())
+        return cols
+
+
+DEFAULT_LABEL_VERSION = "v1_any_offense"
+
+
+LABEL_VERSIONS: Dict[str, LabelSpec] = {
+    "v1_any_offense": LabelSpec(
+        name="v1_any_offense",
+        primary="anytime_td_offense",
+        labels={
+            "anytime_td_offense": LabelRules(include_other=False),
+            "anytime_td_rush": LabelRules(include_rush=True, include_rec=False, include_pass_thrown=False, include_other=False),
+            "anytime_td_rec": LabelRules(include_rush=False, include_rec=True, include_pass_thrown=False, include_other=False),
+            "anytime_td_pass_thrown": LabelRules(include_rush=False, include_rec=False, include_pass_thrown=True, include_other=False),
+            "anytime_td_all": LabelRules(include_other=True),
+        },
+        aliases={
+            # Maintain legacy column name as an alias to the offense-only label.
+            "anytime_td": "anytime_td_offense",
+            # Keep td_count pointing to the offense definition for backward compatibility.
+            "td_count": "td_count_offense",
+        },
+    ),
+    "v1_any_all": LabelSpec(
+        name="v1_any_all",
+        primary="anytime_td_all",
+        labels={
+            "anytime_td_all": LabelRules(include_other=True),
+            "anytime_td_offense": LabelRules(include_other=False),
+            "anytime_td_rush": LabelRules(include_rush=True, include_rec=False, include_pass_thrown=False, include_other=False),
+            "anytime_td_rec": LabelRules(include_rush=False, include_rec=True, include_pass_thrown=False, include_other=False),
+            "anytime_td_pass_thrown": LabelRules(include_rush=False, include_rec=False, include_pass_thrown=True, include_other=False),
+        },
+        aliases={
+            "anytime_td": "anytime_td_all",
+            "td_count": "td_count_all",
+        },
+    ),
+}
+
+
+def get_label_spec(version: str | None) -> LabelSpec:
+    """Return a concrete LabelSpec for the requested version (or default)."""
+
+    version = version or DEFAULT_LABEL_VERSION
+    if version not in LABEL_VERSIONS:
+        raise ValueError(
+            f"Unknown label_version '{version}'. "
+            f"Available: {sorted(LABEL_VERSIONS.keys())}"
+        )
+    return LABEL_VERSIONS[version]
+
+
+def _sum_expr(exprs: Iterable[pl.Expr]) -> pl.Expr:
+    exprs = list(exprs)
+    if not exprs:
+        return pl.lit(0).cast(pl.Int64)
+    acc = exprs[0]
+    for expr in exprs[1:]:
+        acc = acc + expr
+    return acc
+
+
+def compute_td_labels(df: pl.DataFrame, *, version: str | None = None) -> pl.DataFrame:
+    """Compute TD label columns according to a label version.
+
+    Parameters
+    ----------
+    df : pl.DataFrame
+        Player-game frame containing touchdown components.
+    version : str | None
+        Label version identifier. Defaults to DEFAULT_LABEL_VERSION.
+    """
+
+    spec = get_label_spec(version)
+    rush = pl.col("rushing_td_count").fill_null(0).cast(pl.Int64)
+    rec = pl.col("receiving_td_count").fill_null(0).cast(pl.Int64)
+    passing = pl.col("passing_td").fill_null(0).cast(pl.Int64)
+    reported_total = pl.col("touchdowns").fill_null(0).cast(pl.Int64)
+
+    offense_total = _sum_expr([rush, rec, passing]).alias("_td_offense_total")
+    other_total = (reported_total - offense_total).clip_min(0).alias("_td_other_total")
+    all_total = (offense_total + other_total).alias("_td_all_total")
+
+    totals_exprs = [
+        offense_total,
+        other_total,
+        all_total,
+    ]
+
+    label_exprs: list[pl.Expr] = [
+        pl.col("_td_offense_total").alias("td_count_offense"),
+        pl.col("_td_all_total").alias("td_count_all"),
+    ]
+
+    for label_name, rules in spec.labels.items():
+        parts: list[pl.Expr] = []
+        if rules.include_rush:
+            parts.append(rush)
+        if rules.include_rec:
+            parts.append(rec)
+        if rules.include_pass_thrown:
+            parts.append(passing)
+        if rules.include_other:
+            parts.append(pl.col("_td_other_total"))
+        total_expr = _sum_expr(parts)
+        label_exprs.append((total_expr > 0).cast(pl.Int8).alias(label_name))
+
+    # Canonical counts for compatibility
+    if "td_count" not in df.columns:
+        # Fill td_count using the alias mapping; default to offense count.
+        target_alias = spec.aliases.get("td_count") or "td_count_offense"
+        label_exprs.append(pl.col(target_alias).alias("td_count"))
+
+    df = df.with_columns(totals_exprs).with_columns(label_exprs)
+
+    # Resolve aliases (e.g., anytime_td -> anytime_td_offense)
+    if spec.aliases:
+        alias_exprs = []
+        for alias_name, source_name in spec.aliases.items():
+            if source_name in df.columns:
+                alias_exprs.append(pl.col(source_name).alias(alias_name))
+        if alias_exprs:
+            df = df.with_columns(alias_exprs)
+
+    drop_cols = [col for col in ("_td_offense_total", "_td_other_total", "_td_all_total") if col in df.columns]
+    if drop_cols:
+        df = df.drop(drop_cols)
+    return df


thinking
**Updating player game level logic and imports**

thinking
**Updating player_game_level with label_version**
file update
M /Users/jameswest/Desktop/nfl_predict/utils/feature/player_game_level.py
@@ -35,2 +35,3 @@
 from utils.feature.player_drive_level import _load_play_level_data
+from utils.feature.labels import DEFAULT_LABEL_VERSION, compute_td_labels
 from utils.train.injury_availability import (
apply_patch(auto_approved=true) exited 0 in 47ms:
Success. Updated the following files:
M utils/feature/player_game_level.py
file update:
diff --git a/utils/feature/labels.py b/utils/feature/labels.py
new file mode 100644
index 0000000000000000000000000000000000000000..b34571f04254cd7bceb9363a190ee7d305852bd5
--- /dev/null
+++ b/utils/feature/labels.py
@@ -0,0 +1,169 @@
+"""Label semantics and versioning for NFL player-level targets.
+
+This module centralizes anytime-TD label definitions so that:
+- Semantics are explicit and versioned.
+- Training can request a specific label column per problem.
+- Feature generation can emit multiple label variants for analysis.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass, field
+from typing import Dict, Iterable, Mapping
+
+import polars as pl
+
+
+@dataclass(frozen=True)
+class LabelRules:
+    """Rules controlling which TD components count toward a label."""
+
+    include_rush: bool = True
+    include_rec: bool = True
+    include_pass_thrown: bool = True  # credit passers for thrown TDs
+    include_other: bool = False  # fumble returns, defensive/special teams if present
+
+
+@dataclass(frozen=True)
+class LabelSpec:
+    """Container describing a label version."""
+
+    name: str
+    primary: str
+    labels: Mapping[str, LabelRules]
+    aliases: Mapping[str, str] = field(default_factory=dict)
+
+    @property
+    def all_columns(self) -> set[str]:
+        cols = set(self.labels.keys())
+        cols.update(self.aliases.keys())
+        return cols
+
+
+DEFAULT_LABEL_VERSION = "v1_any_offense"
+
+
+LABEL_VERSIONS: Dict[str, LabelSpec] = {
+    "v1_any_offense": LabelSpec(
+        name="v1_any_offense",
+        primary="anytime_td_offense",
+        labels={
+            "anytime_td_offense": LabelRules(include_other=False),
+            "anytime_td_rush": LabelRules(include_rush=True, include_rec=False, include_pass_thrown=False, include_other=False),
+            "anytime_td_rec": LabelRules(include_rush=False, include_rec=True, include_pass_thrown=False, include_other=False),
+            "anytime_td_pass_thrown": LabelRules(include_rush=False, include_rec=False, include_pass_thrown=True, include_other=False),
+            "anytime_td_all": LabelRules(include_other=True),
+        },
+        aliases={
+            # Maintain legacy column name as an alias to the offense-only label.
+            "anytime_td": "anytime_td_offense",
+            # Keep td_count pointing to the offense definition for backward compatibility.
+            "td_count": "td_count_offense",
+        },
+    ),
+    "v1_any_all": LabelSpec(
+        name="v1_any_all",
+        primary="anytime_td_all",
+        labels={
+            "anytime_td_all": LabelRules(include_other=True),
+            "anytime_td_offense": LabelRules(include_other=False),
+            "anytime_td_rush": LabelRules(include_rush=True, include_rec=False, include_pass_thrown=False, include_other=False),
+            "anytime_td_rec": LabelRules(include_rush=False, include_rec=True, include_pass_thrown=False, include_other=False),
+            "anytime_td_pass_thrown": LabelRules(include_rush=False, include_rec=False, include_pass_thrown=True, include_other=False),
+        },
+        aliases={
+            "anytime_td": "anytime_td_all",
+            "td_count": "td_count_all",
+        },
+    ),
+}
+
+
+def get_label_spec(version: str | None) -> LabelSpec:
+    """Return a concrete LabelSpec for the requested version (or default)."""
+
+    version = version or DEFAULT_LABEL_VERSION
+    if version not in LABEL_VERSIONS:
+        raise ValueError(
+            f"Unknown label_version '{version}'. "
+            f"Available: {sorted(LABEL_VERSIONS.keys())}"
+        )
+    return LABEL_VERSIONS[version]
+
+
+def _sum_expr(exprs: Iterable[pl.Expr]) -> pl.Expr:
+    exprs = list(exprs)
+    if not exprs:
+        return pl.lit(0).cast(pl.Int64)
+    acc = exprs[0]
+    for expr in exprs[1:]:
+        acc = acc + expr
+    return acc
+
+
+def compute_td_labels(df: pl.DataFrame, *, version: str | None = None) -> pl.DataFrame:
+    """Compute TD label columns according to a label version.
+
+    Parameters
+    ----------
+    df : pl.DataFrame
+        Player-game frame containing touchdown components.
+    version : str | None
+        Label version identifier. Defaults to DEFAULT_LABEL_VERSION.
+    """
+
+    spec = get_label_spec(version)
+    rush = pl.col("rushing_td_count").fill_null(0).cast(pl.Int64)
+    rec = pl.col("receiving_td_count").fill_null(0).cast(pl.Int64)
+    passing = pl.col("passing_td").fill_null(0).cast(pl.Int64)
+    reported_total = pl.col("touchdowns").fill_null(0).cast(pl.Int64)
+
+    offense_total = _sum_expr([rush, rec, passing]).alias("_td_offense_total")
+    other_total = (reported_total - offense_total).clip_min(0).alias("_td_other_total")
+    all_total = (offense_total + other_total).alias("_td_all_total")
+
+    totals_exprs = [
+        offense_total,
+        other_total,
+        all_total,
+    ]
+
+    label_exprs: list[pl.Expr] = [
+        pl.col("_td_offense_total").alias("td_count_offense"),
+        pl.col("_td_all_total").alias("td_count_all"),
+    ]
+
+    for label_name, rules in spec.labels.items():
+        parts: list[pl.Expr] = []
+        if rules.include_rush:
+            parts.append(rush)
+        if rules.include_rec:
+            parts.append(rec)
+        if rules.include_pass_thrown:
+            parts.append(passing)
+        if rules.include_other:
+            parts.append(pl.col("_td_other_total"))
+        total_expr = _sum_expr(parts)
+        label_exprs.append((total_expr > 0).cast(pl.Int8).alias(label_name))
+
+    # Canonical counts for compatibility
+    if "td_count" not in df.columns:
+        # Fill td_count using the alias mapping; default to offense count.
+        target_alias = spec.aliases.get("td_count") or "td_count_offense"
+        label_exprs.append(pl.col(target_alias).alias("td_count"))
+
+    df = df.with_columns(totals_exprs).with_columns(label_exprs)
+
+    # Resolve aliases (e.g., anytime_td -> anytime_td_offense)
+    if spec.aliases:
+        alias_exprs = []
+        for alias_name, source_name in spec.aliases.items():
+            if source_name in df.columns:
+                alias_exprs.append(pl.col(source_name).alias(alias_name))
+        if alias_exprs:
+            df = df.with_columns(alias_exprs)
+
+    drop_cols = [col for col in ("_td_offense_total", "_td_other_total", "_td_all_total") if col in df.columns]
+    if drop_cols:
+        df = df.drop(drop_cols)
+    return df
diff --git a/utils/feature/player_game_level.py b/utils/feature/player_game_level.py
index b6fe516c5f03d575038eef554d5ab39ea5d5c90d..4a13d97dc1b6f98c4a3df5cf400eeacc445020f1
--- a/utils/feature/player_game_level.py
+++ b/utils/feature/player_game_level.py
@@ -33,6 +33,7 @@
 from utils.collect.nfl_schedules import get_schedule
 from utils.feature.asof import decision_cutoff_hours_default, fallback_cutoff_hours, get_decision_cutoff_hours, get_fallback_cutoff_hours
 from utils.feature.player_drive_level import _load_play_level_data
+from utils.feature.labels import DEFAULT_LABEL_VERSION, compute_td_labels
 from utils.train.injury_availability import (
     load_latest_artifact,
     predict_probabilities as predict_injury_probabilities,

file update:
diff --git a/utils/feature/labels.py b/utils/feature/labels.py
new file mode 100644
index 0000000000000000000000000000000000000000..b34571f04254cd7bceb9363a190ee7d305852bd5
--- /dev/null
+++ b/utils/feature/labels.py
@@ -0,0 +1,169 @@
+"""Label semantics and versioning for NFL player-level targets.
+
+This module centralizes anytime-TD label definitions so that:
+- Semantics are explicit and versioned.
+- Training can request a specific label column per problem.
+- Feature generation can emit multiple label variants for analysis.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass, field
+from typing import Dict, Iterable, Mapping
+
+import polars as pl
+
+
+@dataclass(frozen=True)
+class LabelRules:
+    """Rules controlling which TD components count toward a label."""
+
+    include_rush: bool = True
+    include_rec: bool = True
+    include_pass_thrown: bool = True  # credit passers for thrown TDs
+    include_other: bool = False  # fumble returns, defensive/special teams if present
+
+
+@dataclass(frozen=True)
+class LabelSpec:
+    """Container describing a label version."""
+
+    name: str
+    primary: str
+    labels: Mapping[str, LabelRules]
+    aliases: Mapping[str, str] = field(default_factory=dict)
+
+    @property
+    def all_columns(self) -> set[str]:
+        cols = set(self.labels.keys())
+        cols.update(self.aliases.keys())
+        return cols
+
+
+DEFAULT_LABEL_VERSION = "v1_any_offense"
+
+
+LABEL_VERSIONS: Dict[str, LabelSpec] = {
+    "v1_any_offense": LabelSpec(
+        name="v1_any_offense",
+        primary="anytime_td_offense",
+        labels={
+            "anytime_td_offense": LabelRules(include_other=False),
+            "anytime_td_rush": LabelRules(include_rush=True, include_rec=False, include_pass_thrown=False, include_other=False),
+            "anytime_td_rec": LabelRules(include_rush=False, include_rec=True, include_pass_thrown=False, include_other=False),
+            "anytime_td_pass_thrown": LabelRules(include_rush=False, include_rec=False, include_pass_thrown=True, include_other=False),
+            "anytime_td_all": LabelRules(include_other=True),
+        },
+        aliases={
+            # Maintain legacy column name as an alias to the offense-only label.
+            "anytime_td": "anytime_td_offense",
+            # Keep td_count pointing to the offense definition for backward compatibility.
+            "td_count": "td_count_offense",
+        },
+    ),
+    "v1_any_all": LabelSpec(
+        name="v1_any_all",
+        primary="anytime_td_all",
+        labels={
+            "anytime_td_all": LabelRules(include_other=True),
+            "anytime_td_offense": LabelRules(include_other=False),
+            "anytime_td_rush": LabelRules(include_rush=True, include_rec=False, include_pass_thrown=False, include_other=False),
+            "anytime_td_rec": LabelRules(include_rush=False, include_rec=True, include_pass_thrown=False, include_other=False),
+            "anytime_td_pass_thrown": LabelRules(include_rush=False, include_rec=False, include_pass_thrown=True, include_other=False),
+        },
+        aliases={
+            "anytime_td": "anytime_td_all",
+            "td_count": "td_count_all",
+        },
+    ),
+}
+
+
+def get_label_spec(version: str | None) -> LabelSpec:
+    """Return a concrete LabelSpec for the requested version (or default)."""
+
+    version = version or DEFAULT_LABEL_VERSION
+    if version not in LABEL_VERSIONS:
+        raise ValueError(
+            f"Unknown label_version '{version}'. "
+            f"Available: {sorted(LABEL_VERSIONS.keys())}"
+        )
+    return LABEL_VERSIONS[version]
+
+
+def _sum_expr(exprs: Iterable[pl.Expr]) -> pl.Expr:
+    exprs = list(exprs)
+    if not exprs:
+        return pl.lit(0).cast(pl.Int64)
+    acc = exprs[0]
+    for expr in exprs[1:]:
+        acc = acc + expr
+    return acc
+
+
+def compute_td_labels(df: pl.DataFrame, *, version: str | None = None) -> pl.DataFrame:
+    """Compute TD label columns according to a label version.
+
+    Parameters
+    ----------
+    df : pl.DataFrame
+        Player-game frame containing touchdown components.
+    version : str | None
+        Label version identifier. Defaults to DEFAULT_LABEL_VERSION.
+    """
+
+    spec = get_label_spec(version)
+    rush = pl.col("rushing_td_count").fill_null(0).cast(pl.Int64)
+    rec = pl.col("receiving_td_count").fill_null(0).cast(pl.Int64)
+    passing = pl.col("passing_td").fill_null(0).cast(pl.Int64)
+    reported_total = pl.col("touchdowns").fill_null(0).cast(pl.Int64)
+
+    offense_total = _sum_expr([rush, rec, passing]).alias("_td_offense_total")
+    other_total = (reported_total - offense_total).clip_min(0).alias("_td_other_total")
+    all_total = (offense_total + other_total).alias("_td_all_total")
+
+    totals_exprs = [
+        offense_total,
+        other_total,
+        all_total,
+    ]
+
+    label_exprs: list[pl.Expr] = [
+        pl.col("_td_offense_total").alias("td_count_offense"),
+        pl.col("_td_all_total").alias("td_count_all"),
+    ]
+
+    for label_name, rules in spec.labels.items():
+        parts: list[pl.Expr] = []
+        if rules.include_rush:
+            parts.append(rush)
+        if rules.include_rec:
+            parts.append(rec)
+        if rules.include_pass_thrown:
+            parts.append(passing)
+        if rules.include_other:
+            parts.append(pl.col("_td_other_total"))
+        total_expr = _sum_expr(parts)
+        label_exprs.append((total_expr > 0).cast(pl.Int8).alias(label_name))
+
+    # Canonical counts for compatibility
+    if "td_count" not in df.columns:
+        # Fill td_count using the alias mapping; default to offense count.
+        target_alias = spec.aliases.get("td_count") or "td_count_offense"
+        label_exprs.append(pl.col(target_alias).alias("td_count"))
+
+    df = df.with_columns(totals_exprs).with_columns(label_exprs)
+
+    # Resolve aliases (e.g., anytime_td -> anytime_td_offense)
+    if spec.aliases:
+        alias_exprs = []
+        for alias_name, source_name in spec.aliases.items():
+            if source_name in df.columns:
+                alias_exprs.append(pl.col(source_name).alias(alias_name))
+        if alias_exprs:
+            df = df.with_columns(alias_exprs)
+
+    drop_cols = [col for col in ("_td_offense_total", "_td_other_total", "_td_all_total") if col in df.columns]
+    if drop_cols:
+        df = df.drop(drop_cols)
+    return df
diff --git a/utils/feature/player_game_level.py b/utils/feature/player_game_level.py
index b6fe516c5f03d575038eef554d5ab39ea5d5c90d..4a13d97dc1b6f98c4a3df5cf400eeacc445020f1
--- a/utils/feature/player_game_level.py
+++ b/utils/feature/player_game_level.py
@@ -33,6 +33,7 @@
 from utils.collect.nfl_schedules import get_schedule
 from utils.feature.asof import decision_cutoff_hours_default, fallback_cutoff_hours, get_decision_cutoff_hours, get_fallback_cutoff_hours
 from utils.feature.player_drive_level import _load_play_level_data
+from utils.feature.labels import DEFAULT_LABEL_VERSION, compute_td_labels
 from utils.train.injury_availability import (
     load_latest_artifact,
     predict_probabilities as predict_injury_probabilities,


thinking
**Updating docstring to reflect new labels**
file update
M /Users/jameswest/Desktop/nfl_predict/utils/feature/player_game_level.py
@@ -6,4 +6,8 @@
 Target columns created:
-- anytime_td (binary): Did player score a TD (receiving or rushing)?
-- td_count (int): Number of TDs scored (receiving + rushing)
+- anytime_td_offense (binary): Did player score an offensive TD (rush/rec/pass thrown)?
+- anytime_td_all (binary): Did player score any TD (including defensive/special teams if present)?
+- anytime_td_rush / anytime_td_rec / anytime_td_pass_thrown: Type-specific TD flags.
+- anytime_td (binary): Legacy alias → current label version primary.
+- td_count_offense / td_count_all: TD counts aligned to label semantics.
+- td_count (int): Legacy alias for the primary td_count.
 - passing_td (int): Number of passing TDs (for QBs)
apply_patch(auto_approved=true) exited 0 in 42ms:
Success. Updated the following files:
M utils/feature/player_game_level.py
file update:
diff --git a/utils/feature/labels.py b/utils/feature/labels.py
new file mode 100644
index 0000000000000000000000000000000000000000..b34571f04254cd7bceb9363a190ee7d305852bd5
--- /dev/null
+++ b/utils/feature/labels.py
@@ -0,0 +1,169 @@
+"""Label semantics and versioning for NFL player-level targets.
+
+This module centralizes anytime-TD label definitions so that:
+- Semantics are explicit and versioned.
+- Training can request a specific label column per problem.
+- Feature generation can emit multiple label variants for analysis.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass, field
+from typing import Dict, Iterable, Mapping
+
+import polars as pl
+
+
+@dataclass(frozen=True)
+class LabelRules:
+    """Rules controlling which TD components count toward a label."""
+
+    include_rush: bool = True
+    include_rec: bool = True
+    include_pass_thrown: bool = True  # credit passers for thrown TDs
+    include_other: bool = False  # fumble returns, defensive/special teams if present
+
+
+@dataclass(frozen=True)
+class LabelSpec:
+    """Container describing a label version."""
+
+    name: str
+    primary: str
+    labels: Mapping[str, LabelRules]
+    aliases: Mapping[str, str] = field(default_factory=dict)
+
+    @property
+    def all_columns(self) -> set[str]:
+        cols = set(self.labels.keys())
+        cols.update(self.aliases.keys())
+        return cols
+
+
+DEFAULT_LABEL_VERSION = "v1_any_offense"
+
+
+LABEL_VERSIONS: Dict[str, LabelSpec] = {
+    "v1_any_offense": LabelSpec(
+        name="v1_any_offense",
+        primary="anytime_td_offense",
+        labels={
+            "anytime_td_offense": LabelRules(include_other=False),
+            "anytime_td_rush": LabelRules(include_rush=True, include_rec=False, include_pass_thrown=False, include_other=False),
+            "anytime_td_rec": LabelRules(include_rush=False, include_rec=True, include_pass_thrown=False, include_other=False),
+            "anytime_td_pass_thrown": LabelRules(include_rush=False, include_rec=False, include_pass_thrown=True, include_other=False),
+            "anytime_td_all": LabelRules(include_other=True),
+        },
+        aliases={
+            # Maintain legacy column name as an alias to the offense-only label.
+            "anytime_td": "anytime_td_offense",
+            # Keep td_count pointing to the offense definition for backward compatibility.
+            "td_count": "td_count_offense",
+        },
+    ),
+    "v1_any_all": LabelSpec(
+        name="v1_any_all",
+        primary="anytime_td_all",
+        labels={
+            "anytime_td_all": LabelRules(include_other=True),
+            "anytime_td_offense": LabelRules(include_other=False),
+            "anytime_td_rush": LabelRules(include_rush=True, include_rec=False, include_pass_thrown=False, include_other=False),
+            "anytime_td_rec": LabelRules(include_rush=False, include_rec=True, include_pass_thrown=False, include_other=False),
+            "anytime_td_pass_thrown": LabelRules(include_rush=False, include_rec=False, include_pass_thrown=True, include_other=False),
+        },
+        aliases={
+            "anytime_td": "anytime_td_all",
+            "td_count": "td_count_all",
+        },
+    ),
+}
+
+
+def get_label_spec(version: str | None) -> LabelSpec:
+    """Return a concrete LabelSpec for the requested version (or default)."""
+
+    version = version or DEFAULT_LABEL_VERSION
+    if version not in LABEL_VERSIONS:
+        raise ValueError(
+            f"Unknown label_version '{version}'. "
+            f"Available: {sorted(LABEL_VERSIONS.keys())}"
+        )
+    return LABEL_VERSIONS[version]
+
+
+def _sum_expr(exprs: Iterable[pl.Expr]) -> pl.Expr:
+    exprs = list(exprs)
+    if not exprs:
+        return pl.lit(0).cast(pl.Int64)
+    acc = exprs[0]
+    for expr in exprs[1:]:
+        acc = acc + expr
+    return acc
+
+
+def compute_td_labels(df: pl.DataFrame, *, version: str | None = None) -> pl.DataFrame:
+    """Compute TD label columns according to a label version.
+
+    Parameters
+    ----------
+    df : pl.DataFrame
+        Player-game frame containing touchdown components.
+    version : str | None
+        Label version identifier. Defaults to DEFAULT_LABEL_VERSION.
+    """
+
+    spec = get_label_spec(version)
+    rush = pl.col("rushing_td_count").fill_null(0).cast(pl.Int64)
+    rec = pl.col("receiving_td_count").fill_null(0).cast(pl.Int64)
+    passing = pl.col("passing_td").fill_null(0).cast(pl.Int64)
+    reported_total = pl.col("touchdowns").fill_null(0).cast(pl.Int64)
+
+    offense_total = _sum_expr([rush, rec, passing]).alias("_td_offense_total")
+    other_total = (reported_total - offense_total).clip_min(0).alias("_td_other_total")
+    all_total = (offense_total + other_total).alias("_td_all_total")
+
+    totals_exprs = [
+        offense_total,
+        other_total,
+        all_total,
+    ]
+
+    label_exprs: list[pl.Expr] = [
+        pl.col("_td_offense_total").alias("td_count_offense"),
+        pl.col("_td_all_total").alias("td_count_all"),
+    ]
+
+    for label_name, rules in spec.labels.items():
+        parts: list[pl.Expr] = []
+        if rules.include_rush:
+            parts.append(rush)
+        if rules.include_rec:
+            parts.append(rec)
+        if rules.include_pass_thrown:
+            parts.append(passing)
+        if rules.include_other:
+            parts.append(pl.col("_td_other_total"))
+        total_expr = _sum_expr(parts)
+        label_exprs.append((total_expr > 0).cast(pl.Int8).alias(label_name))
+
+    # Canonical counts for compatibility
+    if "td_count" not in df.columns:
+        # Fill td_count using the alias mapping; default to offense count.
+        target_alias = spec.aliases.get("td_count") or "td_count_offense"
+        label_exprs.append(pl.col(target_alias).alias("td_count"))
+
+    df = df.with_columns(totals_exprs).with_columns(label_exprs)
+
+    # Resolve aliases (e.g., anytime_td -> anytime_td_offense)
+    if spec.aliases:
+        alias_exprs = []
+        for alias_name, source_name in spec.aliases.items():
+            if source_name in df.columns:
+                alias_exprs.append(pl.col(source_name).alias(alias_name))
+        if alias_exprs:
+            df = df.with_columns(alias_exprs)
+
+    drop_cols = [col for col in ("_td_offense_total", "_td_other_total", "_td_all_total") if col in df.columns]
+    if drop_cols:
+        df = df.drop(drop_cols)
+    return df
diff --git a/utils/feature/player_game_level.py b/utils/feature/player_game_level.py
index b6fe516c5f03d575038eef554d5ab39ea5d5c90d..a71e724c25206d81ec403a5aecc4282ba3d2c5f5
--- a/utils/feature/player_game_level.py
+++ b/utils/feature/player_game_level.py
@@ -4,8 +4,12 @@
 Each player gets one row per game with their total stats.
 
 Target columns created:
-- anytime_td (binary): Did player score a TD (receiving or rushing)?
-- td_count (int): Number of TDs scored (receiving + rushing)
+- anytime_td_offense (binary): Did player score an offensive TD (rush/rec/pass thrown)?
+- anytime_td_all (binary): Did player score any TD (including defensive/special teams if present)?
+- anytime_td_rush / anytime_td_rec / anytime_td_pass_thrown: Type-specific TD flags.
+- anytime_td (binary): Legacy alias → current label version primary.
+- td_count_offense / td_count_all: TD counts aligned to label semantics.
+- td_count (int): Legacy alias for the primary td_count.
 - passing_td (int): Number of passing TDs (for QBs)
 - receiving_yards (float): Total receiving yards
 - rushing_yards (float): Total rushing yards
@@ -33,6 +37,7 @@
 from utils.collect.nfl_schedules import get_schedule
 from utils.feature.asof import decision_cutoff_hours_default, fallback_cutoff_hours, get_decision_cutoff_hours, get_fallback_cutoff_hours
 from utils.feature.player_drive_level import _load_play_level_data
+from utils.feature.labels import DEFAULT_LABEL_VERSION, compute_td_labels
 from utils.train.injury_availability import (
     load_latest_artifact,
     predict_probabilities as predict_injury_probabilities,

file update:
diff --git a/utils/feature/labels.py b/utils/feature/labels.py
new file mode 100644
index 0000000000000000000000000000000000000000..b34571f04254cd7bceb9363a190ee7d305852bd5
--- /dev/null
+++ b/utils/feature/labels.py
@@ -0,0 +1,169 @@
+"""Label semantics and versioning for NFL player-level targets.
+
+This module centralizes anytime-TD label definitions so that:
+- Semantics are explicit and versioned.
+- Training can request a specific label column per problem.
+- Feature generation can emit multiple label variants for analysis.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass, field
+from typing import Dict, Iterable, Mapping
+
+import polars as pl
+
+
+@dataclass(frozen=True)
+class LabelRules:
+    """Rules controlling which TD components count toward a label."""
+
+    include_rush: bool = True
+    include_rec: bool = True
+    include_pass_thrown: bool = True  # credit passers for thrown TDs
+    include_other: bool = False  # fumble returns, defensive/special teams if present
+
+
+@dataclass(frozen=True)
+class LabelSpec:
+    """Container describing a label version."""
+
+    name: str
+    primary: str
+    labels: Mapping[str, LabelRules]
+    aliases: Mapping[str, str] = field(default_factory=dict)
+
+    @property
+    def all_columns(self) -> set[str]:
+        cols = set(self.labels.keys())
+        cols.update(self.aliases.keys())
+        return cols
+
+
+DEFAULT_LABEL_VERSION = "v1_any_offense"
+
+
+LABEL_VERSIONS: Dict[str, LabelSpec] = {
+    "v1_any_offense": LabelSpec(
+        name="v1_any_offense",
+        primary="anytime_td_offense",
+        labels={
+            "anytime_td_offense": LabelRules(include_other=False),
+            "anytime_td_rush": LabelRules(include_rush=True, include_rec=False, include_pass_thrown=False, include_other=False),
+            "anytime_td_rec": LabelRules(include_rush=False, include_rec=True, include_pass_thrown=False, include_other=False),
+            "anytime_td_pass_thrown": LabelRules(include_rush=False, include_rec=False, include_pass_thrown=True, include_other=False),
+            "anytime_td_all": LabelRules(include_other=True),
+        },
+        aliases={
+            # Maintain legacy column name as an alias to the offense-only label.
+            "anytime_td": "anytime_td_offense",
+            # Keep td_count pointing to the offense definition for backward compatibility.
+            "td_count": "td_count_offense",
+        },
+    ),
+    "v1_any_all": LabelSpec(
+        name="v1_any_all",
+        primary="anytime_td_all",
+        labels={
+            "anytime_td_all": LabelRules(include_other=True),
+            "anytime_td_offense": LabelRules(include_other=False),
+            "anytime_td_rush": LabelRules(include_rush=True, include_rec=False, include_pass_thrown=False, include_other=False),
+            "anytime_td_rec": LabelRules(include_rush=False, include_rec=True, include_pass_thrown=False, include_other=False),
+            "anytime_td_pass_thrown": LabelRules(include_rush=False, include_rec=False, include_pass_thrown=True, include_other=False),
+        },
+        aliases={
+            "anytime_td": "anytime_td_all",
+            "td_count": "td_count_all",
+        },
+    ),
+}
+
+
+def get_label_spec(version: str | None) -> LabelSpec:
+    """Return a concrete LabelSpec for the requested version (or default)."""
+
+    version = version or DEFAULT_LABEL_VERSION
+    if version not in LABEL_VERSIONS:
+        raise ValueError(
+            f"Unknown label_version '{version}'. "
+            f"Available: {sorted(LABEL_VERSIONS.keys())}"
+        )
+    return LABEL_VERSIONS[version]
+
+
+def _sum_expr(exprs: Iterable[pl.Expr]) -> pl.Expr:
+    exprs = list(exprs)
+    if not exprs:
+        return pl.lit(0).cast(pl.Int64)
+    acc = exprs[0]
+    for expr in exprs[1:]:
+        acc = acc + expr
+    return acc
+
+
+def compute_td_labels(df: pl.DataFrame, *, version: str | None = None) -> pl.DataFrame:
+    """Compute TD label columns according to a label version.
+
+    Parameters
+    ----------
+    df : pl.DataFrame
+        Player-game frame containing touchdown components.
+    version : str | None
+        Label version identifier. Defaults to DEFAULT_LABEL_VERSION.
+    """
+
+    spec = get_label_spec(version)
+    rush = pl.col("rushing_td_count").fill_null(0).cast(pl.Int64)
+    rec = pl.col("receiving_td_count").fill_null(0).cast(pl.Int64)
+    passing = pl.col("passing_td").fill_null(0).cast(pl.Int64)
+    reported_total = pl.col("touchdowns").fill_null(0).cast(pl.Int64)
+
+    offense_total = _sum_expr([rush, rec, passing]).alias("_td_offense_total")
+    other_total = (reported_total - offense_total).clip_min(0).alias("_td_other_total")
+    all_total = (offense_total + other_total).alias("_td_all_total")
+
+    totals_exprs = [
+        offense_total,
+        other_total,
+        all_total,
+    ]
+
+    label_exprs: list[pl.Expr] = [
+        pl.col("_td_offense_total").alias("td_count_offense"),
+        pl.col("_td_all_total").alias("td_count_all"),
+    ]
+
+    for label_name, rules in spec.labels.items():
+        parts: list[pl.Expr] = []
+        if rules.include_rush:
+            parts.append(rush)
+        if rules.include_rec:
+            parts.append(rec)
+        if rules.include_pass_thrown:
+            parts.append(passing)
+        if rules.include_other:
+            parts.append(pl.col("_td_other_total"))
+        total_expr = _sum_expr(parts)
+        label_exprs.append((total_expr > 0).cast(pl.Int8).alias(label_name))
+
+    # Canonical counts for compatibility
+    if "td_count" not in df.columns:
+        # Fill td_count using the alias mapping; default to offense count.
+        target_alias = spec.aliases.get("td_count") or "td_count_offense"
+        label_exprs.append(pl.col(target_alias).alias("td_count"))
+
+    df = df.with_columns(totals_exprs).with_columns(label_exprs)
+
+    # Resolve aliases (e.g., anytime_td -> anytime_td_offense)
+    if spec.aliases:
+        alias_exprs = []
+        for alias_name, source_name in spec.aliases.items():
+            if source_name in df.columns:
+                alias_exprs.append(pl.col(source_name).alias(alias_name))
+        if alias_exprs:
+            df = df.with_columns(alias_exprs)
+
+    drop_cols = [col for col in ("_td_offense_total", "_td_other_total", "_td_all_total") if col in df.columns]
+    if drop_cols:
+        df = df.drop(drop_cols)
+    return df
diff --git a/utils/feature/player_game_level.py b/utils/feature/player_game_level.py
index b6fe516c5f03d575038eef554d5ab39ea5d5c90d..a71e724c25206d81ec403a5aecc4282ba3d2c5f5
--- a/utils/feature/player_game_level.py
+++ b/utils/feature/player_game_level.py
@@ -4,8 +4,12 @@
 Each player gets one row per game with their total stats.
 
 Target columns created:
-- anytime_td (binary): Did player score a TD (receiving or rushing)?
-- td_count (int): Number of TDs scored (receiving + rushing)
+- anytime_td_offense (binary): Did player score an offensive TD (rush/rec/pass thrown)?
+- anytime_td_all (binary): Did player score any TD (including defensive/special teams if present)?
+- anytime_td_rush / anytime_td_rec / anytime_td_pass_thrown: Type-specific TD flags.
+- anytime_td (binary): Legacy alias → current label version primary.
+- td_count_offense / td_count_all: TD counts aligned to label semantics.
+- td_count (int): Legacy alias for the primary td_count.
 - passing_td (int): Number of passing TDs (for QBs)
 - receiving_yards (float): Total receiving yards
 - rushing_yards (float): Total rushing yards
@@ -33,6 +37,7 @@
 from utils.collect.nfl_schedules import get_schedule
 from utils.feature.asof import decision_cutoff_hours_default, fallback_cutoff_hours, get_decision_cutoff_hours, get_fallback_cutoff_hours
 from utils.feature.player_drive_level import _load_play_level_data
+from utils.feature.labels import DEFAULT_LABEL_VERSION, compute_td_labels
 from utils.train.injury_availability import (
     load_latest_artifact,
     predict_probabilities as predict_injury_probabilities,


thinking
**Updating function signature and call**
file update
M /Users/jameswest/Desktop/nfl_predict/utils/feature/player_game_level.py
@@ -1589,3 +1589,8 @@
     return df
-def build_player_game_level(*, start_date: date, end_date: date) -> None:
+def build_player_game_level(
+    *,
+    start_date: date,
+    end_date: date,
+    label_version: str | None = None,
+) -> None:
     """Aggregate play-level data to player-game level.
@@ -1687,3 +1692,3 @@
     # (e.g., QB who also rushed, WR who also rushed)
-    df_merged = _merge_multi_role_players(df_all)
+    df_merged = _merge_multi_role_players(df_all, label_version=label_version or DEFAULT_LABEL_VERSION)
 
apply_patch(auto_approved=true) exited 0 in 44ms:
Success. Updated the following files:
M utils/feature/player_game_level.py
file update:
diff --git a/utils/feature/labels.py b/utils/feature/labels.py
new file mode 100644
index 0000000000000000000000000000000000000000..b34571f04254cd7bceb9363a190ee7d305852bd5
--- /dev/null
+++ b/utils/feature/labels.py
@@ -0,0 +1,169 @@
+"""Label semantics and versioning for NFL player-level targets.
+
+This module centralizes anytime-TD label definitions so that:
+- Semantics are explicit and versioned.
+- Training can request a specific label column per problem.
+- Feature generation can emit multiple label variants for analysis.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass, field
+from typing import Dict, Iterable, Mapping
+
+import polars as pl
+
+
+@dataclass(frozen=True)
+class LabelRules:
+    """Rules controlling which TD components count toward a label."""
+
+    include_rush: bool = True
+    include_rec: bool = True
+    include_pass_thrown: bool = True  # credit passers for thrown TDs
+    include_other: bool = False  # fumble returns, defensive/special teams if present
+
+
+@dataclass(frozen=True)
+class LabelSpec:
+    """Container describing a label version."""
+
+    name: str
+    primary: str
+    labels: Mapping[str, LabelRules]
+    aliases: Mapping[str, str] = field(default_factory=dict)
+
+    @property
+    def all_columns(self) -> set[str]:
+        cols = set(self.labels.keys())
+        cols.update(self.aliases.keys())
+        return cols
+
+
+DEFAULT_LABEL_VERSION = "v1_any_offense"
+
+
+LABEL_VERSIONS: Dict[str, LabelSpec] = {
+    "v1_any_offense": LabelSpec(
+        name="v1_any_offense",
+        primary="anytime_td_offense",
+        labels={
+            "anytime_td_offense": LabelRules(include_other=False),
+            "anytime_td_rush": LabelRules(include_rush=True, include_rec=False, include_pass_thrown=False, include_other=False),
+            "anytime_td_rec": LabelRules(include_rush=False, include_rec=True, include_pass_thrown=False, include_other=False),
+            "anytime_td_pass_thrown": LabelRules(include_rush=False, include_rec=False, include_pass_thrown=True, include_other=False),
+            "anytime_td_all": LabelRules(include_other=True),
+        },
+        aliases={
+            # Maintain legacy column name as an alias to the offense-only label.
+            "anytime_td": "anytime_td_offense",
+            # Keep td_count pointing to the offense definition for backward compatibility.
+            "td_count": "td_count_offense",
+        },
+    ),
+    "v1_any_all": LabelSpec(
+        name="v1_any_all",
+        primary="anytime_td_all",
+        labels={
+            "anytime_td_all": LabelRules(include_other=True),
+            "anytime_td_offense": LabelRules(include_other=False),
+            "anytime_td_rush": LabelRules(include_rush=True, include_rec=False, include_pass_thrown=False, include_other=False),
+            "anytime_td_rec": LabelRules(include_rush=False, include_rec=True, include_pass_thrown=False, include_other=False),
+            "anytime_td_pass_thrown": LabelRules(include_rush=False, include_rec=False, include_pass_thrown=True, include_other=False),
+        },
+        aliases={
+            "anytime_td": "anytime_td_all",
+            "td_count": "td_count_all",
+        },
+    ),
+}
+
+
+def get_label_spec(version: str | None) -> LabelSpec:
+    """Return a concrete LabelSpec for the requested version (or default)."""
+
+    version = version or DEFAULT_LABEL_VERSION
+    if version not in LABEL_VERSIONS:
+        raise ValueError(
+            f"Unknown label_version '{version}'. "
+            f"Available: {sorted(LABEL_VERSIONS.keys())}"
+        )
+    return LABEL_VERSIONS[version]
+
+
+def _sum_expr(exprs: Iterable[pl.Expr]) -> pl.Expr:
+    exprs = list(exprs)
+    if not exprs:
+        return pl.lit(0).cast(pl.Int64)
+    acc = exprs[0]
+    for expr in exprs[1:]:
+        acc = acc + expr
+    return acc
+
+
+def compute_td_labels(df: pl.DataFrame, *, version: str | None = None) -> pl.DataFrame:
+    """Compute TD label columns according to a label version.
+
+    Parameters
+    ----------
+    df : pl.DataFrame
+        Player-game frame containing touchdown components.
+    version : str | None
+        Label version identifier. Defaults to DEFAULT_LABEL_VERSION.
+    """
+
+    spec = get_label_spec(version)
+    rush = pl.col("rushing_td_count").fill_null(0).cast(pl.Int64)
+    rec = pl.col("receiving_td_count").fill_null(0).cast(pl.Int64)
+    passing = pl.col("passing_td").fill_null(0).cast(pl.Int64)
+    reported_total = pl.col("touchdowns").fill_null(0).cast(pl.Int64)
+
+    offense_total = _sum_expr([rush, rec, passing]).alias("_td_offense_total")
+    other_total = (reported_total - offense_total).clip_min(0).alias("_td_other_total")
+    all_total = (offense_total + other_total).alias("_td_all_total")
+
+    totals_exprs = [
+        offense_total,
+        other_total,
+        all_total,
+    ]
+
+    label_exprs: list[pl.Expr] = [
+        pl.col("_td_offense_total").alias("td_count_offense"),
+        pl.col("_td_all_total").alias("td_count_all"),
+    ]
+
+    for label_name, rules in spec.labels.items():
+        parts: list[pl.Expr] = []
+        if rules.include_rush:
+            parts.append(rush)
+        if rules.include_rec:
+            parts.append(rec)
+        if rules.include_pass_thrown:
+            parts.append(passing)
+        if rules.include_other:
+            parts.append(pl.col("_td_other_total"))
+        total_expr = _sum_expr(parts)
+        label_exprs.append((total_expr > 0).cast(pl.Int8).alias(label_name))
+
+    # Canonical counts for compatibility
+    if "td_count" not in df.columns:
+        # Fill td_count using the alias mapping; default to offense count.
+        target_alias = spec.aliases.get("td_count") or "td_count_offense"
+        label_exprs.append(pl.col(target_alias).alias("td_count"))
+
+    df = df.with_columns(totals_exprs).with_columns(label_exprs)
+
+    # Resolve aliases (e.g., anytime_td -> anytime_td_offense)
+    if spec.aliases:
+        alias_exprs = []
+        for alias_name, source_name in spec.aliases.items():
+            if source_name in df.columns:
+                alias_exprs.append(pl.col(source_name).alias(alias_name))
+        if alias_exprs:
+            df = df.with_columns(alias_exprs)
+
+    drop_cols = [col for col in ("_td_offense_total", "_td_other_total", "_td_all_total") if col in df.columns]
+    if drop_cols:
+        df = df.drop(drop_cols)
+    return df
diff --git a/utils/feature/player_game_level.py b/utils/feature/player_game_level.py
index b6fe516c5f03d575038eef554d5ab39ea5d5c90d..81de3d8723bd1876b3f71a46031e0fc32d3eef51
--- a/utils/feature/player_game_level.py
+++ b/utils/feature/player_game_level.py
@@ -4,8 +4,12 @@
 Each player gets one row per game with their total stats.
 
 Target columns created:
-- anytime_td (binary): Did player score a TD (receiving or rushing)?
-- td_count (int): Number of TDs scored (receiving + rushing)
+- anytime_td_offense (binary): Did player score an offensive TD (rush/rec/pass thrown)?
+- anytime_td_all (binary): Did player score any TD (including defensive/special teams if present)?
+- anytime_td_rush / anytime_td_rec / anytime_td_pass_thrown: Type-specific TD flags.
+- anytime_td (binary): Legacy alias → current label version primary.
+- td_count_offense / td_count_all: TD counts aligned to label semantics.
+- td_count (int): Legacy alias for the primary td_count.
 - passing_td (int): Number of passing TDs (for QBs)
 - receiving_yards (float): Total receiving yards
 - rushing_yards (float): Total rushing yards
@@ -33,6 +37,7 @@
 from utils.collect.nfl_schedules import get_schedule
 from utils.feature.asof import decision_cutoff_hours_default, fallback_cutoff_hours, get_decision_cutoff_hours, get_fallback_cutoff_hours
 from utils.feature.player_drive_level import _load_play_level_data
+from utils.feature.labels import DEFAULT_LABEL_VERSION, compute_td_labels
 from utils.train.injury_availability import (
     load_latest_artifact,
     predict_probabilities as predict_injury_probabilities,
@@ -1582,7 +1587,12 @@
     if flag_cols:
         df = df.with_columns([pl.col(col).cast(pl.Int8) for col in flag_cols])
     return df
-def build_player_game_level(*, start_date: date, end_date: date) -> None:
+def build_player_game_level(
+    *,
+    start_date: date,
+    end_date: date,
+    label_version: str | None = None,
+) -> None:
     """Aggregate play-level data to player-game level.
     
     Creates one row per (player, game) with accumulated stats.
@@ -1680,7 +1690,7 @@
     
     # Merge rows where same player had multiple roles in same game
     # (e.g., QB who also rushed, WR who also rushed)
-    df_merged = _merge_multi_role_players(df_all)
+    df_merged = _merge_multi_role_players(df_all, label_version=label_version or DEFAULT_LABEL_VERSION)
 
     df_merged = _append_zero_usage_players(df_merged, seasons_in_window)
     

file update:
diff --git a/utils/feature/labels.py b/utils/feature/labels.py
new file mode 100644
index 0000000000000000000000000000000000000000..b34571f04254cd7bceb9363a190ee7d305852bd5
--- /dev/null
+++ b/utils/feature/labels.py
@@ -0,0 +1,169 @@
+"""Label semantics and versioning for NFL player-level targets.
+
+This module centralizes anytime-TD label definitions so that:
+- Semantics are explicit and versioned.
+- Training can request a specific label column per problem.
+- Feature generation can emit multiple label variants for analysis.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass, field
+from typing import Dict, Iterable, Mapping
+
+import polars as pl
+
+
+@dataclass(frozen=True)
+class LabelRules:
+    """Rules controlling which TD components count toward a label."""
+
+    include_rush: bool = True
+    include_rec: bool = True
+    include_pass_thrown: bool = True  # credit passers for thrown TDs
+    include_other: bool = False  # fumble returns, defensive/special teams if present
+
+
+@dataclass(frozen=True)
+class LabelSpec:
+    """Container describing a label version."""
+
+    name: str
+    primary: str
+    labels: Mapping[str, LabelRules]
+    aliases: Mapping[str, str] = field(default_factory=dict)
+
+    @property
+    def all_columns(self) -> set[str]:
+        cols = set(self.labels.keys())
+        cols.update(self.aliases.keys())
+        return cols
+
+
+DEFAULT_LABEL_VERSION = "v1_any_offense"
+
+
+LABEL_VERSIONS: Dict[str, LabelSpec] = {
+    "v1_any_offense": LabelSpec(
+        name="v1_any_offense",
+        primary="anytime_td_offense",
+        labels={
+            "anytime_td_offense": LabelRules(include_other=False),
+            "anytime_td_rush": LabelRules(include_rush=True, include_rec=False, include_pass_thrown=False, include_other=False),
+            "anytime_td_rec": LabelRules(include_rush=False, include_rec=True, include_pass_thrown=False, include_other=False),
+            "anytime_td_pass_thrown": LabelRules(include_rush=False, include_rec=False, include_pass_thrown=True, include_other=False),
+            "anytime_td_all": LabelRules(include_other=True),
+        },
+        aliases={
+            # Maintain legacy column name as an alias to the offense-only label.
+            "anytime_td": "anytime_td_offense",
+            # Keep td_count pointing to the offense definition for backward compatibility.
+            "td_count": "td_count_offense",
+        },
+    ),
+    "v1_any_all": LabelSpec(
+        name="v1_any_all",
+        primary="anytime_td_all",
+        labels={
+            "anytime_td_all": LabelRules(include_other=True),
+            "anytime_td_offense": LabelRules(include_other=False),
+            "anytime_td_rush": LabelRules(include_rush=True, include_rec=False, include_pass_thrown=False, include_other=False),
+            "anytime_td_rec": LabelRules(include_rush=False, include_rec=True, include_pass_thrown=False, include_other=False),
+            "anytime_td_pass_thrown": LabelRules(include_rush=False, include_rec=False, include_pass_thrown=True, include_other=False),
+        },
+        aliases={
+            "anytime_td": "anytime_td_all",
+            "td_count": "td_count_all",
+        },
+    ),
+}
+
+
+def get_label_spec(version: str | None) -> LabelSpec:
+    """Return a concrete LabelSpec for the requested version (or default)."""
+
+    version = version or DEFAULT_LABEL_VERSION
+    if version not in LABEL_VERSIONS:
+        raise ValueError(
+            f"Unknown label_version '{version}'. "
+            f"Available: {sorted(LABEL_VERSIONS.keys())}"
+        )
+    return LABEL_VERSIONS[version]
+
+
+def _sum_expr(exprs: Iterable[pl.Expr]) -> pl.Expr:
+    exprs = list(exprs)
+    if not exprs:
+        return pl.lit(0).cast(pl.Int64)
+    acc = exprs[0]
+    for expr in exprs[1:]:
+        acc = acc + expr
+    return acc
+
+
+def compute_td_labels(df: pl.DataFrame, *, version: str | None = None) -> pl.DataFrame:
+    """Compute TD label columns according to a label version.
+
+    Parameters
+    ----------
+    df : pl.DataFrame
+        Player-game frame containing touchdown components.
+    version : str | None
+        Label version identifier. Defaults to DEFAULT_LABEL_VERSION.
+    """
+
+    spec = get_label_spec(version)
+    rush = pl.col("rushing_td_count").fill_null(0).cast(pl.Int64)
+    rec = pl.col("receiving_td_count").fill_null(0).cast(pl.Int64)
+    passing = pl.col("passing_td").fill_null(0).cast(pl.Int64)
+    reported_total = pl.col("touchdowns").fill_null(0).cast(pl.Int64)
+
+    offense_total = _sum_expr([rush, rec, passing]).alias("_td_offense_total")
+    other_total = (reported_total - offense_total).clip_min(0).alias("_td_other_total")
+    all_total = (offense_total + other_total).alias("_td_all_total")
+
+    totals_exprs = [
+        offense_total,
+        other_total,
+        all_total,
+    ]
+
+    label_exprs: list[pl.Expr] = [
+        pl.col("_td_offense_total").alias("td_count_offense"),
+        pl.col("_td_all_total").alias("td_count_all"),
+    ]
+
+    for label_name, rules in spec.labels.items():
+        parts: list[pl.Expr] = []
+        if rules.include_rush:
+            parts.append(rush)
+        if rules.include_rec:
+            parts.append(rec)
+        if rules.include_pass_thrown:
+            parts.append(passing)
+        if rules.include_other:
+            parts.append(pl.col("_td_other_total"))
+        total_expr = _sum_expr(parts)
+        label_exprs.append((total_expr > 0).cast(pl.Int8).alias(label_name))
+
+    # Canonical counts for compatibility
+    if "td_count" not in df.columns:
+        # Fill td_count using the alias mapping; default to offense count.
+        target_alias = spec.aliases.get("td_count") or "td_count_offense"
+        label_exprs.append(pl.col(target_alias).alias("td_count"))
+
+    df = df.with_columns(totals_exprs).with_columns(label_exprs)
+
+    # Resolve aliases (e.g., anytime_td -> anytime_td_offense)
+    if spec.aliases:
+        alias_exprs = []
+        for alias_name, source_name in spec.aliases.items():
+            if source_name in df.columns:
+                alias_exprs.append(pl.col(source_name).alias(alias_name))
+        if alias_exprs:
+            df = df.with_columns(alias_exprs)
+
+    drop_cols = [col for col in ("_td_offense_total", "_td_other_total", "_td_all_total") if col in df.columns]
+    if drop_cols:
+        df = df.drop(drop_cols)
+    return df
diff --git a/utils/feature/player_game_level.py b/utils/feature/player_game_level.py
index b6fe516c5f03d575038eef554d5ab39ea5d5c90d..81de3d8723bd1876b3f71a46031e0fc32d3eef51
--- a/utils/feature/player_game_level.py
+++ b/utils/feature/player_game_level.py
@@ -4,8 +4,12 @@
 Each player gets one row per game with their total stats.
 
 Target columns created:
-- anytime_td (binary): Did player score a TD (receiving or rushing)?
-- td_count (int): Number of TDs scored (receiving + rushing)
+- anytime_td_offense (binary): Did player score an offensive TD (rush/rec/pass thrown)?
+- anytime_td_all (binary): Did player score any TD (including defensive/special teams if present)?
+- anytime_td_rush / anytime_td_rec / anytime_td_pass_thrown: Type-specific TD flags.
+- anytime_td (binary): Legacy alias → current label version primary.
+- td_count_offense / td_count_all: TD counts aligned to label semantics.
+- td_count (int): Legacy alias for the primary td_count.
 - passing_td (int): Number of passing TDs (for QBs)
 - receiving_yards (float): Total receiving yards
 - rushing_yards (float): Total rushing yards
@@ -33,6 +37,7 @@
 from utils.collect.nfl_schedules import get_schedule
 from utils.feature.asof import decision_cutoff_hours_default, fallback_cutoff_hours, get_decision_cutoff_hours, get_fallback_cutoff_hours
 from utils.feature.player_drive_level import _load_play_level_data
+from utils.feature.labels import DEFAULT_LABEL_VERSION, compute_td_labels
 from utils.train.injury_availability import (
     load_latest_artifact,
     predict_probabilities as predict_injury_probabilities,
@@ -1582,7 +1587,12 @@
     if flag_cols:
         df = df.with_columns([pl.col(col).cast(pl.Int8) for col in flag_cols])
     return df
-def build_player_game_level(*, start_date: date, end_date: date) -> None:
+def build_player_game_level(
+    *,
+    start_date: date,
+    end_date: date,
+    label_version: str | None = None,
+) -> None:
     """Aggregate play-level data to player-game level.
     
     Creates one row per (player, game) with accumulated stats.
@@ -1680,7 +1690,7 @@
     
     # Merge rows where same player had multiple roles in same game
     # (e.g., QB who also rushed, WR who also rushed)
-    df_merged = _merge_multi_role_players(df_all)
+    df_merged = _merge_multi_role_players(df_all, label_version=label_version or DEFAULT_LABEL_VERSION)
 
     df_merged = _append_zero_usage_players(df_merged, seasons_in_window)
     


thinking
**Updating _merge_multi_role_players function**
file update
M /Users/jameswest/Desktop/nfl_predict/utils/feature/player_game_level.py
@@ -3380,3 +3380,3 @@
 
-def _merge_multi_role_players(df: pl.DataFrame) -> pl.DataFrame:
+def _merge_multi_role_players(df: pl.DataFrame, *, label_version: str | None = None) -> pl.DataFrame:
     """Merge stats for players who had multiple roles in same game.
@@ -3434,4 +3434,2 @@
 
-    # Fallback touchdown logic: if generic touchdown attribution is missing,
-    # derive it from rushing + receiving touchdowns.
     merged = merged.with_columns([
@@ -3447,15 +3445,3 @@
 
-    merged = merged.with_columns([
-        pl.when(pl.col("touchdowns") > 0)
-        .then(pl.col("touchdowns"))
-        .otherwise(pl.col("rushing_td_count") + pl.col("receiving_td_count"))
-        .cast(pl.Int64)
-        .alias("_total_touchdowns")
-    ])
-
-    merged = merged.with_columns([
-        (pl.col("_total_touchdowns") > 0).cast(pl.Int8).alias("anytime_td"),
-        pl.col("_total_touchdowns").alias("td_count"),
-    ]).drop("_total_touchdowns")
-    
+    merged = compute_td_labels(merged, version=label_version)
     return merged
apply_patch(auto_approved=true) exited 0 in 43ms:
Success. Updated the following files:
M utils/feature/player_game_level.py
file update:
diff --git a/utils/feature/labels.py b/utils/feature/labels.py
new file mode 100644
index 0000000000000000000000000000000000000000..b34571f04254cd7bceb9363a190ee7d305852bd5
--- /dev/null
+++ b/utils/feature/labels.py
@@ -0,0 +1,169 @@
+"""Label semantics and versioning for NFL player-level targets.
+
+This module centralizes anytime-TD label definitions so that:
+- Semantics are explicit and versioned.
+- Training can request a specific label column per problem.
+- Feature generation can emit multiple label variants for analysis.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass, field
+from typing import Dict, Iterable, Mapping
+
+import polars as pl
+
+
+@dataclass(frozen=True)
+class LabelRules:
+    """Rules controlling which TD components count toward a label."""
+
+    include_rush: bool = True
+    include_rec: bool = True
+    include_pass_thrown: bool = True  # credit passers for thrown TDs
+    include_other: bool = False  # fumble returns, defensive/special teams if present
+
+
+@dataclass(frozen=True)
+class LabelSpec:
+    """Container describing a label version."""
+
+    name: str
+    primary: str
+    labels: Mapping[str, LabelRules]
+    aliases: Mapping[str, str] = field(default_factory=dict)
+
+    @property
+    def all_columns(self) -> set[str]:
+        cols = set(self.labels.keys())
+        cols.update(self.aliases.keys())
+        return cols
+
+
+DEFAULT_LABEL_VERSION = "v1_any_offense"
+
+
+LABEL_VERSIONS: Dict[str, LabelSpec] = {
+    "v1_any_offense": LabelSpec(
+        name="v1_any_offense",
+        primary="anytime_td_offense",
+        labels={
+            "anytime_td_offense": LabelRules(include_other=False),
+            "anytime_td_rush": LabelRules(include_rush=True, include_rec=False, include_pass_thrown=False, include_other=False),
+            "anytime_td_rec": LabelRules(include_rush=False, include_rec=True, include_pass_thrown=False, include_other=False),
+            "anytime_td_pass_thrown": LabelRules(include_rush=False, include_rec=False, include_pass_thrown=True, include_other=False),
+            "anytime_td_all": LabelRules(include_other=True),
+        },
+        aliases={
+            # Maintain legacy column name as an alias to the offense-only label.
+            "anytime_td": "anytime_td_offense",
+            # Keep td_count pointing to the offense definition for backward compatibility.
+            "td_count": "td_count_offense",
+        },
+    ),
+    "v1_any_all": LabelSpec(
+        name="v1_any_all",
+        primary="anytime_td_all",
+        labels={
+            "anytime_td_all": LabelRules(include_other=True),
+            "anytime_td_offense": LabelRules(include_other=False),
+            "anytime_td_rush": LabelRules(include_rush=True, include_rec=False, include_pass_thrown=False, include_other=False),
+            "anytime_td_rec": LabelRules(include_rush=False, include_rec=True, include_pass_thrown=False, include_other=False),
+            "anytime_td_pass_thrown": LabelRules(include_rush=False, include_rec=False, include_pass_thrown=True, include_other=False),
+        },
+        aliases={
+            "anytime_td": "anytime_td_all",
+            "td_count": "td_count_all",
+        },
+    ),
+}
+
+
+def get_label_spec(version: str | None) -> LabelSpec:
+    """Return a concrete LabelSpec for the requested version (or default)."""
+
+    version = version or DEFAULT_LABEL_VERSION
+    if version not in LABEL_VERSIONS:
+        raise ValueError(
+            f"Unknown label_version '{version}'. "
+            f"Available: {sorted(LABEL_VERSIONS.keys())}"
+        )
+    return LABEL_VERSIONS[version]
+
+
+def _sum_expr(exprs: Iterable[pl.Expr]) -> pl.Expr:
+    exprs = list(exprs)
+    if not exprs:
+        return pl.lit(0).cast(pl.Int64)
+    acc = exprs[0]
+    for expr in exprs[1:]:
+        acc = acc + expr
+    return acc
+
+
+def compute_td_labels(df: pl.DataFrame, *, version: str | None = None) -> pl.DataFrame:
+    """Compute TD label columns according to a label version.
+
+    Parameters
+    ----------
+    df : pl.DataFrame
+        Player-game frame containing touchdown components.
+    version : str | None
+        Label version identifier. Defaults to DEFAULT_LABEL_VERSION.
+    """
+
+    spec = get_label_spec(version)
+    rush = pl.col("rushing_td_count").fill_null(0).cast(pl.Int64)
+    rec = pl.col("receiving_td_count").fill_null(0).cast(pl.Int64)
+    passing = pl.col("passing_td").fill_null(0).cast(pl.Int64)
+    reported_total = pl.col("touchdowns").fill_null(0).cast(pl.Int64)
+
+    offense_total = _sum_expr([rush, rec, passing]).alias("_td_offense_total")
+    other_total = (reported_total - offense_total).clip_min(0).alias("_td_other_total")
+    all_total = (offense_total + other_total).alias("_td_all_total")
+
+    totals_exprs = [
+        offense_total,
+        other_total,
+        all_total,
+    ]
+
+    label_exprs: list[pl.Expr] = [
+        pl.col("_td_offense_total").alias("td_count_offense"),
+        pl.col("_td_all_total").alias("td_count_all"),
+    ]
+
+    for label_name, rules in spec.labels.items():
+        parts: list[pl.Expr] = []
+        if rules.include_rush:
+            parts.append(rush)
+        if rules.include_rec:
+            parts.append(rec)
+        if rules.include_pass_thrown:
+            parts.append(passing)
+        if rules.include_other:
+            parts.append(pl.col("_td_other_total"))
+        total_expr = _sum_expr(parts)
+        label_exprs.append((total_expr > 0).cast(pl.Int8).alias(label_name))
+
+    # Canonical counts for compatibility
+    if "td_count" not in df.columns:
+        # Fill td_count using the alias mapping; default to offense count.
+        target_alias = spec.aliases.get("td_count") or "td_count_offense"
+        label_exprs.append(pl.col(target_alias).alias("td_count"))
+
+    df = df.with_columns(totals_exprs).with_columns(label_exprs)
+
+    # Resolve aliases (e.g., anytime_td -> anytime_td_offense)
+    if spec.aliases:
+        alias_exprs = []
+        for alias_name, source_name in spec.aliases.items():
+            if source_name in df.columns:
+                alias_exprs.append(pl.col(source_name).alias(alias_name))
+        if alias_exprs:
+            df = df.with_columns(alias_exprs)
+
+    drop_cols = [col for col in ("_td_offense_total", "_td_other_total", "_td_all_total") if col in df.columns]
+    if drop_cols:
+        df = df.drop(drop_cols)
+    return df
diff --git a/utils/feature/player_game_level.py b/utils/feature/player_game_level.py
index b6fe516c5f03d575038eef554d5ab39ea5d5c90d..dd4f1f7fcc9de4d8c63390f0a160005eeae48e2f
--- a/utils/feature/player_game_level.py
+++ b/utils/feature/player_game_level.py
@@ -4,8 +4,12 @@
 Each player gets one row per game with their total stats.
 
 Target columns created:
-- anytime_td (binary): Did player score a TD (receiving or rushing)?
-- td_count (int): Number of TDs scored (receiving + rushing)
+- anytime_td_offense (binary): Did player score an offensive TD (rush/rec/pass thrown)?
+- anytime_td_all (binary): Did player score any TD (including defensive/special teams if present)?
+- anytime_td_rush / anytime_td_rec / anytime_td_pass_thrown: Type-specific TD flags.
+- anytime_td (binary): Legacy alias → current label version primary.
+- td_count_offense / td_count_all: TD counts aligned to label semantics.
+- td_count (int): Legacy alias for the primary td_count.
 - passing_td (int): Number of passing TDs (for QBs)
 - receiving_yards (float): Total receiving yards
 - rushing_yards (float): Total rushing yards
@@ -33,6 +37,7 @@
 from utils.collect.nfl_schedules import get_schedule
 from utils.feature.asof import decision_cutoff_hours_default, fallback_cutoff_hours, get_decision_cutoff_hours, get_fallback_cutoff_hours
 from utils.feature.player_drive_level import _load_play_level_data
+from utils.feature.labels import DEFAULT_LABEL_VERSION, compute_td_labels
 from utils.train.injury_availability import (
     load_latest_artifact,
     predict_probabilities as predict_injury_probabilities,
@@ -1582,7 +1587,12 @@
     if flag_cols:
         df = df.with_columns([pl.col(col).cast(pl.Int8) for col in flag_cols])
     return df
-def build_player_game_level(*, start_date: date, end_date: date) -> None:
+def build_player_game_level(
+    *,
+    start_date: date,
+    end_date: date,
+    label_version: str | None = None,
+) -> None:
     """Aggregate play-level data to player-game level.
     
     Creates one row per (player, game) with accumulated stats.
@@ -1680,7 +1690,7 @@
     
     # Merge rows where same player had multiple roles in same game
     # (e.g., QB who also rushed, WR who also rushed)
-    df_merged = _merge_multi_role_players(df_all)
+    df_merged = _merge_multi_role_players(df_all, label_version=label_version or DEFAULT_LABEL_VERSION)
 
     df_merged = _append_zero_usage_players(df_merged, seasons_in_window)
     
@@ -3368,7 +3378,7 @@
     )
 
 
-def _merge_multi_role_players(df: pl.DataFrame) -> pl.DataFrame:
+def _merge_multi_role_players(df: pl.DataFrame, *, label_version: str | None = None) -> pl.DataFrame:
     """Merge stats for players who had multiple roles in same game.
     
     Example: QB who passed and rushed, WR who received and rushed.
@@ -3422,8 +3432,6 @@
         if col in merged.columns:
             merged = merged.with_columns(pl.col(col).fill_null(0))
 
-    # Fallback touchdown logic: if generic touchdown attribution is missing,
-    # derive it from rushing + receiving touchdowns.
     merged = merged.with_columns([
         pl.col("touchdowns").fill_null(0).alias("touchdowns"),
         pl.col("rushing_td_count").fill_null(0).alias("rushing_td_count"),
@@ -3435,17 +3443,5 @@
         pl.col("goal_to_go_carry").fill_null(0).alias("goal_to_go_carry"),
     ])
 
-    merged = merged.with_columns([
-        pl.when(pl.col("touchdowns") > 0)
-        .then(pl.col("touchdowns"))
-        .otherwise(pl.col("rushing_td_count") + pl.col("receiving_td_count"))
-        .cast(pl.Int64)
-        .alias("_total_touchdowns")
-    ])
-
-    merged = merged.with_columns([
-        (pl.col("_total_touchdowns") > 0).cast(pl.Int8).alias("anytime_td"),
-        pl.col("_total_touchdowns").alias("td_count"),
-    ]).drop("_total_touchdowns")
-    
+    merged = compute_td_labels(merged, version=label_version)
     return merged

file update:
diff --git a/utils/feature/labels.py b/utils/feature/labels.py
new file mode 100644
index 0000000000000000000000000000000000000000..b34571f04254cd7bceb9363a190ee7d305852bd5
--- /dev/null
+++ b/utils/feature/labels.py
@@ -0,0 +1,169 @@
+"""Label semantics and versioning for NFL player-level targets.
+
+This module centralizes anytime-TD label definitions so that:
+- Semantics are explicit and versioned.
+- Training can request a specific label column per problem.
+- Feature generation can emit multiple label variants for analysis.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass, field
+from typing import Dict, Iterable, Mapping
+
+import polars as pl
+
+
+@dataclass(frozen=True)
+class LabelRules:
+    """Rules controlling which TD components count toward a label."""
+
+    include_rush: bool = True
+    include_rec: bool = True
+    include_pass_thrown: bool = True  # credit passers for thrown TDs
+    include_other: bool = False  # fumble returns, defensive/special teams if present
+
+
+@dataclass(frozen=True)
+class LabelSpec:
+    """Container describing a label version."""
+
+    name: str
+    primary: str
+    labels: Mapping[str, LabelRules]
+    aliases: Mapping[str, str] = field(default_factory=dict)
+
+    @property
+    def all_columns(self) -> set[str]:
+        cols = set(self.labels.keys())
+        cols.update(self.aliases.keys())
+        return cols
+
+
+DEFAULT_LABEL_VERSION = "v1_any_offense"
+
+
+LABEL_VERSIONS: Dict[str, LabelSpec] = {
+    "v1_any_offense": LabelSpec(
+        name="v1_any_offense",
+        primary="anytime_td_offense",
+        labels={
+            "anytime_td_offense": LabelRules(include_other=False),
+            "anytime_td_rush": LabelRules(include_rush=True, include_rec=False, include_pass_thrown=False, include_other=False),
+            "anytime_td_rec": LabelRules(include_rush=False, include_rec=True, include_pass_thrown=False, include_other=False),
+            "anytime_td_pass_thrown": LabelRules(include_rush=False, include_rec=False, include_pass_thrown=True, include_other=False),
+            "anytime_td_all": LabelRules(include_other=True),
+        },
+        aliases={
+            # Maintain legacy column name as an alias to the offense-only label.
+            "anytime_td": "anytime_td_offense",
+            # Keep td_count pointing to the offense definition for backward compatibility.
+            "td_count": "td_count_offense",
+        },
+    ),
+    "v1_any_all": LabelSpec(
+        name="v1_any_all",
+        primary="anytime_td_all",
+        labels={
+            "anytime_td_all": LabelRules(include_other=True),
+            "anytime_td_offense": LabelRules(include_other=False),
+            "anytime_td_rush": LabelRules(include_rush=True, include_rec=False, include_pass_thrown=False, include_other=False),
+            "anytime_td_rec": LabelRules(include_rush=False, include_rec=True, include_pass_thrown=False, include_other=False),
+            "anytime_td_pass_thrown": LabelRules(include_rush=False, include_rec=False, include_pass_thrown=True, include_other=False),
+        },
+        aliases={
+            "anytime_td": "anytime_td_all",
+            "td_count": "td_count_all",
+        },
+    ),
+}
+
+
+def get_label_spec(version: str | None) -> LabelSpec:
+    """Return a concrete LabelSpec for the requested version (or default)."""
+
+    version = version or DEFAULT_LABEL_VERSION
+    if version not in LABEL_VERSIONS:
+        raise ValueError(
+            f"Unknown label_version '{version}'. "
+            f"Available: {sorted(LABEL_VERSIONS.keys())}"
+        )
+    return LABEL_VERSIONS[version]
+
+
+def _sum_expr(exprs: Iterable[pl.Expr]) -> pl.Expr:
+    exprs = list(exprs)
+    if not exprs:
+        return pl.lit(0).cast(pl.Int64)
+    acc = exprs[0]
+    for expr in exprs[1:]:
+        acc = acc + expr
+    return acc
+
+
+def compute_td_labels(df: pl.DataFrame, *, version: str | None = None) -> pl.DataFrame:
+    """Compute TD label columns according to a label version.
+
+    Parameters
+    ----------
+    df : pl.DataFrame
+        Player-game frame containing touchdown components.
+    version : str | None
+        Label version identifier. Defaults to DEFAULT_LABEL_VERSION.
+    """
+
+    spec = get_label_spec(version)
+    rush = pl.col("rushing_td_count").fill_null(0).cast(pl.Int64)
+    rec = pl.col("receiving_td_count").fill_null(0).cast(pl.Int64)
+    passing = pl.col("passing_td").fill_null(0).cast(pl.Int64)
+    reported_total = pl.col("touchdowns").fill_null(0).cast(pl.Int64)
+
+    offense_total = _sum_expr([rush, rec, passing]).alias("_td_offense_total")
+    other_total = (reported_total - offense_total).clip_min(0).alias("_td_other_total")
+    all_total = (offense_total + other_total).alias("_td_all_total")
+
+    totals_exprs = [
+        offense_total,
+        other_total,
+        all_total,
+    ]
+
+    label_exprs: list[pl.Expr] = [
+        pl.col("_td_offense_total").alias("td_count_offense"),
+        pl.col("_td_all_total").alias("td_count_all"),
+    ]
+
+    for label_name, rules in spec.labels.items():
+        parts: list[pl.Expr] = []
+        if rules.include_rush:
+            parts.append(rush)
+        if rules.include_rec:
+            parts.append(rec)
+        if rules.include_pass_thrown:
+            parts.append(passing)
+        if rules.include_other:
+            parts.append(pl.col("_td_other_total"))
+        total_expr = _sum_expr(parts)
+        label_exprs.append((total_expr > 0).cast(pl.Int8).alias(label_name))
+
+    # Canonical counts for compatibility
+    if "td_count" not in df.columns:
+        # Fill td_count using the alias mapping; default to offense count.
+        target_alias = spec.aliases.get("td_count") or "td_count_offense"
+        label_exprs.append(pl.col(target_alias).alias("td_count"))
+
+    df = df.with_columns(totals_exprs).with_columns(label_exprs)
+
+    # Resolve aliases (e.g., anytime_td -> anytime_td_offense)
+    if spec.aliases:
+        alias_exprs = []
+        for alias_name, source_name in spec.aliases.items():
+            if source_name in df.columns:
+                alias_exprs.append(pl.col(source_name).alias(alias_name))
+        if alias_exprs:
+            df = df.with_columns(alias_exprs)
+
+    drop_cols = [col for col in ("_td_offense_total", "_td_other_total", "_td_all_total") if col in df.columns]
+    if drop_cols:
+        df = df.drop(drop_cols)
+    return df
diff --git a/utils/feature/player_game_level.py b/utils/feature/player_game_level.py
index b6fe516c5f03d575038eef554d5ab39ea5d5c90d..dd4f1f7fcc9de4d8c63390f0a160005eeae48e2f
--- a/utils/feature/player_game_level.py
+++ b/utils/feature/player_game_level.py
@@ -4,8 +4,12 @@
 Each player gets one row per game with their total stats.
 
 Target columns created:
-- anytime_td (binary): Did player score a TD (receiving or rushing)?
-- td_count (int): Number of TDs scored (receiving + rushing)
+- anytime_td_offense (binary): Did player score an offensive TD (rush/rec/pass thrown)?
+- anytime_td_all (binary): Did player score any TD (including defensive/special teams if present)?
+- anytime_td_rush / anytime_td_rec / anytime_td_pass_thrown: Type-specific TD flags.
+- anytime_td (binary): Legacy alias → current label version primary.
+- td_count_offense / td_count_all: TD counts aligned to label semantics.
+- td_count (int): Legacy alias for the primary td_count.
 - passing_td (int): Number of passing TDs (for QBs)
 - receiving_yards (float): Total receiving yards
 - rushing_yards (float): Total rushing yards
@@ -33,6 +37,7 @@
 from utils.collect.nfl_schedules import get_schedule
 from utils.feature.asof import decision_cutoff_hours_default, fallback_cutoff_hours, get_decision_cutoff_hours, get_fallback_cutoff_hours
 from utils.feature.player_drive_level import _load_play_level_data
+from utils.feature.labels import DEFAULT_LABEL_VERSION, compute_td_labels
 from utils.train.injury_availability import (
     load_latest_artifact,
     predict_probabilities as predict_injury_probabilities,
@@ -1582,7 +1587,12 @@
     if flag_cols:
         df = df.with_columns([pl.col(col).cast(pl.Int8) for col in flag_cols])
     return df
-def build_player_game_level(*, start_date: date, end_date: date) -> None:
+def build_player_game_level(
+    *,
+    start_date: date,
+    end_date: date,
+    label_version: str | None = None,
+) -> None:
     """Aggregate play-level data to player-game level.
     
     Creates one row per (player, game) with accumulated stats.
@@ -1680,7 +1690,7 @@
     
     # Merge rows where same player had multiple roles in same game
     # (e.g., QB who also rushed, WR who also rushed)
-    df_merged = _merge_multi_role_players(df_all)
+    df_merged = _merge_multi_role_players(df_all, label_version=label_version or DEFAULT_LABEL_VERSION)
 
     df_merged = _append_zero_usage_players(df_merged, seasons_in_window)
     
@@ -3368,7 +3378,7 @@
     )
 
 
-def _merge_multi_role_players(df: pl.DataFrame) -> pl.DataFrame:
+def _merge_multi_role_players(df: pl.DataFrame, *, label_version: str | None = None) -> pl.DataFrame:
     """Merge stats for players who had multiple roles in same game.
     
     Example: QB who passed and rushed, WR who received and rushed.
@@ -3422,8 +3432,6 @@
         if col in merged.columns:
             merged = merged.with_columns(pl.col(col).fill_null(0))
 
-    # Fallback touchdown logic: if generic touchdown attribution is missing,
-    # derive it from rushing + receiving touchdowns.
     merged = merged.with_columns([
         pl.col("touchdowns").fill_null(0).alias("touchdowns"),
         pl.col("rushing_td_count").fill_null(0).alias("rushing_td_count"),
@@ -3435,17 +3443,5 @@
         pl.col("goal_to_go_carry").fill_null(0).alias("goal_to_go_carry"),
     ])
 
-    merged = merged.with_columns([
-        pl.when(pl.col("touchdowns") > 0)
-        .then(pl.col("touchdowns"))
-        .otherwise(pl.col("rushing_td_count") + pl.col("receiving_td_count"))
-        .cast(pl.Int64)
-        .alias("_total_touchdowns")
-    ])
-
-    merged = merged.with_columns([
-        (pl.col("_total_touchdowns") > 0).cast(pl.Int8).alias("anytime_td"),
-        pl.col("_total_touchdowns").alias("td_count"),
-    ]).drop("_total_touchdowns")
-    
+    merged = compute_td_labels(merged, version=label_version)
     return merged


thinking
**Updating feature matrix functions with label_version parameter**

I'm adding an optional label_version parameter with a sensible default to both _build_feature_matrix_internal and build_feature_matrix functions, adjusting their calls to build_player_game_level accordingly. I'll ensure DEFAULT_LABEL_VERSION is imported properly and update the docstrings and logging to reflect this enhancement.

thinking
**Updating feature matrix for label versioning**

I'll add imports for label specs, update function signatures to accept a label_version parameter, and modify the feature matrix building process to handle different label versions. I'll also enhance logging to track positive rates for both the primary label from the spec and the legacy anytime_td column, making sure not to double count. This should keep backwards compatibility while supporting more flexible label targets.
file update
M /Users/jameswest/Desktop/nfl_predict/pipeline/feature.py
@@ -28,2 +28,3 @@
 from utils.feature.opponent_splits import build_opponent_splits
+from utils.feature.labels import DEFAULT_LABEL_VERSION, get_label_spec
 from utils.feature.targets import validate_target_columns
@@ -235,2 +236,3 @@
     cutoff_label: str | None = None,
+    label_version: str | None = None,
 ) -> pl.DataFrame:
@@ -250,2 +252,3 @@
     clean_min_date, clean_max_date = (None, None)
+    label_version = label_version or DEFAULT_LABEL_VERSION
     if start_date is None or end_date is None:
@@ -296,3 +299,3 @@
             # 5. Player-game aggregations (for rolling window features)
-            build_player_game_level(start_date=cur, end_date=chunk_end)
+            build_player_game_level(start_date=cur, end_date=chunk_end, label_version=label_version)
 
@@ -967,2 +970,3 @@
     cutoff_hours_list: Sequence[float] | None = None,
+    label_version: str | None = None,
 ) -> pl.DataFrame:
@@ -994,2 +998,3 @@
                 cutoff_label=label,
+                label_version=label_version,
             )
apply_patch(auto_approved=true) exited 0 in 50ms:
Success. Updated the following files:
M pipeline/feature.py
file update:
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 6c47a91d08f9d309f94323efd4708bb992dc4ce0..2d8e3dfb5166d1055f456f4b5909a0a747cdb8c2
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -26,6 +26,7 @@
 from utils.feature.player_drive_level import build_player_drive_level
 from utils.feature.player_game_level import build_player_game_level
 from utils.feature.opponent_splits import build_opponent_splits
+from utils.feature.labels import DEFAULT_LABEL_VERSION, get_label_spec
 from utils.feature.targets import validate_target_columns
 from utils.feature.daily_totals import build_daily_cache_range
 from utils.feature.rolling_window import add_rolling_features
@@ -233,6 +234,7 @@
     output_path: Path | None = None,
     primary_output_path: Path | None = None,
     cutoff_label: str | None = None,
+    label_version: str | None = None,
 ) -> pl.DataFrame:
     """Run full feature pipeline up to *inclusive* `end_date` for a single cutoff window.
 
@@ -248,6 +250,7 @@
     primary_output = primary_output_path or target_output_path
     current_cutoff_hours = float(get_decision_cutoff_hours())
     clean_min_date, clean_max_date = (None, None)
+    label_version = label_version or DEFAULT_LABEL_VERSION
     if start_date is None or end_date is None:
         clean_min_date, clean_max_date = _get_clean_date_bounds()
 
@@ -294,7 +297,7 @@
             build_player_drive_level(start_date=cur, end_date=chunk_end)
             
             # 5. Player-game aggregations (for rolling window features)
-            build_player_game_level(start_date=cur, end_date=chunk_end)
+            build_player_game_level(start_date=cur, end_date=chunk_end, label_version=label_version)
 
             # advance to next slice
             cur += timedelta(days=chunk_days)
@@ -965,6 +968,7 @@
     recompute_intermediate: bool = True,
     build_rolling: bool = True,
     cutoff_hours_list: Sequence[float] | None = None,
+    label_version: str | None = None,
 ) -> pl.DataFrame:
     """Build feature matrices for one or more decision cutoff horizons.
 
@@ -992,6 +996,7 @@
                 output_path=output_path,
                 primary_output_path=primary_output,
                 cutoff_label=label,
+                label_version=label_version,
             )
         if idx == 0:
             primary_result = df
diff --git a/utils/feature/labels.py b/utils/feature/labels.py
new file mode 100644
index 0000000000000000000000000000000000000000..b34571f04254cd7bceb9363a190ee7d305852bd5
--- /dev/null
+++ b/utils/feature/labels.py
@@ -0,0 +1,169 @@
+"""Label semantics and versioning for NFL player-level targets.
+
+This module centralizes anytime-TD label definitions so that:
+- Semantics are explicit and versioned.
+- Training can request a specific label column per problem.
+- Feature generation can emit multiple label variants for analysis.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass, field
+from typing import Dict, Iterable, Mapping
+
+import polars as pl
+
+
+@dataclass(frozen=True)
+class LabelRules:
+    """Rules controlling which TD components count toward a label."""
+
+    include_rush: bool = True
+    include_rec: bool = True
+    include_pass_thrown: bool = True  # credit passers for thrown TDs
+    include_other: bool = False  # fumble returns, defensive/special teams if present
+
+
+@dataclass(frozen=True)
+class LabelSpec:
+    """Container describing a label version."""
+
+    name: str
+    primary: str
+    labels: Mapping[str, LabelRules]
+    aliases: Mapping[str, str] = field(default_factory=dict)
+
+    @property
+    def all_columns(self) -> set[str]:
+        cols = set(self.labels.keys())
+        cols.update(self.aliases.keys())
+        return cols
+
+
+DEFAULT_LABEL_VERSION = "v1_any_offense"
+
+
+LABEL_VERSIONS: Dict[str, LabelSpec] = {
+    "v1_any_offense": LabelSpec(
+        name="v1_any_offense",
+        primary="anytime_td_offense",
+        labels={
+            "anytime_td_offense": LabelRules(include_other=False),
+            "anytime_td_rush": LabelRules(include_rush=True, include_rec=False, include_pass_thrown=False, include_other=False),
+            "anytime_td_rec": LabelRules(include_rush=False, include_rec=True, include_pass_thrown=False, include_other=False),
+            "anytime_td_pass_thrown": LabelRules(include_rush=False, include_rec=False, include_pass_thrown=True, include_other=False),
+            "anytime_td_all": LabelRules(include_other=True),
+        },
+        aliases={
+            # Maintain legacy column name as an alias to the offense-only label.
+            "anytime_td": "anytime_td_offense",
+            # Keep td_count pointing to the offense definition for backward compatibility.
+            "td_count": "td_count_offense",
+        },
+    ),
+    "v1_any_all": LabelSpec(
+        name="v1_any_all",
+        primary="anytime_td_all",
+        labels={
+            "anytime_td_all": LabelRules(include_other=True),
+            "anytime_td_offense": LabelRules(include_other=False),
+            "anytime_td_rush": LabelRules(include_rush=True, include_rec=False, include_pass_thrown=False, include_other=False),
+            "anytime_td_rec": LabelRules(include_rush=False, include_rec=True, include_pass_thrown=False, include_other=False),
+            "anytime_td_pass_thrown": LabelRules(include_rush=False, include_rec=False, include_pass_thrown=True, include_other=False),
+        },
+        aliases={
+            "anytime_td": "anytime_td_all",
+            "td_count": "td_count_all",
+        },
+    ),
+}
+
+
+def get_label_spec(version: str | None) -> LabelSpec:
+    """Return a concrete LabelSpec for the requested version (or default)."""
+
+    version = version or DEFAULT_LABEL_VERSION
+    if version not in LABEL_VERSIONS:
+        raise ValueError(
+            f"Unknown label_version '{version}'. "
+            f"Available: {sorted(LABEL_VERSIONS.keys())}"
+        )
+    return LABEL_VERSIONS[version]
+
+
+def _sum_expr(exprs: Iterable[pl.Expr]) -> pl.Expr:
+    exprs = list(exprs)
+    if not exprs:
+        return pl.lit(0).cast(pl.Int64)
+    acc = exprs[0]
+    for expr in exprs[1:]:
+        acc = acc + expr
+    return acc
+
+
+def compute_td_labels(df: pl.DataFrame, *, version: str | None = None) -> pl.DataFrame:
+    """Compute TD label columns according to a label version.
+
+    Parameters
+    ----------
+    df : pl.DataFrame
+        Player-game frame containing touchdown components.
+    version : str | None
+        Label version identifier. Defaults to DEFAULT_LABEL_VERSION.
+    """
+
+    spec = get_label_spec(version)
+    rush = pl.col("rushing_td_count").fill_null(0).cast(pl.Int64)
+    rec = pl.col("receiving_td_count").fill_null(0).cast(pl.Int64)
+    passing = pl.col("passing_td").fill_null(0).cast(pl.Int64)
+    reported_total = pl.col("touchdowns").fill_null(0).cast(pl.Int64)
+
+    offense_total = _sum_expr([rush, rec, passing]).alias("_td_offense_total")
+    other_total = (reported_total - offense_total).clip_min(0).alias("_td_other_total")
+    all_total = (offense_total + other_total).alias("_td_all_total")
+
+    totals_exprs = [
+        offense_total,
+        other_total,
+        all_total,
+    ]
+
+    label_exprs: list[pl.Expr] = [
+        pl.col("_td_offense_total").alias("td_count_offense"),
+        pl.col("_td_all_total").alias("td_count_all"),
+    ]
+
+    for label_name, rules in spec.labels.items():
+        parts: list[pl.Expr] = []
+        if rules.include_rush:
+            parts.append(rush)
+        if rules.include_rec:
+            parts.append(rec)
+        if rules.include_pass_thrown:
+            parts.append(passing)
+        if rules.include_other:
+            parts.append(pl.col("_td_other_total"))
+        total_expr = _sum_expr(parts)
+        label_exprs.append((total_expr > 0).cast(pl.Int8).alias(label_name))
+
+    # Canonical counts for compatibility
+    if "td_count" not in df.columns:
+        # Fill td_count using the alias mapping; default to offense count.
+        target_alias = spec.aliases.get("td_count") or "td_count_offense"
+        label_exprs.append(pl.col(target_alias).alias("td_count"))
+
+    df = df.with_columns(totals_exprs).with_columns(label_exprs)
+
+    # Resolve aliases (e.g., anytime_td -> anytime_td_offense)
+    if spec.aliases:
+        alias_exprs = []
+        for alias_name, source_name in spec.aliases.items():
+            if source_name in df.columns:
+                alias_exprs.append(pl.col(source_name).alias(alias_name))
+        if alias_exprs:
+            df = df.with_columns(alias_exprs)
+
+    drop_cols = [col for col in ("_td_offense_total", "_td_other_total", "_td_all_total") if col in df.columns]
+    if drop_cols:
+        df = df.drop(drop_cols)
+    return df
diff --git a/utils/feature/player_game_level.py b/utils/feature/player_game_level.py
index b6fe516c5f03d575038eef554d5ab39ea5d5c90d..dd4f1f7fcc9de4d8c63390f0a160005eeae48e2f
--- a/utils/feature/player_game_level.py
+++ b/utils/feature/player_game_level.py
@@ -4,8 +4,12 @@
 Each player gets one row per game with their total stats.
 
 Target columns created:
-- anytime_td (binary): Did player score a TD (receiving or rushing)?
-- td_count (int): Number of TDs scored (receiving + rushing)
+- anytime_td_offense (binary): Did player score an offensive TD (rush/rec/pass thrown)?
+- anytime_td_all (binary): Did player score any TD (including defensive/special teams if present)?
+- anytime_td_rush / anytime_td_rec / anytime_td_pass_thrown: Type-specific TD flags.
+- anytime_td (binary): Legacy alias → current label version primary.
+- td_count_offense / td_count_all: TD counts aligned to label semantics.
+- td_count (int): Legacy alias for the primary td_count.
 - passing_td (int): Number of passing TDs (for QBs)
 - receiving_yards (float): Total receiving yards
 - rushing_yards (float): Total rushing yards
@@ -33,6 +37,7 @@
 from utils.collect.nfl_schedules import get_schedule
 from utils.feature.asof import decision_cutoff_hours_default, fallback_cutoff_hours, get_decision_cutoff_hours, get_fallback_cutoff_hours
 from utils.feature.player_drive_level import _load_play_level_data
+from utils.feature.labels import DEFAULT_LABEL_VERSION, compute_td_labels
 from utils.train.injury_availability import (
     load_latest_artifact,
     predict_probabilities as predict_injury_probabilities,
@@ -1582,7 +1587,12 @@
     if flag_cols:
         df = df.with_columns([pl.col(col).cast(pl.Int8) for col in flag_cols])
     return df
-def build_player_game_level(*, start_date: date, end_date: date) -> None:
+def build_player_game_level(
+    *,
+    start_date: date,
+    end_date: date,
+    label_version: str | None = None,
+) -> None:
     """Aggregate play-level data to player-game level.
     
     Creates one row per (player, game) with accumulated stats.
@@ -1680,7 +1690,7 @@
     
     # Merge rows where same player had multiple roles in same game
     # (e.g., QB who also rushed, WR who also rushed)
-    df_merged = _merge_multi_role_players(df_all)
+    df_merged = _merge_multi_role_players(df_all, label_version=label_version or DEFAULT_LABEL_VERSION)
 
     df_merged = _append_zero_usage_players(df_merged, seasons_in_window)
     
@@ -3368,7 +3378,7 @@
     )
 
 
-def _merge_multi_role_players(df: pl.DataFrame) -> pl.DataFrame:
+def _merge_multi_role_players(df: pl.DataFrame, *, label_version: str | None = None) -> pl.DataFrame:
     """Merge stats for players who had multiple roles in same game.
     
     Example: QB who passed and rushed, WR who received and rushed.
@@ -3422,8 +3432,6 @@
         if col in merged.columns:
             merged = merged.with_columns(pl.col(col).fill_null(0))
 
-    # Fallback touchdown logic: if generic touchdown attribution is missing,
-    # derive it from rushing + receiving touchdowns.
     merged = merged.with_columns([
         pl.col("touchdowns").fill_null(0).alias("touchdowns"),
         pl.col("rushing_td_count").fill_null(0).alias("rushing_td_count"),
@@ -3435,17 +3443,5 @@
         pl.col("goal_to_go_carry").fill_null(0).alias("goal_to_go_carry"),
     ])
 
-    merged = merged.with_columns([
-        pl.when(pl.col("touchdowns") > 0)
-        .then(pl.col("touchdowns"))
-        .otherwise(pl.col("rushing_td_count") + pl.col("receiving_td_count"))
-        .cast(pl.Int64)
-        .alias("_total_touchdowns")
-    ])
-
-    merged = merged.with_columns([
-        (pl.col("_total_touchdowns") > 0).cast(pl.Int8).alias("anytime_td"),
-        pl.col("_total_touchdowns").alias("td_count"),
-    ]).drop("_total_touchdowns")
-    
+    merged = compute_td_labels(merged, version=label_version)
     return merged

file update:
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 6c47a91d08f9d309f94323efd4708bb992dc4ce0..2d8e3dfb5166d1055f456f4b5909a0a747cdb8c2
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -26,6 +26,7 @@
 from utils.feature.player_drive_level import build_player_drive_level
 from utils.feature.player_game_level import build_player_game_level
 from utils.feature.opponent_splits import build_opponent_splits
+from utils.feature.labels import DEFAULT_LABEL_VERSION, get_label_spec
 from utils.feature.targets import validate_target_columns
 from utils.feature.daily_totals import build_daily_cache_range
 from utils.feature.rolling_window import add_rolling_features
@@ -233,6 +234,7 @@
     output_path: Path | None = None,
     primary_output_path: Path | None = None,
     cutoff_label: str | None = None,
+    label_version: str | None = None,
 ) -> pl.DataFrame:
     """Run full feature pipeline up to *inclusive* `end_date` for a single cutoff window.
 
@@ -248,6 +250,7 @@
     primary_output = primary_output_path or target_output_path
     current_cutoff_hours = float(get_decision_cutoff_hours())
     clean_min_date, clean_max_date = (None, None)
+    label_version = label_version or DEFAULT_LABEL_VERSION
     if start_date is None or end_date is None:
         clean_min_date, clean_max_date = _get_clean_date_bounds()
 
@@ -294,7 +297,7 @@
             build_player_drive_level(start_date=cur, end_date=chunk_end)
             
             # 5. Player-game aggregations (for rolling window features)
-            build_player_game_level(start_date=cur, end_date=chunk_end)
+            build_player_game_level(start_date=cur, end_date=chunk_end, label_version=label_version)
 
             # advance to next slice
             cur += timedelta(days=chunk_days)
@@ -965,6 +968,7 @@
     recompute_intermediate: bool = True,
     build_rolling: bool = True,
     cutoff_hours_list: Sequence[float] | None = None,
+    label_version: str | None = None,
 ) -> pl.DataFrame:
     """Build feature matrices for one or more decision cutoff horizons.
 
@@ -992,6 +996,7 @@
                 output_path=output_path,
                 primary_output_path=primary_output,
                 cutoff_label=label,
+                label_version=label_version,
             )
         if idx == 0:
             primary_result = df
diff --git a/utils/feature/labels.py b/utils/feature/labels.py
new file mode 100644
index 0000000000000000000000000000000000000000..b34571f04254cd7bceb9363a190ee7d305852bd5
--- /dev/null
+++ b/utils/feature/labels.py
@@ -0,0 +1,169 @@
+"""Label semantics and versioning for NFL player-level targets.
+
+This module centralizes anytime-TD label definitions so that:
+- Semantics are explicit and versioned.
+- Training can request a specific label column per problem.
+- Feature generation can emit multiple label variants for analysis.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass, field
+from typing import Dict, Iterable, Mapping
+
+import polars as pl
+
+
+@dataclass(frozen=True)
+class LabelRules:
+    """Rules controlling which TD components count toward a label."""
+
+    include_rush: bool = True
+    include_rec: bool = True
+    include_pass_thrown: bool = True  # credit passers for thrown TDs
+    include_other: bool = False  # fumble returns, defensive/special teams if present
+
+
+@dataclass(frozen=True)
+class LabelSpec:
+    """Container describing a label version."""
+
+    name: str
+    primary: str
+    labels: Mapping[str, LabelRules]
+    aliases: Mapping[str, str] = field(default_factory=dict)
+
+    @property
+    def all_columns(self) -> set[str]:
+        cols = set(self.labels.keys())
+        cols.update(self.aliases.keys())
+        return cols
+
+
+DEFAULT_LABEL_VERSION = "v1_any_offense"
+
+
+LABEL_VERSIONS: Dict[str, LabelSpec] = {
+    "v1_any_offense": LabelSpec(
+        name="v1_any_offense",
+        primary="anytime_td_offense",
+        labels={
+            "anytime_td_offense": LabelRules(include_other=False),
+            "anytime_td_rush": LabelRules(include_rush=True, include_rec=False, include_pass_thrown=False, include_other=False),
+            "anytime_td_rec": LabelRules(include_rush=False, include_rec=True, include_pass_thrown=False, include_other=False),
+            "anytime_td_pass_thrown": LabelRules(include_rush=False, include_rec=False, include_pass_thrown=True, include_other=False),
+            "anytime_td_all": LabelRules(include_other=True),
+        },
+        aliases={
+            # Maintain legacy column name as an alias to the offense-only label.
+            "anytime_td": "anytime_td_offense",
+            # Keep td_count pointing to the offense definition for backward compatibility.
+            "td_count": "td_count_offense",
+        },
+    ),
+    "v1_any_all": LabelSpec(
+        name="v1_any_all",
+        primary="anytime_td_all",
+        labels={
+            "anytime_td_all": LabelRules(include_other=True),
+            "anytime_td_offense": LabelRules(include_other=False),
+            "anytime_td_rush": LabelRules(include_rush=True, include_rec=False, include_pass_thrown=False, include_other=False),
+            "anytime_td_rec": LabelRules(include_rush=False, include_rec=True, include_pass_thrown=False, include_other=False),
+            "anytime_td_pass_thrown": LabelRules(include_rush=False, include_rec=False, include_pass_thrown=True, include_other=False),
+        },
+        aliases={
+            "anytime_td": "anytime_td_all",
+            "td_count": "td_count_all",
+        },
+    ),
+}
+
+
+def get_label_spec(version: str | None) -> LabelSpec:
+    """Return a concrete LabelSpec for the requested version (or default)."""
+
+    version = version or DEFAULT_LABEL_VERSION
+    if version not in LABEL_VERSIONS:
+        raise ValueError(
+            f"Unknown label_version '{version}'. "
+            f"Available: {sorted(LABEL_VERSIONS.keys())}"
+        )
+    return LABEL_VERSIONS[version]
+
+
+def _sum_expr(exprs: Iterable[pl.Expr]) -> pl.Expr:
+    exprs = list(exprs)
+    if not exprs:
+        return pl.lit(0).cast(pl.Int64)
+    acc = exprs[0]
+    for expr in exprs[1:]:
+        acc = acc + expr
+    return acc
+
+
+def compute_td_labels(df: pl.DataFrame, *, version: str | None = None) -> pl.DataFrame:
+    """Compute TD label columns according to a label version.
+
+    Parameters
+    ----------
+    df : pl.DataFrame
+        Player-game frame containing touchdown components.
+    version : str | None
+        Label version identifier. Defaults to DEFAULT_LABEL_VERSION.
+    """
+
+    spec = get_label_spec(version)
+    rush = pl.col("rushing_td_count").fill_null(0).cast(pl.Int64)
+    rec = pl.col("receiving_td_count").fill_null(0).cast(pl.Int64)
+    passing = pl.col("passing_td").fill_null(0).cast(pl.Int64)
+    reported_total = pl.col("touchdowns").fill_null(0).cast(pl.Int64)
+
+    offense_total = _sum_expr([rush, rec, passing]).alias("_td_offense_total")
+    other_total = (reported_total - offense_total).clip_min(0).alias("_td_other_total")
+    all_total = (offense_total + other_total).alias("_td_all_total")
+
+    totals_exprs = [
+        offense_total,
+        other_total,
+        all_total,
+    ]
+
+    label_exprs: list[pl.Expr] = [
+        pl.col("_td_offense_total").alias("td_count_offense"),
+        pl.col("_td_all_total").alias("td_count_all"),
+    ]
+
+    for label_name, rules in spec.labels.items():
+        parts: list[pl.Expr] = []
+        if rules.include_rush:
+            parts.append(rush)
+        if rules.include_rec:
+            parts.append(rec)
+        if rules.include_pass_thrown:
+            parts.append(passing)
+        if rules.include_other:
+            parts.append(pl.col("_td_other_total"))
+        total_expr = _sum_expr(parts)
+        label_exprs.append((total_expr > 0).cast(pl.Int8).alias(label_name))
+
+    # Canonical counts for compatibility
+    if "td_count" not in df.columns:
+        # Fill td_count using the alias mapping; default to offense count.
+        target_alias = spec.aliases.get("td_count") or "td_count_offense"
+        label_exprs.append(pl.col(target_alias).alias("td_count"))
+
+    df = df.with_columns(totals_exprs).with_columns(label_exprs)
+
+    # Resolve aliases (e.g., anytime_td -> anytime_td_offense)
+    if spec.aliases:
+        alias_exprs = []
+        for alias_name, source_name in spec.aliases.items():
+            if source_name in df.columns:
+                alias_exprs.append(pl.col(source_name).alias(alias_name))
+        if alias_exprs:
+            df = df.with_columns(alias_exprs)
+
+    drop_cols = [col for col in ("_td_offense_total", "_td_other_total", "_td_all_total") if col in df.columns]
+    if drop_cols:
+        df = df.drop(drop_cols)
+    return df
diff --git a/utils/feature/player_game_level.py b/utils/feature/player_game_level.py
index b6fe516c5f03d575038eef554d5ab39ea5d5c90d..dd4f1f7fcc9de4d8c63390f0a160005eeae48e2f
--- a/utils/feature/player_game_level.py
+++ b/utils/feature/player_game_level.py
@@ -4,8 +4,12 @@
 Each player gets one row per game with their total stats.
 
 Target columns created:
-- anytime_td (binary): Did player score a TD (receiving or rushing)?
-- td_count (int): Number of TDs scored (receiving + rushing)
+- anytime_td_offense (binary): Did player score an offensive TD (rush/rec/pass thrown)?
+- anytime_td_all (binary): Did player score any TD (including defensive/special teams if present)?
+- anytime_td_rush / anytime_td_rec / anytime_td_pass_thrown: Type-specific TD flags.
+- anytime_td (binary): Legacy alias → current label version primary.
+- td_count_offense / td_count_all: TD counts aligned to label semantics.
+- td_count (int): Legacy alias for the primary td_count.
 - passing_td (int): Number of passing TDs (for QBs)
 - receiving_yards (float): Total receiving yards
 - rushing_yards (float): Total rushing yards
@@ -33,6 +37,7 @@
 from utils.collect.nfl_schedules import get_schedule
 from utils.feature.asof import decision_cutoff_hours_default, fallback_cutoff_hours, get_decision_cutoff_hours, get_fallback_cutoff_hours
 from utils.feature.player_drive_level import _load_play_level_data
+from utils.feature.labels import DEFAULT_LABEL_VERSION, compute_td_labels
 from utils.train.injury_availability import (
     load_latest_artifact,
     predict_probabilities as predict_injury_probabilities,
@@ -1582,7 +1587,12 @@
     if flag_cols:
         df = df.with_columns([pl.col(col).cast(pl.Int8) for col in flag_cols])
     return df
-def build_player_game_level(*, start_date: date, end_date: date) -> None:
+def build_player_game_level(
+    *,
+    start_date: date,
+    end_date: date,
+    label_version: str | None = None,
+) -> None:
     """Aggregate play-level data to player-game level.
     
     Creates one row per (player, game) with accumulated stats.
@@ -1680,7 +1690,7 @@
     
     # Merge rows where same player had multiple roles in same game
     # (e.g., QB who also rushed, WR who also rushed)
-    df_merged = _merge_multi_role_players(df_all)
+    df_merged = _merge_multi_role_players(df_all, label_version=label_version or DEFAULT_LABEL_VERSION)
 
     df_merged = _append_zero_usage_players(df_merged, seasons_in_window)
     
@@ -3368,7 +3378,7 @@
     )
 
 
-def _merge_multi_role_players(df: pl.DataFrame) -> pl.DataFrame:
+def _merge_multi_role_players(df: pl.DataFrame, *, label_version: str | None = None) -> pl.DataFrame:
     """Merge stats for players who had multiple roles in same game.
     
     Example: QB who passed and rushed, WR who received and rushed.
@@ -3422,8 +3432,6 @@
         if col in merged.columns:
             merged = merged.with_columns(pl.col(col).fill_null(0))
 
-    # Fallback touchdown logic: if generic touchdown attribution is missing,
-    # derive it from rushing + receiving touchdowns.
     merged = merged.with_columns([
         pl.col("touchdowns").fill_null(0).alias("touchdowns"),
         pl.col("rushing_td_count").fill_null(0).alias("rushing_td_count"),
@@ -3435,17 +3443,5 @@
         pl.col("goal_to_go_carry").fill_null(0).alias("goal_to_go_carry"),
     ])
 
-    merged = merged.with_columns([
-        pl.when(pl.col("touchdowns") > 0)
-        .then(pl.col("touchdowns"))
-        .otherwise(pl.col("rushing_td_count") + pl.col("receiving_td_count"))
-        .cast(pl.Int64)
-        .alias("_total_touchdowns")
-    ])
-
-    merged = merged.with_columns([
-        (pl.col("_total_touchdowns") > 0).cast(pl.Int8).alias("anytime_td"),
-        pl.col("_total_touchdowns").alias("td_count"),
-    ]).drop("_total_touchdowns")
-    
+    merged = compute_td_labels(merged, version=label_version)
     return merged


thinking
**Improving logging for label rates**
file update
M /Users/jameswest/Desktop/nfl_predict/pipeline/feature.py
@@ -953,7 +953,15 @@
     
-    # Log target distribution for anytime_td
-    if "anytime_td" in df_player_game_all.columns:
-        td_count = df_player_game_all["anytime_td"].sum()
-        td_rate = td_count / len(df_player_game_all) * 100
-        logging.info("    Anytime TD rate: %.2f%% (%d/%d)", td_rate, td_count, len(df_player_game_all))
+    spec = get_label_spec(label_version)
+    label_candidates = {spec.primary, "anytime_td"}
+    for label_col in label_candidates:
+        if label_col in df_player_game_all.columns:
+            td_count = df_player_game_all[label_col].sum()
+            td_rate = td_count / len(df_player_game_all) * 100
+            logging.info(
+                "    Label %s rate: %.2f%% (%d/%d)",
+                label_col,
+                td_rate,
+                td_count,
+                len(df_player_game_all),
+            )
     
apply_patch(auto_approved=true) exited 0 in 53ms:
Success. Updated the following files:
M pipeline/feature.py
file update:
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 6c47a91d08f9d309f94323efd4708bb992dc4ce0..5ba68e8bf1acd3a789a76a8857674e6f6433017b
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -26,6 +26,7 @@
 from utils.feature.player_drive_level import build_player_drive_level
 from utils.feature.player_game_level import build_player_game_level
 from utils.feature.opponent_splits import build_opponent_splits
+from utils.feature.labels import DEFAULT_LABEL_VERSION, get_label_spec
 from utils.feature.targets import validate_target_columns
 from utils.feature.daily_totals import build_daily_cache_range
 from utils.feature.rolling_window import add_rolling_features
@@ -233,6 +234,7 @@
     output_path: Path | None = None,
     primary_output_path: Path | None = None,
     cutoff_label: str | None = None,
+    label_version: str | None = None,
 ) -> pl.DataFrame:
     """Run full feature pipeline up to *inclusive* `end_date` for a single cutoff window.
 
@@ -248,6 +250,7 @@
     primary_output = primary_output_path or target_output_path
     current_cutoff_hours = float(get_decision_cutoff_hours())
     clean_min_date, clean_max_date = (None, None)
+    label_version = label_version or DEFAULT_LABEL_VERSION
     if start_date is None or end_date is None:
         clean_min_date, clean_max_date = _get_clean_date_bounds()
 
@@ -294,7 +297,7 @@
             build_player_drive_level(start_date=cur, end_date=chunk_end)
             
             # 5. Player-game aggregations (for rolling window features)
-            build_player_game_level(start_date=cur, end_date=chunk_end)
+            build_player_game_level(start_date=cur, end_date=chunk_end, label_version=label_version)
 
             # advance to next slice
             cur += timedelta(days=chunk_days)
@@ -948,11 +951,19 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    # Log target distribution for anytime_td
-    if "anytime_td" in df_player_game_all.columns:
-        td_count = df_player_game_all["anytime_td"].sum()
-        td_rate = td_count / len(df_player_game_all) * 100
-        logging.info("    Anytime TD rate: %.2f%% (%d/%d)", td_rate, td_count, len(df_player_game_all))
+    spec = get_label_spec(label_version)
+    label_candidates = {spec.primary, "anytime_td"}
+    for label_col in label_candidates:
+        if label_col in df_player_game_all.columns:
+            td_count = df_player_game_all[label_col].sum()
+            td_rate = td_count / len(df_player_game_all) * 100
+            logging.info(
+                "    Label %s rate: %.2f%% (%d/%d)",
+                label_col,
+                td_rate,
+                td_count,
+                len(df_player_game_all),
+            )
     
     return df_player_game_all
 
@@ -965,6 +976,7 @@
     recompute_intermediate: bool = True,
     build_rolling: bool = True,
     cutoff_hours_list: Sequence[float] | None = None,
+    label_version: str | None = None,
 ) -> pl.DataFrame:
     """Build feature matrices for one or more decision cutoff horizons.
 
@@ -992,6 +1004,7 @@
                 output_path=output_path,
                 primary_output_path=primary_output,
                 cutoff_label=label,
+                label_version=label_version,
             )
         if idx == 0:
             primary_result = df
diff --git a/utils/feature/labels.py b/utils/feature/labels.py
new file mode 100644
index 0000000000000000000000000000000000000000..b34571f04254cd7bceb9363a190ee7d305852bd5
--- /dev/null
+++ b/utils/feature/labels.py
@@ -0,0 +1,169 @@
+"""Label semantics and versioning for NFL player-level targets.
+
+This module centralizes anytime-TD label definitions so that:
+- Semantics are explicit and versioned.
+- Training can request a specific label column per problem.
+- Feature generation can emit multiple label variants for analysis.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass, field
+from typing import Dict, Iterable, Mapping
+
+import polars as pl
+
+
+@dataclass(frozen=True)
+class LabelRules:
+    """Rules controlling which TD components count toward a label."""
+
+    include_rush: bool = True
+    include_rec: bool = True
+    include_pass_thrown: bool = True  # credit passers for thrown TDs
+    include_other: bool = False  # fumble returns, defensive/special teams if present
+
+
+@dataclass(frozen=True)
+class LabelSpec:
+    """Container describing a label version."""
+
+    name: str
+    primary: str
+    labels: Mapping[str, LabelRules]
+    aliases: Mapping[str, str] = field(default_factory=dict)
+
+    @property
+    def all_columns(self) -> set[str]:
+        cols = set(self.labels.keys())
+        cols.update(self.aliases.keys())
+        return cols
+
+
+DEFAULT_LABEL_VERSION = "v1_any_offense"
+
+
+LABEL_VERSIONS: Dict[str, LabelSpec] = {
+    "v1_any_offense": LabelSpec(
+        name="v1_any_offense",
+        primary="anytime_td_offense",
+        labels={
+            "anytime_td_offense": LabelRules(include_other=False),
+            "anytime_td_rush": LabelRules(include_rush=True, include_rec=False, include_pass_thrown=False, include_other=False),
+            "anytime_td_rec": LabelRules(include_rush=False, include_rec=True, include_pass_thrown=False, include_other=False),
+            "anytime_td_pass_thrown": LabelRules(include_rush=False, include_rec=False, include_pass_thrown=True, include_other=False),
+            "anytime_td_all": LabelRules(include_other=True),
+        },
+        aliases={
+            # Maintain legacy column name as an alias to the offense-only label.
+            "anytime_td": "anytime_td_offense",
+            # Keep td_count pointing to the offense definition for backward compatibility.
+            "td_count": "td_count_offense",
+        },
+    ),
+    "v1_any_all": LabelSpec(
+        name="v1_any_all",
+        primary="anytime_td_all",
+        labels={
+            "anytime_td_all": LabelRules(include_other=True),
+            "anytime_td_offense": LabelRules(include_other=False),
+            "anytime_td_rush": LabelRules(include_rush=True, include_rec=False, include_pass_thrown=False, include_other=False),
+            "anytime_td_rec": LabelRules(include_rush=False, include_rec=True, include_pass_thrown=False, include_other=False),
+            "anytime_td_pass_thrown": LabelRules(include_rush=False, include_rec=False, include_pass_thrown=True, include_other=False),
+        },
+        aliases={
+            "anytime_td": "anytime_td_all",
+            "td_count": "td_count_all",
+        },
+    ),
+}
+
+
+def get_label_spec(version: str | None) -> LabelSpec:
+    """Return a concrete LabelSpec for the requested version (or default)."""
+
+    version = version or DEFAULT_LABEL_VERSION
+    if version not in LABEL_VERSIONS:
+        raise ValueError(
+            f"Unknown label_version '{version}'. "
+            f"Available: {sorted(LABEL_VERSIONS.keys())}"
+        )
+    return LABEL_VERSIONS[version]
+
+
+def _sum_expr(exprs: Iterable[pl.Expr]) -> pl.Expr:
+    exprs = list(exprs)
+    if not exprs:
+        return pl.lit(0).cast(pl.Int64)
+    acc = exprs[0]
+    for expr in exprs[1:]:
+        acc = acc + expr
+    return acc
+
+
+def compute_td_labels(df: pl.DataFrame, *, version: str | None = None) -> pl.DataFrame:
+    """Compute TD label columns according to a label version.
+
+    Parameters
+    ----------
+    df : pl.DataFrame
+        Player-game frame containing touchdown components.
+    version : str | None
+        Label version identifier. Defaults to DEFAULT_LABEL_VERSION.
+    """
+
+    spec = get_label_spec(version)
+    rush = pl.col("rushing_td_count").fill_null(0).cast(pl.Int64)
+    rec = pl.col("receiving_td_count").fill_null(0).cast(pl.Int64)
+    passing = pl.col("passing_td").fill_null(0).cast(pl.Int64)
+    reported_total = pl.col("touchdowns").fill_null(0).cast(pl.Int64)
+
+    offense_total = _sum_expr([rush, rec, passing]).alias("_td_offense_total")
+    other_total = (reported_total - offense_total).clip_min(0).alias("_td_other_total")
+    all_total = (offense_total + other_total).alias("_td_all_total")
+
+    totals_exprs = [
+        offense_total,
+        other_total,
+        all_total,
+    ]
+
+    label_exprs: list[pl.Expr] = [
+        pl.col("_td_offense_total").alias("td_count_offense"),
+        pl.col("_td_all_total").alias("td_count_all"),
+    ]
+
+    for label_name, rules in spec.labels.items():
+        parts: list[pl.Expr] = []
+        if rules.include_rush:
+            parts.append(rush)
+        if rules.include_rec:
+            parts.append(rec)
+        if rules.include_pass_thrown:
+            parts.append(passing)
+        if rules.include_other:
+            parts.append(pl.col("_td_other_total"))
+        total_expr = _sum_expr(parts)
+        label_exprs.append((total_expr > 0).cast(pl.Int8).alias(label_name))
+
+    # Canonical counts for compatibility
+    if "td_count" not in df.columns:
+        # Fill td_count using the alias mapping; default to offense count.
+        target_alias = spec.aliases.get("td_count") or "td_count_offense"
+        label_exprs.append(pl.col(target_alias).alias("td_count"))
+
+    df = df.with_columns(totals_exprs).with_columns(label_exprs)
+
+    # Resolve aliases (e.g., anytime_td -> anytime_td_offense)
+    if spec.aliases:
+        alias_exprs = []
+        for alias_name, source_name in spec.aliases.items():
+            if source_name in df.columns:
+                alias_exprs.append(pl.col(source_name).alias(alias_name))
+        if alias_exprs:
+            df = df.with_columns(alias_exprs)
+
+    drop_cols = [col for col in ("_td_offense_total", "_td_other_total", "_td_all_total") if col in df.columns]
+    if drop_cols:
+        df = df.drop(drop_cols)
+    return df
diff --git a/utils/feature/player_game_level.py b/utils/feature/player_game_level.py
index b6fe516c5f03d575038eef554d5ab39ea5d5c90d..dd4f1f7fcc9de4d8c63390f0a160005eeae48e2f
--- a/utils/feature/player_game_level.py
+++ b/utils/feature/player_game_level.py
@@ -4,8 +4,12 @@
 Each player gets one row per game with their total stats.
 
 Target columns created:
-- anytime_td (binary): Did player score a TD (receiving or rushing)?
-- td_count (int): Number of TDs scored (receiving + rushing)
+- anytime_td_offense (binary): Did player score an offensive TD (rush/rec/pass thrown)?
+- anytime_td_all (binary): Did player score any TD (including defensive/special teams if present)?
+- anytime_td_rush / anytime_td_rec / anytime_td_pass_thrown: Type-specific TD flags.
+- anytime_td (binary): Legacy alias → current label version primary.
+- td_count_offense / td_count_all: TD counts aligned to label semantics.
+- td_count (int): Legacy alias for the primary td_count.
 - passing_td (int): Number of passing TDs (for QBs)
 - receiving_yards (float): Total receiving yards
 - rushing_yards (float): Total rushing yards
@@ -33,6 +37,7 @@
 from utils.collect.nfl_schedules import get_schedule
 from utils.feature.asof import decision_cutoff_hours_default, fallback_cutoff_hours, get_decision_cutoff_hours, get_fallback_cutoff_hours
 from utils.feature.player_drive_level import _load_play_level_data
+from utils.feature.labels import DEFAULT_LABEL_VERSION, compute_td_labels
 from utils.train.injury_availability import (
     load_latest_artifact,
     predict_probabilities as predict_injury_probabilities,
@@ -1582,7 +1587,12 @@
     if flag_cols:
         df = df.with_columns([pl.col(col).cast(pl.Int8) for col in flag_cols])
     return df
-def build_player_game_level(*, start_date: date, end_date: date) -> None:
+def build_player_game_level(
+    *,
+    start_date: date,
+    end_date: date,
+    label_version: str | None = None,
+) -> None:
     """Aggregate play-level data to player-game level.
     
     Creates one row per (player, game) with accumulated stats.
@@ -1680,7 +1690,7 @@
     
     # Merge rows where same player had multiple roles in same game
     # (e.g., QB who also rushed, WR who also rushed)
-    df_merged = _merge_multi_role_players(df_all)
+    df_merged = _merge_multi_role_players(df_all, label_version=label_version or DEFAULT_LABEL_VERSION)
 
     df_merged = _append_zero_usage_players(df_merged, seasons_in_window)
     
@@ -3368,7 +3378,7 @@
     )
 
 
-def _merge_multi_role_players(df: pl.DataFrame) -> pl.DataFrame:
+def _merge_multi_role_players(df: pl.DataFrame, *, label_version: str | None = None) -> pl.DataFrame:
     """Merge stats for players who had multiple roles in same game.
     
     Example: QB who passed and rushed, WR who received and rushed.
@@ -3422,8 +3432,6 @@
         if col in merged.columns:
             merged = merged.with_columns(pl.col(col).fill_null(0))
 
-    # Fallback touchdown logic: if generic touchdown attribution is missing,
-    # derive it from rushing + receiving touchdowns.
     merged = merged.with_columns([
         pl.col("touchdowns").fill_null(0).alias("touchdowns"),
         pl.col("rushing_td_count").fill_null(0).alias("rushing_td_count"),
@@ -3435,17 +3443,5 @@
         pl.col("goal_to_go_carry").fill_null(0).alias("goal_to_go_carry"),
     ])
 
-    merged = merged.with_columns([
-        pl.when(pl.col("touchdowns") > 0)
-        .then(pl.col("touchdowns"))
-        .otherwise(pl.col("rushing_td_count") + pl.col("receiving_td_count"))
-        .cast(pl.Int64)
-        .alias("_total_touchdowns")
-    ])
-
-    merged = merged.with_columns([
-        (pl.col("_total_touchdowns") > 0).cast(pl.Int8).alias("anytime_td"),
-        pl.col("_total_touchdowns").alias("td_count"),
-    ]).drop("_total_touchdowns")
-    
+    merged = compute_td_labels(merged, version=label_version)
     return merged

file update:
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 6c47a91d08f9d309f94323efd4708bb992dc4ce0..5ba68e8bf1acd3a789a76a8857674e6f6433017b
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -26,6 +26,7 @@
 from utils.feature.player_drive_level import build_player_drive_level
 from utils.feature.player_game_level import build_player_game_level
 from utils.feature.opponent_splits import build_opponent_splits
+from utils.feature.labels import DEFAULT_LABEL_VERSION, get_label_spec
 from utils.feature.targets import validate_target_columns
 from utils.feature.daily_totals import build_daily_cache_range
 from utils.feature.rolling_window import add_rolling_features
@@ -233,6 +234,7 @@
     output_path: Path | None = None,
     primary_output_path: Path | None = None,
     cutoff_label: str | None = None,
+    label_version: str | None = None,
 ) -> pl.DataFrame:
     """Run full feature pipeline up to *inclusive* `end_date` for a single cutoff window.
 
@@ -248,6 +250,7 @@
     primary_output = primary_output_path or target_output_path
     current_cutoff_hours = float(get_decision_cutoff_hours())
     clean_min_date, clean_max_date = (None, None)
+    label_version = label_version or DEFAULT_LABEL_VERSION
     if start_date is None or end_date is None:
         clean_min_date, clean_max_date = _get_clean_date_bounds()
 
@@ -294,7 +297,7 @@
             build_player_drive_level(start_date=cur, end_date=chunk_end)
             
             # 5. Player-game aggregations (for rolling window features)
-            build_player_game_level(start_date=cur, end_date=chunk_end)
+            build_player_game_level(start_date=cur, end_date=chunk_end, label_version=label_version)
 
             # advance to next slice
             cur += timedelta(days=chunk_days)
@@ -948,11 +951,19 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    # Log target distribution for anytime_td
-    if "anytime_td" in df_player_game_all.columns:
-        td_count = df_player_game_all["anytime_td"].sum()
-        td_rate = td_count / len(df_player_game_all) * 100
-        logging.info("    Anytime TD rate: %.2f%% (%d/%d)", td_rate, td_count, len(df_player_game_all))
+    spec = get_label_spec(label_version)
+    label_candidates = {spec.primary, "anytime_td"}
+    for label_col in label_candidates:
+        if label_col in df_player_game_all.columns:
+            td_count = df_player_game_all[label_col].sum()
+            td_rate = td_count / len(df_player_game_all) * 100
+            logging.info(
+                "    Label %s rate: %.2f%% (%d/%d)",
+                label_col,
+                td_rate,
+                td_count,
+                len(df_player_game_all),
+            )
     
     return df_player_game_all
 
@@ -965,6 +976,7 @@
     recompute_intermediate: bool = True,
     build_rolling: bool = True,
     cutoff_hours_list: Sequence[float] | None = None,
+    label_version: str | None = None,
 ) -> pl.DataFrame:
     """Build feature matrices for one or more decision cutoff horizons.
 
@@ -992,6 +1004,7 @@
                 output_path=output_path,
                 primary_output_path=primary_output,
                 cutoff_label=label,
+                label_version=label_version,
             )
         if idx == 0:
             primary_result = df
diff --git a/utils/feature/labels.py b/utils/feature/labels.py
new file mode 100644
index 0000000000000000000000000000000000000000..b34571f04254cd7bceb9363a190ee7d305852bd5
--- /dev/null
+++ b/utils/feature/labels.py
@@ -0,0 +1,169 @@
+"""Label semantics and versioning for NFL player-level targets.
+
+This module centralizes anytime-TD label definitions so that:
+- Semantics are explicit and versioned.
+- Training can request a specific label column per problem.
+- Feature generation can emit multiple label variants for analysis.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass, field
+from typing import Dict, Iterable, Mapping
+
+import polars as pl
+
+
+@dataclass(frozen=True)
+class LabelRules:
+    """Rules controlling which TD components count toward a label."""
+
+    include_rush: bool = True
+    include_rec: bool = True
+    include_pass_thrown: bool = True  # credit passers for thrown TDs
+    include_other: bool = False  # fumble returns, defensive/special teams if present
+
+
+@dataclass(frozen=True)
+class LabelSpec:
+    """Container describing a label version."""
+
+    name: str
+    primary: str
+    labels: Mapping[str, LabelRules]
+    aliases: Mapping[str, str] = field(default_factory=dict)
+
+    @property
+    def all_columns(self) -> set[str]:
+        cols = set(self.labels.keys())
+        cols.update(self.aliases.keys())
+        return cols
+
+
+DEFAULT_LABEL_VERSION = "v1_any_offense"
+
+
+LABEL_VERSIONS: Dict[str, LabelSpec] = {
+    "v1_any_offense": LabelSpec(
+        name="v1_any_offense",
+        primary="anytime_td_offense",
+        labels={
+            "anytime_td_offense": LabelRules(include_other=False),
+            "anytime_td_rush": LabelRules(include_rush=True, include_rec=False, include_pass_thrown=False, include_other=False),
+            "anytime_td_rec": LabelRules(include_rush=False, include_rec=True, include_pass_thrown=False, include_other=False),
+            "anytime_td_pass_thrown": LabelRules(include_rush=False, include_rec=False, include_pass_thrown=True, include_other=False),
+            "anytime_td_all": LabelRules(include_other=True),
+        },
+        aliases={
+            # Maintain legacy column name as an alias to the offense-only label.
+            "anytime_td": "anytime_td_offense",
+            # Keep td_count pointing to the offense definition for backward compatibility.
+            "td_count": "td_count_offense",
+        },
+    ),
+    "v1_any_all": LabelSpec(
+        name="v1_any_all",
+        primary="anytime_td_all",
+        labels={
+            "anytime_td_all": LabelRules(include_other=True),
+            "anytime_td_offense": LabelRules(include_other=False),
+            "anytime_td_rush": LabelRules(include_rush=True, include_rec=False, include_pass_thrown=False, include_other=False),
+            "anytime_td_rec": LabelRules(include_rush=False, include_rec=True, include_pass_thrown=False, include_other=False),
+            "anytime_td_pass_thrown": LabelRules(include_rush=False, include_rec=False, include_pass_thrown=True, include_other=False),
+        },
+        aliases={
+            "anytime_td": "anytime_td_all",
+            "td_count": "td_count_all",
+        },
+    ),
+}
+
+
+def get_label_spec(version: str | None) -> LabelSpec:
+    """Return a concrete LabelSpec for the requested version (or default)."""
+
+    version = version or DEFAULT_LABEL_VERSION
+    if version not in LABEL_VERSIONS:
+        raise ValueError(
+            f"Unknown label_version '{version}'. "
+            f"Available: {sorted(LABEL_VERSIONS.keys())}"
+        )
+    return LABEL_VERSIONS[version]
+
+
+def _sum_expr(exprs: Iterable[pl.Expr]) -> pl.Expr:
+    exprs = list(exprs)
+    if not exprs:
+        return pl.lit(0).cast(pl.Int64)
+    acc = exprs[0]
+    for expr in exprs[1:]:
+        acc = acc + expr
+    return acc
+
+
+def compute_td_labels(df: pl.DataFrame, *, version: str | None = None) -> pl.DataFrame:
+    """Compute TD label columns according to a label version.
+
+    Parameters
+    ----------
+    df : pl.DataFrame
+        Player-game frame containing touchdown components.
+    version : str | None
+        Label version identifier. Defaults to DEFAULT_LABEL_VERSION.
+    """
+
+    spec = get_label_spec(version)
+    rush = pl.col("rushing_td_count").fill_null(0).cast(pl.Int64)
+    rec = pl.col("receiving_td_count").fill_null(0).cast(pl.Int64)
+    passing = pl.col("passing_td").fill_null(0).cast(pl.Int64)
+    reported_total = pl.col("touchdowns").fill_null(0).cast(pl.Int64)
+
+    offense_total = _sum_expr([rush, rec, passing]).alias("_td_offense_total")
+    other_total = (reported_total - offense_total).clip_min(0).alias("_td_other_total")
+    all_total = (offense_total + other_total).alias("_td_all_total")
+
+    totals_exprs = [
+        offense_total,
+        other_total,
+        all_total,
+    ]
+
+    label_exprs: list[pl.Expr] = [
+        pl.col("_td_offense_total").alias("td_count_offense"),
+        pl.col("_td_all_total").alias("td_count_all"),
+    ]
+
+    for label_name, rules in spec.labels.items():
+        parts: list[pl.Expr] = []
+        if rules.include_rush:
+            parts.append(rush)
+        if rules.include_rec:
+            parts.append(rec)
+        if rules.include_pass_thrown:
+            parts.append(passing)
+        if rules.include_other:
+            parts.append(pl.col("_td_other_total"))
+        total_expr = _sum_expr(parts)
+        label_exprs.append((total_expr > 0).cast(pl.Int8).alias(label_name))
+
+    # Canonical counts for compatibility
+    if "td_count" not in df.columns:
+        # Fill td_count using the alias mapping; default to offense count.
+        target_alias = spec.aliases.get("td_count") or "td_count_offense"
+        label_exprs.append(pl.col(target_alias).alias("td_count"))
+
+    df = df.with_columns(totals_exprs).with_columns(label_exprs)
+
+    # Resolve aliases (e.g., anytime_td -> anytime_td_offense)
+    if spec.aliases:
+        alias_exprs = []
+        for alias_name, source_name in spec.aliases.items():
+            if source_name in df.columns:
+                alias_exprs.append(pl.col(source_name).alias(alias_name))
+        if alias_exprs:
+            df = df.with_columns(alias_exprs)
+
+    drop_cols = [col for col in ("_td_offense_total", "_td_other_total", "_td_all_total") if col in df.columns]
+    if drop_cols:
+        df = df.drop(drop_cols)
+    return df
diff --git a/utils/feature/player_game_level.py b/utils/feature/player_game_level.py
index b6fe516c5f03d575038eef554d5ab39ea5d5c90d..dd4f1f7fcc9de4d8c63390f0a160005eeae48e2f
--- a/utils/feature/player_game_level.py
+++ b/utils/feature/player_game_level.py
@@ -4,8 +4,12 @@
 Each player gets one row per game with their total stats.
 
 Target columns created:
-- anytime_td (binary): Did player score a TD (receiving or rushing)?
-- td_count (int): Number of TDs scored (receiving + rushing)
+- anytime_td_offense (binary): Did player score an offensive TD (rush/rec/pass thrown)?
+- anytime_td_all (binary): Did player score any TD (including defensive/special teams if present)?
+- anytime_td_rush / anytime_td_rec / anytime_td_pass_thrown: Type-specific TD flags.
+- anytime_td (binary): Legacy alias → current label version primary.
+- td_count_offense / td_count_all: TD counts aligned to label semantics.
+- td_count (int): Legacy alias for the primary td_count.
 - passing_td (int): Number of passing TDs (for QBs)
 - receiving_yards (float): Total receiving yards
 - rushing_yards (float): Total rushing yards
@@ -33,6 +37,7 @@
 from utils.collect.nfl_schedules import get_schedule
 from utils.feature.asof import decision_cutoff_hours_default, fallback_cutoff_hours, get_decision_cutoff_hours, get_fallback_cutoff_hours
 from utils.feature.player_drive_level import _load_play_level_data
+from utils.feature.labels import DEFAULT_LABEL_VERSION, compute_td_labels
 from utils.train.injury_availability import (
     load_latest_artifact,
     predict_probabilities as predict_injury_probabilities,
@@ -1582,7 +1587,12 @@
     if flag_cols:
         df = df.with_columns([pl.col(col).cast(pl.Int8) for col in flag_cols])
     return df
-def build_player_game_level(*, start_date: date, end_date: date) -> None:
+def build_player_game_level(
+    *,
+    start_date: date,
+    end_date: date,
+    label_version: str | None = None,
+) -> None:
     """Aggregate play-level data to player-game level.
     
     Creates one row per (player, game) with accumulated stats.
@@ -1680,7 +1690,7 @@
     
     # Merge rows where same player had multiple roles in same game
     # (e.g., QB who also rushed, WR who also rushed)
-    df_merged = _merge_multi_role_players(df_all)
+    df_merged = _merge_multi_role_players(df_all, label_version=label_version or DEFAULT_LABEL_VERSION)
 
     df_merged = _append_zero_usage_players(df_merged, seasons_in_window)
     
@@ -3368,7 +3378,7 @@
     )
 
 
-def _merge_multi_role_players(df: pl.DataFrame) -> pl.DataFrame:
+def _merge_multi_role_players(df: pl.DataFrame, *, label_version: str | None = None) -> pl.DataFrame:
     """Merge stats for players who had multiple roles in same game.
     
     Example: QB who passed and rushed, WR who received and rushed.
@@ -3422,8 +3432,6 @@
         if col in merged.columns:
             merged = merged.with_columns(pl.col(col).fill_null(0))
 
-    # Fallback touchdown logic: if generic touchdown attribution is missing,
-    # derive it from rushing + receiving touchdowns.
     merged = merged.with_columns([
         pl.col("touchdowns").fill_null(0).alias("touchdowns"),
         pl.col("rushing_td_count").fill_null(0).alias("rushing_td_count"),
@@ -3435,17 +3443,5 @@
         pl.col("goal_to_go_carry").fill_null(0).alias("goal_to_go_carry"),
     ])
 
-    merged = merged.with_columns([
-        pl.when(pl.col("touchdowns") > 0)
-        .then(pl.col("touchdowns"))
-        .otherwise(pl.col("rushing_td_count") + pl.col("receiving_td_count"))
-        .cast(pl.Int64)
-        .alias("_total_touchdowns")
-    ])
-
-    merged = merged.with_columns([
-        (pl.col("_total_touchdowns") > 0).cast(pl.Int8).alias("anytime_td"),
-        pl.col("_total_touchdowns").alias("td_count"),
-    ]).drop("_total_touchdowns")
-    
+    merged = compute_td_labels(merged, version=label_version)
     return merged


thinking
**Planning updates to target schema and validation**

thinking
**Verifying null_count usage in Polars**
file update
M /Users/jameswest/Desktop/nfl_predict/utils/feature/targets.py
@@ -9,2 +9,4 @@
 
+from utils.feature.labels import DEFAULT_LABEL_VERSION, get_label_spec
+
 logger = logging.getLogger(__name__)
@@ -16,2 +18,7 @@
     "anytime_td": pl.Int8,  # Primary MVP target: did player score a TD?
+    "anytime_td_offense": pl.Int8,
+    "anytime_td_all": pl.Int8,
+    "anytime_td_rush": pl.Int8,
+    "anytime_td_rec": pl.Int8,
+    "anytime_td_pass_thrown": pl.Int8,
     
@@ -19,2 +26,4 @@
     "td_count": pl.Int64,  # Number of TDs scored (receiving + rushing)
+    "td_count_offense": pl.Int64,
+    "td_count_all": pl.Int64,
     "passing_td": pl.Int64,  # Number of passing TDs (QB only)
@@ -105,2 +114,38 @@
     """
-    return validate_target_columns(df, strict=False)
\ No newline at end of file
+    return validate_target_columns(df, strict=False)
+
+
+def require_target_column(
+    df: pl.DataFrame,
+    target_col: str,
+    *,
+    label_version: str | None = None,
+    min_non_null: int = 1,
+) -> pl.DataFrame:
+    """Ensure the configured target column exists and is populated.
+
+    Raises a ValueError if the column is missing or entirely null.
+    """
+
+    if target_col not in df.columns:
+        alias_hint = ""
+        if label_version:
+            try:
+                spec = get_label_spec(label_version or DEFAULT_LABEL_VERSION)
+                if target_col in spec.aliases:
+                    alias_hint = f" Target maps to '{spec.aliases[target_col]}' under {spec.name}."
+            except Exception:
+                alias_hint = ""
+        raise ValueError(f"Target column '{target_col}' not found in feature frame.{alias_hint}")
+
+    series = df[target_col]
+    non_null = series.drop_nulls().height
+    if non_null < min_non_null:
+        raise ValueError(
+            f"Target column '{target_col}' has insufficient non-null rows "
+            f"({non_null}/{len(series)})."
+        )
+    nulls = len(series) - non_null
+    if nulls > 0:
+        logger.warning("Target %s contains %d null rows; they will be dropped.", target_col, nulls)
+    return df
apply_patch(auto_approved=true) exited 0 in 71ms:
Success. Updated the following files:
M utils/feature/targets.py
file update:
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 6c47a91d08f9d309f94323efd4708bb992dc4ce0..5ba68e8bf1acd3a789a76a8857674e6f6433017b
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -26,6 +26,7 @@
 from utils.feature.player_drive_level import build_player_drive_level
 from utils.feature.player_game_level import build_player_game_level
 from utils.feature.opponent_splits import build_opponent_splits
+from utils.feature.labels import DEFAULT_LABEL_VERSION, get_label_spec
 from utils.feature.targets import validate_target_columns
 from utils.feature.daily_totals import build_daily_cache_range
 from utils.feature.rolling_window import add_rolling_features
@@ -233,6 +234,7 @@
     output_path: Path | None = None,
     primary_output_path: Path | None = None,
     cutoff_label: str | None = None,
+    label_version: str | None = None,
 ) -> pl.DataFrame:
     """Run full feature pipeline up to *inclusive* `end_date` for a single cutoff window.
 
@@ -248,6 +250,7 @@
     primary_output = primary_output_path or target_output_path
     current_cutoff_hours = float(get_decision_cutoff_hours())
     clean_min_date, clean_max_date = (None, None)
+    label_version = label_version or DEFAULT_LABEL_VERSION
     if start_date is None or end_date is None:
         clean_min_date, clean_max_date = _get_clean_date_bounds()
 
@@ -294,7 +297,7 @@
             build_player_drive_level(start_date=cur, end_date=chunk_end)
             
             # 5. Player-game aggregations (for rolling window features)
-            build_player_game_level(start_date=cur, end_date=chunk_end)
+            build_player_game_level(start_date=cur, end_date=chunk_end, label_version=label_version)
 
             # advance to next slice
             cur += timedelta(days=chunk_days)
@@ -948,11 +951,19 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    # Log target distribution for anytime_td
-    if "anytime_td" in df_player_game_all.columns:
-        td_count = df_player_game_all["anytime_td"].sum()
-        td_rate = td_count / len(df_player_game_all) * 100
-        logging.info("    Anytime TD rate: %.2f%% (%d/%d)", td_rate, td_count, len(df_player_game_all))
+    spec = get_label_spec(label_version)
+    label_candidates = {spec.primary, "anytime_td"}
+    for label_col in label_candidates:
+        if label_col in df_player_game_all.columns:
+            td_count = df_player_game_all[label_col].sum()
+            td_rate = td_count / len(df_player_game_all) * 100
+            logging.info(
+                "    Label %s rate: %.2f%% (%d/%d)",
+                label_col,
+                td_rate,
+                td_count,
+                len(df_player_game_all),
+            )
     
     return df_player_game_all
 
@@ -965,6 +976,7 @@
     recompute_intermediate: bool = True,
     build_rolling: bool = True,
     cutoff_hours_list: Sequence[float] | None = None,
+    label_version: str | None = None,
 ) -> pl.DataFrame:
     """Build feature matrices for one or more decision cutoff horizons.
 
@@ -992,6 +1004,7 @@
                 output_path=output_path,
                 primary_output_path=primary_output,
                 cutoff_label=label,
+                label_version=label_version,
             )
         if idx == 0:
             primary_result = df
diff --git a/utils/feature/labels.py b/utils/feature/labels.py
new file mode 100644
index 0000000000000000000000000000000000000000..b34571f04254cd7bceb9363a190ee7d305852bd5
--- /dev/null
+++ b/utils/feature/labels.py
@@ -0,0 +1,169 @@
+"""Label semantics and versioning for NFL player-level targets.
+
+This module centralizes anytime-TD label definitions so that:
+- Semantics are explicit and versioned.
+- Training can request a specific label column per problem.
+- Feature generation can emit multiple label variants for analysis.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass, field
+from typing import Dict, Iterable, Mapping
+
+import polars as pl
+
+
+@dataclass(frozen=True)
+class LabelRules:
+    """Rules controlling which TD components count toward a label."""
+
+    include_rush: bool = True
+    include_rec: bool = True
+    include_pass_thrown: bool = True  # credit passers for thrown TDs
+    include_other: bool = False  # fumble returns, defensive/special teams if present
+
+
+@dataclass(frozen=True)
+class LabelSpec:
+    """Container describing a label version."""
+
+    name: str
+    primary: str
+    labels: Mapping[str, LabelRules]
+    aliases: Mapping[str, str] = field(default_factory=dict)
+
+    @property
+    def all_columns(self) -> set[str]:
+        cols = set(self.labels.keys())
+        cols.update(self.aliases.keys())
+        return cols
+
+
+DEFAULT_LABEL_VERSION = "v1_any_offense"
+
+
+LABEL_VERSIONS: Dict[str, LabelSpec] = {
+    "v1_any_offense": LabelSpec(
+        name="v1_any_offense",
+        primary="anytime_td_offense",
+        labels={
+            "anytime_td_offense": LabelRules(include_other=False),
+            "anytime_td_rush": LabelRules(include_rush=True, include_rec=False, include_pass_thrown=False, include_other=False),
+            "anytime_td_rec": LabelRules(include_rush=False, include_rec=True, include_pass_thrown=False, include_other=False),
+            "anytime_td_pass_thrown": LabelRules(include_rush=False, include_rec=False, include_pass_thrown=True, include_other=False),
+            "anytime_td_all": LabelRules(include_other=True),
+        },
+        aliases={
+            # Maintain legacy column name as an alias to the offense-only label.
+            "anytime_td": "anytime_td_offense",
+            # Keep td_count pointing to the offense definition for backward compatibility.
+            "td_count": "td_count_offense",
+        },
+    ),
+    "v1_any_all": LabelSpec(
+        name="v1_any_all",
+        primary="anytime_td_all",
+        labels={
+            "anytime_td_all": LabelRules(include_other=True),
+            "anytime_td_offense": LabelRules(include_other=False),
+            "anytime_td_rush": LabelRules(include_rush=True, include_rec=False, include_pass_thrown=False, include_other=False),
+            "anytime_td_rec": LabelRules(include_rush=False, include_rec=True, include_pass_thrown=False, include_other=False),
+            "anytime_td_pass_thrown": LabelRules(include_rush=False, include_rec=False, include_pass_thrown=True, include_other=False),
+        },
+        aliases={
+            "anytime_td": "anytime_td_all",
+            "td_count": "td_count_all",
+        },
+    ),
+}
+
+
+def get_label_spec(version: str | None) -> LabelSpec:
+    """Return a concrete LabelSpec for the requested version (or default)."""
+
+    version = version or DEFAULT_LABEL_VERSION
+    if version not in LABEL_VERSIONS:
+        raise ValueError(
+            f"Unknown label_version '{version}'. "
+            f"Available: {sorted(LABEL_VERSIONS.keys())}"
+        )
+    return LABEL_VERSIONS[version]
+
+
+def _sum_expr(exprs: Iterable[pl.Expr]) -> pl.Expr:
+    exprs = list(exprs)
+    if not exprs:
+        return pl.lit(0).cast(pl.Int64)
+    acc = exprs[0]
+    for expr in exprs[1:]:
+        acc = acc + expr
+    return acc
+
+
+def compute_td_labels(df: pl.DataFrame, *, version: str | None = None) -> pl.DataFrame:
+    """Compute TD label columns according to a label version.
+
+    Parameters
+    ----------
+    df : pl.DataFrame
+        Player-game frame containing touchdown components.
+    version : str | None
+        Label version identifier. Defaults to DEFAULT_LABEL_VERSION.
+    """
+
+    spec = get_label_spec(version)
+    rush = pl.col("rushing_td_count").fill_null(0).cast(pl.Int64)
+    rec = pl.col("receiving_td_count").fill_null(0).cast(pl.Int64)
+    passing = pl.col("passing_td").fill_null(0).cast(pl.Int64)
+    reported_total = pl.col("touchdowns").fill_null(0).cast(pl.Int64)
+
+    offense_total = _sum_expr([rush, rec, passing]).alias("_td_offense_total")
+    other_total = (reported_total - offense_total).clip_min(0).alias("_td_other_total")
+    all_total = (offense_total + other_total).alias("_td_all_total")
+
+    totals_exprs = [
+        offense_total,
+        other_total,
+        all_total,
+    ]
+
+    label_exprs: list[pl.Expr] = [
+        pl.col("_td_offense_total").alias("td_count_offense"),
+        pl.col("_td_all_total").alias("td_count_all"),
+    ]
+
+    for label_name, rules in spec.labels.items():
+        parts: list[pl.Expr] = []
+        if rules.include_rush:
+            parts.append(rush)
+        if rules.include_rec:
+            parts.append(rec)
+        if rules.include_pass_thrown:
+            parts.append(passing)
+        if rules.include_other:
+            parts.append(pl.col("_td_other_total"))
+        total_expr = _sum_expr(parts)
+        label_exprs.append((total_expr > 0).cast(pl.Int8).alias(label_name))
+
+    # Canonical counts for compatibility
+    if "td_count" not in df.columns:
+        # Fill td_count using the alias mapping; default to offense count.
+        target_alias = spec.aliases.get("td_count") or "td_count_offense"
+        label_exprs.append(pl.col(target_alias).alias("td_count"))
+
+    df = df.with_columns(totals_exprs).with_columns(label_exprs)
+
+    # Resolve aliases (e.g., anytime_td -> anytime_td_offense)
+    if spec.aliases:
+        alias_exprs = []
+        for alias_name, source_name in spec.aliases.items():
+            if source_name in df.columns:
+                alias_exprs.append(pl.col(source_name).alias(alias_name))
+        if alias_exprs:
+            df = df.with_columns(alias_exprs)
+
+    drop_cols = [col for col in ("_td_offense_total", "_td_other_total", "_td_all_total") if col in df.columns]
+    if drop_cols:
+        df = df.drop(drop_cols)
+    return df
diff --git a/utils/feature/player_game_level.py b/utils/feature/player_game_level.py
index b6fe516c5f03d575038eef554d5ab39ea5d5c90d..dd4f1f7fcc9de4d8c63390f0a160005eeae48e2f
--- a/utils/feature/player_game_level.py
+++ b/utils/feature/player_game_level.py
@@ -4,8 +4,12 @@
 Each player gets one row per game with their total stats.
 
 Target columns created:
-- anytime_td (binary): Did player score a TD (receiving or rushing)?
-- td_count (int): Number of TDs scored (receiving + rushing)
+- anytime_td_offense (binary): Did player score an offensive TD (rush/rec/pass thrown)?
+- anytime_td_all (binary): Did player score any TD (including defensive/special teams if present)?
+- anytime_td_rush / anytime_td_rec / anytime_td_pass_thrown: Type-specific TD flags.
+- anytime_td (binary): Legacy alias → current label version primary.
+- td_count_offense / td_count_all: TD counts aligned to label semantics.
+- td_count (int): Legacy alias for the primary td_count.
 - passing_td (int): Number of passing TDs (for QBs)
 - receiving_yards (float): Total receiving yards
 - rushing_yards (float): Total rushing yards
@@ -33,6 +37,7 @@
 from utils.collect.nfl_schedules import get_schedule
 from utils.feature.asof import decision_cutoff_hours_default, fallback_cutoff_hours, get_decision_cutoff_hours, get_fallback_cutoff_hours
 from utils.feature.player_drive_level import _load_play_level_data
+from utils.feature.labels import DEFAULT_LABEL_VERSION, compute_td_labels
 from utils.train.injury_availability import (
     load_latest_artifact,
     predict_probabilities as predict_injury_probabilities,
@@ -1582,7 +1587,12 @@
     if flag_cols:
         df = df.with_columns([pl.col(col).cast(pl.Int8) for col in flag_cols])
     return df
-def build_player_game_level(*, start_date: date, end_date: date) -> None:
+def build_player_game_level(
+    *,
+    start_date: date,
+    end_date: date,
+    label_version: str | None = None,
+) -> None:
     """Aggregate play-level data to player-game level.
     
     Creates one row per (player, game) with accumulated stats.
@@ -1680,7 +1690,7 @@
     
     # Merge rows where same player had multiple roles in same game
     # (e.g., QB who also rushed, WR who also rushed)
-    df_merged = _merge_multi_role_players(df_all)
+    df_merged = _merge_multi_role_players(df_all, label_version=label_version or DEFAULT_LABEL_VERSION)
 
     df_merged = _append_zero_usage_players(df_merged, seasons_in_window)
     
@@ -3368,7 +3378,7 @@
     )
 
 
-def _merge_multi_role_players(df: pl.DataFrame) -> pl.DataFrame:
+def _merge_multi_role_players(df: pl.DataFrame, *, label_version: str | None = None) -> pl.DataFrame:
     """Merge stats for players who had multiple roles in same game.
     
     Example: QB who passed and rushed, WR who received and rushed.
@@ -3422,8 +3432,6 @@
         if col in merged.columns:
             merged = merged.with_columns(pl.col(col).fill_null(0))
 
-    # Fallback touchdown logic: if generic touchdown attribution is missing,
-    # derive it from rushing + receiving touchdowns.
     merged = merged.with_columns([
         pl.col("touchdowns").fill_null(0).alias("touchdowns"),
         pl.col("rushing_td_count").fill_null(0).alias("rushing_td_count"),
@@ -3435,17 +3443,5 @@
         pl.col("goal_to_go_carry").fill_null(0).alias("goal_to_go_carry"),
     ])
 
-    merged = merged.with_columns([
-        pl.when(pl.col("touchdowns") > 0)
-        .then(pl.col("touchdowns"))
-        .otherwise(pl.col("rushing_td_count") + pl.col("receiving_td_count"))
-        .cast(pl.Int64)
-        .alias("_total_touchdowns")
-    ])
-
-    merged = merged.with_columns([
-        (pl.col("_total_touchdowns") > 0).cast(pl.Int8).alias("anytime_td"),
-        pl.col("_total_touchdowns").alias("td_count"),
-    ]).drop("_total_touchdowns")
-    
+    merged = compute_td_labels(merged, version=label_version)
     return merged
diff --git a/utils/feature/targets.py b/utils/feature/targets.py
index 7738086dcbfda7432b937cc7d8095988cb0edff0..769ee8735c4024c4410ddd674b11112f093624dd
--- a/utils/feature/targets.py
+++ b/utils/feature/targets.py
@@ -7,6 +7,8 @@
 import polars as pl
 import logging
 
+from utils.feature.labels import DEFAULT_LABEL_VERSION, get_label_spec
+
 logger = logging.getLogger(__name__)
 
 
@@ -14,9 +16,16 @@
 NFL_TARGET_SCHEMA = {
     # Binary classification targets
     "anytime_td": pl.Int8,  # Primary MVP target: did player score a TD?
+    "anytime_td_offense": pl.Int8,
+    "anytime_td_all": pl.Int8,
+    "anytime_td_rush": pl.Int8,
+    "anytime_td_rec": pl.Int8,
+    "anytime_td_pass_thrown": pl.Int8,
     
     # Count/regression targets
     "td_count": pl.Int64,  # Number of TDs scored (receiving + rushing)
+    "td_count_offense": pl.Int64,
+    "td_count_all": pl.Int64,
     "passing_td": pl.Int64,  # Number of passing TDs (QB only)
     
     # Yardage regression targets
@@ -103,4 +112,40 @@
     pl.DataFrame
         DataFrame with validated target columns
     """
-    return validate_target_columns(df, strict=False)
\ No newline at end of file
+    return validate_target_columns(df, strict=False)
+
+
+def require_target_column(
+    df: pl.DataFrame,
+    target_col: str,
+    *,
+    label_version: str | None = None,
+    min_non_null: int = 1,
+) -> pl.DataFrame:
+    """Ensure the configured target column exists and is populated.
+
+    Raises a ValueError if the column is missing or entirely null.
+    """
+
+    if target_col not in df.columns:
+        alias_hint = ""
+        if label_version:
+            try:
+                spec = get_label_spec(label_version or DEFAULT_LABEL_VERSION)
+                if target_col in spec.aliases:
+                    alias_hint = f" Target maps to '{spec.aliases[target_col]}' under {spec.name}."
+            except Exception:
+                alias_hint = ""
+        raise ValueError(f"Target column '{target_col}' not found in feature frame.{alias_hint}")
+
+    series = df[target_col]
+    non_null = series.drop_nulls().height
+    if non_null < min_non_null:
+        raise ValueError(
+            f"Target column '{target_col}' has insufficient non-null rows "
+            f"({non_null}/{len(series)})."
+        )
+    nulls = len(series) - non_null
+    if nulls > 0:
+        logger.warning("Target %s contains %d null rows; they will be dropped.", target_col, nulls)
+    return df

file update:
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 6c47a91d08f9d309f94323efd4708bb992dc4ce0..5ba68e8bf1acd3a789a76a8857674e6f6433017b
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -26,6 +26,7 @@
 from utils.feature.player_drive_level import build_player_drive_level
 from utils.feature.player_game_level import build_player_game_level
 from utils.feature.opponent_splits import build_opponent_splits
+from utils.feature.labels import DEFAULT_LABEL_VERSION, get_label_spec
 from utils.feature.targets import validate_target_columns
 from utils.feature.daily_totals import build_daily_cache_range
 from utils.feature.rolling_window import add_rolling_features
@@ -233,6 +234,7 @@
     output_path: Path | None = None,
     primary_output_path: Path | None = None,
     cutoff_label: str | None = None,
+    label_version: str | None = None,
 ) -> pl.DataFrame:
     """Run full feature pipeline up to *inclusive* `end_date` for a single cutoff window.
 
@@ -248,6 +250,7 @@
     primary_output = primary_output_path or target_output_path
     current_cutoff_hours = float(get_decision_cutoff_hours())
     clean_min_date, clean_max_date = (None, None)
+    label_version = label_version or DEFAULT_LABEL_VERSION
     if start_date is None or end_date is None:
         clean_min_date, clean_max_date = _get_clean_date_bounds()
 
@@ -294,7 +297,7 @@
             build_player_drive_level(start_date=cur, end_date=chunk_end)
             
             # 5. Player-game aggregations (for rolling window features)
-            build_player_game_level(start_date=cur, end_date=chunk_end)
+            build_player_game_level(start_date=cur, end_date=chunk_end, label_version=label_version)
 
             # advance to next slice
             cur += timedelta(days=chunk_days)
@@ -948,11 +951,19 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    # Log target distribution for anytime_td
-    if "anytime_td" in df_player_game_all.columns:
-        td_count = df_player_game_all["anytime_td"].sum()
-        td_rate = td_count / len(df_player_game_all) * 100
-        logging.info("    Anytime TD rate: %.2f%% (%d/%d)", td_rate, td_count, len(df_player_game_all))
+    spec = get_label_spec(label_version)
+    label_candidates = {spec.primary, "anytime_td"}
+    for label_col in label_candidates:
+        if label_col in df_player_game_all.columns:
+            td_count = df_player_game_all[label_col].sum()
+            td_rate = td_count / len(df_player_game_all) * 100
+            logging.info(
+                "    Label %s rate: %.2f%% (%d/%d)",
+                label_col,
+                td_rate,
+                td_count,
+                len(df_player_game_all),
+            )
     
     return df_player_game_all
 
@@ -965,6 +976,7 @@
     recompute_intermediate: bool = True,
     build_rolling: bool = True,
     cutoff_hours_list: Sequence[float] | None = None,
+    label_version: str | None = None,
 ) -> pl.DataFrame:
     """Build feature matrices for one or more decision cutoff horizons.
 
@@ -992,6 +1004,7 @@
                 output_path=output_path,
                 primary_output_path=primary_output,
                 cutoff_label=label,
+                label_version=label_version,
             )
         if idx == 0:
             primary_result = df
diff --git a/utils/feature/labels.py b/utils/feature/labels.py
new file mode 100644
index 0000000000000000000000000000000000000000..b34571f04254cd7bceb9363a190ee7d305852bd5
--- /dev/null
+++ b/utils/feature/labels.py
@@ -0,0 +1,169 @@
+"""Label semantics and versioning for NFL player-level targets.
+
+This module centralizes anytime-TD label definitions so that:
+- Semantics are explicit and versioned.
+- Training can request a specific label column per problem.
+- Feature generation can emit multiple label variants for analysis.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass, field
+from typing import Dict, Iterable, Mapping
+
+import polars as pl
+
+
+@dataclass(frozen=True)
+class LabelRules:
+    """Rules controlling which TD components count toward a label."""
+
+    include_rush: bool = True
+    include_rec: bool = True
+    include_pass_thrown: bool = True  # credit passers for thrown TDs
+    include_other: bool = False  # fumble returns, defensive/special teams if present
+
+
+@dataclass(frozen=True)
+class LabelSpec:
+    """Container describing a label version."""
+
+    name: str
+    primary: str
+    labels: Mapping[str, LabelRules]
+    aliases: Mapping[str, str] = field(default_factory=dict)
+
+    @property
+    def all_columns(self) -> set[str]:
+        cols = set(self.labels.keys())
+        cols.update(self.aliases.keys())
+        return cols
+
+
+DEFAULT_LABEL_VERSION = "v1_any_offense"
+
+
+LABEL_VERSIONS: Dict[str, LabelSpec] = {
+    "v1_any_offense": LabelSpec(
+        name="v1_any_offense",
+        primary="anytime_td_offense",
+        labels={
+            "anytime_td_offense": LabelRules(include_other=False),
+            "anytime_td_rush": LabelRules(include_rush=True, include_rec=False, include_pass_thrown=False, include_other=False),
+            "anytime_td_rec": LabelRules(include_rush=False, include_rec=True, include_pass_thrown=False, include_other=False),
+            "anytime_td_pass_thrown": LabelRules(include_rush=False, include_rec=False, include_pass_thrown=True, include_other=False),
+            "anytime_td_all": LabelRules(include_other=True),
+        },
+        aliases={
+            # Maintain legacy column name as an alias to the offense-only label.
+            "anytime_td": "anytime_td_offense",
+            # Keep td_count pointing to the offense definition for backward compatibility.
+            "td_count": "td_count_offense",
+        },
+    ),
+    "v1_any_all": LabelSpec(
+        name="v1_any_all",
+        primary="anytime_td_all",
+        labels={
+            "anytime_td_all": LabelRules(include_other=True),
+            "anytime_td_offense": LabelRules(include_other=False),
+            "anytime_td_rush": LabelRules(include_rush=True, include_rec=False, include_pass_thrown=False, include_other=False),
+            "anytime_td_rec": LabelRules(include_rush=False, include_rec=True, include_pass_thrown=False, include_other=False),
+            "anytime_td_pass_thrown": LabelRules(include_rush=False, include_rec=False, include_pass_thrown=True, include_other=False),
+        },
+        aliases={
+            "anytime_td": "anytime_td_all",
+            "td_count": "td_count_all",
+        },
+    ),
+}
+
+
+def get_label_spec(version: str | None) -> LabelSpec:
+    """Return a concrete LabelSpec for the requested version (or default)."""
+
+    version = version or DEFAULT_LABEL_VERSION
+    if version not in LABEL_VERSIONS:
+        raise ValueError(
+            f"Unknown label_version '{version}'. "
+            f"Available: {sorted(LABEL_VERSIONS.keys())}"
+        )
+    return LABEL_VERSIONS[version]
+
+
+def _sum_expr(exprs: Iterable[pl.Expr]) -> pl.Expr:
+    exprs = list(exprs)
+    if not exprs:
+        return pl.lit(0).cast(pl.Int64)
+    acc = exprs[0]
+    for expr in exprs[1:]:
+        acc = acc + expr
+    return acc
+
+
+def compute_td_labels(df: pl.DataFrame, *, version: str | None = None) -> pl.DataFrame:
+    """Compute TD label columns according to a label version.
+
+    Parameters
+    ----------
+    df : pl.DataFrame
+        Player-game frame containing touchdown components.
+    version : str | None
+        Label version identifier. Defaults to DEFAULT_LABEL_VERSION.
+    """
+
+    spec = get_label_spec(version)
+    rush = pl.col("rushing_td_count").fill_null(0).cast(pl.Int64)
+    rec = pl.col("receiving_td_count").fill_null(0).cast(pl.Int64)
+    passing = pl.col("passing_td").fill_null(0).cast(pl.Int64)
+    reported_total = pl.col("touchdowns").fill_null(0).cast(pl.Int64)
+
+    offense_total = _sum_expr([rush, rec, passing]).alias("_td_offense_total")
+    other_total = (reported_total - offense_total).clip_min(0).alias("_td_other_total")
+    all_total = (offense_total + other_total).alias("_td_all_total")
+
+    totals_exprs = [
+        offense_total,
+        other_total,
+        all_total,
+    ]
+
+    label_exprs: list[pl.Expr] = [
+        pl.col("_td_offense_total").alias("td_count_offense"),
+        pl.col("_td_all_total").alias("td_count_all"),
+    ]
+
+    for label_name, rules in spec.labels.items():
+        parts: list[pl.Expr] = []
+        if rules.include_rush:
+            parts.append(rush)
+        if rules.include_rec:
+            parts.append(rec)
+        if rules.include_pass_thrown:
+            parts.append(passing)
+        if rules.include_other:
+            parts.append(pl.col("_td_other_total"))
+        total_expr = _sum_expr(parts)
+        label_exprs.append((total_expr > 0).cast(pl.Int8).alias(label_name))
+
+    # Canonical counts for compatibility
+    if "td_count" not in df.columns:
+        # Fill td_count using the alias mapping; default to offense count.
+        target_alias = spec.aliases.get("td_count") or "td_count_offense"
+        label_exprs.append(pl.col(target_alias).alias("td_count"))
+
+    df = df.with_columns(totals_exprs).with_columns(label_exprs)
+
+    # Resolve aliases (e.g., anytime_td -> anytime_td_offense)
+    if spec.aliases:
+        alias_exprs = []
+        for alias_name, source_name in spec.aliases.items():
+            if source_name in df.columns:
+                alias_exprs.append(pl.col(source_name).alias(alias_name))
+        if alias_exprs:
+            df = df.with_columns(alias_exprs)
+
+    drop_cols = [col for col in ("_td_offense_total", "_td_other_total", "_td_all_total") if col in df.columns]
+    if drop_cols:
+        df = df.drop(drop_cols)
+    return df
diff --git a/utils/feature/player_game_level.py b/utils/feature/player_game_level.py
index b6fe516c5f03d575038eef554d5ab39ea5d5c90d..dd4f1f7fcc9de4d8c63390f0a160005eeae48e2f
--- a/utils/feature/player_game_level.py
+++ b/utils/feature/player_game_level.py
@@ -4,8 +4,12 @@
 Each player gets one row per game with their total stats.
 
 Target columns created:
-- anytime_td (binary): Did player score a TD (receiving or rushing)?
-- td_count (int): Number of TDs scored (receiving + rushing)
+- anytime_td_offense (binary): Did player score an offensive TD (rush/rec/pass thrown)?
+- anytime_td_all (binary): Did player score any TD (including defensive/special teams if present)?
+- anytime_td_rush / anytime_td_rec / anytime_td_pass_thrown: Type-specific TD flags.
+- anytime_td (binary): Legacy alias → current label version primary.
+- td_count_offense / td_count_all: TD counts aligned to label semantics.
+- td_count (int): Legacy alias for the primary td_count.
 - passing_td (int): Number of passing TDs (for QBs)
 - receiving_yards (float): Total receiving yards
 - rushing_yards (float): Total rushing yards
@@ -33,6 +37,7 @@
 from utils.collect.nfl_schedules import get_schedule
 from utils.feature.asof import decision_cutoff_hours_default, fallback_cutoff_hours, get_decision_cutoff_hours, get_fallback_cutoff_hours
 from utils.feature.player_drive_level import _load_play_level_data
+from utils.feature.labels import DEFAULT_LABEL_VERSION, compute_td_labels
 from utils.train.injury_availability import (
     load_latest_artifact,
     predict_probabilities as predict_injury_probabilities,
@@ -1582,7 +1587,12 @@
     if flag_cols:
         df = df.with_columns([pl.col(col).cast(pl.Int8) for col in flag_cols])
     return df
-def build_player_game_level(*, start_date: date, end_date: date) -> None:
+def build_player_game_level(
+    *,
+    start_date: date,
+    end_date: date,
+    label_version: str | None = None,
+) -> None:
     """Aggregate play-level data to player-game level.
     
     Creates one row per (player, game) with accumulated stats.
@@ -1680,7 +1690,7 @@
     
     # Merge rows where same player had multiple roles in same game
     # (e.g., QB who also rushed, WR who also rushed)
-    df_merged = _merge_multi_role_players(df_all)
+    df_merged = _merge_multi_role_players(df_all, label_version=label_version or DEFAULT_LABEL_VERSION)
 
     df_merged = _append_zero_usage_players(df_merged, seasons_in_window)
     
@@ -3368,7 +3378,7 @@
     )
 
 
-def _merge_multi_role_players(df: pl.DataFrame) -> pl.DataFrame:
+def _merge_multi_role_players(df: pl.DataFrame, *, label_version: str | None = None) -> pl.DataFrame:
     """Merge stats for players who had multiple roles in same game.
     
     Example: QB who passed and rushed, WR who received and rushed.
@@ -3422,8 +3432,6 @@
         if col in merged.columns:
             merged = merged.with_columns(pl.col(col).fill_null(0))
 
-    # Fallback touchdown logic: if generic touchdown attribution is missing,
-    # derive it from rushing + receiving touchdowns.
     merged = merged.with_columns([
         pl.col("touchdowns").fill_null(0).alias("touchdowns"),
         pl.col("rushing_td_count").fill_null(0).alias("rushing_td_count"),
@@ -3435,17 +3443,5 @@
         pl.col("goal_to_go_carry").fill_null(0).alias("goal_to_go_carry"),
     ])
 
-    merged = merged.with_columns([
-        pl.when(pl.col("touchdowns") > 0)
-        .then(pl.col("touchdowns"))
-        .otherwise(pl.col("rushing_td_count") + pl.col("receiving_td_count"))
-        .cast(pl.Int64)
-        .alias("_total_touchdowns")
-    ])
-
-    merged = merged.with_columns([
-        (pl.col("_total_touchdowns") > 0).cast(pl.Int8).alias("anytime_td"),
-        pl.col("_total_touchdowns").alias("td_count"),
-    ]).drop("_total_touchdowns")
-    
+    merged = compute_td_labels(merged, version=label_version)
     return merged
diff --git a/utils/feature/targets.py b/utils/feature/targets.py
index 7738086dcbfda7432b937cc7d8095988cb0edff0..769ee8735c4024c4410ddd674b11112f093624dd
--- a/utils/feature/targets.py
+++ b/utils/feature/targets.py
@@ -7,6 +7,8 @@
 import polars as pl
 import logging
 
+from utils.feature.labels import DEFAULT_LABEL_VERSION, get_label_spec
+
 logger = logging.getLogger(__name__)
 
 
@@ -14,9 +16,16 @@
 NFL_TARGET_SCHEMA = {
     # Binary classification targets
     "anytime_td": pl.Int8,  # Primary MVP target: did player score a TD?
+    "anytime_td_offense": pl.Int8,
+    "anytime_td_all": pl.Int8,
+    "anytime_td_rush": pl.Int8,
+    "anytime_td_rec": pl.Int8,
+    "anytime_td_pass_thrown": pl.Int8,
     
     # Count/regression targets
     "td_count": pl.Int64,  # Number of TDs scored (receiving + rushing)
+    "td_count_offense": pl.Int64,
+    "td_count_all": pl.Int64,
     "passing_td": pl.Int64,  # Number of passing TDs (QB only)
     
     # Yardage regression targets
@@ -103,4 +112,40 @@
     pl.DataFrame
         DataFrame with validated target columns
     """
-    return validate_target_columns(df, strict=False)
\ No newline at end of file
+    return validate_target_columns(df, strict=False)
+
+
+def require_target_column(
+    df: pl.DataFrame,
+    target_col: str,
+    *,
+    label_version: str | None = None,
+    min_non_null: int = 1,
+) -> pl.DataFrame:
+    """Ensure the configured target column exists and is populated.
+
+    Raises a ValueError if the column is missing or entirely null.
+    """
+
+    if target_col not in df.columns:
+        alias_hint = ""
+        if label_version:
+            try:
+                spec = get_label_spec(label_version or DEFAULT_LABEL_VERSION)
+                if target_col in spec.aliases:
+                    alias_hint = f" Target maps to '{spec.aliases[target_col]}' under {spec.name}."
+            except Exception:
+                alias_hint = ""
+        raise ValueError(f"Target column '{target_col}' not found in feature frame.{alias_hint}")
+
+    series = df[target_col]
+    non_null = series.drop_nulls().height
+    if non_null < min_non_null:
+        raise ValueError(
+            f"Target column '{target_col}' has insufficient non-null rows "
+            f"({non_null}/{len(series)})."
+        )
+    nulls = len(series) - non_null
+    if nulls > 0:
+        logger.warning("Target %s contains %d null rows; they will be dropped.", target_col, nulls)
+    return df


thinking
**Adding and verifying imports for new function**
file update
M /Users/jameswest/Desktop/nfl_predict/pipeline/train.py
@@ -100,2 +100,3 @@
 )
+from utils.feature.targets import require_target_column
 
apply_patch(auto_approved=true) exited 0 in 75ms:
Success. Updated the following files:
M pipeline/train.py
file update:
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 6c47a91d08f9d309f94323efd4708bb992dc4ce0..5ba68e8bf1acd3a789a76a8857674e6f6433017b
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -26,6 +26,7 @@
 from utils.feature.player_drive_level import build_player_drive_level
 from utils.feature.player_game_level import build_player_game_level
 from utils.feature.opponent_splits import build_opponent_splits
+from utils.feature.labels import DEFAULT_LABEL_VERSION, get_label_spec
 from utils.feature.targets import validate_target_columns
 from utils.feature.daily_totals import build_daily_cache_range
 from utils.feature.rolling_window import add_rolling_features
@@ -233,6 +234,7 @@
     output_path: Path | None = None,
     primary_output_path: Path | None = None,
     cutoff_label: str | None = None,
+    label_version: str | None = None,
 ) -> pl.DataFrame:
     """Run full feature pipeline up to *inclusive* `end_date` for a single cutoff window.
 
@@ -248,6 +250,7 @@
     primary_output = primary_output_path or target_output_path
     current_cutoff_hours = float(get_decision_cutoff_hours())
     clean_min_date, clean_max_date = (None, None)
+    label_version = label_version or DEFAULT_LABEL_VERSION
     if start_date is None or end_date is None:
         clean_min_date, clean_max_date = _get_clean_date_bounds()
 
@@ -294,7 +297,7 @@
             build_player_drive_level(start_date=cur, end_date=chunk_end)
             
             # 5. Player-game aggregations (for rolling window features)
-            build_player_game_level(start_date=cur, end_date=chunk_end)
+            build_player_game_level(start_date=cur, end_date=chunk_end, label_version=label_version)
 
             # advance to next slice
             cur += timedelta(days=chunk_days)
@@ -948,11 +951,19 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    # Log target distribution for anytime_td
-    if "anytime_td" in df_player_game_all.columns:
-        td_count = df_player_game_all["anytime_td"].sum()
-        td_rate = td_count / len(df_player_game_all) * 100
-        logging.info("    Anytime TD rate: %.2f%% (%d/%d)", td_rate, td_count, len(df_player_game_all))
+    spec = get_label_spec(label_version)
+    label_candidates = {spec.primary, "anytime_td"}
+    for label_col in label_candidates:
+        if label_col in df_player_game_all.columns:
+            td_count = df_player_game_all[label_col].sum()
+            td_rate = td_count / len(df_player_game_all) * 100
+            logging.info(
+                "    Label %s rate: %.2f%% (%d/%d)",
+                label_col,
+                td_rate,
+                td_count,
+                len(df_player_game_all),
+            )
     
     return df_player_game_all
 
@@ -965,6 +976,7 @@
     recompute_intermediate: bool = True,
     build_rolling: bool = True,
     cutoff_hours_list: Sequence[float] | None = None,
+    label_version: str | None = None,
 ) -> pl.DataFrame:
     """Build feature matrices for one or more decision cutoff horizons.
 
@@ -992,6 +1004,7 @@
                 output_path=output_path,
                 primary_output_path=primary_output,
                 cutoff_label=label,
+                label_version=label_version,
             )
         if idx == 0:
             primary_result = df
diff --git a/pipeline/train.py b/pipeline/train.py
index 265bc29f4861d2d4d26f54fd7f77304de8fe6742..8d8dfc57bf00bbf0193dc6b51286d20f30451bd9
--- a/pipeline/train.py
+++ b/pipeline/train.py
@@ -98,6 +98,7 @@
     fit_team_conformal_sums,
     composite_sum_interval,
 )
+from utils.feature.targets import require_target_column
 
 # Ignore specific, noisy warnings from dependencies
 warnings.filterwarnings(
diff --git a/utils/feature/labels.py b/utils/feature/labels.py
new file mode 100644
index 0000000000000000000000000000000000000000..b34571f04254cd7bceb9363a190ee7d305852bd5
--- /dev/null
+++ b/utils/feature/labels.py
@@ -0,0 +1,169 @@
+"""Label semantics and versioning for NFL player-level targets.
+
+This module centralizes anytime-TD label definitions so that:
+- Semantics are explicit and versioned.
+- Training can request a specific label column per problem.
+- Feature generation can emit multiple label variants for analysis.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass, field
+from typing import Dict, Iterable, Mapping
+
+import polars as pl
+
+
+@dataclass(frozen=True)
+class LabelRules:
+    """Rules controlling which TD components count toward a label."""
+
+    include_rush: bool = True
+    include_rec: bool = True
+    include_pass_thrown: bool = True  # credit passers for thrown TDs
+    include_other: bool = False  # fumble returns, defensive/special teams if present
+
+
+@dataclass(frozen=True)
+class LabelSpec:
+    """Container describing a label version."""
+
+    name: str
+    primary: str
+    labels: Mapping[str, LabelRules]
+    aliases: Mapping[str, str] = field(default_factory=dict)
+
+    @property
+    def all_columns(self) -> set[str]:
+        cols = set(self.labels.keys())
+        cols.update(self.aliases.keys())
+        return cols
+
+
+DEFAULT_LABEL_VERSION = "v1_any_offense"
+
+
+LABEL_VERSIONS: Dict[str, LabelSpec] = {
+    "v1_any_offense": LabelSpec(
+        name="v1_any_offense",
+        primary="anytime_td_offense",
+        labels={
+            "anytime_td_offense": LabelRules(include_other=False),
+            "anytime_td_rush": LabelRules(include_rush=True, include_rec=False, include_pass_thrown=False, include_other=False),
+            "anytime_td_rec": LabelRules(include_rush=False, include_rec=True, include_pass_thrown=False, include_other=False),
+            "anytime_td_pass_thrown": LabelRules(include_rush=False, include_rec=False, include_pass_thrown=True, include_other=False),
+            "anytime_td_all": LabelRules(include_other=True),
+        },
+        aliases={
+            # Maintain legacy column name as an alias to the offense-only label.
+            "anytime_td": "anytime_td_offense",
+            # Keep td_count pointing to the offense definition for backward compatibility.
+            "td_count": "td_count_offense",
+        },
+    ),
+    "v1_any_all": LabelSpec(
+        name="v1_any_all",
+        primary="anytime_td_all",
+        labels={
+            "anytime_td_all": LabelRules(include_other=True),
+            "anytime_td_offense": LabelRules(include_other=False),
+            "anytime_td_rush": LabelRules(include_rush=True, include_rec=False, include_pass_thrown=False, include_other=False),
+            "anytime_td_rec": LabelRules(include_rush=False, include_rec=True, include_pass_thrown=False, include_other=False),
+            "anytime_td_pass_thrown": LabelRules(include_rush=False, include_rec=False, include_pass_thrown=True, include_other=False),
+        },
+        aliases={
+            "anytime_td": "anytime_td_all",
+            "td_count": "td_count_all",
+        },
+    ),
+}
+
+
+def get_label_spec(version: str | None) -> LabelSpec:
+    """Return a concrete LabelSpec for the requested version (or default)."""
+
+    version = version or DEFAULT_LABEL_VERSION
+    if version not in LABEL_VERSIONS:
+        raise ValueError(
+            f"Unknown label_version '{version}'. "
+            f"Available: {sorted(LABEL_VERSIONS.keys())}"
+        )
+    return LABEL_VERSIONS[version]
+
+
+def _sum_expr(exprs: Iterable[pl.Expr]) -> pl.Expr:
+    exprs = list(exprs)
+    if not exprs:
+        return pl.lit(0).cast(pl.Int64)
+    acc = exprs[0]
+    for expr in exprs[1:]:
+        acc = acc + expr
+    return acc
+
+
+def compute_td_labels(df: pl.DataFrame, *, version: str | None = None) -> pl.DataFrame:
+    """Compute TD label columns according to a label version.
+
+    Parameters
+    ----------
+    df : pl.DataFrame
+        Player-game frame containing touchdown components.
+    version : str | None
+        Label version identifier. Defaults to DEFAULT_LABEL_VERSION.
+    """
+
+    spec = get_label_spec(version)
+    rush = pl.col("rushing_td_count").fill_null(0).cast(pl.Int64)
+    rec = pl.col("receiving_td_count").fill_null(0).cast(pl.Int64)
+    passing = pl.col("passing_td").fill_null(0).cast(pl.Int64)
+    reported_total = pl.col("touchdowns").fill_null(0).cast(pl.Int64)
+
+    offense_total = _sum_expr([rush, rec, passing]).alias("_td_offense_total")
+    other_total = (reported_total - offense_total).clip_min(0).alias("_td_other_total")
+    all_total = (offense_total + other_total).alias("_td_all_total")
+
+    totals_exprs = [
+        offense_total,
+        other_total,
+        all_total,
+    ]
+
+    label_exprs: list[pl.Expr] = [
+        pl.col("_td_offense_total").alias("td_count_offense"),
+        pl.col("_td_all_total").alias("td_count_all"),
+    ]
+
+    for label_name, rules in spec.labels.items():
+        parts: list[pl.Expr] = []
+        if rules.include_rush:
+            parts.append(rush)
+        if rules.include_rec:
+            parts.append(rec)
+        if rules.include_pass_thrown:
+            parts.append(passing)
+        if rules.include_other:
+            parts.append(pl.col("_td_other_total"))
+        total_expr = _sum_expr(parts)
+        label_exprs.append((total_expr > 0).cast(pl.Int8).alias(label_name))
+
+    # Canonical counts for compatibility
+    if "td_count" not in df.columns:
+        # Fill td_count using the alias mapping; default to offense count.
+        target_alias = spec.aliases.get("td_count") or "td_count_offense"
+        label_exprs.append(pl.col(target_alias).alias("td_count"))
+
+    df = df.with_columns(totals_exprs).with_columns(label_exprs)
+
+    # Resolve aliases (e.g., anytime_td -> anytime_td_offense)
+    if spec.aliases:
+        alias_exprs = []
+        for alias_name, source_name in spec.aliases.items():
+            if source_name in df.columns:
+                alias_exprs.append(pl.col(source_name).alias(alias_name))
+        if alias_exprs:
+            df = df.with_columns(alias_exprs)
+
+    drop_cols = [col for col in ("_td_offense_total", "_td_other_total", "_td_all_total") if col in df.columns]
+    if drop_cols:
+        df = df.drop(drop_cols)
+    return df
diff --git a/utils/feature/player_game_level.py b/utils/feature/player_game_level.py
index b6fe516c5f03d575038eef554d5ab39ea5d5c90d..dd4f1f7fcc9de4d8c63390f0a160005eeae48e2f
--- a/utils/feature/player_game_level.py
+++ b/utils/feature/player_game_level.py
@@ -4,8 +4,12 @@
 Each player gets one row per game with their total stats.
 
 Target columns created:
-- anytime_td (binary): Did player score a TD (receiving or rushing)?
-- td_count (int): Number of TDs scored (receiving + rushing)
+- anytime_td_offense (binary): Did player score an offensive TD (rush/rec/pass thrown)?
+- anytime_td_all (binary): Did player score any TD (including defensive/special teams if present)?
+- anytime_td_rush / anytime_td_rec / anytime_td_pass_thrown: Type-specific TD flags.
+- anytime_td (binary): Legacy alias → current label version primary.
+- td_count_offense / td_count_all: TD counts aligned to label semantics.
+- td_count (int): Legacy alias for the primary td_count.
 - passing_td (int): Number of passing TDs (for QBs)
 - receiving_yards (float): Total receiving yards
 - rushing_yards (float): Total rushing yards
@@ -33,6 +37,7 @@
 from utils.collect.nfl_schedules import get_schedule
 from utils.feature.asof import decision_cutoff_hours_default, fallback_cutoff_hours, get_decision_cutoff_hours, get_fallback_cutoff_hours
 from utils.feature.player_drive_level import _load_play_level_data
+from utils.feature.labels import DEFAULT_LABEL_VERSION, compute_td_labels
 from utils.train.injury_availability import (
     load_latest_artifact,
     predict_probabilities as predict_injury_probabilities,
@@ -1582,7 +1587,12 @@
     if flag_cols:
         df = df.with_columns([pl.col(col).cast(pl.Int8) for col in flag_cols])
     return df
-def build_player_game_level(*, start_date: date, end_date: date) -> None:
+def build_player_game_level(
+    *,
+    start_date: date,
+    end_date: date,
+    label_version: str | None = None,
+) -> None:
     """Aggregate play-level data to player-game level.
     
     Creates one row per (player, game) with accumulated stats.
@@ -1680,7 +1690,7 @@
     
     # Merge rows where same player had multiple roles in same game
     # (e.g., QB who also rushed, WR who also rushed)
-    df_merged = _merge_multi_role_players(df_all)
+    df_merged = _merge_multi_role_players(df_all, label_version=label_version or DEFAULT_LABEL_VERSION)
 
     df_merged = _append_zero_usage_players(df_merged, seasons_in_window)
     
@@ -3368,7 +3378,7 @@
     )
 
 
-def _merge_multi_role_players(df: pl.DataFrame) -> pl.DataFrame:
+def _merge_multi_role_players(df: pl.DataFrame, *, label_version: str | None = None) -> pl.DataFrame:
     """Merge stats for players who had multiple roles in same game.
     
     Example: QB who passed and rushed, WR who received and rushed.
@@ -3422,8 +3432,6 @@
         if col in merged.columns:
             merged = merged.with_columns(pl.col(col).fill_null(0))
 
-    # Fallback touchdown logic: if generic touchdown attribution is missing,
-    # derive it from rushing + receiving touchdowns.
     merged = merged.with_columns([
         pl.col("touchdowns").fill_null(0).alias("touchdowns"),
         pl.col("rushing_td_count").fill_null(0).alias("rushing_td_count"),
@@ -3435,17 +3443,5 @@
         pl.col("goal_to_go_carry").fill_null(0).alias("goal_to_go_carry"),
     ])
 
-    merged = merged.with_columns([
-        pl.when(pl.col("touchdowns") > 0)
-        .then(pl.col("touchdowns"))
-        .otherwise(pl.col("rushing_td_count") + pl.col("receiving_td_count"))
-        .cast(pl.Int64)
-        .alias("_total_touchdowns")
-    ])
-
-    merged = merged.with_columns([
-        (pl.col("_total_touchdowns") > 0).cast(pl.Int8).alias("anytime_td"),
-        pl.col("_total_touchdowns").alias("td_count"),
-    ]).drop("_total_touchdowns")
-    
+    merged = compute_td_labels(merged, version=label_version)
     return merged
diff --git a/utils/feature/targets.py b/utils/feature/targets.py
index 7738086dcbfda7432b937cc7d8095988cb0edff0..769ee8735c4024c4410ddd674b11112f093624dd
--- a/utils/feature/targets.py
+++ b/utils/feature/targets.py
@@ -7,6 +7,8 @@
 import polars as pl
 import logging
 
+from utils.feature.labels import DEFAULT_LABEL_VERSION, get_label_spec
+
 logger = logging.getLogger(__name__)
 
 
@@ -14,9 +16,16 @@
 NFL_TARGET_SCHEMA = {
     # Binary classification targets
     "anytime_td": pl.Int8,  # Primary MVP target: did player score a TD?
+    "anytime_td_offense": pl.Int8,
+    "anytime_td_all": pl.Int8,
+    "anytime_td_rush": pl.Int8,
+    "anytime_td_rec": pl.Int8,
+    "anytime_td_pass_thrown": pl.Int8,
     
     # Count/regression targets
     "td_count": pl.Int64,  # Number of TDs scored (receiving + rushing)
+    "td_count_offense": pl.Int64,
+    "td_count_all": pl.Int64,
     "passing_td": pl.Int64,  # Number of passing TDs (QB only)
     
     # Yardage regression targets
@@ -103,4 +112,40 @@
     pl.DataFrame
         DataFrame with validated target columns
     """
-    return validate_target_columns(df, strict=False)
\ No newline at end of file
+    return validate_target_columns(df, strict=False)
+
+
+def require_target_column(
+    df: pl.DataFrame,
+    target_col: str,
+    *,
+    label_version: str | None = None,
+    min_non_null: int = 1,
+) -> pl.DataFrame:
+    """Ensure the configured target column exists and is populated.
+
+    Raises a ValueError if the column is missing or entirely null.
+    """
+
+    if target_col not in df.columns:
+        alias_hint = ""
+        if label_version:
+            try:
+                spec = get_label_spec(label_version or DEFAULT_LABEL_VERSION)
+                if target_col in spec.aliases:
+                    alias_hint = f" Target maps to '{spec.aliases[target_col]}' under {spec.name}."
+            except Exception:
+                alias_hint = ""
+        raise ValueError(f"Target column '{target_col}' not found in feature frame.{alias_hint}")
+
+    series = df[target_col]
+    non_null = series.drop_nulls().height
+    if non_null < min_non_null:
+        raise ValueError(
+            f"Target column '{target_col}' has insufficient non-null rows "
+            f"({non_null}/{len(series)})."
+        )
+    nulls = len(series) - non_null
+    if nulls > 0:
+        logger.warning("Target %s contains %d null rows; they will be dropped.", target_col, nulls)
+    return df

file update:
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 6c47a91d08f9d309f94323efd4708bb992dc4ce0..5ba68e8bf1acd3a789a76a8857674e6f6433017b
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -26,6 +26,7 @@
 from utils.feature.player_drive_level import build_player_drive_level
 from utils.feature.player_game_level import build_player_game_level
 from utils.feature.opponent_splits import build_opponent_splits
+from utils.feature.labels import DEFAULT_LABEL_VERSION, get_label_spec
 from utils.feature.targets import validate_target_columns
 from utils.feature.daily_totals import build_daily_cache_range
 from utils.feature.rolling_window import add_rolling_features
@@ -233,6 +234,7 @@
     output_path: Path | None = None,
     primary_output_path: Path | None = None,
     cutoff_label: str | None = None,
+    label_version: str | None = None,
 ) -> pl.DataFrame:
     """Run full feature pipeline up to *inclusive* `end_date` for a single cutoff window.
 
@@ -248,6 +250,7 @@
     primary_output = primary_output_path or target_output_path
     current_cutoff_hours = float(get_decision_cutoff_hours())
     clean_min_date, clean_max_date = (None, None)
+    label_version = label_version or DEFAULT_LABEL_VERSION
     if start_date is None or end_date is None:
         clean_min_date, clean_max_date = _get_clean_date_bounds()
 
@@ -294,7 +297,7 @@
             build_player_drive_level(start_date=cur, end_date=chunk_end)
             
             # 5. Player-game aggregations (for rolling window features)
-            build_player_game_level(start_date=cur, end_date=chunk_end)
+            build_player_game_level(start_date=cur, end_date=chunk_end, label_version=label_version)
 
             # advance to next slice
             cur += timedelta(days=chunk_days)
@@ -948,11 +951,19 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    # Log target distribution for anytime_td
-    if "anytime_td" in df_player_game_all.columns:
-        td_count = df_player_game_all["anytime_td"].sum()
-        td_rate = td_count / len(df_player_game_all) * 100
-        logging.info("    Anytime TD rate: %.2f%% (%d/%d)", td_rate, td_count, len(df_player_game_all))
+    spec = get_label_spec(label_version)
+    label_candidates = {spec.primary, "anytime_td"}
+    for label_col in label_candidates:
+        if label_col in df_player_game_all.columns:
+            td_count = df_player_game_all[label_col].sum()
+            td_rate = td_count / len(df_player_game_all) * 100
+            logging.info(
+                "    Label %s rate: %.2f%% (%d/%d)",
+                label_col,
+                td_rate,
+                td_count,
+                len(df_player_game_all),
+            )
     
     return df_player_game_all
 
@@ -965,6 +976,7 @@
     recompute_intermediate: bool = True,
     build_rolling: bool = True,
     cutoff_hours_list: Sequence[float] | None = None,
+    label_version: str | None = None,
 ) -> pl.DataFrame:
     """Build feature matrices for one or more decision cutoff horizons.
 
@@ -992,6 +1004,7 @@
                 output_path=output_path,
                 primary_output_path=primary_output,
                 cutoff_label=label,
+                label_version=label_version,
             )
         if idx == 0:
             primary_result = df
diff --git a/pipeline/train.py b/pipeline/train.py
index 265bc29f4861d2d4d26f54fd7f77304de8fe6742..8d8dfc57bf00bbf0193dc6b51286d20f30451bd9
--- a/pipeline/train.py
+++ b/pipeline/train.py
@@ -98,6 +98,7 @@
     fit_team_conformal_sums,
     composite_sum_interval,
 )
+from utils.feature.targets import require_target_column
 
 # Ignore specific, noisy warnings from dependencies
 warnings.filterwarnings(
diff --git a/utils/feature/labels.py b/utils/feature/labels.py
new file mode 100644
index 0000000000000000000000000000000000000000..b34571f04254cd7bceb9363a190ee7d305852bd5
--- /dev/null
+++ b/utils/feature/labels.py
@@ -0,0 +1,169 @@
+"""Label semantics and versioning for NFL player-level targets.
+
+This module centralizes anytime-TD label definitions so that:
+- Semantics are explicit and versioned.
+- Training can request a specific label column per problem.
+- Feature generation can emit multiple label variants for analysis.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass, field
+from typing import Dict, Iterable, Mapping
+
+import polars as pl
+
+
+@dataclass(frozen=True)
+class LabelRules:
+    """Rules controlling which TD components count toward a label."""
+
+    include_rush: bool = True
+    include_rec: bool = True
+    include_pass_thrown: bool = True  # credit passers for thrown TDs
+    include_other: bool = False  # fumble returns, defensive/special teams if present
+
+
+@dataclass(frozen=True)
+class LabelSpec:
+    """Container describing a label version."""
+
+    name: str
+    primary: str
+    labels: Mapping[str, LabelRules]
+    aliases: Mapping[str, str] = field(default_factory=dict)
+
+    @property
+    def all_columns(self) -> set[str]:
+        cols = set(self.labels.keys())
+        cols.update(self.aliases.keys())
+        return cols
+
+
+DEFAULT_LABEL_VERSION = "v1_any_offense"
+
+
+LABEL_VERSIONS: Dict[str, LabelSpec] = {
+    "v1_any_offense": LabelSpec(
+        name="v1_any_offense",
+        primary="anytime_td_offense",
+        labels={
+            "anytime_td_offense": LabelRules(include_other=False),
+            "anytime_td_rush": LabelRules(include_rush=True, include_rec=False, include_pass_thrown=False, include_other=False),
+            "anytime_td_rec": LabelRules(include_rush=False, include_rec=True, include_pass_thrown=False, include_other=False),
+            "anytime_td_pass_thrown": LabelRules(include_rush=False, include_rec=False, include_pass_thrown=True, include_other=False),
+            "anytime_td_all": LabelRules(include_other=True),
+        },
+        aliases={
+            # Maintain legacy column name as an alias to the offense-only label.
+            "anytime_td": "anytime_td_offense",
+            # Keep td_count pointing to the offense definition for backward compatibility.
+            "td_count": "td_count_offense",
+        },
+    ),
+    "v1_any_all": LabelSpec(
+        name="v1_any_all",
+        primary="anytime_td_all",
+        labels={
+            "anytime_td_all": LabelRules(include_other=True),
+            "anytime_td_offense": LabelRules(include_other=False),
+            "anytime_td_rush": LabelRules(include_rush=True, include_rec=False, include_pass_thrown=False, include_other=False),
+            "anytime_td_rec": LabelRules(include_rush=False, include_rec=True, include_pass_thrown=False, include_other=False),
+            "anytime_td_pass_thrown": LabelRules(include_rush=False, include_rec=False, include_pass_thrown=True, include_other=False),
+        },
+        aliases={
+            "anytime_td": "anytime_td_all",
+            "td_count": "td_count_all",
+        },
+    ),
+}
+
+
+def get_label_spec(version: str | None) -> LabelSpec:
+    """Return a concrete LabelSpec for the requested version (or default)."""
+
+    version = version or DEFAULT_LABEL_VERSION
+    if version not in LABEL_VERSIONS:
+        raise ValueError(
+            f"Unknown label_version '{version}'. "
+            f"Available: {sorted(LABEL_VERSIONS.keys())}"
+        )
+    return LABEL_VERSIONS[version]
+
+
+def _sum_expr(exprs: Iterable[pl.Expr]) -> pl.Expr:
+    exprs = list(exprs)
+    if not exprs:
+        return pl.lit(0).cast(pl.Int64)
+    acc = exprs[0]
+    for expr in exprs[1:]:
+        acc = acc + expr
+    return acc
+
+
+def compute_td_labels(df: pl.DataFrame, *, version: str | None = None) -> pl.DataFrame:
+    """Compute TD label columns according to a label version.
+
+    Parameters
+    ----------
+    df : pl.DataFrame
+        Player-game frame containing touchdown components.
+    version : str | None
+        Label version identifier. Defaults to DEFAULT_LABEL_VERSION.
+    """
+
+    spec = get_label_spec(version)
+    rush = pl.col("rushing_td_count").fill_null(0).cast(pl.Int64)
+    rec = pl.col("receiving_td_count").fill_null(0).cast(pl.Int64)
+    passing = pl.col("passing_td").fill_null(0).cast(pl.Int64)
+    reported_total = pl.col("touchdowns").fill_null(0).cast(pl.Int64)
+
+    offense_total = _sum_expr([rush, rec, passing]).alias("_td_offense_total")
+    other_total = (reported_total - offense_total).clip_min(0).alias("_td_other_total")
+    all_total = (offense_total + other_total).alias("_td_all_total")
+
+    totals_exprs = [
+        offense_total,
+        other_total,
+        all_total,
+    ]
+
+    label_exprs: list[pl.Expr] = [
+        pl.col("_td_offense_total").alias("td_count_offense"),
+        pl.col("_td_all_total").alias("td_count_all"),
+    ]
+
+    for label_name, rules in spec.labels.items():
+        parts: list[pl.Expr] = []
+        if rules.include_rush:
+            parts.append(rush)
+        if rules.include_rec:
+            parts.append(rec)
+        if rules.include_pass_thrown:
+            parts.append(passing)
+        if rules.include_other:
+            parts.append(pl.col("_td_other_total"))
+        total_expr = _sum_expr(parts)
+        label_exprs.append((total_expr > 0).cast(pl.Int8).alias(label_name))
+
+    # Canonical counts for compatibility
+    if "td_count" not in df.columns:
+        # Fill td_count using the alias mapping; default to offense count.
+        target_alias = spec.aliases.get("td_count") or "td_count_offense"
+        label_exprs.append(pl.col(target_alias).alias("td_count"))
+
+    df = df.with_columns(totals_exprs).with_columns(label_exprs)
+
+    # Resolve aliases (e.g., anytime_td -> anytime_td_offense)
+    if spec.aliases:
+        alias_exprs = []
+        for alias_name, source_name in spec.aliases.items():
+            if source_name in df.columns:
+                alias_exprs.append(pl.col(source_name).alias(alias_name))
+        if alias_exprs:
+            df = df.with_columns(alias_exprs)
+
+    drop_cols = [col for col in ("_td_offense_total", "_td_other_total", "_td_all_total") if col in df.columns]
+    if drop_cols:
+        df = df.drop(drop_cols)
+    return df
diff --git a/utils/feature/player_game_level.py b/utils/feature/player_game_level.py
index b6fe516c5f03d575038eef554d5ab39ea5d5c90d..dd4f1f7fcc9de4d8c63390f0a160005eeae48e2f
--- a/utils/feature/player_game_level.py
+++ b/utils/feature/player_game_level.py
@@ -4,8 +4,12 @@
 Each player gets one row per game with their total stats.
 
 Target columns created:
-- anytime_td (binary): Did player score a TD (receiving or rushing)?
-- td_count (int): Number of TDs scored (receiving + rushing)
+- anytime_td_offense (binary): Did player score an offensive TD (rush/rec/pass thrown)?
+- anytime_td_all (binary): Did player score any TD (including defensive/special teams if present)?
+- anytime_td_rush / anytime_td_rec / anytime_td_pass_thrown: Type-specific TD flags.
+- anytime_td (binary): Legacy alias → current label version primary.
+- td_count_offense / td_count_all: TD counts aligned to label semantics.
+- td_count (int): Legacy alias for the primary td_count.
 - passing_td (int): Number of passing TDs (for QBs)
 - receiving_yards (float): Total receiving yards
 - rushing_yards (float): Total rushing yards
@@ -33,6 +37,7 @@
 from utils.collect.nfl_schedules import get_schedule
 from utils.feature.asof import decision_cutoff_hours_default, fallback_cutoff_hours, get_decision_cutoff_hours, get_fallback_cutoff_hours
 from utils.feature.player_drive_level import _load_play_level_data
+from utils.feature.labels import DEFAULT_LABEL_VERSION, compute_td_labels
 from utils.train.injury_availability import (
     load_latest_artifact,
     predict_probabilities as predict_injury_probabilities,
@@ -1582,7 +1587,12 @@
     if flag_cols:
         df = df.with_columns([pl.col(col).cast(pl.Int8) for col in flag_cols])
     return df
-def build_player_game_level(*, start_date: date, end_date: date) -> None:
+def build_player_game_level(
+    *,
+    start_date: date,
+    end_date: date,
+    label_version: str | None = None,
+) -> None:
     """Aggregate play-level data to player-game level.
     
     Creates one row per (player, game) with accumulated stats.
@@ -1680,7 +1690,7 @@
     
     # Merge rows where same player had multiple roles in same game
     # (e.g., QB who also rushed, WR who also rushed)
-    df_merged = _merge_multi_role_players(df_all)
+    df_merged = _merge_multi_role_players(df_all, label_version=label_version or DEFAULT_LABEL_VERSION)
 
     df_merged = _append_zero_usage_players(df_merged, seasons_in_window)
     
@@ -3368,7 +3378,7 @@
     )
 
 
-def _merge_multi_role_players(df: pl.DataFrame) -> pl.DataFrame:
+def _merge_multi_role_players(df: pl.DataFrame, *, label_version: str | None = None) -> pl.DataFrame:
     """Merge stats for players who had multiple roles in same game.
     
     Example: QB who passed and rushed, WR who received and rushed.
@@ -3422,8 +3432,6 @@
         if col in merged.columns:
             merged = merged.with_columns(pl.col(col).fill_null(0))
 
-    # Fallback touchdown logic: if generic touchdown attribution is missing,
-    # derive it from rushing + receiving touchdowns.
     merged = merged.with_columns([
         pl.col("touchdowns").fill_null(0).alias("touchdowns"),
         pl.col("rushing_td_count").fill_null(0).alias("rushing_td_count"),
@@ -3435,17 +3443,5 @@
         pl.col("goal_to_go_carry").fill_null(0).alias("goal_to_go_carry"),
     ])
 
-    merged = merged.with_columns([
-        pl.when(pl.col("touchdowns") > 0)
-        .then(pl.col("touchdowns"))
-        .otherwise(pl.col("rushing_td_count") + pl.col("receiving_td_count"))
-        .cast(pl.Int64)
-        .alias("_total_touchdowns")
-    ])
-
-    merged = merged.with_columns([
-        (pl.col("_total_touchdowns") > 0).cast(pl.Int8).alias("anytime_td"),
-        pl.col("_total_touchdowns").alias("td_count"),
-    ]).drop("_total_touchdowns")
-    
+    merged = compute_td_labels(merged, version=label_version)
     return merged
diff --git a/utils/feature/targets.py b/utils/feature/targets.py
index 7738086dcbfda7432b937cc7d8095988cb0edff0..769ee8735c4024c4410ddd674b11112f093624dd
--- a/utils/feature/targets.py
+++ b/utils/feature/targets.py
@@ -7,6 +7,8 @@
 import polars as pl
 import logging
 
+from utils.feature.labels import DEFAULT_LABEL_VERSION, get_label_spec
+
 logger = logging.getLogger(__name__)
 
 
@@ -14,9 +16,16 @@
 NFL_TARGET_SCHEMA = {
     # Binary classification targets
     "anytime_td": pl.Int8,  # Primary MVP target: did player score a TD?
+    "anytime_td_offense": pl.Int8,
+    "anytime_td_all": pl.Int8,
+    "anytime_td_rush": pl.Int8,
+    "anytime_td_rec": pl.Int8,
+    "anytime_td_pass_thrown": pl.Int8,
     
     # Count/regression targets
     "td_count": pl.Int64,  # Number of TDs scored (receiving + rushing)
+    "td_count_offense": pl.Int64,
+    "td_count_all": pl.Int64,
     "passing_td": pl.Int64,  # Number of passing TDs (QB only)
     
     # Yardage regression targets
@@ -103,4 +112,40 @@
     pl.DataFrame
         DataFrame with validated target columns
     """
-    return validate_target_columns(df, strict=False)
\ No newline at end of file
+    return validate_target_columns(df, strict=False)
+
+
+def require_target_column(
+    df: pl.DataFrame,
+    target_col: str,
+    *,
+    label_version: str | None = None,
+    min_non_null: int = 1,
+) -> pl.DataFrame:
+    """Ensure the configured target column exists and is populated.
+
+    Raises a ValueError if the column is missing or entirely null.
+    """
+
+    if target_col not in df.columns:
+        alias_hint = ""
+        if label_version:
+            try:
+                spec = get_label_spec(label_version or DEFAULT_LABEL_VERSION)
+                if target_col in spec.aliases:
+                    alias_hint = f" Target maps to '{spec.aliases[target_col]}' under {spec.name}."
+            except Exception:
+                alias_hint = ""
+        raise ValueError(f"Target column '{target_col}' not found in feature frame.{alias_hint}")
+
+    series = df[target_col]
+    non_null = series.drop_nulls().height
+    if non_null < min_non_null:
+        raise ValueError(
+            f"Target column '{target_col}' has insufficient non-null rows "
+            f"({non_null}/{len(series)})."
+        )
+    nulls = len(series) - non_null
+    if nulls > 0:
+        logger.warning("Target %s contains %d null rows; they will be dropped.", target_col, nulls)
+    return df


thinking
**Determining placement for require_target_column call**
exec
/bin/zsh -lc 'cd /Users/jameswest/Desktop/nfl_predict && rg "target_col = None" -n pipeline/train.py' in /Users/jameswest/Desktop/nfl_predict succeeded in 758ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
262:        self.target_col = None
file update:
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 6c47a91d08f9d309f94323efd4708bb992dc4ce0..5ba68e8bf1acd3a789a76a8857674e6f6433017b
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -26,6 +26,7 @@
 from utils.feature.player_drive_level import build_player_drive_level
 from utils.feature.player_game_level import build_player_game_level
 from utils.feature.opponent_splits import build_opponent_splits
+from utils.feature.labels import DEFAULT_LABEL_VERSION, get_label_spec
 from utils.feature.targets import validate_target_columns
 from utils.feature.daily_totals import build_daily_cache_range
 from utils.feature.rolling_window import add_rolling_features
@@ -233,6 +234,7 @@
     output_path: Path | None = None,
     primary_output_path: Path | None = None,
     cutoff_label: str | None = None,
+    label_version: str | None = None,
 ) -> pl.DataFrame:
     """Run full feature pipeline up to *inclusive* `end_date` for a single cutoff window.
 
@@ -248,6 +250,7 @@
     primary_output = primary_output_path or target_output_path
     current_cutoff_hours = float(get_decision_cutoff_hours())
     clean_min_date, clean_max_date = (None, None)
+    label_version = label_version or DEFAULT_LABEL_VERSION
     if start_date is None or end_date is None:
         clean_min_date, clean_max_date = _get_clean_date_bounds()
 
@@ -294,7 +297,7 @@
             build_player_drive_level(start_date=cur, end_date=chunk_end)
             
             # 5. Player-game aggregations (for rolling window features)
-            build_player_game_level(start_date=cur, end_date=chunk_end)
+            build_player_game_level(start_date=cur, end_date=chunk_end, label_version=label_version)
 
             # advance to next slice
             cur += timedelta(days=chunk_days)
@@ -948,11 +951,19 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    # Log target distribution for anytime_td
-    if "anytime_td" in df_player_game_all.columns:
-        td_count = df_player_game_all["anytime_td"].sum()
-        td_rate = td_count / len(df_player_game_all) * 100
-        logging.info("    Anytime TD rate: %.2f%% (%d/%d)", td_rate, td_count, len(df_player_game_all))
+    spec = get_label_spec(label_version)
+    label_candidates = {spec.primary, "anytime_td"}
+    for label_col in label_candidates:
+        if label_col in df_player_game_all.columns:
+            td_count = df_player_game_all[label_col].sum()
+            td_rate = td_count / len(df_player_game_all) * 100
+            logging.info(
+                "    Label %s rate: %.2f%% (%d/%d)",
+                label_col,
+                td_rate,
+                td_count,
+                len(df_player_game_all),
+            )
     
     return df_player_game_all
 
@@ -965,6 +976,7 @@
     recompute_intermediate: bool = True,
     build_rolling: bool = True,
     cutoff_hours_list: Sequence[float] | None = None,
+    label_version: str | None = None,
 ) -> pl.DataFrame:
     """Build feature matrices for one or more decision cutoff horizons.
 
@@ -992,6 +1004,7 @@
                 output_path=output_path,
                 primary_output_path=primary_output,
                 cutoff_label=label,
+                label_version=label_version,
             )
         if idx == 0:
             primary_result = df
diff --git a/pipeline/train.py b/pipeline/train.py
index 265bc29f4861d2d4d26f54fd7f77304de8fe6742..8d8dfc57bf00bbf0193dc6b51286d20f30451bd9
--- a/pipeline/train.py
+++ b/pipeline/train.py
@@ -98,6 +98,7 @@
     fit_team_conformal_sums,
     composite_sum_interval,
 )
+from utils.feature.targets import require_target_column
 
 # Ignore specific, noisy warnings from dependencies
 warnings.filterwarnings(
diff --git a/utils/feature/labels.py b/utils/feature/labels.py
new file mode 100644
index 0000000000000000000000000000000000000000..b34571f04254cd7bceb9363a190ee7d305852bd5
--- /dev/null
+++ b/utils/feature/labels.py
@@ -0,0 +1,169 @@
+"""Label semantics and versioning for NFL player-level targets.
+
+This module centralizes anytime-TD label definitions so that:
+- Semantics are explicit and versioned.
+- Training can request a specific label column per problem.
+- Feature generation can emit multiple label variants for analysis.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass, field
+from typing import Dict, Iterable, Mapping
+
+import polars as pl
+
+
+@dataclass(frozen=True)
+class LabelRules:
+    """Rules controlling which TD components count toward a label."""
+
+    include_rush: bool = True
+    include_rec: bool = True
+    include_pass_thrown: bool = True  # credit passers for thrown TDs
+    include_other: bool = False  # fumble returns, defensive/special teams if present
+
+
+@dataclass(frozen=True)
+class LabelSpec:
+    """Container describing a label version."""
+
+    name: str
+    primary: str
+    labels: Mapping[str, LabelRules]
+    aliases: Mapping[str, str] = field(default_factory=dict)
+
+    @property
+    def all_columns(self) -> set[str]:
+        cols = set(self.labels.keys())
+        cols.update(self.aliases.keys())
+        return cols
+
+
+DEFAULT_LABEL_VERSION = "v1_any_offense"
+
+
+LABEL_VERSIONS: Dict[str, LabelSpec] = {
+    "v1_any_offense": LabelSpec(
+        name="v1_any_offense",
+        primary="anytime_td_offense",
+        labels={
+            "anytime_td_offense": LabelRules(include_other=False),
+            "anytime_td_rush": LabelRules(include_rush=True, include_rec=False, include_pass_thrown=False, include_other=False),
+            "anytime_td_rec": LabelRules(include_rush=False, include_rec=True, include_pass_thrown=False, include_other=False),
+            "anytime_td_pass_thrown": LabelRules(include_rush=False, include_rec=False, include_pass_thrown=True, include_other=False),
+            "anytime_td_all": LabelRules(include_other=True),
+        },
+        aliases={
+            # Maintain legacy column name as an alias to the offense-only label.
+            "anytime_td": "anytime_td_offense",
+            # Keep td_count pointing to the offense definition for backward compatibility.
+            "td_count": "td_count_offense",
+        },
+    ),
+    "v1_any_all": LabelSpec(
+        name="v1_any_all",
+        primary="anytime_td_all",
+        labels={
+            "anytime_td_all": LabelRules(include_other=True),
+            "anytime_td_offense": LabelRules(include_other=False),
+            "anytime_td_rush": LabelRules(include_rush=True, include_rec=False, include_pass_thrown=False, include_other=False),
+            "anytime_td_rec": LabelRules(include_rush=False, include_rec=True, include_pass_thrown=False, include_other=False),
+            "anytime_td_pass_thrown": LabelRules(include_rush=False, include_rec=False, include_pass_thrown=True, include_other=False),
+        },
+        aliases={
+            "anytime_td": "anytime_td_all",
+            "td_count": "td_count_all",
+        },
+    ),
+}
+
+
+def get_label_spec(version: str | None) -> LabelSpec:
+    """Return a concrete LabelSpec for the requested version (or default)."""
+
+    version = version or DEFAULT_LABEL_VERSION
+    if version not in LABEL_VERSIONS:
+        raise ValueError(
+            f"Unknown label_version '{version}'. "
+            f"Available: {sorted(LABEL_VERSIONS.keys())}"
+        )
+    return LABEL_VERSIONS[version]
+
+
+def _sum_expr(exprs: Iterable[pl.Expr]) -> pl.Expr:
+    exprs = list(exprs)
+    if not exprs:
+        return pl.lit(0).cast(pl.Int64)
+    acc = exprs[0]
+    for expr in exprs[1:]:
+        acc = acc + expr
+    return acc
+
+
+def compute_td_labels(df: pl.DataFrame, *, version: str | None = None) -> pl.DataFrame:
+    """Compute TD label columns according to a label version.
+
+    Parameters
+    ----------
+    df : pl.DataFrame
+        Player-game frame containing touchdown components.
+    version : str | None
+        Label version identifier. Defaults to DEFAULT_LABEL_VERSION.
+    """
+
+    spec = get_label_spec(version)
+    rush = pl.col("rushing_td_count").fill_null(0).cast(pl.Int64)
+    rec = pl.col("receiving_td_count").fill_null(0).cast(pl.Int64)
+    passing = pl.col("passing_td").fill_null(0).cast(pl.Int64)
+    reported_total = pl.col("touchdowns").fill_null(0).cast(pl.Int64)
+
+    offense_total = _sum_expr([rush, rec, passing]).alias("_td_offense_total")
+    other_total = (reported_total - offense_total).clip_min(0).alias("_td_other_total")
+    all_total = (offense_total + other_total).alias("_td_all_total")
+
+    totals_exprs = [
+        offense_total,
+        other_total,
+        all_total,
+    ]
+
+    label_exprs: list[pl.Expr] = [
+        pl.col("_td_offense_total").alias("td_count_offense"),
+        pl.col("_td_all_total").alias("td_count_all"),
+    ]
+
+    for label_name, rules in spec.labels.items():
+        parts: list[pl.Expr] = []
+        if rules.include_rush:
+            parts.append(rush)
+        if rules.include_rec:
+            parts.append(rec)
+        if rules.include_pass_thrown:
+            parts.append(passing)
+        if rules.include_other:
+            parts.append(pl.col("_td_other_total"))
+        total_expr = _sum_expr(parts)
+        label_exprs.append((total_expr > 0).cast(pl.Int8).alias(label_name))
+
+    # Canonical counts for compatibility
+    if "td_count" not in df.columns:
+        # Fill td_count using the alias mapping; default to offense count.
+        target_alias = spec.aliases.get("td_count") or "td_count_offense"
+        label_exprs.append(pl.col(target_alias).alias("td_count"))
+
+    df = df.with_columns(totals_exprs).with_columns(label_exprs)
+
+    # Resolve aliases (e.g., anytime_td -> anytime_td_offense)
+    if spec.aliases:
+        alias_exprs = []
+        for alias_name, source_name in spec.aliases.items():
+            if source_name in df.columns:
+                alias_exprs.append(pl.col(source_name).alias(alias_name))
+        if alias_exprs:
+            df = df.with_columns(alias_exprs)
+
+    drop_cols = [col for col in ("_td_offense_total", "_td_other_total", "_td_all_total") if col in df.columns]
+    if drop_cols:
+        df = df.drop(drop_cols)
+    return df
diff --git a/utils/feature/player_game_level.py b/utils/feature/player_game_level.py
index b6fe516c5f03d575038eef554d5ab39ea5d5c90d..dd4f1f7fcc9de4d8c63390f0a160005eeae48e2f
--- a/utils/feature/player_game_level.py
+++ b/utils/feature/player_game_level.py
@@ -4,8 +4,12 @@
 Each player gets one row per game with their total stats.
 
 Target columns created:
-- anytime_td (binary): Did player score a TD (receiving or rushing)?
-- td_count (int): Number of TDs scored (receiving + rushing)
+- anytime_td_offense (binary): Did player score an offensive TD (rush/rec/pass thrown)?
+- anytime_td_all (binary): Did player score any TD (including defensive/special teams if present)?
+- anytime_td_rush / anytime_td_rec / anytime_td_pass_thrown: Type-specific TD flags.
+- anytime_td (binary): Legacy alias → current label version primary.
+- td_count_offense / td_count_all: TD counts aligned to label semantics.
+- td_count (int): Legacy alias for the primary td_count.
 - passing_td (int): Number of passing TDs (for QBs)
 - receiving_yards (float): Total receiving yards
 - rushing_yards (float): Total rushing yards
@@ -33,6 +37,7 @@
 from utils.collect.nfl_schedules import get_schedule
 from utils.feature.asof import decision_cutoff_hours_default, fallback_cutoff_hours, get_decision_cutoff_hours, get_fallback_cutoff_hours
 from utils.feature.player_drive_level import _load_play_level_data
+from utils.feature.labels import DEFAULT_LABEL_VERSION, compute_td_labels
 from utils.train.injury_availability import (
     load_latest_artifact,
     predict_probabilities as predict_injury_probabilities,
@@ -1582,7 +1587,12 @@
     if flag_cols:
         df = df.with_columns([pl.col(col).cast(pl.Int8) for col in flag_cols])
     return df
-def build_player_game_level(*, start_date: date, end_date: date) -> None:
+def build_player_game_level(
+    *,
+    start_date: date,
+    end_date: date,
+    label_version: str | None = None,
+) -> None:
     """Aggregate play-level data to player-game level.
     
     Creates one row per (player, game) with accumulated stats.
@@ -1680,7 +1690,7 @@
     
     # Merge rows where same player had multiple roles in same game
     # (e.g., QB who also rushed, WR who also rushed)
-    df_merged = _merge_multi_role_players(df_all)
+    df_merged = _merge_multi_role_players(df_all, label_version=label_version or DEFAULT_LABEL_VERSION)
 
     df_merged = _append_zero_usage_players(df_merged, seasons_in_window)
     
@@ -3368,7 +3378,7 @@
     )
 
 
-def _merge_multi_role_players(df: pl.DataFrame) -> pl.DataFrame:
+def _merge_multi_role_players(df: pl.DataFrame, *, label_version: str | None = None) -> pl.DataFrame:
     """Merge stats for players who had multiple roles in same game.
     
     Example: QB who passed and rushed, WR who received and rushed.
@@ -3422,8 +3432,6 @@
         if col in merged.columns:
             merged = merged.with_columns(pl.col(col).fill_null(0))
 
-    # Fallback touchdown logic: if generic touchdown attribution is missing,
-    # derive it from rushing + receiving touchdowns.
     merged = merged.with_columns([
         pl.col("touchdowns").fill_null(0).alias("touchdowns"),
         pl.col("rushing_td_count").fill_null(0).alias("rushing_td_count"),
@@ -3435,17 +3443,5 @@
         pl.col("goal_to_go_carry").fill_null(0).alias("goal_to_go_carry"),
     ])
 
-    merged = merged.with_columns([
-        pl.when(pl.col("touchdowns") > 0)
-        .then(pl.col("touchdowns"))
-        .otherwise(pl.col("rushing_td_count") + pl.col("receiving_td_count"))
-        .cast(pl.Int64)
-        .alias("_total_touchdowns")
-    ])
-
-    merged = merged.with_columns([
-        (pl.col("_total_touchdowns") > 0).cast(pl.Int8).alias("anytime_td"),
-        pl.col("_total_touchdowns").alias("td_count"),
-    ]).drop("_total_touchdowns")
-    
+    merged = compute_td_labels(merged, version=label_version)
     return merged
diff --git a/utils/feature/targets.py b/utils/feature/targets.py
index 7738086dcbfda7432b937cc7d8095988cb0edff0..769ee8735c4024c4410ddd674b11112f093624dd
--- a/utils/feature/targets.py
+++ b/utils/feature/targets.py
@@ -7,6 +7,8 @@
 import polars as pl
 import logging
 
+from utils.feature.labels import DEFAULT_LABEL_VERSION, get_label_spec
+
 logger = logging.getLogger(__name__)
 
 
@@ -14,9 +16,16 @@
 NFL_TARGET_SCHEMA = {
     # Binary classification targets
     "anytime_td": pl.Int8,  # Primary MVP target: did player score a TD?
+    "anytime_td_offense": pl.Int8,
+    "anytime_td_all": pl.Int8,
+    "anytime_td_rush": pl.Int8,
+    "anytime_td_rec": pl.Int8,
+    "anytime_td_pass_thrown": pl.Int8,
     
     # Count/regression targets
     "td_count": pl.Int64,  # Number of TDs scored (receiving + rushing)
+    "td_count_offense": pl.Int64,
+    "td_count_all": pl.Int64,
     "passing_td": pl.Int64,  # Number of passing TDs (QB only)
     
     # Yardage regression targets
@@ -103,4 +112,40 @@
     pl.DataFrame
         DataFrame with validated target columns
     """
-    return validate_target_columns(df, strict=False)
\ No newline at end of file
+    return validate_target_columns(df, strict=False)
+
+
+def require_target_column(
+    df: pl.DataFrame,
+    target_col: str,
+    *,
+    label_version: str | None = None,
+    min_non_null: int = 1,
+) -> pl.DataFrame:
+    """Ensure the configured target column exists and is populated.
+
+    Raises a ValueError if the column is missing or entirely null.
+    """
+
+    if target_col not in df.columns:
+        alias_hint = ""
+        if label_version:
+            try:
+                spec = get_label_spec(label_version or DEFAULT_LABEL_VERSION)
+                if target_col in spec.aliases:
+                    alias_hint = f" Target maps to '{spec.aliases[target_col]}' under {spec.name}."
+            except Exception:
+                alias_hint = ""
+        raise ValueError(f"Target column '{target_col}' not found in feature frame.{alias_hint}")
+
+    series = df[target_col]
+    non_null = series.drop_nulls().height
+    if non_null < min_non_null:
+        raise ValueError(
+            f"Target column '{target_col}' has insufficient non-null rows "
+            f"({non_null}/{len(series)})."
+        )
+    nulls = len(series) - non_null
+    if nulls > 0:
+        logger.warning("Target %s contains %d null rows; they will be dropped.", target_col, nulls)
+    return df


thinking
**Preparing to add attribute in __init__**
exec
/bin/zsh -lc "cd /Users/jameswest/Desktop/nfl_predict && sed -n '240,280p' pipeline/train.py" in /Users/jameswest/Desktop/nfl_predict succeeded in 693ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
        self.model_dir = self.paths.model_dir
        self.metric_dir = self.paths.metric_dir
        self.production_mode = self.cfg.production_mode
        self.base_seed = int(self.cfg.base_seed)
        self.run_tag = str(self.cfg.run_tag or "")
        self.versioning_mode = str(self.cfg.versioning_mode)
        if self.cutoff_label != "default":
            suffix = f"cutoff_{self.cutoff_label}"
            self.run_tag = f"{self.run_tag}_{suffix}" if self.run_tag else suffix
        self.run_id = make_run_id(self.run_tag)

        # Sample weighting configuration
        self.sample_weight_cfg = copy.deepcopy(self.config['training'].get('sample_weighting', {}))

        self.time_col = self.config['data_split']['time_col']
        self.group_col = self.config['data_split']['group_col']  # game_id for NFL

        # Ensure output directories exist
        self.model_dir.mkdir(parents=True, exist_ok=True)
file update:
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 6c47a91d08f9d309f94323efd4708bb992dc4ce0..5ba68e8bf1acd3a789a76a8857674e6f6433017b
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -26,6 +26,7 @@
 from utils.feature.player_drive_level import build_player_drive_level
 from utils.feature.player_game_level import build_player_game_level
 from utils.feature.opponent_splits import build_opponent_splits
+from utils.feature.labels import DEFAULT_LABEL_VERSION, get_label_spec
 from utils.feature.targets import validate_target_columns
 from utils.feature.daily_totals import build_daily_cache_range
 from utils.feature.rolling_window import add_rolling_features
@@ -233,6 +234,7 @@
     output_path: Path | None = None,
     primary_output_path: Path | None = None,
     cutoff_label: str | None = None,
+    label_version: str | None = None,
 ) -> pl.DataFrame:
     """Run full feature pipeline up to *inclusive* `end_date` for a single cutoff window.
 
@@ -248,6 +250,7 @@
     primary_output = primary_output_path or target_output_path
     current_cutoff_hours = float(get_decision_cutoff_hours())
     clean_min_date, clean_max_date = (None, None)
+    label_version = label_version or DEFAULT_LABEL_VERSION
     if start_date is None or end_date is None:
         clean_min_date, clean_max_date = _get_clean_date_bounds()
 
@@ -294,7 +297,7 @@
             build_player_drive_level(start_date=cur, end_date=chunk_end)
             
             # 5. Player-game aggregations (for rolling window features)
-            build_player_game_level(start_date=cur, end_date=chunk_end)
+            build_player_game_level(start_date=cur, end_date=chunk_end, label_version=label_version)
 
             # advance to next slice
             cur += timedelta(days=chunk_days)
@@ -948,11 +951,19 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    # Log target distribution for anytime_td
-    if "anytime_td" in df_player_game_all.columns:
-        td_count = df_player_game_all["anytime_td"].sum()
-        td_rate = td_count / len(df_player_game_all) * 100
-        logging.info("    Anytime TD rate: %.2f%% (%d/%d)", td_rate, td_count, len(df_player_game_all))
+    spec = get_label_spec(label_version)
+    label_candidates = {spec.primary, "anytime_td"}
+    for label_col in label_candidates:
+        if label_col in df_player_game_all.columns:
+            td_count = df_player_game_all[label_col].sum()
+            td_rate = td_count / len(df_player_game_all) * 100
+            logging.info(
+                "    Label %s rate: %.2f%% (%d/%d)",
+                label_col,
+                td_rate,
+                td_count,
+                len(df_player_game_all),
+            )
     
     return df_player_game_all
 
@@ -965,6 +976,7 @@
     recompute_intermediate: bool = True,
     build_rolling: bool = True,
     cutoff_hours_list: Sequence[float] | None = None,
+    label_version: str | None = None,
 ) -> pl.DataFrame:
     """Build feature matrices for one or more decision cutoff horizons.
 
@@ -992,6 +1004,7 @@
                 output_path=output_path,
                 primary_output_path=primary_output,
                 cutoff_label=label,
+                label_version=label_version,
             )
         if idx == 0:
             primary_result = df
diff --git a/pipeline/train.py b/pipeline/train.py
index 265bc29f4861d2d4d26f54fd7f77304de8fe6742..8d8dfc57bf00bbf0193dc6b51286d20f30451bd9
--- a/pipeline/train.py
+++ b/pipeline/train.py
@@ -98,6 +98,7 @@
     fit_team_conformal_sums,
     composite_sum_interval,
 )
+from utils.feature.targets import require_target_column
 
 # Ignore specific, noisy warnings from dependencies
 warnings.filterwarnings(
diff --git a/utils/feature/labels.py b/utils/feature/labels.py
new file mode 100644
index 0000000000000000000000000000000000000000..b34571f04254cd7bceb9363a190ee7d305852bd5
--- /dev/null
+++ b/utils/feature/labels.py
@@ -0,0 +1,169 @@
+"""Label semantics and versioning for NFL player-level targets.
+
+This module centralizes anytime-TD label definitions so that:
+- Semantics are explicit and versioned.
+- Training can request a specific label column per problem.
+- Feature generation can emit multiple label variants for analysis.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass, field
+from typing import Dict, Iterable, Mapping
+
+import polars as pl
+
+
+@dataclass(frozen=True)
+class LabelRules:
+    """Rules controlling which TD components count toward a label."""
+
+    include_rush: bool = True
+    include_rec: bool = True
+    include_pass_thrown: bool = True  # credit passers for thrown TDs
+    include_other: bool = False  # fumble returns, defensive/special teams if present
+
+
+@dataclass(frozen=True)
+class LabelSpec:
+    """Container describing a label version."""
+
+    name: str
+    primary: str
+    labels: Mapping[str, LabelRules]
+    aliases: Mapping[str, str] = field(default_factory=dict)
+
+    @property
+    def all_columns(self) -> set[str]:
+        cols = set(self.labels.keys())
+        cols.update(self.aliases.keys())
+        return cols
+
+
+DEFAULT_LABEL_VERSION = "v1_any_offense"
+
+
+LABEL_VERSIONS: Dict[str, LabelSpec] = {
+    "v1_any_offense": LabelSpec(
+        name="v1_any_offense",
+        primary="anytime_td_offense",
+        labels={
+            "anytime_td_offense": LabelRules(include_other=False),
+            "anytime_td_rush": LabelRules(include_rush=True, include_rec=False, include_pass_thrown=False, include_other=False),
+            "anytime_td_rec": LabelRules(include_rush=False, include_rec=True, include_pass_thrown=False, include_other=False),
+            "anytime_td_pass_thrown": LabelRules(include_rush=False, include_rec=False, include_pass_thrown=True, include_other=False),
+            "anytime_td_all": LabelRules(include_other=True),
+        },
+        aliases={
+            # Maintain legacy column name as an alias to the offense-only label.
+            "anytime_td": "anytime_td_offense",
+            # Keep td_count pointing to the offense definition for backward compatibility.
+            "td_count": "td_count_offense",
+        },
+    ),
+    "v1_any_all": LabelSpec(
+        name="v1_any_all",
+        primary="anytime_td_all",
+        labels={
+            "anytime_td_all": LabelRules(include_other=True),
+            "anytime_td_offense": LabelRules(include_other=False),
+            "anytime_td_rush": LabelRules(include_rush=True, include_rec=False, include_pass_thrown=False, include_other=False),
+            "anytime_td_rec": LabelRules(include_rush=False, include_rec=True, include_pass_thrown=False, include_other=False),
+            "anytime_td_pass_thrown": LabelRules(include_rush=False, include_rec=False, include_pass_thrown=True, include_other=False),
+        },
+        aliases={
+            "anytime_td": "anytime_td_all",
+            "td_count": "td_count_all",
+        },
+    ),
+}
+
+
+def get_label_spec(version: str | None) -> LabelSpec:
+    """Return a concrete LabelSpec for the requested version (or default)."""
+
+    version = version or DEFAULT_LABEL_VERSION
+    if version not in LABEL_VERSIONS:
+        raise ValueError(
+            f"Unknown label_version '{version}'. "
+            f"Available: {sorted(LABEL_VERSIONS.keys())}"
+        )
+    return LABEL_VERSIONS[version]
+
+
+def _sum_expr(exprs: Iterable[pl.Expr]) -> pl.Expr:
+    exprs = list(exprs)
+    if not exprs:
+        return pl.lit(0).cast(pl.Int64)
+    acc = exprs[0]
+    for expr in exprs[1:]:
+        acc = acc + expr
+    return acc
+
+
+def compute_td_labels(df: pl.DataFrame, *, version: str | None = None) -> pl.DataFrame:
+    """Compute TD label columns according to a label version.
+
+    Parameters
+    ----------
+    df : pl.DataFrame
+        Player-game frame containing touchdown components.
+    version : str | None
+        Label version identifier. Defaults to DEFAULT_LABEL_VERSION.
+    """
+
+    spec = get_label_spec(version)
+    rush = pl.col("rushing_td_count").fill_null(0).cast(pl.Int64)
+    rec = pl.col("receiving_td_count").fill_null(0).cast(pl.Int64)
+    passing = pl.col("passing_td").fill_null(0).cast(pl.Int64)
+    reported_total = pl.col("touchdowns").fill_null(0).cast(pl.Int64)
+
+    offense_total = _sum_expr([rush, rec, passing]).alias("_td_offense_total")
+    other_total = (reported_total - offense_total).clip_min(0).alias("_td_other_total")
+    all_total = (offense_total + other_total).alias("_td_all_total")
+
+    totals_exprs = [
+        offense_total,
+        other_total,
+        all_total,
+    ]
+
+    label_exprs: list[pl.Expr] = [
+        pl.col("_td_offense_total").alias("td_count_offense"),
+        pl.col("_td_all_total").alias("td_count_all"),
+    ]
+
+    for label_name, rules in spec.labels.items():
+        parts: list[pl.Expr] = []
+        if rules.include_rush:
+            parts.append(rush)
+        if rules.include_rec:
+            parts.append(rec)
+        if rules.include_pass_thrown:
+            parts.append(passing)
+        if rules.include_other:
+            parts.append(pl.col("_td_other_total"))
+        total_expr = _sum_expr(parts)
+        label_exprs.append((total_expr > 0).cast(pl.Int8).alias(label_name))
+
+    # Canonical counts for compatibility
+    if "td_count" not in df.columns:
+        # Fill td_count using the alias mapping; default to offense count.
+        target_alias = spec.aliases.get("td_count") or "td_count_offense"
+        label_exprs.append(pl.col(target_alias).alias("td_count"))
+
+    df = df.with_columns(totals_exprs).with_columns(label_exprs)
+
+    # Resolve aliases (e.g., anytime_td -> anytime_td_offense)
+    if spec.aliases:
+        alias_exprs = []
+        for alias_name, source_name in spec.aliases.items():
+            if source_name in df.columns:
+                alias_exprs.append(pl.col(source_name).alias(alias_name))
+        if alias_exprs:
+            df = df.with_columns(alias_exprs)
+
+    drop_cols = [col for col in ("_td_offense_total", "_td_other_total", "_td_all_total") if col in df.columns]
+    if drop_cols:
+        df = df.drop(drop_cols)
+    return df
diff --git a/utils/feature/player_game_level.py b/utils/feature/player_game_level.py
index b6fe516c5f03d575038eef554d5ab39ea5d5c90d..dd4f1f7fcc9de4d8c63390f0a160005eeae48e2f
--- a/utils/feature/player_game_level.py
+++ b/utils/feature/player_game_level.py
@@ -4,8 +4,12 @@
 Each player gets one row per game with their total stats.
 
 Target columns created:
-- anytime_td (binary): Did player score a TD (receiving or rushing)?
-- td_count (int): Number of TDs scored (receiving + rushing)
+- anytime_td_offense (binary): Did player score an offensive TD (rush/rec/pass thrown)?
+- anytime_td_all (binary): Did player score any TD (including defensive/special teams if present)?
+- anytime_td_rush / anytime_td_rec / anytime_td_pass_thrown: Type-specific TD flags.
+- anytime_td (binary): Legacy alias → current label version primary.
+- td_count_offense / td_count_all: TD counts aligned to label semantics.
+- td_count (int): Legacy alias for the primary td_count.
 - passing_td (int): Number of passing TDs (for QBs)
 - receiving_yards (float): Total receiving yards
 - rushing_yards (float): Total rushing yards
@@ -33,6 +37,7 @@
 from utils.collect.nfl_schedules import get_schedule
 from utils.feature.asof import decision_cutoff_hours_default, fallback_cutoff_hours, get_decision_cutoff_hours, get_fallback_cutoff_hours
 from utils.feature.player_drive_level import _load_play_level_data
+from utils.feature.labels import DEFAULT_LABEL_VERSION, compute_td_labels
 from utils.train.injury_availability import (
     load_latest_artifact,
     predict_probabilities as predict_injury_probabilities,
@@ -1582,7 +1587,12 @@
     if flag_cols:
         df = df.with_columns([pl.col(col).cast(pl.Int8) for col in flag_cols])
     return df
-def build_player_game_level(*, start_date: date, end_date: date) -> None:
+def build_player_game_level(
+    *,
+    start_date: date,
+    end_date: date,
+    label_version: str | None = None,
+) -> None:
     """Aggregate play-level data to player-game level.
     
     Creates one row per (player, game) with accumulated stats.
@@ -1680,7 +1690,7 @@
     
     # Merge rows where same player had multiple roles in same game
     # (e.g., QB who also rushed, WR who also rushed)
-    df_merged = _merge_multi_role_players(df_all)
+    df_merged = _merge_multi_role_players(df_all, label_version=label_version or DEFAULT_LABEL_VERSION)
 
     df_merged = _append_zero_usage_players(df_merged, seasons_in_window)
     
@@ -3368,7 +3378,7 @@
     )
 
 
-def _merge_multi_role_players(df: pl.DataFrame) -> pl.DataFrame:
+def _merge_multi_role_players(df: pl.DataFrame, *, label_version: str | None = None) -> pl.DataFrame:
     """Merge stats for players who had multiple roles in same game.
     
     Example: QB who passed and rushed, WR who received and rushed.
@@ -3422,8 +3432,6 @@
         if col in merged.columns:
             merged = merged.with_columns(pl.col(col).fill_null(0))
 
-    # Fallback touchdown logic: if generic touchdown attribution is missing,
-    # derive it from rushing + receiving touchdowns.
     merged = merged.with_columns([
         pl.col("touchdowns").fill_null(0).alias("touchdowns"),
         pl.col("rushing_td_count").fill_null(0).alias("rushing_td_count"),
@@ -3435,17 +3443,5 @@
         pl.col("goal_to_go_carry").fill_null(0).alias("goal_to_go_carry"),
     ])
 
-    merged = merged.with_columns([
-        pl.when(pl.col("touchdowns") > 0)
-        .then(pl.col("touchdowns"))
-        .otherwise(pl.col("rushing_td_count") + pl.col("receiving_td_count"))
-        .cast(pl.Int64)
-        .alias("_total_touchdowns")
-    ])
-
-    merged = merged.with_columns([
-        (pl.col("_total_touchdowns") > 0).cast(pl.Int8).alias("anytime_td"),
-        pl.col("_total_touchdowns").alias("td_count"),
-    ]).drop("_total_touchdowns")
-    
+    merged = compute_td_labels(merged, version=label_version)
     return merged
diff --git a/utils/feature/targets.py b/utils/feature/targets.py
index 7738086dcbfda7432b937cc7d8095988cb0edff0..769ee8735c4024c4410ddd674b11112f093624dd
--- a/utils/feature/targets.py
+++ b/utils/feature/targets.py
@@ -7,6 +7,8 @@
 import polars as pl
 import logging
 
+from utils.feature.labels import DEFAULT_LABEL_VERSION, get_label_spec
+
 logger = logging.getLogger(__name__)
 
 
@@ -14,9 +16,16 @@
 NFL_TARGET_SCHEMA = {
     # Binary classification targets
     "anytime_td": pl.Int8,  # Primary MVP target: did player score a TD?
+    "anytime_td_offense": pl.Int8,
+    "anytime_td_all": pl.Int8,
+    "anytime_td_rush": pl.Int8,
+    "anytime_td_rec": pl.Int8,
+    "anytime_td_pass_thrown": pl.Int8,
     
     # Count/regression targets
     "td_count": pl.Int64,  # Number of TDs scored (receiving + rushing)
+    "td_count_offense": pl.Int64,
+    "td_count_all": pl.Int64,
     "passing_td": pl.Int64,  # Number of passing TDs (QB only)
     
     # Yardage regression targets
@@ -103,4 +112,40 @@
     pl.DataFrame
         DataFrame with validated target columns
     """
-    return validate_target_columns(df, strict=False)
\ No newline at end of file
+    return validate_target_columns(df, strict=False)
+
+
+def require_target_column(
+    df: pl.DataFrame,
+    target_col: str,
+    *,
+    label_version: str | None = None,
+    min_non_null: int = 1,
+) -> pl.DataFrame:
+    """Ensure the configured target column exists and is populated.
+
+    Raises a ValueError if the column is missing or entirely null.
+    """
+
+    if target_col not in df.columns:
+        alias_hint = ""
+        if label_version:
+            try:
+                spec = get_label_spec(label_version or DEFAULT_LABEL_VERSION)
+                if target_col in spec.aliases:
+                    alias_hint = f" Target maps to '{spec.aliases[target_col]}' under {spec.name}."
+            except Exception:
+                alias_hint = ""
+        raise ValueError(f"Target column '{target_col}' not found in feature frame.{alias_hint}")
+
+    series = df[target_col]
+    non_null = series.drop_nulls().height
+    if non_null < min_non_null:
+        raise ValueError(
+            f"Target column '{target_col}' has insufficient non-null rows "
+            f"({non_null}/{len(series)})."
+        )
+    nulls = len(series) - non_null
+    if nulls > 0:
+        logger.warning("Target %s contains %d null rows; they will be dropped.", target_col, nulls)
+    return df


thinking
**Adding label_version attribute**
file update
M /Users/jameswest/Desktop/nfl_predict/pipeline/train.py
@@ -262,2 +262,3 @@
         self.target_col = None
+        self.label_version = None
         self.feature_columns = None
apply_patch(auto_approved=true) exited 0 in 72ms:
Success. Updated the following files:
M pipeline/train.py
file update:
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 6c47a91d08f9d309f94323efd4708bb992dc4ce0..5ba68e8bf1acd3a789a76a8857674e6f6433017b
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -26,6 +26,7 @@
 from utils.feature.player_drive_level import build_player_drive_level
 from utils.feature.player_game_level import build_player_game_level
 from utils.feature.opponent_splits import build_opponent_splits
+from utils.feature.labels import DEFAULT_LABEL_VERSION, get_label_spec
 from utils.feature.targets import validate_target_columns
 from utils.feature.daily_totals import build_daily_cache_range
 from utils.feature.rolling_window import add_rolling_features
@@ -233,6 +234,7 @@
     output_path: Path | None = None,
     primary_output_path: Path | None = None,
     cutoff_label: str | None = None,
+    label_version: str | None = None,
 ) -> pl.DataFrame:
     """Run full feature pipeline up to *inclusive* `end_date` for a single cutoff window.
 
@@ -248,6 +250,7 @@
     primary_output = primary_output_path or target_output_path
     current_cutoff_hours = float(get_decision_cutoff_hours())
     clean_min_date, clean_max_date = (None, None)
+    label_version = label_version or DEFAULT_LABEL_VERSION
     if start_date is None or end_date is None:
         clean_min_date, clean_max_date = _get_clean_date_bounds()
 
@@ -294,7 +297,7 @@
             build_player_drive_level(start_date=cur, end_date=chunk_end)
             
             # 5. Player-game aggregations (for rolling window features)
-            build_player_game_level(start_date=cur, end_date=chunk_end)
+            build_player_game_level(start_date=cur, end_date=chunk_end, label_version=label_version)
 
             # advance to next slice
             cur += timedelta(days=chunk_days)
@@ -948,11 +951,19 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    # Log target distribution for anytime_td
-    if "anytime_td" in df_player_game_all.columns:
-        td_count = df_player_game_all["anytime_td"].sum()
-        td_rate = td_count / len(df_player_game_all) * 100
-        logging.info("    Anytime TD rate: %.2f%% (%d/%d)", td_rate, td_count, len(df_player_game_all))
+    spec = get_label_spec(label_version)
+    label_candidates = {spec.primary, "anytime_td"}
+    for label_col in label_candidates:
+        if label_col in df_player_game_all.columns:
+            td_count = df_player_game_all[label_col].sum()
+            td_rate = td_count / len(df_player_game_all) * 100
+            logging.info(
+                "    Label %s rate: %.2f%% (%d/%d)",
+                label_col,
+                td_rate,
+                td_count,
+                len(df_player_game_all),
+            )
     
     return df_player_game_all
 
@@ -965,6 +976,7 @@
     recompute_intermediate: bool = True,
     build_rolling: bool = True,
     cutoff_hours_list: Sequence[float] | None = None,
+    label_version: str | None = None,
 ) -> pl.DataFrame:
     """Build feature matrices for one or more decision cutoff horizons.
 
@@ -992,6 +1004,7 @@
                 output_path=output_path,
                 primary_output_path=primary_output,
                 cutoff_label=label,
+                label_version=label_version,
             )
         if idx == 0:
             primary_result = df
diff --git a/pipeline/train.py b/pipeline/train.py
index 265bc29f4861d2d4d26f54fd7f77304de8fe6742..92f3a070f97cf9315884003db88ef545163f2ff8
--- a/pipeline/train.py
+++ b/pipeline/train.py
@@ -98,6 +98,7 @@
     fit_team_conformal_sums,
     composite_sum_interval,
 )
+from utils.feature.targets import require_target_column
 
 # Ignore specific, noisy warnings from dependencies
 warnings.filterwarnings(
@@ -259,6 +260,7 @@
 
         # Per-problem attributes initialised later
         self.target_col = None
+        self.label_version = None
         self.feature_columns = None
 
         self.models = {}
diff --git a/utils/feature/labels.py b/utils/feature/labels.py
new file mode 100644
index 0000000000000000000000000000000000000000..b34571f04254cd7bceb9363a190ee7d305852bd5
--- /dev/null
+++ b/utils/feature/labels.py
@@ -0,0 +1,169 @@
+"""Label semantics and versioning for NFL player-level targets.
+
+This module centralizes anytime-TD label definitions so that:
+- Semantics are explicit and versioned.
+- Training can request a specific label column per problem.
+- Feature generation can emit multiple label variants for analysis.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass, field
+from typing import Dict, Iterable, Mapping
+
+import polars as pl
+
+
+@dataclass(frozen=True)
+class LabelRules:
+    """Rules controlling which TD components count toward a label."""
+
+    include_rush: bool = True
+    include_rec: bool = True
+    include_pass_thrown: bool = True  # credit passers for thrown TDs
+    include_other: bool = False  # fumble returns, defensive/special teams if present
+
+
+@dataclass(frozen=True)
+class LabelSpec:
+    """Container describing a label version."""
+
+    name: str
+    primary: str
+    labels: Mapping[str, LabelRules]
+    aliases: Mapping[str, str] = field(default_factory=dict)
+
+    @property
+    def all_columns(self) -> set[str]:
+        cols = set(self.labels.keys())
+        cols.update(self.aliases.keys())
+        return cols
+
+
+DEFAULT_LABEL_VERSION = "v1_any_offense"
+
+
+LABEL_VERSIONS: Dict[str, LabelSpec] = {
+    "v1_any_offense": LabelSpec(
+        name="v1_any_offense",
+        primary="anytime_td_offense",
+        labels={
+            "anytime_td_offense": LabelRules(include_other=False),
+            "anytime_td_rush": LabelRules(include_rush=True, include_rec=False, include_pass_thrown=False, include_other=False),
+            "anytime_td_rec": LabelRules(include_rush=False, include_rec=True, include_pass_thrown=False, include_other=False),
+            "anytime_td_pass_thrown": LabelRules(include_rush=False, include_rec=False, include_pass_thrown=True, include_other=False),
+            "anytime_td_all": LabelRules(include_other=True),
+        },
+        aliases={
+            # Maintain legacy column name as an alias to the offense-only label.
+            "anytime_td": "anytime_td_offense",
+            # Keep td_count pointing to the offense definition for backward compatibility.
+            "td_count": "td_count_offense",
+        },
+    ),
+    "v1_any_all": LabelSpec(
+        name="v1_any_all",
+        primary="anytime_td_all",
+        labels={
+            "anytime_td_all": LabelRules(include_other=True),
+            "anytime_td_offense": LabelRules(include_other=False),
+            "anytime_td_rush": LabelRules(include_rush=True, include_rec=False, include_pass_thrown=False, include_other=False),
+            "anytime_td_rec": LabelRules(include_rush=False, include_rec=True, include_pass_thrown=False, include_other=False),
+            "anytime_td_pass_thrown": LabelRules(include_rush=False, include_rec=False, include_pass_thrown=True, include_other=False),
+        },
+        aliases={
+            "anytime_td": "anytime_td_all",
+            "td_count": "td_count_all",
+        },
+    ),
+}
+
+
+def get_label_spec(version: str | None) -> LabelSpec:
+    """Return a concrete LabelSpec for the requested version (or default)."""
+
+    version = version or DEFAULT_LABEL_VERSION
+    if version not in LABEL_VERSIONS:
+        raise ValueError(
+            f"Unknown label_version '{version}'. "
+            f"Available: {sorted(LABEL_VERSIONS.keys())}"
+        )
+    return LABEL_VERSIONS[version]
+
+
+def _sum_expr(exprs: Iterable[pl.Expr]) -> pl.Expr:
+    exprs = list(exprs)
+    if not exprs:
+        return pl.lit(0).cast(pl.Int64)
+    acc = exprs[0]
+    for expr in exprs[1:]:
+        acc = acc + expr
+    return acc
+
+
+def compute_td_labels(df: pl.DataFrame, *, version: str | None = None) -> pl.DataFrame:
+    """Compute TD label columns according to a label version.
+
+    Parameters
+    ----------
+    df : pl.DataFrame
+        Player-game frame containing touchdown components.
+    version : str | None
+        Label version identifier. Defaults to DEFAULT_LABEL_VERSION.
+    """
+
+    spec = get_label_spec(version)
+    rush = pl.col("rushing_td_count").fill_null(0).cast(pl.Int64)
+    rec = pl.col("receiving_td_count").fill_null(0).cast(pl.Int64)
+    passing = pl.col("passing_td").fill_null(0).cast(pl.Int64)
+    reported_total = pl.col("touchdowns").fill_null(0).cast(pl.Int64)
+
+    offense_total = _sum_expr([rush, rec, passing]).alias("_td_offense_total")
+    other_total = (reported_total - offense_total).clip_min(0).alias("_td_other_total")
+    all_total = (offense_total + other_total).alias("_td_all_total")
+
+    totals_exprs = [
+        offense_total,
+        other_total,
+        all_total,
+    ]
+
+    label_exprs: list[pl.Expr] = [
+        pl.col("_td_offense_total").alias("td_count_offense"),
+        pl.col("_td_all_total").alias("td_count_all"),
+    ]
+
+    for label_name, rules in spec.labels.items():
+        parts: list[pl.Expr] = []
+        if rules.include_rush:
+            parts.append(rush)
+        if rules.include_rec:
+            parts.append(rec)
+        if rules.include_pass_thrown:
+            parts.append(passing)
+        if rules.include_other:
+            parts.append(pl.col("_td_other_total"))
+        total_expr = _sum_expr(parts)
+        label_exprs.append((total_expr > 0).cast(pl.Int8).alias(label_name))
+
+    # Canonical counts for compatibility
+    if "td_count" not in df.columns:
+        # Fill td_count using the alias mapping; default to offense count.
+        target_alias = spec.aliases.get("td_count") or "td_count_offense"
+        label_exprs.append(pl.col(target_alias).alias("td_count"))
+
+    df = df.with_columns(totals_exprs).with_columns(label_exprs)
+
+    # Resolve aliases (e.g., anytime_td -> anytime_td_offense)
+    if spec.aliases:
+        alias_exprs = []
+        for alias_name, source_name in spec.aliases.items():
+            if source_name in df.columns:
+                alias_exprs.append(pl.col(source_name).alias(alias_name))
+        if alias_exprs:
+            df = df.with_columns(alias_exprs)
+
+    drop_cols = [col for col in ("_td_offense_total", "_td_other_total", "_td_all_total") if col in df.columns]
+    if drop_cols:
+        df = df.drop(drop_cols)
+    return df
diff --git a/utils/feature/player_game_level.py b/utils/feature/player_game_level.py
index b6fe516c5f03d575038eef554d5ab39ea5d5c90d..dd4f1f7fcc9de4d8c63390f0a160005eeae48e2f
--- a/utils/feature/player_game_level.py
+++ b/utils/feature/player_game_level.py
@@ -4,8 +4,12 @@
 Each player gets one row per game with their total stats.
 
 Target columns created:
-- anytime_td (binary): Did player score a TD (receiving or rushing)?
-- td_count (int): Number of TDs scored (receiving + rushing)
+- anytime_td_offense (binary): Did player score an offensive TD (rush/rec/pass thrown)?
+- anytime_td_all (binary): Did player score any TD (including defensive/special teams if present)?
+- anytime_td_rush / anytime_td_rec / anytime_td_pass_thrown: Type-specific TD flags.
+- anytime_td (binary): Legacy alias → current label version primary.
+- td_count_offense / td_count_all: TD counts aligned to label semantics.
+- td_count (int): Legacy alias for the primary td_count.
 - passing_td (int): Number of passing TDs (for QBs)
 - receiving_yards (float): Total receiving yards
 - rushing_yards (float): Total rushing yards
@@ -33,6 +37,7 @@
 from utils.collect.nfl_schedules import get_schedule
 from utils.feature.asof import decision_cutoff_hours_default, fallback_cutoff_hours, get_decision_cutoff_hours, get_fallback_cutoff_hours
 from utils.feature.player_drive_level import _load_play_level_data
+from utils.feature.labels import DEFAULT_LABEL_VERSION, compute_td_labels
 from utils.train.injury_availability import (
     load_latest_artifact,
     predict_probabilities as predict_injury_probabilities,
@@ -1582,7 +1587,12 @@
     if flag_cols:
         df = df.with_columns([pl.col(col).cast(pl.Int8) for col in flag_cols])
     return df
-def build_player_game_level(*, start_date: date, end_date: date) -> None:
+def build_player_game_level(
+    *,
+    start_date: date,
+    end_date: date,
+    label_version: str | None = None,
+) -> None:
     """Aggregate play-level data to player-game level.
     
     Creates one row per (player, game) with accumulated stats.
@@ -1680,7 +1690,7 @@
     
     # Merge rows where same player had multiple roles in same game
     # (e.g., QB who also rushed, WR who also rushed)
-    df_merged = _merge_multi_role_players(df_all)
+    df_merged = _merge_multi_role_players(df_all, label_version=label_version or DEFAULT_LABEL_VERSION)
 
     df_merged = _append_zero_usage_players(df_merged, seasons_in_window)
     
@@ -3368,7 +3378,7 @@
     )
 
 
-def _merge_multi_role_players(df: pl.DataFrame) -> pl.DataFrame:
+def _merge_multi_role_players(df: pl.DataFrame, *, label_version: str | None = None) -> pl.DataFrame:
     """Merge stats for players who had multiple roles in same game.
     
     Example: QB who passed and rushed, WR who received and rushed.
@@ -3422,8 +3432,6 @@
         if col in merged.columns:
             merged = merged.with_columns(pl.col(col).fill_null(0))
 
-    # Fallback touchdown logic: if generic touchdown attribution is missing,
-    # derive it from rushing + receiving touchdowns.
     merged = merged.with_columns([
         pl.col("touchdowns").fill_null(0).alias("touchdowns"),
         pl.col("rushing_td_count").fill_null(0).alias("rushing_td_count"),
@@ -3435,17 +3443,5 @@
         pl.col("goal_to_go_carry").fill_null(0).alias("goal_to_go_carry"),
     ])
 
-    merged = merged.with_columns([
-        pl.when(pl.col("touchdowns") > 0)
-        .then(pl.col("touchdowns"))
-        .otherwise(pl.col("rushing_td_count") + pl.col("receiving_td_count"))
-        .cast(pl.Int64)
-        .alias("_total_touchdowns")
-    ])
-
-    merged = merged.with_columns([
-        (pl.col("_total_touchdowns") > 0).cast(pl.Int8).alias("anytime_td"),
-        pl.col("_total_touchdowns").alias("td_count"),
-    ]).drop("_total_touchdowns")
-    
+    merged = compute_td_labels(merged, version=label_version)
     return merged
diff --git a/utils/feature/targets.py b/utils/feature/targets.py
index 7738086dcbfda7432b937cc7d8095988cb0edff0..769ee8735c4024c4410ddd674b11112f093624dd
--- a/utils/feature/targets.py
+++ b/utils/feature/targets.py
@@ -7,6 +7,8 @@
 import polars as pl
 import logging
 
+from utils.feature.labels import DEFAULT_LABEL_VERSION, get_label_spec
+
 logger = logging.getLogger(__name__)
 
 
@@ -14,9 +16,16 @@
 NFL_TARGET_SCHEMA = {
     # Binary classification targets
     "anytime_td": pl.Int8,  # Primary MVP target: did player score a TD?
+    "anytime_td_offense": pl.Int8,
+    "anytime_td_all": pl.Int8,
+    "anytime_td_rush": pl.Int8,
+    "anytime_td_rec": pl.Int8,
+    "anytime_td_pass_thrown": pl.Int8,
     
     # Count/regression targets
     "td_count": pl.Int64,  # Number of TDs scored (receiving + rushing)
+    "td_count_offense": pl.Int64,
+    "td_count_all": pl.Int64,
     "passing_td": pl.Int64,  # Number of passing TDs (QB only)
     
     # Yardage regression targets
@@ -103,4 +112,40 @@
     pl.DataFrame
         DataFrame with validated target columns
     """
-    return validate_target_columns(df, strict=False)
\ No newline at end of file
+    return validate_target_columns(df, strict=False)
+
+
+def require_target_column(
+    df: pl.DataFrame,
+    target_col: str,
+    *,
+    label_version: str | None = None,
+    min_non_null: int = 1,
+) -> pl.DataFrame:
+    """Ensure the configured target column exists and is populated.
+
+    Raises a ValueError if the column is missing or entirely null.
+    """
+
+    if target_col not in df.columns:
+        alias_hint = ""
+        if label_version:
+            try:
+                spec = get_label_spec(label_version or DEFAULT_LABEL_VERSION)
+                if target_col in spec.aliases:
+                    alias_hint = f" Target maps to '{spec.aliases[target_col]}' under {spec.name}."
+            except Exception:
+                alias_hint = ""
+        raise ValueError(f"Target column '{target_col}' not found in feature frame.{alias_hint}")
+
+    series = df[target_col]
+    non_null = series.drop_nulls().height
+    if non_null < min_non_null:
+        raise ValueError(
+            f"Target column '{target_col}' has insufficient non-null rows "
+            f"({non_null}/{len(series)})."
+        )
+    nulls = len(series) - non_null
+    if nulls > 0:
+        logger.warning("Target %s contains %d null rows; they will be dropped.", target_col, nulls)
+    return df

file update:
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 6c47a91d08f9d309f94323efd4708bb992dc4ce0..5ba68e8bf1acd3a789a76a8857674e6f6433017b
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -26,6 +26,7 @@
 from utils.feature.player_drive_level import build_player_drive_level
 from utils.feature.player_game_level import build_player_game_level
 from utils.feature.opponent_splits import build_opponent_splits
+from utils.feature.labels import DEFAULT_LABEL_VERSION, get_label_spec
 from utils.feature.targets import validate_target_columns
 from utils.feature.daily_totals import build_daily_cache_range
 from utils.feature.rolling_window import add_rolling_features
@@ -233,6 +234,7 @@
     output_path: Path | None = None,
     primary_output_path: Path | None = None,
     cutoff_label: str | None = None,
+    label_version: str | None = None,
 ) -> pl.DataFrame:
     """Run full feature pipeline up to *inclusive* `end_date` for a single cutoff window.
 
@@ -248,6 +250,7 @@
     primary_output = primary_output_path or target_output_path
     current_cutoff_hours = float(get_decision_cutoff_hours())
     clean_min_date, clean_max_date = (None, None)
+    label_version = label_version or DEFAULT_LABEL_VERSION
     if start_date is None or end_date is None:
         clean_min_date, clean_max_date = _get_clean_date_bounds()
 
@@ -294,7 +297,7 @@
             build_player_drive_level(start_date=cur, end_date=chunk_end)
             
             # 5. Player-game aggregations (for rolling window features)
-            build_player_game_level(start_date=cur, end_date=chunk_end)
+            build_player_game_level(start_date=cur, end_date=chunk_end, label_version=label_version)
 
             # advance to next slice
             cur += timedelta(days=chunk_days)
@@ -948,11 +951,19 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    # Log target distribution for anytime_td
-    if "anytime_td" in df_player_game_all.columns:
-        td_count = df_player_game_all["anytime_td"].sum()
-        td_rate = td_count / len(df_player_game_all) * 100
-        logging.info("    Anytime TD rate: %.2f%% (%d/%d)", td_rate, td_count, len(df_player_game_all))
+    spec = get_label_spec(label_version)
+    label_candidates = {spec.primary, "anytime_td"}
+    for label_col in label_candidates:
+        if label_col in df_player_game_all.columns:
+            td_count = df_player_game_all[label_col].sum()
+            td_rate = td_count / len(df_player_game_all) * 100
+            logging.info(
+                "    Label %s rate: %.2f%% (%d/%d)",
+                label_col,
+                td_rate,
+                td_count,
+                len(df_player_game_all),
+            )
     
     return df_player_game_all
 
@@ -965,6 +976,7 @@
     recompute_intermediate: bool = True,
     build_rolling: bool = True,
     cutoff_hours_list: Sequence[float] | None = None,
+    label_version: str | None = None,
 ) -> pl.DataFrame:
     """Build feature matrices for one or more decision cutoff horizons.
 
@@ -992,6 +1004,7 @@
                 output_path=output_path,
                 primary_output_path=primary_output,
                 cutoff_label=label,
+                label_version=label_version,
             )
         if idx == 0:
             primary_result = df
diff --git a/pipeline/train.py b/pipeline/train.py
index 265bc29f4861d2d4d26f54fd7f77304de8fe6742..92f3a070f97cf9315884003db88ef545163f2ff8
--- a/pipeline/train.py
+++ b/pipeline/train.py
@@ -98,6 +98,7 @@
     fit_team_conformal_sums,
     composite_sum_interval,
 )
+from utils.feature.targets import require_target_column
 
 # Ignore specific, noisy warnings from dependencies
 warnings.filterwarnings(
@@ -259,6 +260,7 @@
 
         # Per-problem attributes initialised later
         self.target_col = None
+        self.label_version = None
         self.feature_columns = None
 
         self.models = {}
diff --git a/utils/feature/labels.py b/utils/feature/labels.py
new file mode 100644
index 0000000000000000000000000000000000000000..b34571f04254cd7bceb9363a190ee7d305852bd5
--- /dev/null
+++ b/utils/feature/labels.py
@@ -0,0 +1,169 @@
+"""Label semantics and versioning for NFL player-level targets.
+
+This module centralizes anytime-TD label definitions so that:
+- Semantics are explicit and versioned.
+- Training can request a specific label column per problem.
+- Feature generation can emit multiple label variants for analysis.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass, field
+from typing import Dict, Iterable, Mapping
+
+import polars as pl
+
+
+@dataclass(frozen=True)
+class LabelRules:
+    """Rules controlling which TD components count toward a label."""
+
+    include_rush: bool = True
+    include_rec: bool = True
+    include_pass_thrown: bool = True  # credit passers for thrown TDs
+    include_other: bool = False  # fumble returns, defensive/special teams if present
+
+
+@dataclass(frozen=True)
+class LabelSpec:
+    """Container describing a label version."""
+
+    name: str
+    primary: str
+    labels: Mapping[str, LabelRules]
+    aliases: Mapping[str, str] = field(default_factory=dict)
+
+    @property
+    def all_columns(self) -> set[str]:
+        cols = set(self.labels.keys())
+        cols.update(self.aliases.keys())
+        return cols
+
+
+DEFAULT_LABEL_VERSION = "v1_any_offense"
+
+
+LABEL_VERSIONS: Dict[str, LabelSpec] = {
+    "v1_any_offense": LabelSpec(
+        name="v1_any_offense",
+        primary="anytime_td_offense",
+        labels={
+            "anytime_td_offense": LabelRules(include_other=False),
+            "anytime_td_rush": LabelRules(include_rush=True, include_rec=False, include_pass_thrown=False, include_other=False),
+            "anytime_td_rec": LabelRules(include_rush=False, include_rec=True, include_pass_thrown=False, include_other=False),
+            "anytime_td_pass_thrown": LabelRules(include_rush=False, include_rec=False, include_pass_thrown=True, include_other=False),
+            "anytime_td_all": LabelRules(include_other=True),
+        },
+        aliases={
+            # Maintain legacy column name as an alias to the offense-only label.
+            "anytime_td": "anytime_td_offense",
+            # Keep td_count pointing to the offense definition for backward compatibility.
+            "td_count": "td_count_offense",
+        },
+    ),
+    "v1_any_all": LabelSpec(
+        name="v1_any_all",
+        primary="anytime_td_all",
+        labels={
+            "anytime_td_all": LabelRules(include_other=True),
+            "anytime_td_offense": LabelRules(include_other=False),
+            "anytime_td_rush": LabelRules(include_rush=True, include_rec=False, include_pass_thrown=False, include_other=False),
+            "anytime_td_rec": LabelRules(include_rush=False, include_rec=True, include_pass_thrown=False, include_other=False),
+            "anytime_td_pass_thrown": LabelRules(include_rush=False, include_rec=False, include_pass_thrown=True, include_other=False),
+        },
+        aliases={
+            "anytime_td": "anytime_td_all",
+            "td_count": "td_count_all",
+        },
+    ),
+}
+
+
+def get_label_spec(version: str | None) -> LabelSpec:
+    """Return a concrete LabelSpec for the requested version (or default)."""
+
+    version = version or DEFAULT_LABEL_VERSION
+    if version not in LABEL_VERSIONS:
+        raise ValueError(
+            f"Unknown label_version '{version}'. "
+            f"Available: {sorted(LABEL_VERSIONS.keys())}"
+        )
+    return LABEL_VERSIONS[version]
+
+
+def _sum_expr(exprs: Iterable[pl.Expr]) -> pl.Expr:
+    exprs = list(exprs)
+    if not exprs:
+        return pl.lit(0).cast(pl.Int64)
+    acc = exprs[0]
+    for expr in exprs[1:]:
+        acc = acc + expr
+    return acc
+
+
+def compute_td_labels(df: pl.DataFrame, *, version: str | None = None) -> pl.DataFrame:
+    """Compute TD label columns according to a label version.
+
+    Parameters
+    ----------
+    df : pl.DataFrame
+        Player-game frame containing touchdown components.
+    version : str | None
+        Label version identifier. Defaults to DEFAULT_LABEL_VERSION.
+    """
+
+    spec = get_label_spec(version)
+    rush = pl.col("rushing_td_count").fill_null(0).cast(pl.Int64)
+    rec = pl.col("receiving_td_count").fill_null(0).cast(pl.Int64)
+    passing = pl.col("passing_td").fill_null(0).cast(pl.Int64)
+    reported_total = pl.col("touchdowns").fill_null(0).cast(pl.Int64)
+
+    offense_total = _sum_expr([rush, rec, passing]).alias("_td_offense_total")
+    other_total = (reported_total - offense_total).clip_min(0).alias("_td_other_total")
+    all_total = (offense_total + other_total).alias("_td_all_total")
+
+    totals_exprs = [
+        offense_total,
+        other_total,
+        all_total,
+    ]
+
+    label_exprs: list[pl.Expr] = [
+        pl.col("_td_offense_total").alias("td_count_offense"),
+        pl.col("_td_all_total").alias("td_count_all"),
+    ]
+
+    for label_name, rules in spec.labels.items():
+        parts: list[pl.Expr] = []
+        if rules.include_rush:
+            parts.append(rush)
+        if rules.include_rec:
+            parts.append(rec)
+        if rules.include_pass_thrown:
+            parts.append(passing)
+        if rules.include_other:
+            parts.append(pl.col("_td_other_total"))
+        total_expr = _sum_expr(parts)
+        label_exprs.append((total_expr > 0).cast(pl.Int8).alias(label_name))
+
+    # Canonical counts for compatibility
+    if "td_count" not in df.columns:
+        # Fill td_count using the alias mapping; default to offense count.
+        target_alias = spec.aliases.get("td_count") or "td_count_offense"
+        label_exprs.append(pl.col(target_alias).alias("td_count"))
+
+    df = df.with_columns(totals_exprs).with_columns(label_exprs)
+
+    # Resolve aliases (e.g., anytime_td -> anytime_td_offense)
+    if spec.aliases:
+        alias_exprs = []
+        for alias_name, source_name in spec.aliases.items():
+            if source_name in df.columns:
+                alias_exprs.append(pl.col(source_name).alias(alias_name))
+        if alias_exprs:
+            df = df.with_columns(alias_exprs)
+
+    drop_cols = [col for col in ("_td_offense_total", "_td_other_total", "_td_all_total") if col in df.columns]
+    if drop_cols:
+        df = df.drop(drop_cols)
+    return df
diff --git a/utils/feature/player_game_level.py b/utils/feature/player_game_level.py
index b6fe516c5f03d575038eef554d5ab39ea5d5c90d..dd4f1f7fcc9de4d8c63390f0a160005eeae48e2f
--- a/utils/feature/player_game_level.py
+++ b/utils/feature/player_game_level.py
@@ -4,8 +4,12 @@
 Each player gets one row per game with their total stats.
 
 Target columns created:
-- anytime_td (binary): Did player score a TD (receiving or rushing)?
-- td_count (int): Number of TDs scored (receiving + rushing)
+- anytime_td_offense (binary): Did player score an offensive TD (rush/rec/pass thrown)?
+- anytime_td_all (binary): Did player score any TD (including defensive/special teams if present)?
+- anytime_td_rush / anytime_td_rec / anytime_td_pass_thrown: Type-specific TD flags.
+- anytime_td (binary): Legacy alias → current label version primary.
+- td_count_offense / td_count_all: TD counts aligned to label semantics.
+- td_count (int): Legacy alias for the primary td_count.
 - passing_td (int): Number of passing TDs (for QBs)
 - receiving_yards (float): Total receiving yards
 - rushing_yards (float): Total rushing yards
@@ -33,6 +37,7 @@
 from utils.collect.nfl_schedules import get_schedule
 from utils.feature.asof import decision_cutoff_hours_default, fallback_cutoff_hours, get_decision_cutoff_hours, get_fallback_cutoff_hours
 from utils.feature.player_drive_level import _load_play_level_data
+from utils.feature.labels import DEFAULT_LABEL_VERSION, compute_td_labels
 from utils.train.injury_availability import (
     load_latest_artifact,
     predict_probabilities as predict_injury_probabilities,
@@ -1582,7 +1587,12 @@
     if flag_cols:
         df = df.with_columns([pl.col(col).cast(pl.Int8) for col in flag_cols])
     return df
-def build_player_game_level(*, start_date: date, end_date: date) -> None:
+def build_player_game_level(
+    *,
+    start_date: date,
+    end_date: date,
+    label_version: str | None = None,
+) -> None:
     """Aggregate play-level data to player-game level.
     
     Creates one row per (player, game) with accumulated stats.
@@ -1680,7 +1690,7 @@
     
     # Merge rows where same player had multiple roles in same game
     # (e.g., QB who also rushed, WR who also rushed)
-    df_merged = _merge_multi_role_players(df_all)
+    df_merged = _merge_multi_role_players(df_all, label_version=label_version or DEFAULT_LABEL_VERSION)
 
     df_merged = _append_zero_usage_players(df_merged, seasons_in_window)
     
@@ -3368,7 +3378,7 @@
     )
 
 
-def _merge_multi_role_players(df: pl.DataFrame) -> pl.DataFrame:
+def _merge_multi_role_players(df: pl.DataFrame, *, label_version: str | None = None) -> pl.DataFrame:
     """Merge stats for players who had multiple roles in same game.
     
     Example: QB who passed and rushed, WR who received and rushed.
@@ -3422,8 +3432,6 @@
         if col in merged.columns:
             merged = merged.with_columns(pl.col(col).fill_null(0))
 
-    # Fallback touchdown logic: if generic touchdown attribution is missing,
-    # derive it from rushing + receiving touchdowns.
     merged = merged.with_columns([
         pl.col("touchdowns").fill_null(0).alias("touchdowns"),
         pl.col("rushing_td_count").fill_null(0).alias("rushing_td_count"),
@@ -3435,17 +3443,5 @@
         pl.col("goal_to_go_carry").fill_null(0).alias("goal_to_go_carry"),
     ])
 
-    merged = merged.with_columns([
-        pl.when(pl.col("touchdowns") > 0)
-        .then(pl.col("touchdowns"))
-        .otherwise(pl.col("rushing_td_count") + pl.col("receiving_td_count"))
-        .cast(pl.Int64)
-        .alias("_total_touchdowns")
-    ])
-
-    merged = merged.with_columns([
-        (pl.col("_total_touchdowns") > 0).cast(pl.Int8).alias("anytime_td"),
-        pl.col("_total_touchdowns").alias("td_count"),
-    ]).drop("_total_touchdowns")
-    
+    merged = compute_td_labels(merged, version=label_version)
     return merged
diff --git a/utils/feature/targets.py b/utils/feature/targets.py
index 7738086dcbfda7432b937cc7d8095988cb0edff0..769ee8735c4024c4410ddd674b11112f093624dd
--- a/utils/feature/targets.py
+++ b/utils/feature/targets.py
@@ -7,6 +7,8 @@
 import polars as pl
 import logging
 
+from utils.feature.labels import DEFAULT_LABEL_VERSION, get_label_spec
+
 logger = logging.getLogger(__name__)
 
 
@@ -14,9 +16,16 @@
 NFL_TARGET_SCHEMA = {
     # Binary classification targets
     "anytime_td": pl.Int8,  # Primary MVP target: did player score a TD?
+    "anytime_td_offense": pl.Int8,
+    "anytime_td_all": pl.Int8,
+    "anytime_td_rush": pl.Int8,
+    "anytime_td_rec": pl.Int8,
+    "anytime_td_pass_thrown": pl.Int8,
     
     # Count/regression targets
     "td_count": pl.Int64,  # Number of TDs scored (receiving + rushing)
+    "td_count_offense": pl.Int64,
+    "td_count_all": pl.Int64,
     "passing_td": pl.Int64,  # Number of passing TDs (QB only)
     
     # Yardage regression targets
@@ -103,4 +112,40 @@
     pl.DataFrame
         DataFrame with validated target columns
     """
-    return validate_target_columns(df, strict=False)
\ No newline at end of file
+    return validate_target_columns(df, strict=False)
+
+
+def require_target_column(
+    df: pl.DataFrame,
+    target_col: str,
+    *,
+    label_version: str | None = None,
+    min_non_null: int = 1,
+) -> pl.DataFrame:
+    """Ensure the configured target column exists and is populated.
+
+    Raises a ValueError if the column is missing or entirely null.
+    """
+
+    if target_col not in df.columns:
+        alias_hint = ""
+        if label_version:
+            try:
+                spec = get_label_spec(label_version or DEFAULT_LABEL_VERSION)
+                if target_col in spec.aliases:
+                    alias_hint = f" Target maps to '{spec.aliases[target_col]}' under {spec.name}."
+            except Exception:
+                alias_hint = ""
+        raise ValueError(f"Target column '{target_col}' not found in feature frame.{alias_hint}")
+
+    series = df[target_col]
+    non_null = series.drop_nulls().height
+    if non_null < min_non_null:
+        raise ValueError(
+            f"Target column '{target_col}' has insufficient non-null rows "
+            f"({non_null}/{len(series)})."
+        )
+    nulls = len(series) - non_null
+    if nulls > 0:
+        logger.warning("Target %s contains %d null rows; they will be dropped.", target_col, nulls)
+    return df


thinking
**Injecting label_version handling**
file update
M /Users/jameswest/Desktop/nfl_predict/pipeline/train.py
@@ -2167,2 +2167,3 @@
             self.target_col = problem_copy['target_col']
+            self.label_version = problem_copy.get('label_version') or problem_copy.get("labels", {}).get("version")
             derived_cfg = problem_copy.get('derived_target')
@@ -2273,2 +2274,8 @@
             df_problem = self._apply_problem_level_overrides(df_problem, problem_copy)
+            df_problem = require_target_column(
+                df_problem,
+                self.target_col,
+                label_version=self.label_version,
+                min_non_null=1,
+            )
             
apply_patch(auto_approved=true) exited 0 in 82ms:
Success. Updated the following files:
M pipeline/train.py
file update:
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 6c47a91d08f9d309f94323efd4708bb992dc4ce0..5ba68e8bf1acd3a789a76a8857674e6f6433017b
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -26,6 +26,7 @@
 from utils.feature.player_drive_level import build_player_drive_level
 from utils.feature.player_game_level import build_player_game_level
 from utils.feature.opponent_splits import build_opponent_splits
+from utils.feature.labels import DEFAULT_LABEL_VERSION, get_label_spec
 from utils.feature.targets import validate_target_columns
 from utils.feature.daily_totals import build_daily_cache_range
 from utils.feature.rolling_window import add_rolling_features
@@ -233,6 +234,7 @@
     output_path: Path | None = None,
     primary_output_path: Path | None = None,
     cutoff_label: str | None = None,
+    label_version: str | None = None,
 ) -> pl.DataFrame:
     """Run full feature pipeline up to *inclusive* `end_date` for a single cutoff window.
 
@@ -248,6 +250,7 @@
     primary_output = primary_output_path or target_output_path
     current_cutoff_hours = float(get_decision_cutoff_hours())
     clean_min_date, clean_max_date = (None, None)
+    label_version = label_version or DEFAULT_LABEL_VERSION
     if start_date is None or end_date is None:
         clean_min_date, clean_max_date = _get_clean_date_bounds()
 
@@ -294,7 +297,7 @@
             build_player_drive_level(start_date=cur, end_date=chunk_end)
             
             # 5. Player-game aggregations (for rolling window features)
-            build_player_game_level(start_date=cur, end_date=chunk_end)
+            build_player_game_level(start_date=cur, end_date=chunk_end, label_version=label_version)
 
             # advance to next slice
             cur += timedelta(days=chunk_days)
@@ -948,11 +951,19 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    # Log target distribution for anytime_td
-    if "anytime_td" in df_player_game_all.columns:
-        td_count = df_player_game_all["anytime_td"].sum()
-        td_rate = td_count / len(df_player_game_all) * 100
-        logging.info("    Anytime TD rate: %.2f%% (%d/%d)", td_rate, td_count, len(df_player_game_all))
+    spec = get_label_spec(label_version)
+    label_candidates = {spec.primary, "anytime_td"}
+    for label_col in label_candidates:
+        if label_col in df_player_game_all.columns:
+            td_count = df_player_game_all[label_col].sum()
+            td_rate = td_count / len(df_player_game_all) * 100
+            logging.info(
+                "    Label %s rate: %.2f%% (%d/%d)",
+                label_col,
+                td_rate,
+                td_count,
+                len(df_player_game_all),
+            )
     
     return df_player_game_all
 
@@ -965,6 +976,7 @@
     recompute_intermediate: bool = True,
     build_rolling: bool = True,
     cutoff_hours_list: Sequence[float] | None = None,
+    label_version: str | None = None,
 ) -> pl.DataFrame:
     """Build feature matrices for one or more decision cutoff horizons.
 
@@ -992,6 +1004,7 @@
                 output_path=output_path,
                 primary_output_path=primary_output,
                 cutoff_label=label,
+                label_version=label_version,
             )
         if idx == 0:
             primary_result = df
diff --git a/pipeline/train.py b/pipeline/train.py
index 265bc29f4861d2d4d26f54fd7f77304de8fe6742..fe70207dcdf25d209ee3ad55080b7ce826347c44
--- a/pipeline/train.py
+++ b/pipeline/train.py
@@ -98,6 +98,7 @@
     fit_team_conformal_sums,
     composite_sum_interval,
 )
+from utils.feature.targets import require_target_column
 
 # Ignore specific, noisy warnings from dependencies
 warnings.filterwarnings(
@@ -259,6 +260,7 @@
 
         # Per-problem attributes initialised later
         self.target_col = None
+        self.label_version = None
         self.feature_columns = None
 
         self.models = {}
@@ -2163,6 +2165,7 @@
             
             problem_copy = copy.deepcopy(problem)
             self.target_col = problem_copy['target_col']
+            self.label_version = problem_copy.get('label_version') or problem_copy.get("labels", {}).get("version")
             derived_cfg = problem_copy.get('derived_target')
             target_load_cols: list[str] = []
             if derived_cfg:
@@ -2269,6 +2272,12 @@
                 df_problem = df_problem.loc[:, ~df_problem.columns.duplicated()]
 
             df_problem = self._apply_problem_level_overrides(df_problem, problem_copy)
+            df_problem = require_target_column(
+                df_problem,
+                self.target_col,
+                label_version=self.label_version,
+                min_non_null=1,
+            )
             
             # Merge input predictions if required
             if input_preds:
diff --git a/utils/feature/labels.py b/utils/feature/labels.py
new file mode 100644
index 0000000000000000000000000000000000000000..b34571f04254cd7bceb9363a190ee7d305852bd5
--- /dev/null
+++ b/utils/feature/labels.py
@@ -0,0 +1,169 @@
+"""Label semantics and versioning for NFL player-level targets.
+
+This module centralizes anytime-TD label definitions so that:
+- Semantics are explicit and versioned.
+- Training can request a specific label column per problem.
+- Feature generation can emit multiple label variants for analysis.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass, field
+from typing import Dict, Iterable, Mapping
+
+import polars as pl
+
+
+@dataclass(frozen=True)
+class LabelRules:
+    """Rules controlling which TD components count toward a label."""
+
+    include_rush: bool = True
+    include_rec: bool = True
+    include_pass_thrown: bool = True  # credit passers for thrown TDs
+    include_other: bool = False  # fumble returns, defensive/special teams if present
+
+
+@dataclass(frozen=True)
+class LabelSpec:
+    """Container describing a label version."""
+
+    name: str
+    primary: str
+    labels: Mapping[str, LabelRules]
+    aliases: Mapping[str, str] = field(default_factory=dict)
+
+    @property
+    def all_columns(self) -> set[str]:
+        cols = set(self.labels.keys())
+        cols.update(self.aliases.keys())
+        return cols
+
+
+DEFAULT_LABEL_VERSION = "v1_any_offense"
+
+
+LABEL_VERSIONS: Dict[str, LabelSpec] = {
+    "v1_any_offense": LabelSpec(
+        name="v1_any_offense",
+        primary="anytime_td_offense",
+        labels={
+            "anytime_td_offense": LabelRules(include_other=False),
+            "anytime_td_rush": LabelRules(include_rush=True, include_rec=False, include_pass_thrown=False, include_other=False),
+            "anytime_td_rec": LabelRules(include_rush=False, include_rec=True, include_pass_thrown=False, include_other=False),
+            "anytime_td_pass_thrown": LabelRules(include_rush=False, include_rec=False, include_pass_thrown=True, include_other=False),
+            "anytime_td_all": LabelRules(include_other=True),
+        },
+        aliases={
+            # Maintain legacy column name as an alias to the offense-only label.
+            "anytime_td": "anytime_td_offense",
+            # Keep td_count pointing to the offense definition for backward compatibility.
+            "td_count": "td_count_offense",
+        },
+    ),
+    "v1_any_all": LabelSpec(
+        name="v1_any_all",
+        primary="anytime_td_all",
+        labels={
+            "anytime_td_all": LabelRules(include_other=True),
+            "anytime_td_offense": LabelRules(include_other=False),
+            "anytime_td_rush": LabelRules(include_rush=True, include_rec=False, include_pass_thrown=False, include_other=False),
+            "anytime_td_rec": LabelRules(include_rush=False, include_rec=True, include_pass_thrown=False, include_other=False),
+            "anytime_td_pass_thrown": LabelRules(include_rush=False, include_rec=False, include_pass_thrown=True, include_other=False),
+        },
+        aliases={
+            "anytime_td": "anytime_td_all",
+            "td_count": "td_count_all",
+        },
+    ),
+}
+
+
+def get_label_spec(version: str | None) -> LabelSpec:
+    """Return a concrete LabelSpec for the requested version (or default)."""
+
+    version = version or DEFAULT_LABEL_VERSION
+    if version not in LABEL_VERSIONS:
+        raise ValueError(
+            f"Unknown label_version '{version}'. "
+            f"Available: {sorted(LABEL_VERSIONS.keys())}"
+        )
+    return LABEL_VERSIONS[version]
+
+
+def _sum_expr(exprs: Iterable[pl.Expr]) -> pl.Expr:
+    exprs = list(exprs)
+    if not exprs:
+        return pl.lit(0).cast(pl.Int64)
+    acc = exprs[0]
+    for expr in exprs[1:]:
+        acc = acc + expr
+    return acc
+
+
+def compute_td_labels(df: pl.DataFrame, *, version: str | None = None) -> pl.DataFrame:
+    """Compute TD label columns according to a label version.
+
+    Parameters
+    ----------
+    df : pl.DataFrame
+        Player-game frame containing touchdown components.
+    version : str | None
+        Label version identifier. Defaults to DEFAULT_LABEL_VERSION.
+    """
+
+    spec = get_label_spec(version)
+    rush = pl.col("rushing_td_count").fill_null(0).cast(pl.Int64)
+    rec = pl.col("receiving_td_count").fill_null(0).cast(pl.Int64)
+    passing = pl.col("passing_td").fill_null(0).cast(pl.Int64)
+    reported_total = pl.col("touchdowns").fill_null(0).cast(pl.Int64)
+
+    offense_total = _sum_expr([rush, rec, passing]).alias("_td_offense_total")
+    other_total = (reported_total - offense_total).clip_min(0).alias("_td_other_total")
+    all_total = (offense_total + other_total).alias("_td_all_total")
+
+    totals_exprs = [
+        offense_total,
+        other_total,
+        all_total,
+    ]
+
+    label_exprs: list[pl.Expr] = [
+        pl.col("_td_offense_total").alias("td_count_offense"),
+        pl.col("_td_all_total").alias("td_count_all"),
+    ]
+
+    for label_name, rules in spec.labels.items():
+        parts: list[pl.Expr] = []
+        if rules.include_rush:
+            parts.append(rush)
+        if rules.include_rec:
+            parts.append(rec)
+        if rules.include_pass_thrown:
+            parts.append(passing)
+        if rules.include_other:
+            parts.append(pl.col("_td_other_total"))
+        total_expr = _sum_expr(parts)
+        label_exprs.append((total_expr > 0).cast(pl.Int8).alias(label_name))
+
+    # Canonical counts for compatibility
+    if "td_count" not in df.columns:
+        # Fill td_count using the alias mapping; default to offense count.
+        target_alias = spec.aliases.get("td_count") or "td_count_offense"
+        label_exprs.append(pl.col(target_alias).alias("td_count"))
+
+    df = df.with_columns(totals_exprs).with_columns(label_exprs)
+
+    # Resolve aliases (e.g., anytime_td -> anytime_td_offense)
+    if spec.aliases:
+        alias_exprs = []
+        for alias_name, source_name in spec.aliases.items():
+            if source_name in df.columns:
+                alias_exprs.append(pl.col(source_name).alias(alias_name))
+        if alias_exprs:
+            df = df.with_columns(alias_exprs)
+
+    drop_cols = [col for col in ("_td_offense_total", "_td_other_total", "_td_all_total") if col in df.columns]
+    if drop_cols:
+        df = df.drop(drop_cols)
+    return df
diff --git a/utils/feature/player_game_level.py b/utils/feature/player_game_level.py
index b6fe516c5f03d575038eef554d5ab39ea5d5c90d..dd4f1f7fcc9de4d8c63390f0a160005eeae48e2f
--- a/utils/feature/player_game_level.py
+++ b/utils/feature/player_game_level.py
@@ -4,8 +4,12 @@
 Each player gets one row per game with their total stats.
 
 Target columns created:
-- anytime_td (binary): Did player score a TD (receiving or rushing)?
-- td_count (int): Number of TDs scored (receiving + rushing)
+- anytime_td_offense (binary): Did player score an offensive TD (rush/rec/pass thrown)?
+- anytime_td_all (binary): Did player score any TD (including defensive/special teams if present)?
+- anytime_td_rush / anytime_td_rec / anytime_td_pass_thrown: Type-specific TD flags.
+- anytime_td (binary): Legacy alias → current label version primary.
+- td_count_offense / td_count_all: TD counts aligned to label semantics.
+- td_count (int): Legacy alias for the primary td_count.
 - passing_td (int): Number of passing TDs (for QBs)
 - receiving_yards (float): Total receiving yards
 - rushing_yards (float): Total rushing yards
@@ -33,6 +37,7 @@
 from utils.collect.nfl_schedules import get_schedule
 from utils.feature.asof import decision_cutoff_hours_default, fallback_cutoff_hours, get_decision_cutoff_hours, get_fallback_cutoff_hours
 from utils.feature.player_drive_level import _load_play_level_data
+from utils.feature.labels import DEFAULT_LABEL_VERSION, compute_td_labels
 from utils.train.injury_availability import (
     load_latest_artifact,
     predict_probabilities as predict_injury_probabilities,
@@ -1582,7 +1587,12 @@
     if flag_cols:
         df = df.with_columns([pl.col(col).cast(pl.Int8) for col in flag_cols])
     return df
-def build_player_game_level(*, start_date: date, end_date: date) -> None:
+def build_player_game_level(
+    *,
+    start_date: date,
+    end_date: date,
+    label_version: str | None = None,
+) -> None:
     """Aggregate play-level data to player-game level.
     
     Creates one row per (player, game) with accumulated stats.
@@ -1680,7 +1690,7 @@
     
     # Merge rows where same player had multiple roles in same game
     # (e.g., QB who also rushed, WR who also rushed)
-    df_merged = _merge_multi_role_players(df_all)
+    df_merged = _merge_multi_role_players(df_all, label_version=label_version or DEFAULT_LABEL_VERSION)
 
     df_merged = _append_zero_usage_players(df_merged, seasons_in_window)
     
@@ -3368,7 +3378,7 @@
     )
 
 
-def _merge_multi_role_players(df: pl.DataFrame) -> pl.DataFrame:
+def _merge_multi_role_players(df: pl.DataFrame, *, label_version: str | None = None) -> pl.DataFrame:
     """Merge stats for players who had multiple roles in same game.
     
     Example: QB who passed and rushed, WR who received and rushed.
@@ -3422,8 +3432,6 @@
         if col in merged.columns:
             merged = merged.with_columns(pl.col(col).fill_null(0))
 
-    # Fallback touchdown logic: if generic touchdown attribution is missing,
-    # derive it from rushing + receiving touchdowns.
     merged = merged.with_columns([
         pl.col("touchdowns").fill_null(0).alias("touchdowns"),
         pl.col("rushing_td_count").fill_null(0).alias("rushing_td_count"),
@@ -3435,17 +3443,5 @@
         pl.col("goal_to_go_carry").fill_null(0).alias("goal_to_go_carry"),
     ])
 
-    merged = merged.with_columns([
-        pl.when(pl.col("touchdowns") > 0)
-        .then(pl.col("touchdowns"))
-        .otherwise(pl.col("rushing_td_count") + pl.col("receiving_td_count"))
-        .cast(pl.Int64)
-        .alias("_total_touchdowns")
-    ])
-
-    merged = merged.with_columns([
-        (pl.col("_total_touchdowns") > 0).cast(pl.Int8).alias("anytime_td"),
-        pl.col("_total_touchdowns").alias("td_count"),
-    ]).drop("_total_touchdowns")
-    
+    merged = compute_td_labels(merged, version=label_version)
     return merged
diff --git a/utils/feature/targets.py b/utils/feature/targets.py
index 7738086dcbfda7432b937cc7d8095988cb0edff0..769ee8735c4024c4410ddd674b11112f093624dd
--- a/utils/feature/targets.py
+++ b/utils/feature/targets.py
@@ -7,6 +7,8 @@
 import polars as pl
 import logging
 
+from utils.feature.labels import DEFAULT_LABEL_VERSION, get_label_spec
+
 logger = logging.getLogger(__name__)
 
 
@@ -14,9 +16,16 @@
 NFL_TARGET_SCHEMA = {
     # Binary classification targets
     "anytime_td": pl.Int8,  # Primary MVP target: did player score a TD?
+    "anytime_td_offense": pl.Int8,
+    "anytime_td_all": pl.Int8,
+    "anytime_td_rush": pl.Int8,
+    "anytime_td_rec": pl.Int8,
+    "anytime_td_pass_thrown": pl.Int8,
     
     # Count/regression targets
     "td_count": pl.Int64,  # Number of TDs scored (receiving + rushing)
+    "td_count_offense": pl.Int64,
+    "td_count_all": pl.Int64,
     "passing_td": pl.Int64,  # Number of passing TDs (QB only)
     
     # Yardage regression targets
@@ -103,4 +112,40 @@
     pl.DataFrame
         DataFrame with validated target columns
     """
-    return validate_target_columns(df, strict=False)
\ No newline at end of file
+    return validate_target_columns(df, strict=False)
+
+
+def require_target_column(
+    df: pl.DataFrame,
+    target_col: str,
+    *,
+    label_version: str | None = None,
+    min_non_null: int = 1,
+) -> pl.DataFrame:
+    """Ensure the configured target column exists and is populated.
+
+    Raises a ValueError if the column is missing or entirely null.
+    """
+
+    if target_col not in df.columns:
+        alias_hint = ""
+        if label_version:
+            try:
+                spec = get_label_spec(label_version or DEFAULT_LABEL_VERSION)
+                if target_col in spec.aliases:
+                    alias_hint = f" Target maps to '{spec.aliases[target_col]}' under {spec.name}."
+            except Exception:
+                alias_hint = ""
+        raise ValueError(f"Target column '{target_col}' not found in feature frame.{alias_hint}")
+
+    series = df[target_col]
+    non_null = series.drop_nulls().height
+    if non_null < min_non_null:
+        raise ValueError(
+            f"Target column '{target_col}' has insufficient non-null rows "
+            f"({non_null}/{len(series)})."
+        )
+    nulls = len(series) - non_null
+    if nulls > 0:
+        logger.warning("Target %s contains %d null rows; they will be dropped.", target_col, nulls)
+    return df

file update:
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 6c47a91d08f9d309f94323efd4708bb992dc4ce0..5ba68e8bf1acd3a789a76a8857674e6f6433017b
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -26,6 +26,7 @@
 from utils.feature.player_drive_level import build_player_drive_level
 from utils.feature.player_game_level import build_player_game_level
 from utils.feature.opponent_splits import build_opponent_splits
+from utils.feature.labels import DEFAULT_LABEL_VERSION, get_label_spec
 from utils.feature.targets import validate_target_columns
 from utils.feature.daily_totals import build_daily_cache_range
 from utils.feature.rolling_window import add_rolling_features
@@ -233,6 +234,7 @@
     output_path: Path | None = None,
     primary_output_path: Path | None = None,
     cutoff_label: str | None = None,
+    label_version: str | None = None,
 ) -> pl.DataFrame:
     """Run full feature pipeline up to *inclusive* `end_date` for a single cutoff window.
 
@@ -248,6 +250,7 @@
     primary_output = primary_output_path or target_output_path
     current_cutoff_hours = float(get_decision_cutoff_hours())
     clean_min_date, clean_max_date = (None, None)
+    label_version = label_version or DEFAULT_LABEL_VERSION
     if start_date is None or end_date is None:
         clean_min_date, clean_max_date = _get_clean_date_bounds()
 
@@ -294,7 +297,7 @@
             build_player_drive_level(start_date=cur, end_date=chunk_end)
             
             # 5. Player-game aggregations (for rolling window features)
-            build_player_game_level(start_date=cur, end_date=chunk_end)
+            build_player_game_level(start_date=cur, end_date=chunk_end, label_version=label_version)
 
             # advance to next slice
             cur += timedelta(days=chunk_days)
@@ -948,11 +951,19 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    # Log target distribution for anytime_td
-    if "anytime_td" in df_player_game_all.columns:
-        td_count = df_player_game_all["anytime_td"].sum()
-        td_rate = td_count / len(df_player_game_all) * 100
-        logging.info("    Anytime TD rate: %.2f%% (%d/%d)", td_rate, td_count, len(df_player_game_all))
+    spec = get_label_spec(label_version)
+    label_candidates = {spec.primary, "anytime_td"}
+    for label_col in label_candidates:
+        if label_col in df_player_game_all.columns:
+            td_count = df_player_game_all[label_col].sum()
+            td_rate = td_count / len(df_player_game_all) * 100
+            logging.info(
+                "    Label %s rate: %.2f%% (%d/%d)",
+                label_col,
+                td_rate,
+                td_count,
+                len(df_player_game_all),
+            )
     
     return df_player_game_all
 
@@ -965,6 +976,7 @@
     recompute_intermediate: bool = True,
     build_rolling: bool = True,
     cutoff_hours_list: Sequence[float] | None = None,
+    label_version: str | None = None,
 ) -> pl.DataFrame:
     """Build feature matrices for one or more decision cutoff horizons.
 
@@ -992,6 +1004,7 @@
                 output_path=output_path,
                 primary_output_path=primary_output,
                 cutoff_label=label,
+                label_version=label_version,
             )
         if idx == 0:
             primary_result = df
diff --git a/pipeline/train.py b/pipeline/train.py
index 265bc29f4861d2d4d26f54fd7f77304de8fe6742..fe70207dcdf25d209ee3ad55080b7ce826347c44
--- a/pipeline/train.py
+++ b/pipeline/train.py
@@ -98,6 +98,7 @@
     fit_team_conformal_sums,
     composite_sum_interval,
 )
+from utils.feature.targets import require_target_column
 
 # Ignore specific, noisy warnings from dependencies
 warnings.filterwarnings(
@@ -259,6 +260,7 @@
 
         # Per-problem attributes initialised later
         self.target_col = None
+        self.label_version = None
         self.feature_columns = None
 
         self.models = {}
@@ -2163,6 +2165,7 @@
             
             problem_copy = copy.deepcopy(problem)
             self.target_col = problem_copy['target_col']
+            self.label_version = problem_copy.get('label_version') or problem_copy.get("labels", {}).get("version")
             derived_cfg = problem_copy.get('derived_target')
             target_load_cols: list[str] = []
             if derived_cfg:
@@ -2269,6 +2272,12 @@
                 df_problem = df_problem.loc[:, ~df_problem.columns.duplicated()]
 
             df_problem = self._apply_problem_level_overrides(df_problem, problem_copy)
+            df_problem = require_target_column(
+                df_problem,
+                self.target_col,
+                label_version=self.label_version,
+                min_non_null=1,
+            )
             
             # Merge input predictions if required
             if input_preds:
diff --git a/utils/feature/labels.py b/utils/feature/labels.py
new file mode 100644
index 0000000000000000000000000000000000000000..b34571f04254cd7bceb9363a190ee7d305852bd5
--- /dev/null
+++ b/utils/feature/labels.py
@@ -0,0 +1,169 @@
+"""Label semantics and versioning for NFL player-level targets.
+
+This module centralizes anytime-TD label definitions so that:
+- Semantics are explicit and versioned.
+- Training can request a specific label column per problem.
+- Feature generation can emit multiple label variants for analysis.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass, field
+from typing import Dict, Iterable, Mapping
+
+import polars as pl
+
+
+@dataclass(frozen=True)
+class LabelRules:
+    """Rules controlling which TD components count toward a label."""
+
+    include_rush: bool = True
+    include_rec: bool = True
+    include_pass_thrown: bool = True  # credit passers for thrown TDs
+    include_other: bool = False  # fumble returns, defensive/special teams if present
+
+
+@dataclass(frozen=True)
+class LabelSpec:
+    """Container describing a label version."""
+
+    name: str
+    primary: str
+    labels: Mapping[str, LabelRules]
+    aliases: Mapping[str, str] = field(default_factory=dict)
+
+    @property
+    def all_columns(self) -> set[str]:
+        cols = set(self.labels.keys())
+        cols.update(self.aliases.keys())
+        return cols
+
+
+DEFAULT_LABEL_VERSION = "v1_any_offense"
+
+
+LABEL_VERSIONS: Dict[str, LabelSpec] = {
+    "v1_any_offense": LabelSpec(
+        name="v1_any_offense",
+        primary="anytime_td_offense",
+        labels={
+            "anytime_td_offense": LabelRules(include_other=False),
+            "anytime_td_rush": LabelRules(include_rush=True, include_rec=False, include_pass_thrown=False, include_other=False),
+            "anytime_td_rec": LabelRules(include_rush=False, include_rec=True, include_pass_thrown=False, include_other=False),
+            "anytime_td_pass_thrown": LabelRules(include_rush=False, include_rec=False, include_pass_thrown=True, include_other=False),
+            "anytime_td_all": LabelRules(include_other=True),
+        },
+        aliases={
+            # Maintain legacy column name as an alias to the offense-only label.
+            "anytime_td": "anytime_td_offense",
+            # Keep td_count pointing to the offense definition for backward compatibility.
+            "td_count": "td_count_offense",
+        },
+    ),
+    "v1_any_all": LabelSpec(
+        name="v1_any_all",
+        primary="anytime_td_all",
+        labels={
+            "anytime_td_all": LabelRules(include_other=True),
+            "anytime_td_offense": LabelRules(include_other=False),
+            "anytime_td_rush": LabelRules(include_rush=True, include_rec=False, include_pass_thrown=False, include_other=False),
+            "anytime_td_rec": LabelRules(include_rush=False, include_rec=True, include_pass_thrown=False, include_other=False),
+            "anytime_td_pass_thrown": LabelRules(include_rush=False, include_rec=False, include_pass_thrown=True, include_other=False),
+        },
+        aliases={
+            "anytime_td": "anytime_td_all",
+            "td_count": "td_count_all",
+        },
+    ),
+}
+
+
+def get_label_spec(version: str | None) -> LabelSpec:
+    """Return a concrete LabelSpec for the requested version (or default)."""
+
+    version = version or DEFAULT_LABEL_VERSION
+    if version not in LABEL_VERSIONS:
+        raise ValueError(
+            f"Unknown label_version '{version}'. "
+            f"Available: {sorted(LABEL_VERSIONS.keys())}"
+        )
+    return LABEL_VERSIONS[version]
+
+
+def _sum_expr(exprs: Iterable[pl.Expr]) -> pl.Expr:
+    exprs = list(exprs)
+    if not exprs:
+        return pl.lit(0).cast(pl.Int64)
+    acc = exprs[0]
+    for expr in exprs[1:]:
+        acc = acc + expr
+    return acc
+
+
+def compute_td_labels(df: pl.DataFrame, *, version: str | None = None) -> pl.DataFrame:
+    """Compute TD label columns according to a label version.
+
+    Parameters
+    ----------
+    df : pl.DataFrame
+        Player-game frame containing touchdown components.
+    version : str | None
+        Label version identifier. Defaults to DEFAULT_LABEL_VERSION.
+    """
+
+    spec = get_label_spec(version)
+    rush = pl.col("rushing_td_count").fill_null(0).cast(pl.Int64)
+    rec = pl.col("receiving_td_count").fill_null(0).cast(pl.Int64)
+    passing = pl.col("passing_td").fill_null(0).cast(pl.Int64)
+    reported_total = pl.col("touchdowns").fill_null(0).cast(pl.Int64)
+
+    offense_total = _sum_expr([rush, rec, passing]).alias("_td_offense_total")
+    other_total = (reported_total - offense_total).clip_min(0).alias("_td_other_total")
+    all_total = (offense_total + other_total).alias("_td_all_total")
+
+    totals_exprs = [
+        offense_total,
+        other_total,
+        all_total,
+    ]
+
+    label_exprs: list[pl.Expr] = [
+        pl.col("_td_offense_total").alias("td_count_offense"),
+        pl.col("_td_all_total").alias("td_count_all"),
+    ]
+
+    for label_name, rules in spec.labels.items():
+        parts: list[pl.Expr] = []
+        if rules.include_rush:
+            parts.append(rush)
+        if rules.include_rec:
+            parts.append(rec)
+        if rules.include_pass_thrown:
+            parts.append(passing)
+        if rules.include_other:
+            parts.append(pl.col("_td_other_total"))
+        total_expr = _sum_expr(parts)
+        label_exprs.append((total_expr > 0).cast(pl.Int8).alias(label_name))
+
+    # Canonical counts for compatibility
+    if "td_count" not in df.columns:
+        # Fill td_count using the alias mapping; default to offense count.
+        target_alias = spec.aliases.get("td_count") or "td_count_offense"
+        label_exprs.append(pl.col(target_alias).alias("td_count"))
+
+    df = df.with_columns(totals_exprs).with_columns(label_exprs)
+
+    # Resolve aliases (e.g., anytime_td -> anytime_td_offense)
+    if spec.aliases:
+        alias_exprs = []
+        for alias_name, source_name in spec.aliases.items():
+            if source_name in df.columns:
+                alias_exprs.append(pl.col(source_name).alias(alias_name))
+        if alias_exprs:
+            df = df.with_columns(alias_exprs)
+
+    drop_cols = [col for col in ("_td_offense_total", "_td_other_total", "_td_all_total") if col in df.columns]
+    if drop_cols:
+        df = df.drop(drop_cols)
+    return df
diff --git a/utils/feature/player_game_level.py b/utils/feature/player_game_level.py
index b6fe516c5f03d575038eef554d5ab39ea5d5c90d..dd4f1f7fcc9de4d8c63390f0a160005eeae48e2f
--- a/utils/feature/player_game_level.py
+++ b/utils/feature/player_game_level.py
@@ -4,8 +4,12 @@
 Each player gets one row per game with their total stats.
 
 Target columns created:
-- anytime_td (binary): Did player score a TD (receiving or rushing)?
-- td_count (int): Number of TDs scored (receiving + rushing)
+- anytime_td_offense (binary): Did player score an offensive TD (rush/rec/pass thrown)?
+- anytime_td_all (binary): Did player score any TD (including defensive/special teams if present)?
+- anytime_td_rush / anytime_td_rec / anytime_td_pass_thrown: Type-specific TD flags.
+- anytime_td (binary): Legacy alias → current label version primary.
+- td_count_offense / td_count_all: TD counts aligned to label semantics.
+- td_count (int): Legacy alias for the primary td_count.
 - passing_td (int): Number of passing TDs (for QBs)
 - receiving_yards (float): Total receiving yards
 - rushing_yards (float): Total rushing yards
@@ -33,6 +37,7 @@
 from utils.collect.nfl_schedules import get_schedule
 from utils.feature.asof import decision_cutoff_hours_default, fallback_cutoff_hours, get_decision_cutoff_hours, get_fallback_cutoff_hours
 from utils.feature.player_drive_level import _load_play_level_data
+from utils.feature.labels import DEFAULT_LABEL_VERSION, compute_td_labels
 from utils.train.injury_availability import (
     load_latest_artifact,
     predict_probabilities as predict_injury_probabilities,
@@ -1582,7 +1587,12 @@
     if flag_cols:
         df = df.with_columns([pl.col(col).cast(pl.Int8) for col in flag_cols])
     return df
-def build_player_game_level(*, start_date: date, end_date: date) -> None:
+def build_player_game_level(
+    *,
+    start_date: date,
+    end_date: date,
+    label_version: str | None = None,
+) -> None:
     """Aggregate play-level data to player-game level.
     
     Creates one row per (player, game) with accumulated stats.
@@ -1680,7 +1690,7 @@
     
     # Merge rows where same player had multiple roles in same game
     # (e.g., QB who also rushed, WR who also rushed)
-    df_merged = _merge_multi_role_players(df_all)
+    df_merged = _merge_multi_role_players(df_all, label_version=label_version or DEFAULT_LABEL_VERSION)
 
     df_merged = _append_zero_usage_players(df_merged, seasons_in_window)
     
@@ -3368,7 +3378,7 @@
     )
 
 
-def _merge_multi_role_players(df: pl.DataFrame) -> pl.DataFrame:
+def _merge_multi_role_players(df: pl.DataFrame, *, label_version: str | None = None) -> pl.DataFrame:
     """Merge stats for players who had multiple roles in same game.
     
     Example: QB who passed and rushed, WR who received and rushed.
@@ -3422,8 +3432,6 @@
         if col in merged.columns:
             merged = merged.with_columns(pl.col(col).fill_null(0))
 
-    # Fallback touchdown logic: if generic touchdown attribution is missing,
-    # derive it from rushing + receiving touchdowns.
     merged = merged.with_columns([
         pl.col("touchdowns").fill_null(0).alias("touchdowns"),
         pl.col("rushing_td_count").fill_null(0).alias("rushing_td_count"),
@@ -3435,17 +3443,5 @@
         pl.col("goal_to_go_carry").fill_null(0).alias("goal_to_go_carry"),
     ])
 
-    merged = merged.with_columns([
-        pl.when(pl.col("touchdowns") > 0)
-        .then(pl.col("touchdowns"))
-        .otherwise(pl.col("rushing_td_count") + pl.col("receiving_td_count"))
-        .cast(pl.Int64)
-        .alias("_total_touchdowns")
-    ])
-
-    merged = merged.with_columns([
-        (pl.col("_total_touchdowns") > 0).cast(pl.Int8).alias("anytime_td"),
-        pl.col("_total_touchdowns").alias("td_count"),
-    ]).drop("_total_touchdowns")
-    
+    merged = compute_td_labels(merged, version=label_version)
     return merged
diff --git a/utils/feature/targets.py b/utils/feature/targets.py
index 7738086dcbfda7432b937cc7d8095988cb0edff0..769ee8735c4024c4410ddd674b11112f093624dd
--- a/utils/feature/targets.py
+++ b/utils/feature/targets.py
@@ -7,6 +7,8 @@
 import polars as pl
 import logging
 
+from utils.feature.labels import DEFAULT_LABEL_VERSION, get_label_spec
+
 logger = logging.getLogger(__name__)
 
 
@@ -14,9 +16,16 @@
 NFL_TARGET_SCHEMA = {
     # Binary classification targets
     "anytime_td": pl.Int8,  # Primary MVP target: did player score a TD?
+    "anytime_td_offense": pl.Int8,
+    "anytime_td_all": pl.Int8,
+    "anytime_td_rush": pl.Int8,
+    "anytime_td_rec": pl.Int8,
+    "anytime_td_pass_thrown": pl.Int8,
     
     # Count/regression targets
     "td_count": pl.Int64,  # Number of TDs scored (receiving + rushing)
+    "td_count_offense": pl.Int64,
+    "td_count_all": pl.Int64,
     "passing_td": pl.Int64,  # Number of passing TDs (QB only)
     
     # Yardage regression targets
@@ -103,4 +112,40 @@
     pl.DataFrame
         DataFrame with validated target columns
     """
-    return validate_target_columns(df, strict=False)
\ No newline at end of file
+    return validate_target_columns(df, strict=False)
+
+
+def require_target_column(
+    df: pl.DataFrame,
+    target_col: str,
+    *,
+    label_version: str | None = None,
+    min_non_null: int = 1,
+) -> pl.DataFrame:
+    """Ensure the configured target column exists and is populated.
+
+    Raises a ValueError if the column is missing or entirely null.
+    """
+
+    if target_col not in df.columns:
+        alias_hint = ""
+        if label_version:
+            try:
+                spec = get_label_spec(label_version or DEFAULT_LABEL_VERSION)
+                if target_col in spec.aliases:
+                    alias_hint = f" Target maps to '{spec.aliases[target_col]}' under {spec.name}."
+            except Exception:
+                alias_hint = ""
+        raise ValueError(f"Target column '{target_col}' not found in feature frame.{alias_hint}")
+
+    series = df[target_col]
+    non_null = series.drop_nulls().height
+    if non_null < min_non_null:
+        raise ValueError(
+            f"Target column '{target_col}' has insufficient non-null rows "
+            f"({non_null}/{len(series)})."
+        )
+    nulls = len(series) - non_null
+    if nulls > 0:
+        logger.warning("Target %s contains %d null rows; they will be dropped.", target_col, nulls)
+    return df


thinking
**Ensuring target handling for derived columns**
file update
M /Users/jameswest/Desktop/nfl_predict/config/training.yaml
@@ -477,2 +477,3 @@
     target_col: 'anytime_td'
+    label_version: 'v1_any_offense'
     task_type: 'classification'
apply_patch(auto_approved=true) exited 0 in 102ms:
Success. Updated the following files:
M config/training.yaml
file update:
diff --git a/config/training.yaml b/config/training.yaml
index 3055a636b89249119408aaad970d3025956877db..3953818d861d0410246bff132110722a3ce44007
--- a/config/training.yaml
+++ b/config/training.yaml
@@ -475,6 +475,7 @@
   # Calibrated probability of scoring > 0 TDs.
   - name: 'anytime_td'
     target_col: 'anytime_td'
+    label_version: 'v1_any_offense'
     task_type: 'classification'
     input_predictions:
       - 'availability_active'
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 6c47a91d08f9d309f94323efd4708bb992dc4ce0..5ba68e8bf1acd3a789a76a8857674e6f6433017b
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -26,6 +26,7 @@
 from utils.feature.player_drive_level import build_player_drive_level
 from utils.feature.player_game_level import build_player_game_level
 from utils.feature.opponent_splits import build_opponent_splits
+from utils.feature.labels import DEFAULT_LABEL_VERSION, get_label_spec
 from utils.feature.targets import validate_target_columns
 from utils.feature.daily_totals import build_daily_cache_range
 from utils.feature.rolling_window import add_rolling_features
@@ -233,6 +234,7 @@
     output_path: Path | None = None,
     primary_output_path: Path | None = None,
     cutoff_label: str | None = None,
+    label_version: str | None = None,
 ) -> pl.DataFrame:
     """Run full feature pipeline up to *inclusive* `end_date` for a single cutoff window.
 
@@ -248,6 +250,7 @@
     primary_output = primary_output_path or target_output_path
     current_cutoff_hours = float(get_decision_cutoff_hours())
     clean_min_date, clean_max_date = (None, None)
+    label_version = label_version or DEFAULT_LABEL_VERSION
     if start_date is None or end_date is None:
         clean_min_date, clean_max_date = _get_clean_date_bounds()
 
@@ -294,7 +297,7 @@
             build_player_drive_level(start_date=cur, end_date=chunk_end)
             
             # 5. Player-game aggregations (for rolling window features)
-            build_player_game_level(start_date=cur, end_date=chunk_end)
+            build_player_game_level(start_date=cur, end_date=chunk_end, label_version=label_version)
 
             # advance to next slice
             cur += timedelta(days=chunk_days)
@@ -948,11 +951,19 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    # Log target distribution for anytime_td
-    if "anytime_td" in df_player_game_all.columns:
-        td_count = df_player_game_all["anytime_td"].sum()
-        td_rate = td_count / len(df_player_game_all) * 100
-        logging.info("    Anytime TD rate: %.2f%% (%d/%d)", td_rate, td_count, len(df_player_game_all))
+    spec = get_label_spec(label_version)
+    label_candidates = {spec.primary, "anytime_td"}
+    for label_col in label_candidates:
+        if label_col in df_player_game_all.columns:
+            td_count = df_player_game_all[label_col].sum()
+            td_rate = td_count / len(df_player_game_all) * 100
+            logging.info(
+                "    Label %s rate: %.2f%% (%d/%d)",
+                label_col,
+                td_rate,
+                td_count,
+                len(df_player_game_all),
+            )
     
     return df_player_game_all
 
@@ -965,6 +976,7 @@
     recompute_intermediate: bool = True,
     build_rolling: bool = True,
     cutoff_hours_list: Sequence[float] | None = None,
+    label_version: str | None = None,
 ) -> pl.DataFrame:
     """Build feature matrices for one or more decision cutoff horizons.
 
@@ -992,6 +1004,7 @@
                 output_path=output_path,
                 primary_output_path=primary_output,
                 cutoff_label=label,
+                label_version=label_version,
             )
         if idx == 0:
             primary_result = df
diff --git a/pipeline/train.py b/pipeline/train.py
index 265bc29f4861d2d4d26f54fd7f77304de8fe6742..fe70207dcdf25d209ee3ad55080b7ce826347c44
--- a/pipeline/train.py
+++ b/pipeline/train.py
@@ -98,6 +98,7 @@
     fit_team_conformal_sums,
     composite_sum_interval,
 )
+from utils.feature.targets import require_target_column
 
 # Ignore specific, noisy warnings from dependencies
 warnings.filterwarnings(
@@ -259,6 +260,7 @@
 
         # Per-problem attributes initialised later
         self.target_col = None
+        self.label_version = None
         self.feature_columns = None
 
         self.models = {}
@@ -2163,6 +2165,7 @@
             
             problem_copy = copy.deepcopy(problem)
             self.target_col = problem_copy['target_col']
+            self.label_version = problem_copy.get('label_version') or problem_copy.get("labels", {}).get("version")
             derived_cfg = problem_copy.get('derived_target')
             target_load_cols: list[str] = []
             if derived_cfg:
@@ -2269,6 +2272,12 @@
                 df_problem = df_problem.loc[:, ~df_problem.columns.duplicated()]
 
             df_problem = self._apply_problem_level_overrides(df_problem, problem_copy)
+            df_problem = require_target_column(
+                df_problem,
+                self.target_col,
+                label_version=self.label_version,
+                min_non_null=1,
+            )
             
             # Merge input predictions if required
             if input_preds:
diff --git a/utils/feature/labels.py b/utils/feature/labels.py
new file mode 100644
index 0000000000000000000000000000000000000000..b34571f04254cd7bceb9363a190ee7d305852bd5
--- /dev/null
+++ b/utils/feature/labels.py
@@ -0,0 +1,169 @@
+"""Label semantics and versioning for NFL player-level targets.
+
+This module centralizes anytime-TD label definitions so that:
+- Semantics are explicit and versioned.
+- Training can request a specific label column per problem.
+- Feature generation can emit multiple label variants for analysis.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass, field
+from typing import Dict, Iterable, Mapping
+
+import polars as pl
+
+
+@dataclass(frozen=True)
+class LabelRules:
+    """Rules controlling which TD components count toward a label."""
+
+    include_rush: bool = True
+    include_rec: bool = True
+    include_pass_thrown: bool = True  # credit passers for thrown TDs
+    include_other: bool = False  # fumble returns, defensive/special teams if present
+
+
+@dataclass(frozen=True)
+class LabelSpec:
+    """Container describing a label version."""
+
+    name: str
+    primary: str
+    labels: Mapping[str, LabelRules]
+    aliases: Mapping[str, str] = field(default_factory=dict)
+
+    @property
+    def all_columns(self) -> set[str]:
+        cols = set(self.labels.keys())
+        cols.update(self.aliases.keys())
+        return cols
+
+
+DEFAULT_LABEL_VERSION = "v1_any_offense"
+
+
+LABEL_VERSIONS: Dict[str, LabelSpec] = {
+    "v1_any_offense": LabelSpec(
+        name="v1_any_offense",
+        primary="anytime_td_offense",
+        labels={
+            "anytime_td_offense": LabelRules(include_other=False),
+            "anytime_td_rush": LabelRules(include_rush=True, include_rec=False, include_pass_thrown=False, include_other=False),
+            "anytime_td_rec": LabelRules(include_rush=False, include_rec=True, include_pass_thrown=False, include_other=False),
+            "anytime_td_pass_thrown": LabelRules(include_rush=False, include_rec=False, include_pass_thrown=True, include_other=False),
+            "anytime_td_all": LabelRules(include_other=True),
+        },
+        aliases={
+            # Maintain legacy column name as an alias to the offense-only label.
+            "anytime_td": "anytime_td_offense",
+            # Keep td_count pointing to the offense definition for backward compatibility.
+            "td_count": "td_count_offense",
+        },
+    ),
+    "v1_any_all": LabelSpec(
+        name="v1_any_all",
+        primary="anytime_td_all",
+        labels={
+            "anytime_td_all": LabelRules(include_other=True),
+            "anytime_td_offense": LabelRules(include_other=False),
+            "anytime_td_rush": LabelRules(include_rush=True, include_rec=False, include_pass_thrown=False, include_other=False),
+            "anytime_td_rec": LabelRules(include_rush=False, include_rec=True, include_pass_thrown=False, include_other=False),
+            "anytime_td_pass_thrown": LabelRules(include_rush=False, include_rec=False, include_pass_thrown=True, include_other=False),
+        },
+        aliases={
+            "anytime_td": "anytime_td_all",
+            "td_count": "td_count_all",
+        },
+    ),
+}
+
+
+def get_label_spec(version: str | None) -> LabelSpec:
+    """Return a concrete LabelSpec for the requested version (or default)."""
+
+    version = version or DEFAULT_LABEL_VERSION
+    if version not in LABEL_VERSIONS:
+        raise ValueError(
+            f"Unknown label_version '{version}'. "
+            f"Available: {sorted(LABEL_VERSIONS.keys())}"
+        )
+    return LABEL_VERSIONS[version]
+
+
+def _sum_expr(exprs: Iterable[pl.Expr]) -> pl.Expr:
+    exprs = list(exprs)
+    if not exprs:
+        return pl.lit(0).cast(pl.Int64)
+    acc = exprs[0]
+    for expr in exprs[1:]:
+        acc = acc + expr
+    return acc
+
+
+def compute_td_labels(df: pl.DataFrame, *, version: str | None = None) -> pl.DataFrame:
+    """Compute TD label columns according to a label version.
+
+    Parameters
+    ----------
+    df : pl.DataFrame
+        Player-game frame containing touchdown components.
+    version : str | None
+        Label version identifier. Defaults to DEFAULT_LABEL_VERSION.
+    """
+
+    spec = get_label_spec(version)
+    rush = pl.col("rushing_td_count").fill_null(0).cast(pl.Int64)
+    rec = pl.col("receiving_td_count").fill_null(0).cast(pl.Int64)
+    passing = pl.col("passing_td").fill_null(0).cast(pl.Int64)
+    reported_total = pl.col("touchdowns").fill_null(0).cast(pl.Int64)
+
+    offense_total = _sum_expr([rush, rec, passing]).alias("_td_offense_total")
+    other_total = (reported_total - offense_total).clip_min(0).alias("_td_other_total")
+    all_total = (offense_total + other_total).alias("_td_all_total")
+
+    totals_exprs = [
+        offense_total,
+        other_total,
+        all_total,
+    ]
+
+    label_exprs: list[pl.Expr] = [
+        pl.col("_td_offense_total").alias("td_count_offense"),
+        pl.col("_td_all_total").alias("td_count_all"),
+    ]
+
+    for label_name, rules in spec.labels.items():
+        parts: list[pl.Expr] = []
+        if rules.include_rush:
+            parts.append(rush)
+        if rules.include_rec:
+            parts.append(rec)
+        if rules.include_pass_thrown:
+            parts.append(passing)
+        if rules.include_other:
+            parts.append(pl.col("_td_other_total"))
+        total_expr = _sum_expr(parts)
+        label_exprs.append((total_expr > 0).cast(pl.Int8).alias(label_name))
+
+    # Canonical counts for compatibility
+    if "td_count" not in df.columns:
+        # Fill td_count using the alias mapping; default to offense count.
+        target_alias = spec.aliases.get("td_count") or "td_count_offense"
+        label_exprs.append(pl.col(target_alias).alias("td_count"))
+
+    df = df.with_columns(totals_exprs).with_columns(label_exprs)
+
+    # Resolve aliases (e.g., anytime_td -> anytime_td_offense)
+    if spec.aliases:
+        alias_exprs = []
+        for alias_name, source_name in spec.aliases.items():
+            if source_name in df.columns:
+                alias_exprs.append(pl.col(source_name).alias(alias_name))
+        if alias_exprs:
+            df = df.with_columns(alias_exprs)
+
+    drop_cols = [col for col in ("_td_offense_total", "_td_other_total", "_td_all_total") if col in df.columns]
+    if drop_cols:
+        df = df.drop(drop_cols)
+    return df
diff --git a/utils/feature/player_game_level.py b/utils/feature/player_game_level.py
index b6fe516c5f03d575038eef554d5ab39ea5d5c90d..dd4f1f7fcc9de4d8c63390f0a160005eeae48e2f
--- a/utils/feature/player_game_level.py
+++ b/utils/feature/player_game_level.py
@@ -4,8 +4,12 @@
 Each player gets one row per game with their total stats.
 
 Target columns created:
-- anytime_td (binary): Did player score a TD (receiving or rushing)?
-- td_count (int): Number of TDs scored (receiving + rushing)
+- anytime_td_offense (binary): Did player score an offensive TD (rush/rec/pass thrown)?
+- anytime_td_all (binary): Did player score any TD (including defensive/special teams if present)?
+- anytime_td_rush / anytime_td_rec / anytime_td_pass_thrown: Type-specific TD flags.
+- anytime_td (binary): Legacy alias → current label version primary.
+- td_count_offense / td_count_all: TD counts aligned to label semantics.
+- td_count (int): Legacy alias for the primary td_count.
 - passing_td (int): Number of passing TDs (for QBs)
 - receiving_yards (float): Total receiving yards
 - rushing_yards (float): Total rushing yards
@@ -33,6 +37,7 @@
 from utils.collect.nfl_schedules import get_schedule
 from utils.feature.asof import decision_cutoff_hours_default, fallback_cutoff_hours, get_decision_cutoff_hours, get_fallback_cutoff_hours
 from utils.feature.player_drive_level import _load_play_level_data
+from utils.feature.labels import DEFAULT_LABEL_VERSION, compute_td_labels
 from utils.train.injury_availability import (
     load_latest_artifact,
     predict_probabilities as predict_injury_probabilities,
@@ -1582,7 +1587,12 @@
     if flag_cols:
         df = df.with_columns([pl.col(col).cast(pl.Int8) for col in flag_cols])
     return df
-def build_player_game_level(*, start_date: date, end_date: date) -> None:
+def build_player_game_level(
+    *,
+    start_date: date,
+    end_date: date,
+    label_version: str | None = None,
+) -> None:
     """Aggregate play-level data to player-game level.
     
     Creates one row per (player, game) with accumulated stats.
@@ -1680,7 +1690,7 @@
     
     # Merge rows where same player had multiple roles in same game
     # (e.g., QB who also rushed, WR who also rushed)
-    df_merged = _merge_multi_role_players(df_all)
+    df_merged = _merge_multi_role_players(df_all, label_version=label_version or DEFAULT_LABEL_VERSION)
 
     df_merged = _append_zero_usage_players(df_merged, seasons_in_window)
     
@@ -3368,7 +3378,7 @@
     )
 
 
-def _merge_multi_role_players(df: pl.DataFrame) -> pl.DataFrame:
+def _merge_multi_role_players(df: pl.DataFrame, *, label_version: str | None = None) -> pl.DataFrame:
     """Merge stats for players who had multiple roles in same game.
     
     Example: QB who passed and rushed, WR who received and rushed.
@@ -3422,8 +3432,6 @@
         if col in merged.columns:
             merged = merged.with_columns(pl.col(col).fill_null(0))
 
-    # Fallback touchdown logic: if generic touchdown attribution is missing,
-    # derive it from rushing + receiving touchdowns.
     merged = merged.with_columns([
         pl.col("touchdowns").fill_null(0).alias("touchdowns"),
         pl.col("rushing_td_count").fill_null(0).alias("rushing_td_count"),
@@ -3435,17 +3443,5 @@
         pl.col("goal_to_go_carry").fill_null(0).alias("goal_to_go_carry"),
     ])
 
-    merged = merged.with_columns([
-        pl.when(pl.col("touchdowns") > 0)
-        .then(pl.col("touchdowns"))
-        .otherwise(pl.col("rushing_td_count") + pl.col("receiving_td_count"))
-        .cast(pl.Int64)
-        .alias("_total_touchdowns")
-    ])
-
-    merged = merged.with_columns([
-        (pl.col("_total_touchdowns") > 0).cast(pl.Int8).alias("anytime_td"),
-        pl.col("_total_touchdowns").alias("td_count"),
-    ]).drop("_total_touchdowns")
-    
+    merged = compute_td_labels(merged, version=label_version)
     return merged
diff --git a/utils/feature/targets.py b/utils/feature/targets.py
index 7738086dcbfda7432b937cc7d8095988cb0edff0..769ee8735c4024c4410ddd674b11112f093624dd
--- a/utils/feature/targets.py
+++ b/utils/feature/targets.py
@@ -7,6 +7,8 @@
 import polars as pl
 import logging
 
+from utils.feature.labels import DEFAULT_LABEL_VERSION, get_label_spec
+
 logger = logging.getLogger(__name__)
 
 
@@ -14,9 +16,16 @@
 NFL_TARGET_SCHEMA = {
     # Binary classification targets
     "anytime_td": pl.Int8,  # Primary MVP target: did player score a TD?
+    "anytime_td_offense": pl.Int8,
+    "anytime_td_all": pl.Int8,
+    "anytime_td_rush": pl.Int8,
+    "anytime_td_rec": pl.Int8,
+    "anytime_td_pass_thrown": pl.Int8,
     
     # Count/regression targets
     "td_count": pl.Int64,  # Number of TDs scored (receiving + rushing)
+    "td_count_offense": pl.Int64,
+    "td_count_all": pl.Int64,
     "passing_td": pl.Int64,  # Number of passing TDs (QB only)
     
     # Yardage regression targets
@@ -103,4 +112,40 @@
     pl.DataFrame
         DataFrame with validated target columns
     """
-    return validate_target_columns(df, strict=False)
\ No newline at end of file
+    return validate_target_columns(df, strict=False)
+
+
+def require_target_column(
+    df: pl.DataFrame,
+    target_col: str,
+    *,
+    label_version: str | None = None,
+    min_non_null: int = 1,
+) -> pl.DataFrame:
+    """Ensure the configured target column exists and is populated.
+
+    Raises a ValueError if the column is missing or entirely null.
+    """
+
+    if target_col not in df.columns:
+        alias_hint = ""
+        if label_version:
+            try:
+                spec = get_label_spec(label_version or DEFAULT_LABEL_VERSION)
+                if target_col in spec.aliases:
+                    alias_hint = f" Target maps to '{spec.aliases[target_col]}' under {spec.name}."
+            except Exception:
+                alias_hint = ""
+        raise ValueError(f"Target column '{target_col}' not found in feature frame.{alias_hint}")
+
+    series = df[target_col]
+    non_null = series.drop_nulls().height
+    if non_null < min_non_null:
+        raise ValueError(
+            f"Target column '{target_col}' has insufficient non-null rows "
+            f"({non_null}/{len(series)})."
+        )
+    nulls = len(series) - non_null
+    if nulls > 0:
+        logger.warning("Target %s contains %d null rows; they will be dropped.", target_col, nulls)
+    return df

file update:
diff --git a/config/training.yaml b/config/training.yaml
index 3055a636b89249119408aaad970d3025956877db..3953818d861d0410246bff132110722a3ce44007
--- a/config/training.yaml
+++ b/config/training.yaml
@@ -475,6 +475,7 @@
   # Calibrated probability of scoring > 0 TDs.
   - name: 'anytime_td'
     target_col: 'anytime_td'
+    label_version: 'v1_any_offense'
     task_type: 'classification'
     input_predictions:
       - 'availability_active'
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 6c47a91d08f9d309f94323efd4708bb992dc4ce0..5ba68e8bf1acd3a789a76a8857674e6f6433017b
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -26,6 +26,7 @@
 from utils.feature.player_drive_level import build_player_drive_level
 from utils.feature.player_game_level import build_player_game_level
 from utils.feature.opponent_splits import build_opponent_splits
+from utils.feature.labels import DEFAULT_LABEL_VERSION, get_label_spec
 from utils.feature.targets import validate_target_columns
 from utils.feature.daily_totals import build_daily_cache_range
 from utils.feature.rolling_window import add_rolling_features
@@ -233,6 +234,7 @@
     output_path: Path | None = None,
     primary_output_path: Path | None = None,
     cutoff_label: str | None = None,
+    label_version: str | None = None,
 ) -> pl.DataFrame:
     """Run full feature pipeline up to *inclusive* `end_date` for a single cutoff window.
 
@@ -248,6 +250,7 @@
     primary_output = primary_output_path or target_output_path
     current_cutoff_hours = float(get_decision_cutoff_hours())
     clean_min_date, clean_max_date = (None, None)
+    label_version = label_version or DEFAULT_LABEL_VERSION
     if start_date is None or end_date is None:
         clean_min_date, clean_max_date = _get_clean_date_bounds()
 
@@ -294,7 +297,7 @@
             build_player_drive_level(start_date=cur, end_date=chunk_end)
             
             # 5. Player-game aggregations (for rolling window features)
-            build_player_game_level(start_date=cur, end_date=chunk_end)
+            build_player_game_level(start_date=cur, end_date=chunk_end, label_version=label_version)
 
             # advance to next slice
             cur += timedelta(days=chunk_days)
@@ -948,11 +951,19 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    # Log target distribution for anytime_td
-    if "anytime_td" in df_player_game_all.columns:
-        td_count = df_player_game_all["anytime_td"].sum()
-        td_rate = td_count / len(df_player_game_all) * 100
-        logging.info("    Anytime TD rate: %.2f%% (%d/%d)", td_rate, td_count, len(df_player_game_all))
+    spec = get_label_spec(label_version)
+    label_candidates = {spec.primary, "anytime_td"}
+    for label_col in label_candidates:
+        if label_col in df_player_game_all.columns:
+            td_count = df_player_game_all[label_col].sum()
+            td_rate = td_count / len(df_player_game_all) * 100
+            logging.info(
+                "    Label %s rate: %.2f%% (%d/%d)",
+                label_col,
+                td_rate,
+                td_count,
+                len(df_player_game_all),
+            )
     
     return df_player_game_all
 
@@ -965,6 +976,7 @@
     recompute_intermediate: bool = True,
     build_rolling: bool = True,
     cutoff_hours_list: Sequence[float] | None = None,
+    label_version: str | None = None,
 ) -> pl.DataFrame:
     """Build feature matrices for one or more decision cutoff horizons.
 
@@ -992,6 +1004,7 @@
                 output_path=output_path,
                 primary_output_path=primary_output,
                 cutoff_label=label,
+                label_version=label_version,
             )
         if idx == 0:
             primary_result = df
diff --git a/pipeline/train.py b/pipeline/train.py
index 265bc29f4861d2d4d26f54fd7f77304de8fe6742..fe70207dcdf25d209ee3ad55080b7ce826347c44
--- a/pipeline/train.py
+++ b/pipeline/train.py
@@ -98,6 +98,7 @@
     fit_team_conformal_sums,
     composite_sum_interval,
 )
+from utils.feature.targets import require_target_column
 
 # Ignore specific, noisy warnings from dependencies
 warnings.filterwarnings(
@@ -259,6 +260,7 @@
 
         # Per-problem attributes initialised later
         self.target_col = None
+        self.label_version = None
         self.feature_columns = None
 
         self.models = {}
@@ -2163,6 +2165,7 @@
             
             problem_copy = copy.deepcopy(problem)
             self.target_col = problem_copy['target_col']
+            self.label_version = problem_copy.get('label_version') or problem_copy.get("labels", {}).get("version")
             derived_cfg = problem_copy.get('derived_target')
             target_load_cols: list[str] = []
             if derived_cfg:
@@ -2269,6 +2272,12 @@
                 df_problem = df_problem.loc[:, ~df_problem.columns.duplicated()]
 
             df_problem = self._apply_problem_level_overrides(df_problem, problem_copy)
+            df_problem = require_target_column(
+                df_problem,
+                self.target_col,
+                label_version=self.label_version,
+                min_non_null=1,
+            )
             
             # Merge input predictions if required
             if input_preds:
diff --git a/utils/feature/labels.py b/utils/feature/labels.py
new file mode 100644
index 0000000000000000000000000000000000000000..b34571f04254cd7bceb9363a190ee7d305852bd5
--- /dev/null
+++ b/utils/feature/labels.py
@@ -0,0 +1,169 @@
+"""Label semantics and versioning for NFL player-level targets.
+
+This module centralizes anytime-TD label definitions so that:
+- Semantics are explicit and versioned.
+- Training can request a specific label column per problem.
+- Feature generation can emit multiple label variants for analysis.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass, field
+from typing import Dict, Iterable, Mapping
+
+import polars as pl
+
+
+@dataclass(frozen=True)
+class LabelRules:
+    """Rules controlling which TD components count toward a label."""
+
+    include_rush: bool = True
+    include_rec: bool = True
+    include_pass_thrown: bool = True  # credit passers for thrown TDs
+    include_other: bool = False  # fumble returns, defensive/special teams if present
+
+
+@dataclass(frozen=True)
+class LabelSpec:
+    """Container describing a label version."""
+
+    name: str
+    primary: str
+    labels: Mapping[str, LabelRules]
+    aliases: Mapping[str, str] = field(default_factory=dict)
+
+    @property
+    def all_columns(self) -> set[str]:
+        cols = set(self.labels.keys())
+        cols.update(self.aliases.keys())
+        return cols
+
+
+DEFAULT_LABEL_VERSION = "v1_any_offense"
+
+
+LABEL_VERSIONS: Dict[str, LabelSpec] = {
+    "v1_any_offense": LabelSpec(
+        name="v1_any_offense",
+        primary="anytime_td_offense",
+        labels={
+            "anytime_td_offense": LabelRules(include_other=False),
+            "anytime_td_rush": LabelRules(include_rush=True, include_rec=False, include_pass_thrown=False, include_other=False),
+            "anytime_td_rec": LabelRules(include_rush=False, include_rec=True, include_pass_thrown=False, include_other=False),
+            "anytime_td_pass_thrown": LabelRules(include_rush=False, include_rec=False, include_pass_thrown=True, include_other=False),
+            "anytime_td_all": LabelRules(include_other=True),
+        },
+        aliases={
+            # Maintain legacy column name as an alias to the offense-only label.
+            "anytime_td": "anytime_td_offense",
+            # Keep td_count pointing to the offense definition for backward compatibility.
+            "td_count": "td_count_offense",
+        },
+    ),
+    "v1_any_all": LabelSpec(
+        name="v1_any_all",
+        primary="anytime_td_all",
+        labels={
+            "anytime_td_all": LabelRules(include_other=True),
+            "anytime_td_offense": LabelRules(include_other=False),
+            "anytime_td_rush": LabelRules(include_rush=True, include_rec=False, include_pass_thrown=False, include_other=False),
+            "anytime_td_rec": LabelRules(include_rush=False, include_rec=True, include_pass_thrown=False, include_other=False),
+            "anytime_td_pass_thrown": LabelRules(include_rush=False, include_rec=False, include_pass_thrown=True, include_other=False),
+        },
+        aliases={
+            "anytime_td": "anytime_td_all",
+            "td_count": "td_count_all",
+        },
+    ),
+}
+
+
+def get_label_spec(version: str | None) -> LabelSpec:
+    """Return a concrete LabelSpec for the requested version (or default)."""
+
+    version = version or DEFAULT_LABEL_VERSION
+    if version not in LABEL_VERSIONS:
+        raise ValueError(
+            f"Unknown label_version '{version}'. "
+            f"Available: {sorted(LABEL_VERSIONS.keys())}"
+        )
+    return LABEL_VERSIONS[version]
+
+
+def _sum_expr(exprs: Iterable[pl.Expr]) -> pl.Expr:
+    exprs = list(exprs)
+    if not exprs:
+        return pl.lit(0).cast(pl.Int64)
+    acc = exprs[0]
+    for expr in exprs[1:]:
+        acc = acc + expr
+    return acc
+
+
+def compute_td_labels(df: pl.DataFrame, *, version: str | None = None) -> pl.DataFrame:
+    """Compute TD label columns according to a label version.
+
+    Parameters
+    ----------
+    df : pl.DataFrame
+        Player-game frame containing touchdown components.
+    version : str | None
+        Label version identifier. Defaults to DEFAULT_LABEL_VERSION.
+    """
+
+    spec = get_label_spec(version)
+    rush = pl.col("rushing_td_count").fill_null(0).cast(pl.Int64)
+    rec = pl.col("receiving_td_count").fill_null(0).cast(pl.Int64)
+    passing = pl.col("passing_td").fill_null(0).cast(pl.Int64)
+    reported_total = pl.col("touchdowns").fill_null(0).cast(pl.Int64)
+
+    offense_total = _sum_expr([rush, rec, passing]).alias("_td_offense_total")
+    other_total = (reported_total - offense_total).clip_min(0).alias("_td_other_total")
+    all_total = (offense_total + other_total).alias("_td_all_total")
+
+    totals_exprs = [
+        offense_total,
+        other_total,
+        all_total,
+    ]
+
+    label_exprs: list[pl.Expr] = [
+        pl.col("_td_offense_total").alias("td_count_offense"),
+        pl.col("_td_all_total").alias("td_count_all"),
+    ]
+
+    for label_name, rules in spec.labels.items():
+        parts: list[pl.Expr] = []
+        if rules.include_rush:
+            parts.append(rush)
+        if rules.include_rec:
+            parts.append(rec)
+        if rules.include_pass_thrown:
+            parts.append(passing)
+        if rules.include_other:
+            parts.append(pl.col("_td_other_total"))
+        total_expr = _sum_expr(parts)
+        label_exprs.append((total_expr > 0).cast(pl.Int8).alias(label_name))
+
+    # Canonical counts for compatibility
+    if "td_count" not in df.columns:
+        # Fill td_count using the alias mapping; default to offense count.
+        target_alias = spec.aliases.get("td_count") or "td_count_offense"
+        label_exprs.append(pl.col(target_alias).alias("td_count"))
+
+    df = df.with_columns(totals_exprs).with_columns(label_exprs)
+
+    # Resolve aliases (e.g., anytime_td -> anytime_td_offense)
+    if spec.aliases:
+        alias_exprs = []
+        for alias_name, source_name in spec.aliases.items():
+            if source_name in df.columns:
+                alias_exprs.append(pl.col(source_name).alias(alias_name))
+        if alias_exprs:
+            df = df.with_columns(alias_exprs)
+
+    drop_cols = [col for col in ("_td_offense_total", "_td_other_total", "_td_all_total") if col in df.columns]
+    if drop_cols:
+        df = df.drop(drop_cols)
+    return df
diff --git a/utils/feature/player_game_level.py b/utils/feature/player_game_level.py
index b6fe516c5f03d575038eef554d5ab39ea5d5c90d..dd4f1f7fcc9de4d8c63390f0a160005eeae48e2f
--- a/utils/feature/player_game_level.py
+++ b/utils/feature/player_game_level.py
@@ -4,8 +4,12 @@
 Each player gets one row per game with their total stats.
 
 Target columns created:
-- anytime_td (binary): Did player score a TD (receiving or rushing)?
-- td_count (int): Number of TDs scored (receiving + rushing)
+- anytime_td_offense (binary): Did player score an offensive TD (rush/rec/pass thrown)?
+- anytime_td_all (binary): Did player score any TD (including defensive/special teams if present)?
+- anytime_td_rush / anytime_td_rec / anytime_td_pass_thrown: Type-specific TD flags.
+- anytime_td (binary): Legacy alias → current label version primary.
+- td_count_offense / td_count_all: TD counts aligned to label semantics.
+- td_count (int): Legacy alias for the primary td_count.
 - passing_td (int): Number of passing TDs (for QBs)
 - receiving_yards (float): Total receiving yards
 - rushing_yards (float): Total rushing yards
@@ -33,6 +37,7 @@
 from utils.collect.nfl_schedules import get_schedule
 from utils.feature.asof import decision_cutoff_hours_default, fallback_cutoff_hours, get_decision_cutoff_hours, get_fallback_cutoff_hours
 from utils.feature.player_drive_level import _load_play_level_data
+from utils.feature.labels import DEFAULT_LABEL_VERSION, compute_td_labels
 from utils.train.injury_availability import (
     load_latest_artifact,
     predict_probabilities as predict_injury_probabilities,
@@ -1582,7 +1587,12 @@
     if flag_cols:
         df = df.with_columns([pl.col(col).cast(pl.Int8) for col in flag_cols])
     return df
-def build_player_game_level(*, start_date: date, end_date: date) -> None:
+def build_player_game_level(
+    *,
+    start_date: date,
+    end_date: date,
+    label_version: str | None = None,
+) -> None:
     """Aggregate play-level data to player-game level.
     
     Creates one row per (player, game) with accumulated stats.
@@ -1680,7 +1690,7 @@
     
     # Merge rows where same player had multiple roles in same game
     # (e.g., QB who also rushed, WR who also rushed)
-    df_merged = _merge_multi_role_players(df_all)
+    df_merged = _merge_multi_role_players(df_all, label_version=label_version or DEFAULT_LABEL_VERSION)
 
     df_merged = _append_zero_usage_players(df_merged, seasons_in_window)
     
@@ -3368,7 +3378,7 @@
     )
 
 
-def _merge_multi_role_players(df: pl.DataFrame) -> pl.DataFrame:
+def _merge_multi_role_players(df: pl.DataFrame, *, label_version: str | None = None) -> pl.DataFrame:
     """Merge stats for players who had multiple roles in same game.
     
     Example: QB who passed and rushed, WR who received and rushed.
@@ -3422,8 +3432,6 @@
         if col in merged.columns:
             merged = merged.with_columns(pl.col(col).fill_null(0))
 
-    # Fallback touchdown logic: if generic touchdown attribution is missing,
-    # derive it from rushing + receiving touchdowns.
     merged = merged.with_columns([
         pl.col("touchdowns").fill_null(0).alias("touchdowns"),
         pl.col("rushing_td_count").fill_null(0).alias("rushing_td_count"),
@@ -3435,17 +3443,5 @@
         pl.col("goal_to_go_carry").fill_null(0).alias("goal_to_go_carry"),
     ])
 
-    merged = merged.with_columns([
-        pl.when(pl.col("touchdowns") > 0)
-        .then(pl.col("touchdowns"))
-        .otherwise(pl.col("rushing_td_count") + pl.col("receiving_td_count"))
-        .cast(pl.Int64)
-        .alias("_total_touchdowns")
-    ])
-
-    merged = merged.with_columns([
-        (pl.col("_total_touchdowns") > 0).cast(pl.Int8).alias("anytime_td"),
-        pl.col("_total_touchdowns").alias("td_count"),
-    ]).drop("_total_touchdowns")
-    
+    merged = compute_td_labels(merged, version=label_version)
     return merged
diff --git a/utils/feature/targets.py b/utils/feature/targets.py
index 7738086dcbfda7432b937cc7d8095988cb0edff0..769ee8735c4024c4410ddd674b11112f093624dd
--- a/utils/feature/targets.py
+++ b/utils/feature/targets.py
@@ -7,6 +7,8 @@
 import polars as pl
 import logging
 
+from utils.feature.labels import DEFAULT_LABEL_VERSION, get_label_spec
+
 logger = logging.getLogger(__name__)
 
 
@@ -14,9 +16,16 @@
 NFL_TARGET_SCHEMA = {
     # Binary classification targets
     "anytime_td": pl.Int8,  # Primary MVP target: did player score a TD?
+    "anytime_td_offense": pl.Int8,
+    "anytime_td_all": pl.Int8,
+    "anytime_td_rush": pl.Int8,
+    "anytime_td_rec": pl.Int8,
+    "anytime_td_pass_thrown": pl.Int8,
     
     # Count/regression targets
     "td_count": pl.Int64,  # Number of TDs scored (receiving + rushing)
+    "td_count_offense": pl.Int64,
+    "td_count_all": pl.Int64,
     "passing_td": pl.Int64,  # Number of passing TDs (QB only)
     
     # Yardage regression targets
@@ -103,4 +112,40 @@
     pl.DataFrame
         DataFrame with validated target columns
     """
-    return validate_target_columns(df, strict=False)
\ No newline at end of file
+    return validate_target_columns(df, strict=False)
+
+
+def require_target_column(
+    df: pl.DataFrame,
+    target_col: str,
+    *,
+    label_version: str | None = None,
+    min_non_null: int = 1,
+) -> pl.DataFrame:
+    """Ensure the configured target column exists and is populated.
+
+    Raises a ValueError if the column is missing or entirely null.
+    """
+
+    if target_col not in df.columns:
+        alias_hint = ""
+        if label_version:
+            try:
+                spec = get_label_spec(label_version or DEFAULT_LABEL_VERSION)
+                if target_col in spec.aliases:
+                    alias_hint = f" Target maps to '{spec.aliases[target_col]}' under {spec.name}."
+            except Exception:
+                alias_hint = ""
+        raise ValueError(f"Target column '{target_col}' not found in feature frame.{alias_hint}")
+
+    series = df[target_col]
+    non_null = series.drop_nulls().height
+    if non_null < min_non_null:
+        raise ValueError(
+            f"Target column '{target_col}' has insufficient non-null rows "
+            f"({non_null}/{len(series)})."
+        )
+    nulls = len(series) - non_null
+    if nulls > 0:
+        logger.warning("Target %s contains %d null rows; they will be dropped.", target_col, nulls)
+    return df


thinking
**Preparing label tests and parameter updates**

thinking
**Planning tests for alias checks**
file update
A /Users/jameswest/Desktop/nfl_predict/tests/labels/test_labels.py
import polars as pl

from utils.feature.labels import (
    DEFAULT_LABEL_VERSION,
    compute_td_labels,
    get_label_spec,
)


def _lookup(frame: pl.DataFrame, player_id: str) -> dict:
    return frame.filter(pl.col("player_id") == player_id).to_dicts()[0]


def test_compute_td_labels_offense_and_all_variants():
    df = pl.DataFrame(
        {
            "player_id": ["rush", "rec", "pass", "def"],
            "game_id": ["g1"] * 4,
            "rushing_td_count": [1, 0, 0, 0],
            "receiving_td_count": [0, 1, 0, 0],
            "passing_td": [0, 0, 1, 0],
            # Generic touchdown attribution (e.g., defensive return)
            "touchdowns": [1, 1, 0, 1],
        }
    )

    result = compute_td_labels(df, version="v1_any_offense")

    rush = _lookup(result, "rush")
    assert rush["anytime_td_offense"] == 1
    assert rush["anytime_td_rush"] == 1
    assert rush["anytime_td_rec"] == 0
    assert rush["anytime_td_pass_thrown"] == 0
    assert rush["td_count_offense"] == 1
    assert rush["td_count_all"] == 1
    assert rush["anytime_td"] == rush["anytime_td_offense"]

    rec = _lookup(result, "rec")
    assert rec["anytime_td_offense"] == 1
    assert rec["anytime_td_rec"] == 1
    assert rec["anytime_td_rush"] == 0

    passer = _lookup(result, "pass")
    assert passer["anytime_td_pass_thrown"] == 1
    assert passer["anytime_td_offense"] == 1
    assert passer["anytime_td_all"] == 1  # includes offensive TDs

    defensive = _lookup(result, "def")
    assert defensive["anytime_td_offense"] == 0  # no offensive scoring events
    assert defensive["anytime_td_all"] == 1  # credited via generic touchdown
    assert defensive["anytime_td"] == defensive["anytime_td_offense"]


def test_label_version_any_all_aliases_anytime_td():
    spec = get_label_spec("v1_any_all")
    assert spec.primary == "anytime_td_all"

    df = pl.DataFrame(
        {
            "player_id": ["all"],
            "game_id": ["g1"],
            "rushing_td_count": [0],
            "receiving_td_count": [0],
            "passing_td": [0],
            "touchdowns": [1],
        }
    )
    result = compute_td_labels(df, version="v1_any_all")
    row = _lookup(result, "all")
    # Alias ensures legacy anytime_td follows the version's primary definition.
    assert row["anytime_td_all"] == 1
    assert row["anytime_td"] == row["anytime_td_all"]
apply_patch(auto_approved=true) exited 0 in 118ms:
Success. Updated the following files:
A tests/labels/test_labels.py
file update:
diff --git a/config/training.yaml b/config/training.yaml
index 3055a636b89249119408aaad970d3025956877db..3953818d861d0410246bff132110722a3ce44007
--- a/config/training.yaml
+++ b/config/training.yaml
@@ -475,6 +475,7 @@
   # Calibrated probability of scoring > 0 TDs.
   - name: 'anytime_td'
     target_col: 'anytime_td'
+    label_version: 'v1_any_offense'
     task_type: 'classification'
     input_predictions:
       - 'availability_active'
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 6c47a91d08f9d309f94323efd4708bb992dc4ce0..5ba68e8bf1acd3a789a76a8857674e6f6433017b
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -26,6 +26,7 @@
 from utils.feature.player_drive_level import build_player_drive_level
 from utils.feature.player_game_level import build_player_game_level
 from utils.feature.opponent_splits import build_opponent_splits
+from utils.feature.labels import DEFAULT_LABEL_VERSION, get_label_spec
 from utils.feature.targets import validate_target_columns
 from utils.feature.daily_totals import build_daily_cache_range
 from utils.feature.rolling_window import add_rolling_features
@@ -233,6 +234,7 @@
     output_path: Path | None = None,
     primary_output_path: Path | None = None,
     cutoff_label: str | None = None,
+    label_version: str | None = None,
 ) -> pl.DataFrame:
     """Run full feature pipeline up to *inclusive* `end_date` for a single cutoff window.
 
@@ -248,6 +250,7 @@
     primary_output = primary_output_path or target_output_path
     current_cutoff_hours = float(get_decision_cutoff_hours())
     clean_min_date, clean_max_date = (None, None)
+    label_version = label_version or DEFAULT_LABEL_VERSION
     if start_date is None or end_date is None:
         clean_min_date, clean_max_date = _get_clean_date_bounds()
 
@@ -294,7 +297,7 @@
             build_player_drive_level(start_date=cur, end_date=chunk_end)
             
             # 5. Player-game aggregations (for rolling window features)
-            build_player_game_level(start_date=cur, end_date=chunk_end)
+            build_player_game_level(start_date=cur, end_date=chunk_end, label_version=label_version)
 
             # advance to next slice
             cur += timedelta(days=chunk_days)
@@ -948,11 +951,19 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    # Log target distribution for anytime_td
-    if "anytime_td" in df_player_game_all.columns:
-        td_count = df_player_game_all["anytime_td"].sum()
-        td_rate = td_count / len(df_player_game_all) * 100
-        logging.info("    Anytime TD rate: %.2f%% (%d/%d)", td_rate, td_count, len(df_player_game_all))
+    spec = get_label_spec(label_version)
+    label_candidates = {spec.primary, "anytime_td"}
+    for label_col in label_candidates:
+        if label_col in df_player_game_all.columns:
+            td_count = df_player_game_all[label_col].sum()
+            td_rate = td_count / len(df_player_game_all) * 100
+            logging.info(
+                "    Label %s rate: %.2f%% (%d/%d)",
+                label_col,
+                td_rate,
+                td_count,
+                len(df_player_game_all),
+            )
     
     return df_player_game_all
 
@@ -965,6 +976,7 @@
     recompute_intermediate: bool = True,
     build_rolling: bool = True,
     cutoff_hours_list: Sequence[float] | None = None,
+    label_version: str | None = None,
 ) -> pl.DataFrame:
     """Build feature matrices for one or more decision cutoff horizons.
 
@@ -992,6 +1004,7 @@
                 output_path=output_path,
                 primary_output_path=primary_output,
                 cutoff_label=label,
+                label_version=label_version,
             )
         if idx == 0:
             primary_result = df
diff --git a/pipeline/train.py b/pipeline/train.py
index 265bc29f4861d2d4d26f54fd7f77304de8fe6742..fe70207dcdf25d209ee3ad55080b7ce826347c44
--- a/pipeline/train.py
+++ b/pipeline/train.py
@@ -98,6 +98,7 @@
     fit_team_conformal_sums,
     composite_sum_interval,
 )
+from utils.feature.targets import require_target_column
 
 # Ignore specific, noisy warnings from dependencies
 warnings.filterwarnings(
@@ -259,6 +260,7 @@
 
         # Per-problem attributes initialised later
         self.target_col = None
+        self.label_version = None
         self.feature_columns = None
 
         self.models = {}
@@ -2163,6 +2165,7 @@
             
             problem_copy = copy.deepcopy(problem)
             self.target_col = problem_copy['target_col']
+            self.label_version = problem_copy.get('label_version') or problem_copy.get("labels", {}).get("version")
             derived_cfg = problem_copy.get('derived_target')
             target_load_cols: list[str] = []
             if derived_cfg:
@@ -2269,6 +2272,12 @@
                 df_problem = df_problem.loc[:, ~df_problem.columns.duplicated()]
 
             df_problem = self._apply_problem_level_overrides(df_problem, problem_copy)
+            df_problem = require_target_column(
+                df_problem,
+                self.target_col,
+                label_version=self.label_version,
+                min_non_null=1,
+            )
             
             # Merge input predictions if required
             if input_preds:
diff --git a/tests/labels/test_labels.py b/tests/labels/test_labels.py
new file mode 100644
index 0000000000000000000000000000000000000000..702846263bb6d5ac128d7f352b8e541a33e59571
--- /dev/null
+++ b/tests/labels/test_labels.py
@@ -0,0 +1,72 @@
+import polars as pl
+
+from utils.feature.labels import (
+    DEFAULT_LABEL_VERSION,
+    compute_td_labels,
+    get_label_spec,
+)
+
+
+def _lookup(frame: pl.DataFrame, player_id: str) -> dict:
+    return frame.filter(pl.col("player_id") == player_id).to_dicts()[0]
+
+
+def test_compute_td_labels_offense_and_all_variants():
+    df = pl.DataFrame(
+        {
+            "player_id": ["rush", "rec", "pass", "def"],
+            "game_id": ["g1"] * 4,
+            "rushing_td_count": [1, 0, 0, 0],
+            "receiving_td_count": [0, 1, 0, 0],
+            "passing_td": [0, 0, 1, 0],
+            # Generic touchdown attribution (e.g., defensive return)
+            "touchdowns": [1, 1, 0, 1],
+        }
+    )
+
+    result = compute_td_labels(df, version="v1_any_offense")
+
+    rush = _lookup(result, "rush")
+    assert rush["anytime_td_offense"] == 1
+    assert rush["anytime_td_rush"] == 1
+    assert rush["anytime_td_rec"] == 0
+    assert rush["anytime_td_pass_thrown"] == 0
+    assert rush["td_count_offense"] == 1
+    assert rush["td_count_all"] == 1
+    assert rush["anytime_td"] == rush["anytime_td_offense"]
+
+    rec = _lookup(result, "rec")
+    assert rec["anytime_td_offense"] == 1
+    assert rec["anytime_td_rec"] == 1
+    assert rec["anytime_td_rush"] == 0
+
+    passer = _lookup(result, "pass")
+    assert passer["anytime_td_pass_thrown"] == 1
+    assert passer["anytime_td_offense"] == 1
+    assert passer["anytime_td_all"] == 1  # includes offensive TDs
+
+    defensive = _lookup(result, "def")
+    assert defensive["anytime_td_offense"] == 0  # no offensive scoring events
+    assert defensive["anytime_td_all"] == 1  # credited via generic touchdown
+    assert defensive["anytime_td"] == defensive["anytime_td_offense"]
+
+
+def test_label_version_any_all_aliases_anytime_td():
+    spec = get_label_spec("v1_any_all")
+    assert spec.primary == "anytime_td_all"
+
+    df = pl.DataFrame(
+        {
+            "player_id": ["all"],
+            "game_id": ["g1"],
+            "rushing_td_count": [0],
+            "receiving_td_count": [0],
+            "passing_td": [0],
+            "touchdowns": [1],
+        }
+    )
+    result = compute_td_labels(df, version="v1_any_all")
+    row = _lookup(result, "all")
+    # Alias ensures legacy anytime_td follows the version's primary definition.
+    assert row["anytime_td_all"] == 1
+    assert row["anytime_td"] == row["anytime_td_all"]
diff --git a/utils/feature/labels.py b/utils/feature/labels.py
new file mode 100644
index 0000000000000000000000000000000000000000..b34571f04254cd7bceb9363a190ee7d305852bd5
--- /dev/null
+++ b/utils/feature/labels.py
@@ -0,0 +1,169 @@
+"""Label semantics and versioning for NFL player-level targets.
+
+This module centralizes anytime-TD label definitions so that:
+- Semantics are explicit and versioned.
+- Training can request a specific label column per problem.
+- Feature generation can emit multiple label variants for analysis.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass, field
+from typing import Dict, Iterable, Mapping
+
+import polars as pl
+
+
+@dataclass(frozen=True)
+class LabelRules:
+    """Rules controlling which TD components count toward a label."""
+
+    include_rush: bool = True
+    include_rec: bool = True
+    include_pass_thrown: bool = True  # credit passers for thrown TDs
+    include_other: bool = False  # fumble returns, defensive/special teams if present
+
+
+@dataclass(frozen=True)
+class LabelSpec:
+    """Container describing a label version."""
+
+    name: str
+    primary: str
+    labels: Mapping[str, LabelRules]
+    aliases: Mapping[str, str] = field(default_factory=dict)
+
+    @property
+    def all_columns(self) -> set[str]:
+        cols = set(self.labels.keys())
+        cols.update(self.aliases.keys())
+        return cols
+
+
+DEFAULT_LABEL_VERSION = "v1_any_offense"
+
+
+LABEL_VERSIONS: Dict[str, LabelSpec] = {
+    "v1_any_offense": LabelSpec(
+        name="v1_any_offense",
+        primary="anytime_td_offense",
+        labels={
+            "anytime_td_offense": LabelRules(include_other=False),
+            "anytime_td_rush": LabelRules(include_rush=True, include_rec=False, include_pass_thrown=False, include_other=False),
+            "anytime_td_rec": LabelRules(include_rush=False, include_rec=True, include_pass_thrown=False, include_other=False),
+            "anytime_td_pass_thrown": LabelRules(include_rush=False, include_rec=False, include_pass_thrown=True, include_other=False),
+            "anytime_td_all": LabelRules(include_other=True),
+        },
+        aliases={
+            # Maintain legacy column name as an alias to the offense-only label.
+            "anytime_td": "anytime_td_offense",
+            # Keep td_count pointing to the offense definition for backward compatibility.
+            "td_count": "td_count_offense",
+        },
+    ),
+    "v1_any_all": LabelSpec(
+        name="v1_any_all",
+        primary="anytime_td_all",
+        labels={
+            "anytime_td_all": LabelRules(include_other=True),
+            "anytime_td_offense": LabelRules(include_other=False),
+            "anytime_td_rush": LabelRules(include_rush=True, include_rec=False, include_pass_thrown=False, include_other=False),
+            "anytime_td_rec": LabelRules(include_rush=False, include_rec=True, include_pass_thrown=False, include_other=False),
+            "anytime_td_pass_thrown": LabelRules(include_rush=False, include_rec=False, include_pass_thrown=True, include_other=False),
+        },
+        aliases={
+            "anytime_td": "anytime_td_all",
+            "td_count": "td_count_all",
+        },
+    ),
+}
+
+
+def get_label_spec(version: str | None) -> LabelSpec:
+    """Return a concrete LabelSpec for the requested version (or default)."""
+
+    version = version or DEFAULT_LABEL_VERSION
+    if version not in LABEL_VERSIONS:
+        raise ValueError(
+            f"Unknown label_version '{version}'. "
+            f"Available: {sorted(LABEL_VERSIONS.keys())}"
+        )
+    return LABEL_VERSIONS[version]
+
+
+def _sum_expr(exprs: Iterable[pl.Expr]) -> pl.Expr:
+    exprs = list(exprs)
+    if not exprs:
+        return pl.lit(0).cast(pl.Int64)
+    acc = exprs[0]
+    for expr in exprs[1:]:
+        acc = acc + expr
+    return acc
+
+
+def compute_td_labels(df: pl.DataFrame, *, version: str | None = None) -> pl.DataFrame:
+    """Compute TD label columns according to a label version.
+
+    Parameters
+    ----------
+    df : pl.DataFrame
+        Player-game frame containing touchdown components.
+    version : str | None
+        Label version identifier. Defaults to DEFAULT_LABEL_VERSION.
+    """
+
+    spec = get_label_spec(version)
+    rush = pl.col("rushing_td_count").fill_null(0).cast(pl.Int64)
+    rec = pl.col("receiving_td_count").fill_null(0).cast(pl.Int64)
+    passing = pl.col("passing_td").fill_null(0).cast(pl.Int64)
+    reported_total = pl.col("touchdowns").fill_null(0).cast(pl.Int64)
+
+    offense_total = _sum_expr([rush, rec, passing]).alias("_td_offense_total")
+    other_total = (reported_total - offense_total).clip_min(0).alias("_td_other_total")
+    all_total = (offense_total + other_total).alias("_td_all_total")
+
+    totals_exprs = [
+        offense_total,
+        other_total,
+        all_total,
+    ]
+
+    label_exprs: list[pl.Expr] = [
+        pl.col("_td_offense_total").alias("td_count_offense"),
+        pl.col("_td_all_total").alias("td_count_all"),
+    ]
+
+    for label_name, rules in spec.labels.items():
+        parts: list[pl.Expr] = []
+        if rules.include_rush:
+            parts.append(rush)
+        if rules.include_rec:
+            parts.append(rec)
+        if rules.include_pass_thrown:
+            parts.append(passing)
+        if rules.include_other:
+            parts.append(pl.col("_td_other_total"))
+        total_expr = _sum_expr(parts)
+        label_exprs.append((total_expr > 0).cast(pl.Int8).alias(label_name))
+
+    # Canonical counts for compatibility
+    if "td_count" not in df.columns:
+        # Fill td_count using the alias mapping; default to offense count.
+        target_alias = spec.aliases.get("td_count") or "td_count_offense"
+        label_exprs.append(pl.col(target_alias).alias("td_count"))
+
+    df = df.with_columns(totals_exprs).with_columns(label_exprs)
+
+    # Resolve aliases (e.g., anytime_td -> anytime_td_offense)
+    if spec.aliases:
+        alias_exprs = []
+        for alias_name, source_name in spec.aliases.items():
+            if source_name in df.columns:
+                alias_exprs.append(pl.col(source_name).alias(alias_name))
+        if alias_exprs:
+            df = df.with_columns(alias_exprs)
+
+    drop_cols = [col for col in ("_td_offense_total", "_td_other_total", "_td_all_total") if col in df.columns]
+    if drop_cols:
+        df = df.drop(drop_cols)
+    return df
diff --git a/utils/feature/player_game_level.py b/utils/feature/player_game_level.py
index b6fe516c5f03d575038eef554d5ab39ea5d5c90d..dd4f1f7fcc9de4d8c63390f0a160005eeae48e2f
--- a/utils/feature/player_game_level.py
+++ b/utils/feature/player_game_level.py
@@ -4,8 +4,12 @@
 Each player gets one row per game with their total stats.
 
 Target columns created:
-- anytime_td (binary): Did player score a TD (receiving or rushing)?
-- td_count (int): Number of TDs scored (receiving + rushing)
+- anytime_td_offense (binary): Did player score an offensive TD (rush/rec/pass thrown)?
+- anytime_td_all (binary): Did player score any TD (including defensive/special teams if present)?
+- anytime_td_rush / anytime_td_rec / anytime_td_pass_thrown: Type-specific TD flags.
+- anytime_td (binary): Legacy alias → current label version primary.
+- td_count_offense / td_count_all: TD counts aligned to label semantics.
+- td_count (int): Legacy alias for the primary td_count.
 - passing_td (int): Number of passing TDs (for QBs)
 - receiving_yards (float): Total receiving yards
 - rushing_yards (float): Total rushing yards
@@ -33,6 +37,7 @@
 from utils.collect.nfl_schedules import get_schedule
 from utils.feature.asof import decision_cutoff_hours_default, fallback_cutoff_hours, get_decision_cutoff_hours, get_fallback_cutoff_hours
 from utils.feature.player_drive_level import _load_play_level_data
+from utils.feature.labels import DEFAULT_LABEL_VERSION, compute_td_labels
 from utils.train.injury_availability import (
     load_latest_artifact,
     predict_probabilities as predict_injury_probabilities,
@@ -1582,7 +1587,12 @@
     if flag_cols:
         df = df.with_columns([pl.col(col).cast(pl.Int8) for col in flag_cols])
     return df
-def build_player_game_level(*, start_date: date, end_date: date) -> None:
+def build_player_game_level(
+    *,
+    start_date: date,
+    end_date: date,
+    label_version: str | None = None,
+) -> None:
     """Aggregate play-level data to player-game level.
     
     Creates one row per (player, game) with accumulated stats.
@@ -1680,7 +1690,7 @@
     
     # Merge rows where same player had multiple roles in same game
     # (e.g., QB who also rushed, WR who also rushed)
-    df_merged = _merge_multi_role_players(df_all)
+    df_merged = _merge_multi_role_players(df_all, label_version=label_version or DEFAULT_LABEL_VERSION)
 
     df_merged = _append_zero_usage_players(df_merged, seasons_in_window)
     
@@ -3368,7 +3378,7 @@
     )
 
 
-def _merge_multi_role_players(df: pl.DataFrame) -> pl.DataFrame:
+def _merge_multi_role_players(df: pl.DataFrame, *, label_version: str | None = None) -> pl.DataFrame:
     """Merge stats for players who had multiple roles in same game.
     
     Example: QB who passed and rushed, WR who received and rushed.
@@ -3422,8 +3432,6 @@
         if col in merged.columns:
             merged = merged.with_columns(pl.col(col).fill_null(0))
 
-    # Fallback touchdown logic: if generic touchdown attribution is missing,
-    # derive it from rushing + receiving touchdowns.
     merged = merged.with_columns([
         pl.col("touchdowns").fill_null(0).alias("touchdowns"),
         pl.col("rushing_td_count").fill_null(0).alias("rushing_td_count"),
@@ -3435,17 +3443,5 @@
         pl.col("goal_to_go_carry").fill_null(0).alias("goal_to_go_carry"),
     ])
 
-    merged = merged.with_columns([
-        pl.when(pl.col("touchdowns") > 0)
-        .then(pl.col("touchdowns"))
-        .otherwise(pl.col("rushing_td_count") + pl.col("receiving_td_count"))
-        .cast(pl.Int64)
-        .alias("_total_touchdowns")
-    ])
-
-    merged = merged.with_columns([
-        (pl.col("_total_touchdowns") > 0).cast(pl.Int8).alias("anytime_td"),
-        pl.col("_total_touchdowns").alias("td_count"),
-    ]).drop("_total_touchdowns")
-    
+    merged = compute_td_labels(merged, version=label_version)
     return merged
diff --git a/utils/feature/targets.py b/utils/feature/targets.py
index 7738086dcbfda7432b937cc7d8095988cb0edff0..769ee8735c4024c4410ddd674b11112f093624dd
--- a/utils/feature/targets.py
+++ b/utils/feature/targets.py
@@ -7,6 +7,8 @@
 import polars as pl
 import logging
 
+from utils.feature.labels import DEFAULT_LABEL_VERSION, get_label_spec
+
 logger = logging.getLogger(__name__)
 
 
@@ -14,9 +16,16 @@
 NFL_TARGET_SCHEMA = {
     # Binary classification targets
     "anytime_td": pl.Int8,  # Primary MVP target: did player score a TD?
+    "anytime_td_offense": pl.Int8,
+    "anytime_td_all": pl.Int8,
+    "anytime_td_rush": pl.Int8,
+    "anytime_td_rec": pl.Int8,
+    "anytime_td_pass_thrown": pl.Int8,
     
     # Count/regression targets
     "td_count": pl.Int64,  # Number of TDs scored (receiving + rushing)
+    "td_count_offense": pl.Int64,
+    "td_count_all": pl.Int64,
     "passing_td": pl.Int64,  # Number of passing TDs (QB only)
     
     # Yardage regression targets
@@ -103,4 +112,40 @@
     pl.DataFrame
         DataFrame with validated target columns
     """
-    return validate_target_columns(df, strict=False)
\ No newline at end of file
+    return validate_target_columns(df, strict=False)
+
+
+def require_target_column(
+    df: pl.DataFrame,
+    target_col: str,
+    *,
+    label_version: str | None = None,
+    min_non_null: int = 1,
+) -> pl.DataFrame:
+    """Ensure the configured target column exists and is populated.
+
+    Raises a ValueError if the column is missing or entirely null.
+    """
+
+    if target_col not in df.columns:
+        alias_hint = ""
+        if label_version:
+            try:
+                spec = get_label_spec(label_version or DEFAULT_LABEL_VERSION)
+                if target_col in spec.aliases:
+                    alias_hint = f" Target maps to '{spec.aliases[target_col]}' under {spec.name}."
+            except Exception:
+                alias_hint = ""
+        raise ValueError(f"Target column '{target_col}' not found in feature frame.{alias_hint}")
+
+    series = df[target_col]
+    non_null = series.drop_nulls().height
+    if non_null < min_non_null:
+        raise ValueError(
+            f"Target column '{target_col}' has insufficient non-null rows "
+            f"({non_null}/{len(series)})."
+        )
+    nulls = len(series) - non_null
+    if nulls > 0:
+        logger.warning("Target %s contains %d null rows; they will be dropped.", target_col, nulls)
+    return df

file update:
diff --git a/config/training.yaml b/config/training.yaml
index 3055a636b89249119408aaad970d3025956877db..3953818d861d0410246bff132110722a3ce44007
--- a/config/training.yaml
+++ b/config/training.yaml
@@ -475,6 +475,7 @@
   # Calibrated probability of scoring > 0 TDs.
   - name: 'anytime_td'
     target_col: 'anytime_td'
+    label_version: 'v1_any_offense'
     task_type: 'classification'
     input_predictions:
       - 'availability_active'
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 6c47a91d08f9d309f94323efd4708bb992dc4ce0..5ba68e8bf1acd3a789a76a8857674e6f6433017b
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -26,6 +26,7 @@
 from utils.feature.player_drive_level import build_player_drive_level
 from utils.feature.player_game_level import build_player_game_level
 from utils.feature.opponent_splits import build_opponent_splits
+from utils.feature.labels import DEFAULT_LABEL_VERSION, get_label_spec
 from utils.feature.targets import validate_target_columns
 from utils.feature.daily_totals import build_daily_cache_range
 from utils.feature.rolling_window import add_rolling_features
@@ -233,6 +234,7 @@
     output_path: Path | None = None,
     primary_output_path: Path | None = None,
     cutoff_label: str | None = None,
+    label_version: str | None = None,
 ) -> pl.DataFrame:
     """Run full feature pipeline up to *inclusive* `end_date` for a single cutoff window.
 
@@ -248,6 +250,7 @@
     primary_output = primary_output_path or target_output_path
     current_cutoff_hours = float(get_decision_cutoff_hours())
     clean_min_date, clean_max_date = (None, None)
+    label_version = label_version or DEFAULT_LABEL_VERSION
     if start_date is None or end_date is None:
         clean_min_date, clean_max_date = _get_clean_date_bounds()
 
@@ -294,7 +297,7 @@
             build_player_drive_level(start_date=cur, end_date=chunk_end)
             
             # 5. Player-game aggregations (for rolling window features)
-            build_player_game_level(start_date=cur, end_date=chunk_end)
+            build_player_game_level(start_date=cur, end_date=chunk_end, label_version=label_version)
 
             # advance to next slice
             cur += timedelta(days=chunk_days)
@@ -948,11 +951,19 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    # Log target distribution for anytime_td
-    if "anytime_td" in df_player_game_all.columns:
-        td_count = df_player_game_all["anytime_td"].sum()
-        td_rate = td_count / len(df_player_game_all) * 100
-        logging.info("    Anytime TD rate: %.2f%% (%d/%d)", td_rate, td_count, len(df_player_game_all))
+    spec = get_label_spec(label_version)
+    label_candidates = {spec.primary, "anytime_td"}
+    for label_col in label_candidates:
+        if label_col in df_player_game_all.columns:
+            td_count = df_player_game_all[label_col].sum()
+            td_rate = td_count / len(df_player_game_all) * 100
+            logging.info(
+                "    Label %s rate: %.2f%% (%d/%d)",
+                label_col,
+                td_rate,
+                td_count,
+                len(df_player_game_all),
+            )
     
     return df_player_game_all
 
@@ -965,6 +976,7 @@
     recompute_intermediate: bool = True,
     build_rolling: bool = True,
     cutoff_hours_list: Sequence[float] | None = None,
+    label_version: str | None = None,
 ) -> pl.DataFrame:
     """Build feature matrices for one or more decision cutoff horizons.
 
@@ -992,6 +1004,7 @@
                 output_path=output_path,
                 primary_output_path=primary_output,
                 cutoff_label=label,
+                label_version=label_version,
             )
         if idx == 0:
             primary_result = df
diff --git a/pipeline/train.py b/pipeline/train.py
index 265bc29f4861d2d4d26f54fd7f77304de8fe6742..fe70207dcdf25d209ee3ad55080b7ce826347c44
--- a/pipeline/train.py
+++ b/pipeline/train.py
@@ -98,6 +98,7 @@
     fit_team_conformal_sums,
     composite_sum_interval,
 )
+from utils.feature.targets import require_target_column
 
 # Ignore specific, noisy warnings from dependencies
 warnings.filterwarnings(
@@ -259,6 +260,7 @@
 
         # Per-problem attributes initialised later
         self.target_col = None
+        self.label_version = None
         self.feature_columns = None
 
         self.models = {}
@@ -2163,6 +2165,7 @@
             
             problem_copy = copy.deepcopy(problem)
             self.target_col = problem_copy['target_col']
+            self.label_version = problem_copy.get('label_version') or problem_copy.get("labels", {}).get("version")
             derived_cfg = problem_copy.get('derived_target')
             target_load_cols: list[str] = []
             if derived_cfg:
@@ -2269,6 +2272,12 @@
                 df_problem = df_problem.loc[:, ~df_problem.columns.duplicated()]
 
             df_problem = self._apply_problem_level_overrides(df_problem, problem_copy)
+            df_problem = require_target_column(
+                df_problem,
+                self.target_col,
+                label_version=self.label_version,
+                min_non_null=1,
+            )
             
             # Merge input predictions if required
             if input_preds:
diff --git a/tests/labels/test_labels.py b/tests/labels/test_labels.py
new file mode 100644
index 0000000000000000000000000000000000000000..702846263bb6d5ac128d7f352b8e541a33e59571
--- /dev/null
+++ b/tests/labels/test_labels.py
@@ -0,0 +1,72 @@
+import polars as pl
+
+from utils.feature.labels import (
+    DEFAULT_LABEL_VERSION,
+    compute_td_labels,
+    get_label_spec,
+)
+
+
+def _lookup(frame: pl.DataFrame, player_id: str) -> dict:
+    return frame.filter(pl.col("player_id") == player_id).to_dicts()[0]
+
+
+def test_compute_td_labels_offense_and_all_variants():
+    df = pl.DataFrame(
+        {
+            "player_id": ["rush", "rec", "pass", "def"],
+            "game_id": ["g1"] * 4,
+            "rushing_td_count": [1, 0, 0, 0],
+            "receiving_td_count": [0, 1, 0, 0],
+            "passing_td": [0, 0, 1, 0],
+            # Generic touchdown attribution (e.g., defensive return)
+            "touchdowns": [1, 1, 0, 1],
+        }
+    )
+
+    result = compute_td_labels(df, version="v1_any_offense")
+
+    rush = _lookup(result, "rush")
+    assert rush["anytime_td_offense"] == 1
+    assert rush["anytime_td_rush"] == 1
+    assert rush["anytime_td_rec"] == 0
+    assert rush["anytime_td_pass_thrown"] == 0
+    assert rush["td_count_offense"] == 1
+    assert rush["td_count_all"] == 1
+    assert rush["anytime_td"] == rush["anytime_td_offense"]
+
+    rec = _lookup(result, "rec")
+    assert rec["anytime_td_offense"] == 1
+    assert rec["anytime_td_rec"] == 1
+    assert rec["anytime_td_rush"] == 0
+
+    passer = _lookup(result, "pass")
+    assert passer["anytime_td_pass_thrown"] == 1
+    assert passer["anytime_td_offense"] == 1
+    assert passer["anytime_td_all"] == 1  # includes offensive TDs
+
+    defensive = _lookup(result, "def")
+    assert defensive["anytime_td_offense"] == 0  # no offensive scoring events
+    assert defensive["anytime_td_all"] == 1  # credited via generic touchdown
+    assert defensive["anytime_td"] == defensive["anytime_td_offense"]
+
+
+def test_label_version_any_all_aliases_anytime_td():
+    spec = get_label_spec("v1_any_all")
+    assert spec.primary == "anytime_td_all"
+
+    df = pl.DataFrame(
+        {
+            "player_id": ["all"],
+            "game_id": ["g1"],
+            "rushing_td_count": [0],
+            "receiving_td_count": [0],
+            "passing_td": [0],
+            "touchdowns": [1],
+        }
+    )
+    result = compute_td_labels(df, version="v1_any_all")
+    row = _lookup(result, "all")
+    # Alias ensures legacy anytime_td follows the version's primary definition.
+    assert row["anytime_td_all"] == 1
+    assert row["anytime_td"] == row["anytime_td_all"]
diff --git a/utils/feature/labels.py b/utils/feature/labels.py
new file mode 100644
index 0000000000000000000000000000000000000000..b34571f04254cd7bceb9363a190ee7d305852bd5
--- /dev/null
+++ b/utils/feature/labels.py
@@ -0,0 +1,169 @@
+"""Label semantics and versioning for NFL player-level targets.
+
+This module centralizes anytime-TD label definitions so that:
+- Semantics are explicit and versioned.
+- Training can request a specific label column per problem.
+- Feature generation can emit multiple label variants for analysis.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass, field
+from typing import Dict, Iterable, Mapping
+
+import polars as pl
+
+
+@dataclass(frozen=True)
+class LabelRules:
+    """Rules controlling which TD components count toward a label."""
+
+    include_rush: bool = True
+    include_rec: bool = True
+    include_pass_thrown: bool = True  # credit passers for thrown TDs
+    include_other: bool = False  # fumble returns, defensive/special teams if present
+
+
+@dataclass(frozen=True)
+class LabelSpec:
+    """Container describing a label version."""
+
+    name: str
+    primary: str
+    labels: Mapping[str, LabelRules]
+    aliases: Mapping[str, str] = field(default_factory=dict)
+
+    @property
+    def all_columns(self) -> set[str]:
+        cols = set(self.labels.keys())
+        cols.update(self.aliases.keys())
+        return cols
+
+
+DEFAULT_LABEL_VERSION = "v1_any_offense"
+
+
+LABEL_VERSIONS: Dict[str, LabelSpec] = {
+    "v1_any_offense": LabelSpec(
+        name="v1_any_offense",
+        primary="anytime_td_offense",
+        labels={
+            "anytime_td_offense": LabelRules(include_other=False),
+            "anytime_td_rush": LabelRules(include_rush=True, include_rec=False, include_pass_thrown=False, include_other=False),
+            "anytime_td_rec": LabelRules(include_rush=False, include_rec=True, include_pass_thrown=False, include_other=False),
+            "anytime_td_pass_thrown": LabelRules(include_rush=False, include_rec=False, include_pass_thrown=True, include_other=False),
+            "anytime_td_all": LabelRules(include_other=True),
+        },
+        aliases={
+            # Maintain legacy column name as an alias to the offense-only label.
+            "anytime_td": "anytime_td_offense",
+            # Keep td_count pointing to the offense definition for backward compatibility.
+            "td_count": "td_count_offense",
+        },
+    ),
+    "v1_any_all": LabelSpec(
+        name="v1_any_all",
+        primary="anytime_td_all",
+        labels={
+            "anytime_td_all": LabelRules(include_other=True),
+            "anytime_td_offense": LabelRules(include_other=False),
+            "anytime_td_rush": LabelRules(include_rush=True, include_rec=False, include_pass_thrown=False, include_other=False),
+            "anytime_td_rec": LabelRules(include_rush=False, include_rec=True, include_pass_thrown=False, include_other=False),
+            "anytime_td_pass_thrown": LabelRules(include_rush=False, include_rec=False, include_pass_thrown=True, include_other=False),
+        },
+        aliases={
+            "anytime_td": "anytime_td_all",
+            "td_count": "td_count_all",
+        },
+    ),
+}
+
+
+def get_label_spec(version: str | None) -> LabelSpec:
+    """Return a concrete LabelSpec for the requested version (or default)."""
+
+    version = version or DEFAULT_LABEL_VERSION
+    if version not in LABEL_VERSIONS:
+        raise ValueError(
+            f"Unknown label_version '{version}'. "
+            f"Available: {sorted(LABEL_VERSIONS.keys())}"
+        )
+    return LABEL_VERSIONS[version]
+
+
+def _sum_expr(exprs: Iterable[pl.Expr]) -> pl.Expr:
+    exprs = list(exprs)
+    if not exprs:
+        return pl.lit(0).cast(pl.Int64)
+    acc = exprs[0]
+    for expr in exprs[1:]:
+        acc = acc + expr
+    return acc
+
+
+def compute_td_labels(df: pl.DataFrame, *, version: str | None = None) -> pl.DataFrame:
+    """Compute TD label columns according to a label version.
+
+    Parameters
+    ----------
+    df : pl.DataFrame
+        Player-game frame containing touchdown components.
+    version : str | None
+        Label version identifier. Defaults to DEFAULT_LABEL_VERSION.
+    """
+
+    spec = get_label_spec(version)
+    rush = pl.col("rushing_td_count").fill_null(0).cast(pl.Int64)
+    rec = pl.col("receiving_td_count").fill_null(0).cast(pl.Int64)
+    passing = pl.col("passing_td").fill_null(0).cast(pl.Int64)
+    reported_total = pl.col("touchdowns").fill_null(0).cast(pl.Int64)
+
+    offense_total = _sum_expr([rush, rec, passing]).alias("_td_offense_total")
+    other_total = (reported_total - offense_total).clip_min(0).alias("_td_other_total")
+    all_total = (offense_total + other_total).alias("_td_all_total")
+
+    totals_exprs = [
+        offense_total,
+        other_total,
+        all_total,
+    ]
+
+    label_exprs: list[pl.Expr] = [
+        pl.col("_td_offense_total").alias("td_count_offense"),
+        pl.col("_td_all_total").alias("td_count_all"),
+    ]
+
+    for label_name, rules in spec.labels.items():
+        parts: list[pl.Expr] = []
+        if rules.include_rush:
+            parts.append(rush)
+        if rules.include_rec:
+            parts.append(rec)
+        if rules.include_pass_thrown:
+            parts.append(passing)
+        if rules.include_other:
+            parts.append(pl.col("_td_other_total"))
+        total_expr = _sum_expr(parts)
+        label_exprs.append((total_expr > 0).cast(pl.Int8).alias(label_name))
+
+    # Canonical counts for compatibility
+    if "td_count" not in df.columns:
+        # Fill td_count using the alias mapping; default to offense count.
+        target_alias = spec.aliases.get("td_count") or "td_count_offense"
+        label_exprs.append(pl.col(target_alias).alias("td_count"))
+
+    df = df.with_columns(totals_exprs).with_columns(label_exprs)
+
+    # Resolve aliases (e.g., anytime_td -> anytime_td_offense)
+    if spec.aliases:
+        alias_exprs = []
+        for alias_name, source_name in spec.aliases.items():
+            if source_name in df.columns:
+                alias_exprs.append(pl.col(source_name).alias(alias_name))
+        if alias_exprs:
+            df = df.with_columns(alias_exprs)
+
+    drop_cols = [col for col in ("_td_offense_total", "_td_other_total", "_td_all_total") if col in df.columns]
+    if drop_cols:
+        df = df.drop(drop_cols)
+    return df
diff --git a/utils/feature/player_game_level.py b/utils/feature/player_game_level.py
index b6fe516c5f03d575038eef554d5ab39ea5d5c90d..dd4f1f7fcc9de4d8c63390f0a160005eeae48e2f
--- a/utils/feature/player_game_level.py
+++ b/utils/feature/player_game_level.py
@@ -4,8 +4,12 @@
 Each player gets one row per game with their total stats.
 
 Target columns created:
-- anytime_td (binary): Did player score a TD (receiving or rushing)?
-- td_count (int): Number of TDs scored (receiving + rushing)
+- anytime_td_offense (binary): Did player score an offensive TD (rush/rec/pass thrown)?
+- anytime_td_all (binary): Did player score any TD (including defensive/special teams if present)?
+- anytime_td_rush / anytime_td_rec / anytime_td_pass_thrown: Type-specific TD flags.
+- anytime_td (binary): Legacy alias → current label version primary.
+- td_count_offense / td_count_all: TD counts aligned to label semantics.
+- td_count (int): Legacy alias for the primary td_count.
 - passing_td (int): Number of passing TDs (for QBs)
 - receiving_yards (float): Total receiving yards
 - rushing_yards (float): Total rushing yards
@@ -33,6 +37,7 @@
 from utils.collect.nfl_schedules import get_schedule
 from utils.feature.asof import decision_cutoff_hours_default, fallback_cutoff_hours, get_decision_cutoff_hours, get_fallback_cutoff_hours
 from utils.feature.player_drive_level import _load_play_level_data
+from utils.feature.labels import DEFAULT_LABEL_VERSION, compute_td_labels
 from utils.train.injury_availability import (
     load_latest_artifact,
     predict_probabilities as predict_injury_probabilities,
@@ -1582,7 +1587,12 @@
     if flag_cols:
         df = df.with_columns([pl.col(col).cast(pl.Int8) for col in flag_cols])
     return df
-def build_player_game_level(*, start_date: date, end_date: date) -> None:
+def build_player_game_level(
+    *,
+    start_date: date,
+    end_date: date,
+    label_version: str | None = None,
+) -> None:
     """Aggregate play-level data to player-game level.
     
     Creates one row per (player, game) with accumulated stats.
@@ -1680,7 +1690,7 @@
     
     # Merge rows where same player had multiple roles in same game
     # (e.g., QB who also rushed, WR who also rushed)
-    df_merged = _merge_multi_role_players(df_all)
+    df_merged = _merge_multi_role_players(df_all, label_version=label_version or DEFAULT_LABEL_VERSION)
 
     df_merged = _append_zero_usage_players(df_merged, seasons_in_window)
     
@@ -3368,7 +3378,7 @@
     )
 
 
-def _merge_multi_role_players(df: pl.DataFrame) -> pl.DataFrame:
+def _merge_multi_role_players(df: pl.DataFrame, *, label_version: str | None = None) -> pl.DataFrame:
     """Merge stats for players who had multiple roles in same game.
     
     Example: QB who passed and rushed, WR who received and rushed.
@@ -3422,8 +3432,6 @@
         if col in merged.columns:
             merged = merged.with_columns(pl.col(col).fill_null(0))
 
-    # Fallback touchdown logic: if generic touchdown attribution is missing,
-    # derive it from rushing + receiving touchdowns.
     merged = merged.with_columns([
         pl.col("touchdowns").fill_null(0).alias("touchdowns"),
         pl.col("rushing_td_count").fill_null(0).alias("rushing_td_count"),
@@ -3435,17 +3443,5 @@
         pl.col("goal_to_go_carry").fill_null(0).alias("goal_to_go_carry"),
     ])
 
-    merged = merged.with_columns([
-        pl.when(pl.col("touchdowns") > 0)
-        .then(pl.col("touchdowns"))
-        .otherwise(pl.col("rushing_td_count") + pl.col("receiving_td_count"))
-        .cast(pl.Int64)
-        .alias("_total_touchdowns")
-    ])
-
-    merged = merged.with_columns([
-        (pl.col("_total_touchdowns") > 0).cast(pl.Int8).alias("anytime_td"),
-        pl.col("_total_touchdowns").alias("td_count"),
-    ]).drop("_total_touchdowns")
-    
+    merged = compute_td_labels(merged, version=label_version)
     return merged
diff --git a/utils/feature/targets.py b/utils/feature/targets.py
index 7738086dcbfda7432b937cc7d8095988cb0edff0..769ee8735c4024c4410ddd674b11112f093624dd
--- a/utils/feature/targets.py
+++ b/utils/feature/targets.py
@@ -7,6 +7,8 @@
 import polars as pl
 import logging
 
+from utils.feature.labels import DEFAULT_LABEL_VERSION, get_label_spec
+
 logger = logging.getLogger(__name__)
 
 
@@ -14,9 +16,16 @@
 NFL_TARGET_SCHEMA = {
     # Binary classification targets
     "anytime_td": pl.Int8,  # Primary MVP target: did player score a TD?
+    "anytime_td_offense": pl.Int8,
+    "anytime_td_all": pl.Int8,
+    "anytime_td_rush": pl.Int8,
+    "anytime_td_rec": pl.Int8,
+    "anytime_td_pass_thrown": pl.Int8,
     
     # Count/regression targets
     "td_count": pl.Int64,  # Number of TDs scored (receiving + rushing)
+    "td_count_offense": pl.Int64,
+    "td_count_all": pl.Int64,
     "passing_td": pl.Int64,  # Number of passing TDs (QB only)
     
     # Yardage regression targets
@@ -103,4 +112,40 @@
     pl.DataFrame
         DataFrame with validated target columns
     """
-    return validate_target_columns(df, strict=False)
\ No newline at end of file
+    return validate_target_columns(df, strict=False)
+
+
+def require_target_column(
+    df: pl.DataFrame,
+    target_col: str,
+    *,
+    label_version: str | None = None,
+    min_non_null: int = 1,
+) -> pl.DataFrame:
+    """Ensure the configured target column exists and is populated.
+
+    Raises a ValueError if the column is missing or entirely null.
+    """
+
+    if target_col not in df.columns:
+        alias_hint = ""
+        if label_version:
+            try:
+                spec = get_label_spec(label_version or DEFAULT_LABEL_VERSION)
+                if target_col in spec.aliases:
+                    alias_hint = f" Target maps to '{spec.aliases[target_col]}' under {spec.name}."
+            except Exception:
+                alias_hint = ""
+        raise ValueError(f"Target column '{target_col}' not found in feature frame.{alias_hint}")
+
+    series = df[target_col]
+    non_null = series.drop_nulls().height
+    if non_null < min_non_null:
+        raise ValueError(
+            f"Target column '{target_col}' has insufficient non-null rows "
+            f"({non_null}/{len(series)})."
+        )
+    nulls = len(series) - non_null
+    if nulls > 0:
+        logger.warning("Target %s contains %d null rows; they will be dropped.", target_col, nulls)
+    return df


thinking
**Cleaning up unused imports**
file update
M /Users/jameswest/Desktop/nfl_predict/tests/labels/test_labels.py
@@ -2,7 +2,3 @@
 
-from utils.feature.labels import (
-    DEFAULT_LABEL_VERSION,
-    compute_td_labels,
-    get_label_spec,
-)
+from utils.feature.labels import compute_td_labels, get_label_spec
 
apply_patch(auto_approved=true) exited 0 in 114ms:
Success. Updated the following files:
M tests/labels/test_labels.py
file update:
diff --git a/config/training.yaml b/config/training.yaml
index 3055a636b89249119408aaad970d3025956877db..3953818d861d0410246bff132110722a3ce44007
--- a/config/training.yaml
+++ b/config/training.yaml
@@ -475,6 +475,7 @@
   # Calibrated probability of scoring > 0 TDs.
   - name: 'anytime_td'
     target_col: 'anytime_td'
+    label_version: 'v1_any_offense'
     task_type: 'classification'
     input_predictions:
       - 'availability_active'
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 6c47a91d08f9d309f94323efd4708bb992dc4ce0..5ba68e8bf1acd3a789a76a8857674e6f6433017b
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -26,6 +26,7 @@
 from utils.feature.player_drive_level import build_player_drive_level
 from utils.feature.player_game_level import build_player_game_level
 from utils.feature.opponent_splits import build_opponent_splits
+from utils.feature.labels import DEFAULT_LABEL_VERSION, get_label_spec
 from utils.feature.targets import validate_target_columns
 from utils.feature.daily_totals import build_daily_cache_range
 from utils.feature.rolling_window import add_rolling_features
@@ -233,6 +234,7 @@
     output_path: Path | None = None,
     primary_output_path: Path | None = None,
     cutoff_label: str | None = None,
+    label_version: str | None = None,
 ) -> pl.DataFrame:
     """Run full feature pipeline up to *inclusive* `end_date` for a single cutoff window.
 
@@ -248,6 +250,7 @@
     primary_output = primary_output_path or target_output_path
     current_cutoff_hours = float(get_decision_cutoff_hours())
     clean_min_date, clean_max_date = (None, None)
+    label_version = label_version or DEFAULT_LABEL_VERSION
     if start_date is None or end_date is None:
         clean_min_date, clean_max_date = _get_clean_date_bounds()
 
@@ -294,7 +297,7 @@
             build_player_drive_level(start_date=cur, end_date=chunk_end)
             
             # 5. Player-game aggregations (for rolling window features)
-            build_player_game_level(start_date=cur, end_date=chunk_end)
+            build_player_game_level(start_date=cur, end_date=chunk_end, label_version=label_version)
 
             # advance to next slice
             cur += timedelta(days=chunk_days)
@@ -948,11 +951,19 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    # Log target distribution for anytime_td
-    if "anytime_td" in df_player_game_all.columns:
-        td_count = df_player_game_all["anytime_td"].sum()
-        td_rate = td_count / len(df_player_game_all) * 100
-        logging.info("    Anytime TD rate: %.2f%% (%d/%d)", td_rate, td_count, len(df_player_game_all))
+    spec = get_label_spec(label_version)
+    label_candidates = {spec.primary, "anytime_td"}
+    for label_col in label_candidates:
+        if label_col in df_player_game_all.columns:
+            td_count = df_player_game_all[label_col].sum()
+            td_rate = td_count / len(df_player_game_all) * 100
+            logging.info(
+                "    Label %s rate: %.2f%% (%d/%d)",
+                label_col,
+                td_rate,
+                td_count,
+                len(df_player_game_all),
+            )
     
     return df_player_game_all
 
@@ -965,6 +976,7 @@
     recompute_intermediate: bool = True,
     build_rolling: bool = True,
     cutoff_hours_list: Sequence[float] | None = None,
+    label_version: str | None = None,
 ) -> pl.DataFrame:
     """Build feature matrices for one or more decision cutoff horizons.
 
@@ -992,6 +1004,7 @@
                 output_path=output_path,
                 primary_output_path=primary_output,
                 cutoff_label=label,
+                label_version=label_version,
             )
         if idx == 0:
             primary_result = df
diff --git a/pipeline/train.py b/pipeline/train.py
index 265bc29f4861d2d4d26f54fd7f77304de8fe6742..fe70207dcdf25d209ee3ad55080b7ce826347c44
--- a/pipeline/train.py
+++ b/pipeline/train.py
@@ -98,6 +98,7 @@
     fit_team_conformal_sums,
     composite_sum_interval,
 )
+from utils.feature.targets import require_target_column
 
 # Ignore specific, noisy warnings from dependencies
 warnings.filterwarnings(
@@ -259,6 +260,7 @@
 
         # Per-problem attributes initialised later
         self.target_col = None
+        self.label_version = None
         self.feature_columns = None
 
         self.models = {}
@@ -2163,6 +2165,7 @@
             
             problem_copy = copy.deepcopy(problem)
             self.target_col = problem_copy['target_col']
+            self.label_version = problem_copy.get('label_version') or problem_copy.get("labels", {}).get("version")
             derived_cfg = problem_copy.get('derived_target')
             target_load_cols: list[str] = []
             if derived_cfg:
@@ -2269,6 +2272,12 @@
                 df_problem = df_problem.loc[:, ~df_problem.columns.duplicated()]
 
             df_problem = self._apply_problem_level_overrides(df_problem, problem_copy)
+            df_problem = require_target_column(
+                df_problem,
+                self.target_col,
+                label_version=self.label_version,
+                min_non_null=1,
+            )
             
             # Merge input predictions if required
             if input_preds:
diff --git a/tests/labels/test_labels.py b/tests/labels/test_labels.py
new file mode 100644
index 0000000000000000000000000000000000000000..71743f35f8a9ff386afeaa8a346bdf150f7b9164
--- /dev/null
+++ b/tests/labels/test_labels.py
@@ -0,0 +1,68 @@
+import polars as pl
+
+from utils.feature.labels import compute_td_labels, get_label_spec
+
+
+def _lookup(frame: pl.DataFrame, player_id: str) -> dict:
+    return frame.filter(pl.col("player_id") == player_id).to_dicts()[0]
+
+
+def test_compute_td_labels_offense_and_all_variants():
+    df = pl.DataFrame(
+        {
+            "player_id": ["rush", "rec", "pass", "def"],
+            "game_id": ["g1"] * 4,
+            "rushing_td_count": [1, 0, 0, 0],
+            "receiving_td_count": [0, 1, 0, 0],
+            "passing_td": [0, 0, 1, 0],
+            # Generic touchdown attribution (e.g., defensive return)
+            "touchdowns": [1, 1, 0, 1],
+        }
+    )
+
+    result = compute_td_labels(df, version="v1_any_offense")
+
+    rush = _lookup(result, "rush")
+    assert rush["anytime_td_offense"] == 1
+    assert rush["anytime_td_rush"] == 1
+    assert rush["anytime_td_rec"] == 0
+    assert rush["anytime_td_pass_thrown"] == 0
+    assert rush["td_count_offense"] == 1
+    assert rush["td_count_all"] == 1
+    assert rush["anytime_td"] == rush["anytime_td_offense"]
+
+    rec = _lookup(result, "rec")
+    assert rec["anytime_td_offense"] == 1
+    assert rec["anytime_td_rec"] == 1
+    assert rec["anytime_td_rush"] == 0
+
+    passer = _lookup(result, "pass")
+    assert passer["anytime_td_pass_thrown"] == 1
+    assert passer["anytime_td_offense"] == 1
+    assert passer["anytime_td_all"] == 1  # includes offensive TDs
+
+    defensive = _lookup(result, "def")
+    assert defensive["anytime_td_offense"] == 0  # no offensive scoring events
+    assert defensive["anytime_td_all"] == 1  # credited via generic touchdown
+    assert defensive["anytime_td"] == defensive["anytime_td_offense"]
+
+
+def test_label_version_any_all_aliases_anytime_td():
+    spec = get_label_spec("v1_any_all")
+    assert spec.primary == "anytime_td_all"
+
+    df = pl.DataFrame(
+        {
+            "player_id": ["all"],
+            "game_id": ["g1"],
+            "rushing_td_count": [0],
+            "receiving_td_count": [0],
+            "passing_td": [0],
+            "touchdowns": [1],
+        }
+    )
+    result = compute_td_labels(df, version="v1_any_all")
+    row = _lookup(result, "all")
+    # Alias ensures legacy anytime_td follows the version's primary definition.
+    assert row["anytime_td_all"] == 1
+    assert row["anytime_td"] == row["anytime_td_all"]
diff --git a/utils/feature/labels.py b/utils/feature/labels.py
new file mode 100644
index 0000000000000000000000000000000000000000..b34571f04254cd7bceb9363a190ee7d305852bd5
--- /dev/null
+++ b/utils/feature/labels.py
@@ -0,0 +1,169 @@
+"""Label semantics and versioning for NFL player-level targets.
+
+This module centralizes anytime-TD label definitions so that:
+- Semantics are explicit and versioned.
+- Training can request a specific label column per problem.
+- Feature generation can emit multiple label variants for analysis.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass, field
+from typing import Dict, Iterable, Mapping
+
+import polars as pl
+
+
+@dataclass(frozen=True)
+class LabelRules:
+    """Rules controlling which TD components count toward a label."""
+
+    include_rush: bool = True
+    include_rec: bool = True
+    include_pass_thrown: bool = True  # credit passers for thrown TDs
+    include_other: bool = False  # fumble returns, defensive/special teams if present
+
+
+@dataclass(frozen=True)
+class LabelSpec:
+    """Container describing a label version."""
+
+    name: str
+    primary: str
+    labels: Mapping[str, LabelRules]
+    aliases: Mapping[str, str] = field(default_factory=dict)
+
+    @property
+    def all_columns(self) -> set[str]:
+        cols = set(self.labels.keys())
+        cols.update(self.aliases.keys())
+        return cols
+
+
+DEFAULT_LABEL_VERSION = "v1_any_offense"
+
+
+LABEL_VERSIONS: Dict[str, LabelSpec] = {
+    "v1_any_offense": LabelSpec(
+        name="v1_any_offense",
+        primary="anytime_td_offense",
+        labels={
+            "anytime_td_offense": LabelRules(include_other=False),
+            "anytime_td_rush": LabelRules(include_rush=True, include_rec=False, include_pass_thrown=False, include_other=False),
+            "anytime_td_rec": LabelRules(include_rush=False, include_rec=True, include_pass_thrown=False, include_other=False),
+            "anytime_td_pass_thrown": LabelRules(include_rush=False, include_rec=False, include_pass_thrown=True, include_other=False),
+            "anytime_td_all": LabelRules(include_other=True),
+        },
+        aliases={
+            # Maintain legacy column name as an alias to the offense-only label.
+            "anytime_td": "anytime_td_offense",
+            # Keep td_count pointing to the offense definition for backward compatibility.
+            "td_count": "td_count_offense",
+        },
+    ),
+    "v1_any_all": LabelSpec(
+        name="v1_any_all",
+        primary="anytime_td_all",
+        labels={
+            "anytime_td_all": LabelRules(include_other=True),
+            "anytime_td_offense": LabelRules(include_other=False),
+            "anytime_td_rush": LabelRules(include_rush=True, include_rec=False, include_pass_thrown=False, include_other=False),
+            "anytime_td_rec": LabelRules(include_rush=False, include_rec=True, include_pass_thrown=False, include_other=False),
+            "anytime_td_pass_thrown": LabelRules(include_rush=False, include_rec=False, include_pass_thrown=True, include_other=False),
+        },
+        aliases={
+            "anytime_td": "anytime_td_all",
+            "td_count": "td_count_all",
+        },
+    ),
+}
+
+
+def get_label_spec(version: str | None) -> LabelSpec:
+    """Return a concrete LabelSpec for the requested version (or default)."""
+
+    version = version or DEFAULT_LABEL_VERSION
+    if version not in LABEL_VERSIONS:
+        raise ValueError(
+            f"Unknown label_version '{version}'. "
+            f"Available: {sorted(LABEL_VERSIONS.keys())}"
+        )
+    return LABEL_VERSIONS[version]
+
+
+def _sum_expr(exprs: Iterable[pl.Expr]) -> pl.Expr:
+    exprs = list(exprs)
+    if not exprs:
+        return pl.lit(0).cast(pl.Int64)
+    acc = exprs[0]
+    for expr in exprs[1:]:
+        acc = acc + expr
+    return acc
+
+
+def compute_td_labels(df: pl.DataFrame, *, version: str | None = None) -> pl.DataFrame:
+    """Compute TD label columns according to a label version.
+
+    Parameters
+    ----------
+    df : pl.DataFrame
+        Player-game frame containing touchdown components.
+    version : str | None
+        Label version identifier. Defaults to DEFAULT_LABEL_VERSION.
+    """
+
+    spec = get_label_spec(version)
+    rush = pl.col("rushing_td_count").fill_null(0).cast(pl.Int64)
+    rec = pl.col("receiving_td_count").fill_null(0).cast(pl.Int64)
+    passing = pl.col("passing_td").fill_null(0).cast(pl.Int64)
+    reported_total = pl.col("touchdowns").fill_null(0).cast(pl.Int64)
+
+    offense_total = _sum_expr([rush, rec, passing]).alias("_td_offense_total")
+    other_total = (reported_total - offense_total).clip_min(0).alias("_td_other_total")
+    all_total = (offense_total + other_total).alias("_td_all_total")
+
+    totals_exprs = [
+        offense_total,
+        other_total,
+        all_total,
+    ]
+
+    label_exprs: list[pl.Expr] = [
+        pl.col("_td_offense_total").alias("td_count_offense"),
+        pl.col("_td_all_total").alias("td_count_all"),
+    ]
+
+    for label_name, rules in spec.labels.items():
+        parts: list[pl.Expr] = []
+        if rules.include_rush:
+            parts.append(rush)
+        if rules.include_rec:
+            parts.append(rec)
+        if rules.include_pass_thrown:
+            parts.append(passing)
+        if rules.include_other:
+            parts.append(pl.col("_td_other_total"))
+        total_expr = _sum_expr(parts)
+        label_exprs.append((total_expr > 0).cast(pl.Int8).alias(label_name))
+
+    # Canonical counts for compatibility
+    if "td_count" not in df.columns:
+        # Fill td_count using the alias mapping; default to offense count.
+        target_alias = spec.aliases.get("td_count") or "td_count_offense"
+        label_exprs.append(pl.col(target_alias).alias("td_count"))
+
+    df = df.with_columns(totals_exprs).with_columns(label_exprs)
+
+    # Resolve aliases (e.g., anytime_td -> anytime_td_offense)
+    if spec.aliases:
+        alias_exprs = []
+        for alias_name, source_name in spec.aliases.items():
+            if source_name in df.columns:
+                alias_exprs.append(pl.col(source_name).alias(alias_name))
+        if alias_exprs:
+            df = df.with_columns(alias_exprs)
+
+    drop_cols = [col for col in ("_td_offense_total", "_td_other_total", "_td_all_total") if col in df.columns]
+    if drop_cols:
+        df = df.drop(drop_cols)
+    return df
diff --git a/utils/feature/player_game_level.py b/utils/feature/player_game_level.py
index b6fe516c5f03d575038eef554d5ab39ea5d5c90d..dd4f1f7fcc9de4d8c63390f0a160005eeae48e2f
--- a/utils/feature/player_game_level.py
+++ b/utils/feature/player_game_level.py
@@ -4,8 +4,12 @@
 Each player gets one row per game with their total stats.
 
 Target columns created:
-- anytime_td (binary): Did player score a TD (receiving or rushing)?
-- td_count (int): Number of TDs scored (receiving + rushing)
+- anytime_td_offense (binary): Did player score an offensive TD (rush/rec/pass thrown)?
+- anytime_td_all (binary): Did player score any TD (including defensive/special teams if present)?
+- anytime_td_rush / anytime_td_rec / anytime_td_pass_thrown: Type-specific TD flags.
+- anytime_td (binary): Legacy alias → current label version primary.
+- td_count_offense / td_count_all: TD counts aligned to label semantics.
+- td_count (int): Legacy alias for the primary td_count.
 - passing_td (int): Number of passing TDs (for QBs)
 - receiving_yards (float): Total receiving yards
 - rushing_yards (float): Total rushing yards
@@ -33,6 +37,7 @@
 from utils.collect.nfl_schedules import get_schedule
 from utils.feature.asof import decision_cutoff_hours_default, fallback_cutoff_hours, get_decision_cutoff_hours, get_fallback_cutoff_hours
 from utils.feature.player_drive_level import _load_play_level_data
+from utils.feature.labels import DEFAULT_LABEL_VERSION, compute_td_labels
 from utils.train.injury_availability import (
     load_latest_artifact,
     predict_probabilities as predict_injury_probabilities,
@@ -1582,7 +1587,12 @@
     if flag_cols:
         df = df.with_columns([pl.col(col).cast(pl.Int8) for col in flag_cols])
     return df
-def build_player_game_level(*, start_date: date, end_date: date) -> None:
+def build_player_game_level(
+    *,
+    start_date: date,
+    end_date: date,
+    label_version: str | None = None,
+) -> None:
     """Aggregate play-level data to player-game level.
     
     Creates one row per (player, game) with accumulated stats.
@@ -1680,7 +1690,7 @@
     
     # Merge rows where same player had multiple roles in same game
     # (e.g., QB who also rushed, WR who also rushed)
-    df_merged = _merge_multi_role_players(df_all)
+    df_merged = _merge_multi_role_players(df_all, label_version=label_version or DEFAULT_LABEL_VERSION)
 
     df_merged = _append_zero_usage_players(df_merged, seasons_in_window)
     
@@ -3368,7 +3378,7 @@
     )
 
 
-def _merge_multi_role_players(df: pl.DataFrame) -> pl.DataFrame:
+def _merge_multi_role_players(df: pl.DataFrame, *, label_version: str | None = None) -> pl.DataFrame:
     """Merge stats for players who had multiple roles in same game.
     
     Example: QB who passed and rushed, WR who received and rushed.
@@ -3422,8 +3432,6 @@
         if col in merged.columns:
             merged = merged.with_columns(pl.col(col).fill_null(0))
 
-    # Fallback touchdown logic: if generic touchdown attribution is missing,
-    # derive it from rushing + receiving touchdowns.
     merged = merged.with_columns([
         pl.col("touchdowns").fill_null(0).alias("touchdowns"),
         pl.col("rushing_td_count").fill_null(0).alias("rushing_td_count"),
@@ -3435,17 +3443,5 @@
         pl.col("goal_to_go_carry").fill_null(0).alias("goal_to_go_carry"),
     ])
 
-    merged = merged.with_columns([
-        pl.when(pl.col("touchdowns") > 0)
-        .then(pl.col("touchdowns"))
-        .otherwise(pl.col("rushing_td_count") + pl.col("receiving_td_count"))
-        .cast(pl.Int64)
-        .alias("_total_touchdowns")
-    ])
-
-    merged = merged.with_columns([
-        (pl.col("_total_touchdowns") > 0).cast(pl.Int8).alias("anytime_td"),
-        pl.col("_total_touchdowns").alias("td_count"),
-    ]).drop("_total_touchdowns")
-    
+    merged = compute_td_labels(merged, version=label_version)
     return merged
diff --git a/utils/feature/targets.py b/utils/feature/targets.py
index 7738086dcbfda7432b937cc7d8095988cb0edff0..769ee8735c4024c4410ddd674b11112f093624dd
--- a/utils/feature/targets.py
+++ b/utils/feature/targets.py
@@ -7,6 +7,8 @@
 import polars as pl
 import logging
 
+from utils.feature.labels import DEFAULT_LABEL_VERSION, get_label_spec
+
 logger = logging.getLogger(__name__)
 
 
@@ -14,9 +16,16 @@
 NFL_TARGET_SCHEMA = {
     # Binary classification targets
     "anytime_td": pl.Int8,  # Primary MVP target: did player score a TD?
+    "anytime_td_offense": pl.Int8,
+    "anytime_td_all": pl.Int8,
+    "anytime_td_rush": pl.Int8,
+    "anytime_td_rec": pl.Int8,
+    "anytime_td_pass_thrown": pl.Int8,
     
     # Count/regression targets
     "td_count": pl.Int64,  # Number of TDs scored (receiving + rushing)
+    "td_count_offense": pl.Int64,
+    "td_count_all": pl.Int64,
     "passing_td": pl.Int64,  # Number of passing TDs (QB only)
     
     # Yardage regression targets
@@ -103,4 +112,40 @@
     pl.DataFrame
         DataFrame with validated target columns
     """
-    return validate_target_columns(df, strict=False)
\ No newline at end of file
+    return validate_target_columns(df, strict=False)
+
+
+def require_target_column(
+    df: pl.DataFrame,
+    target_col: str,
+    *,
+    label_version: str | None = None,
+    min_non_null: int = 1,
+) -> pl.DataFrame:
+    """Ensure the configured target column exists and is populated.
+
+    Raises a ValueError if the column is missing or entirely null.
+    """
+
+    if target_col not in df.columns:
+        alias_hint = ""
+        if label_version:
+            try:
+                spec = get_label_spec(label_version or DEFAULT_LABEL_VERSION)
+                if target_col in spec.aliases:
+                    alias_hint = f" Target maps to '{spec.aliases[target_col]}' under {spec.name}."
+            except Exception:
+                alias_hint = ""
+        raise ValueError(f"Target column '{target_col}' not found in feature frame.{alias_hint}")
+
+    series = df[target_col]
+    non_null = series.drop_nulls().height
+    if non_null < min_non_null:
+        raise ValueError(
+            f"Target column '{target_col}' has insufficient non-null rows "
+            f"({non_null}/{len(series)})."
+        )
+    nulls = len(series) - non_null
+    if nulls > 0:
+        logger.warning("Target %s contains %d null rows; they will be dropped.", target_col, nulls)
+    return df

file update:
diff --git a/config/training.yaml b/config/training.yaml
index 3055a636b89249119408aaad970d3025956877db..3953818d861d0410246bff132110722a3ce44007
--- a/config/training.yaml
+++ b/config/training.yaml
@@ -475,6 +475,7 @@
   # Calibrated probability of scoring > 0 TDs.
   - name: 'anytime_td'
     target_col: 'anytime_td'
+    label_version: 'v1_any_offense'
     task_type: 'classification'
     input_predictions:
       - 'availability_active'
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 6c47a91d08f9d309f94323efd4708bb992dc4ce0..5ba68e8bf1acd3a789a76a8857674e6f6433017b
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -26,6 +26,7 @@
 from utils.feature.player_drive_level import build_player_drive_level
 from utils.feature.player_game_level import build_player_game_level
 from utils.feature.opponent_splits import build_opponent_splits
+from utils.feature.labels import DEFAULT_LABEL_VERSION, get_label_spec
 from utils.feature.targets import validate_target_columns
 from utils.feature.daily_totals import build_daily_cache_range
 from utils.feature.rolling_window import add_rolling_features
@@ -233,6 +234,7 @@
     output_path: Path | None = None,
     primary_output_path: Path | None = None,
     cutoff_label: str | None = None,
+    label_version: str | None = None,
 ) -> pl.DataFrame:
     """Run full feature pipeline up to *inclusive* `end_date` for a single cutoff window.
 
@@ -248,6 +250,7 @@
     primary_output = primary_output_path or target_output_path
     current_cutoff_hours = float(get_decision_cutoff_hours())
     clean_min_date, clean_max_date = (None, None)
+    label_version = label_version or DEFAULT_LABEL_VERSION
     if start_date is None or end_date is None:
         clean_min_date, clean_max_date = _get_clean_date_bounds()
 
@@ -294,7 +297,7 @@
             build_player_drive_level(start_date=cur, end_date=chunk_end)
             
             # 5. Player-game aggregations (for rolling window features)
-            build_player_game_level(start_date=cur, end_date=chunk_end)
+            build_player_game_level(start_date=cur, end_date=chunk_end, label_version=label_version)
 
             # advance to next slice
             cur += timedelta(days=chunk_days)
@@ -948,11 +951,19 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    # Log target distribution for anytime_td
-    if "anytime_td" in df_player_game_all.columns:
-        td_count = df_player_game_all["anytime_td"].sum()
-        td_rate = td_count / len(df_player_game_all) * 100
-        logging.info("    Anytime TD rate: %.2f%% (%d/%d)", td_rate, td_count, len(df_player_game_all))
+    spec = get_label_spec(label_version)
+    label_candidates = {spec.primary, "anytime_td"}
+    for label_col in label_candidates:
+        if label_col in df_player_game_all.columns:
+            td_count = df_player_game_all[label_col].sum()
+            td_rate = td_count / len(df_player_game_all) * 100
+            logging.info(
+                "    Label %s rate: %.2f%% (%d/%d)",
+                label_col,
+                td_rate,
+                td_count,
+                len(df_player_game_all),
+            )
     
     return df_player_game_all
 
@@ -965,6 +976,7 @@
     recompute_intermediate: bool = True,
     build_rolling: bool = True,
     cutoff_hours_list: Sequence[float] | None = None,
+    label_version: str | None = None,
 ) -> pl.DataFrame:
     """Build feature matrices for one or more decision cutoff horizons.
 
@@ -992,6 +1004,7 @@
                 output_path=output_path,
                 primary_output_path=primary_output,
                 cutoff_label=label,
+                label_version=label_version,
             )
         if idx == 0:
             primary_result = df
diff --git a/pipeline/train.py b/pipeline/train.py
index 265bc29f4861d2d4d26f54fd7f77304de8fe6742..fe70207dcdf25d209ee3ad55080b7ce826347c44
--- a/pipeline/train.py
+++ b/pipeline/train.py
@@ -98,6 +98,7 @@
     fit_team_conformal_sums,
     composite_sum_interval,
 )
+from utils.feature.targets import require_target_column
 
 # Ignore specific, noisy warnings from dependencies
 warnings.filterwarnings(
@@ -259,6 +260,7 @@
 
         # Per-problem attributes initialised later
         self.target_col = None
+        self.label_version = None
         self.feature_columns = None
 
         self.models = {}
@@ -2163,6 +2165,7 @@
             
             problem_copy = copy.deepcopy(problem)
             self.target_col = problem_copy['target_col']
+            self.label_version = problem_copy.get('label_version') or problem_copy.get("labels", {}).get("version")
             derived_cfg = problem_copy.get('derived_target')
             target_load_cols: list[str] = []
             if derived_cfg:
@@ -2269,6 +2272,12 @@
                 df_problem = df_problem.loc[:, ~df_problem.columns.duplicated()]
 
             df_problem = self._apply_problem_level_overrides(df_problem, problem_copy)
+            df_problem = require_target_column(
+                df_problem,
+                self.target_col,
+                label_version=self.label_version,
+                min_non_null=1,
+            )
             
             # Merge input predictions if required
             if input_preds:
diff --git a/tests/labels/test_labels.py b/tests/labels/test_labels.py
new file mode 100644
index 0000000000000000000000000000000000000000..71743f35f8a9ff386afeaa8a346bdf150f7b9164
--- /dev/null
+++ b/tests/labels/test_labels.py
@@ -0,0 +1,68 @@
+import polars as pl
+
+from utils.feature.labels import compute_td_labels, get_label_spec
+
+
+def _lookup(frame: pl.DataFrame, player_id: str) -> dict:
+    return frame.filter(pl.col("player_id") == player_id).to_dicts()[0]
+
+
+def test_compute_td_labels_offense_and_all_variants():
+    df = pl.DataFrame(
+        {
+            "player_id": ["rush", "rec", "pass", "def"],
+            "game_id": ["g1"] * 4,
+            "rushing_td_count": [1, 0, 0, 0],
+            "receiving_td_count": [0, 1, 0, 0],
+            "passing_td": [0, 0, 1, 0],
+            # Generic touchdown attribution (e.g., defensive return)
+            "touchdowns": [1, 1, 0, 1],
+        }
+    )
+
+    result = compute_td_labels(df, version="v1_any_offense")
+
+    rush = _lookup(result, "rush")
+    assert rush["anytime_td_offense"] == 1
+    assert rush["anytime_td_rush"] == 1
+    assert rush["anytime_td_rec"] == 0
+    assert rush["anytime_td_pass_thrown"] == 0
+    assert rush["td_count_offense"] == 1
+    assert rush["td_count_all"] == 1
+    assert rush["anytime_td"] == rush["anytime_td_offense"]
+
+    rec = _lookup(result, "rec")
+    assert rec["anytime_td_offense"] == 1
+    assert rec["anytime_td_rec"] == 1
+    assert rec["anytime_td_rush"] == 0
+
+    passer = _lookup(result, "pass")
+    assert passer["anytime_td_pass_thrown"] == 1
+    assert passer["anytime_td_offense"] == 1
+    assert passer["anytime_td_all"] == 1  # includes offensive TDs
+
+    defensive = _lookup(result, "def")
+    assert defensive["anytime_td_offense"] == 0  # no offensive scoring events
+    assert defensive["anytime_td_all"] == 1  # credited via generic touchdown
+    assert defensive["anytime_td"] == defensive["anytime_td_offense"]
+
+
+def test_label_version_any_all_aliases_anytime_td():
+    spec = get_label_spec("v1_any_all")
+    assert spec.primary == "anytime_td_all"
+
+    df = pl.DataFrame(
+        {
+            "player_id": ["all"],
+            "game_id": ["g1"],
+            "rushing_td_count": [0],
+            "receiving_td_count": [0],
+            "passing_td": [0],
+            "touchdowns": [1],
+        }
+    )
+    result = compute_td_labels(df, version="v1_any_all")
+    row = _lookup(result, "all")
+    # Alias ensures legacy anytime_td follows the version's primary definition.
+    assert row["anytime_td_all"] == 1
+    assert row["anytime_td"] == row["anytime_td_all"]
diff --git a/utils/feature/labels.py b/utils/feature/labels.py
new file mode 100644
index 0000000000000000000000000000000000000000..b34571f04254cd7bceb9363a190ee7d305852bd5
--- /dev/null
+++ b/utils/feature/labels.py
@@ -0,0 +1,169 @@
+"""Label semantics and versioning for NFL player-level targets.
+
+This module centralizes anytime-TD label definitions so that:
+- Semantics are explicit and versioned.
+- Training can request a specific label column per problem.
+- Feature generation can emit multiple label variants for analysis.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass, field
+from typing import Dict, Iterable, Mapping
+
+import polars as pl
+
+
+@dataclass(frozen=True)
+class LabelRules:
+    """Rules controlling which TD components count toward a label."""
+
+    include_rush: bool = True
+    include_rec: bool = True
+    include_pass_thrown: bool = True  # credit passers for thrown TDs
+    include_other: bool = False  # fumble returns, defensive/special teams if present
+
+
+@dataclass(frozen=True)
+class LabelSpec:
+    """Container describing a label version."""
+
+    name: str
+    primary: str
+    labels: Mapping[str, LabelRules]
+    aliases: Mapping[str, str] = field(default_factory=dict)
+
+    @property
+    def all_columns(self) -> set[str]:
+        cols = set(self.labels.keys())
+        cols.update(self.aliases.keys())
+        return cols
+
+
+DEFAULT_LABEL_VERSION = "v1_any_offense"
+
+
+LABEL_VERSIONS: Dict[str, LabelSpec] = {
+    "v1_any_offense": LabelSpec(
+        name="v1_any_offense",
+        primary="anytime_td_offense",
+        labels={
+            "anytime_td_offense": LabelRules(include_other=False),
+            "anytime_td_rush": LabelRules(include_rush=True, include_rec=False, include_pass_thrown=False, include_other=False),
+            "anytime_td_rec": LabelRules(include_rush=False, include_rec=True, include_pass_thrown=False, include_other=False),
+            "anytime_td_pass_thrown": LabelRules(include_rush=False, include_rec=False, include_pass_thrown=True, include_other=False),
+            "anytime_td_all": LabelRules(include_other=True),
+        },
+        aliases={
+            # Maintain legacy column name as an alias to the offense-only label.
+            "anytime_td": "anytime_td_offense",
+            # Keep td_count pointing to the offense definition for backward compatibility.
+            "td_count": "td_count_offense",
+        },
+    ),
+    "v1_any_all": LabelSpec(
+        name="v1_any_all",
+        primary="anytime_td_all",
+        labels={
+            "anytime_td_all": LabelRules(include_other=True),
+            "anytime_td_offense": LabelRules(include_other=False),
+            "anytime_td_rush": LabelRules(include_rush=True, include_rec=False, include_pass_thrown=False, include_other=False),
+            "anytime_td_rec": LabelRules(include_rush=False, include_rec=True, include_pass_thrown=False, include_other=False),
+            "anytime_td_pass_thrown": LabelRules(include_rush=False, include_rec=False, include_pass_thrown=True, include_other=False),
+        },
+        aliases={
+            "anytime_td": "anytime_td_all",
+            "td_count": "td_count_all",
+        },
+    ),
+}
+
+
+def get_label_spec(version: str | None) -> LabelSpec:
+    """Return a concrete LabelSpec for the requested version (or default)."""
+
+    version = version or DEFAULT_LABEL_VERSION
+    if version not in LABEL_VERSIONS:
+        raise ValueError(
+            f"Unknown label_version '{version}'. "
+            f"Available: {sorted(LABEL_VERSIONS.keys())}"
+        )
+    return LABEL_VERSIONS[version]
+
+
+def _sum_expr(exprs: Iterable[pl.Expr]) -> pl.Expr:
+    exprs = list(exprs)
+    if not exprs:
+        return pl.lit(0).cast(pl.Int64)
+    acc = exprs[0]
+    for expr in exprs[1:]:
+        acc = acc + expr
+    return acc
+
+
+def compute_td_labels(df: pl.DataFrame, *, version: str | None = None) -> pl.DataFrame:
+    """Compute TD label columns according to a label version.
+
+    Parameters
+    ----------
+    df : pl.DataFrame
+        Player-game frame containing touchdown components.
+    version : str | None
+        Label version identifier. Defaults to DEFAULT_LABEL_VERSION.
+    """
+
+    spec = get_label_spec(version)
+    rush = pl.col("rushing_td_count").fill_null(0).cast(pl.Int64)
+    rec = pl.col("receiving_td_count").fill_null(0).cast(pl.Int64)
+    passing = pl.col("passing_td").fill_null(0).cast(pl.Int64)
+    reported_total = pl.col("touchdowns").fill_null(0).cast(pl.Int64)
+
+    offense_total = _sum_expr([rush, rec, passing]).alias("_td_offense_total")
+    other_total = (reported_total - offense_total).clip_min(0).alias("_td_other_total")
+    all_total = (offense_total + other_total).alias("_td_all_total")
+
+    totals_exprs = [
+        offense_total,
+        other_total,
+        all_total,
+    ]
+
+    label_exprs: list[pl.Expr] = [
+        pl.col("_td_offense_total").alias("td_count_offense"),
+        pl.col("_td_all_total").alias("td_count_all"),
+    ]
+
+    for label_name, rules in spec.labels.items():
+        parts: list[pl.Expr] = []
+        if rules.include_rush:
+            parts.append(rush)
+        if rules.include_rec:
+            parts.append(rec)
+        if rules.include_pass_thrown:
+            parts.append(passing)
+        if rules.include_other:
+            parts.append(pl.col("_td_other_total"))
+        total_expr = _sum_expr(parts)
+        label_exprs.append((total_expr > 0).cast(pl.Int8).alias(label_name))
+
+    # Canonical counts for compatibility
+    if "td_count" not in df.columns:
+        # Fill td_count using the alias mapping; default to offense count.
+        target_alias = spec.aliases.get("td_count") or "td_count_offense"
+        label_exprs.append(pl.col(target_alias).alias("td_count"))
+
+    df = df.with_columns(totals_exprs).with_columns(label_exprs)
+
+    # Resolve aliases (e.g., anytime_td -> anytime_td_offense)
+    if spec.aliases:
+        alias_exprs = []
+        for alias_name, source_name in spec.aliases.items():
+            if source_name in df.columns:
+                alias_exprs.append(pl.col(source_name).alias(alias_name))
+        if alias_exprs:
+            df = df.with_columns(alias_exprs)
+
+    drop_cols = [col for col in ("_td_offense_total", "_td_other_total", "_td_all_total") if col in df.columns]
+    if drop_cols:
+        df = df.drop(drop_cols)
+    return df
diff --git a/utils/feature/player_game_level.py b/utils/feature/player_game_level.py
index b6fe516c5f03d575038eef554d5ab39ea5d5c90d..dd4f1f7fcc9de4d8c63390f0a160005eeae48e2f
--- a/utils/feature/player_game_level.py
+++ b/utils/feature/player_game_level.py
@@ -4,8 +4,12 @@
 Each player gets one row per game with their total stats.
 
 Target columns created:
-- anytime_td (binary): Did player score a TD (receiving or rushing)?
-- td_count (int): Number of TDs scored (receiving + rushing)
+- anytime_td_offense (binary): Did player score an offensive TD (rush/rec/pass thrown)?
+- anytime_td_all (binary): Did player score any TD (including defensive/special teams if present)?
+- anytime_td_rush / anytime_td_rec / anytime_td_pass_thrown: Type-specific TD flags.
+- anytime_td (binary): Legacy alias → current label version primary.
+- td_count_offense / td_count_all: TD counts aligned to label semantics.
+- td_count (int): Legacy alias for the primary td_count.
 - passing_td (int): Number of passing TDs (for QBs)
 - receiving_yards (float): Total receiving yards
 - rushing_yards (float): Total rushing yards
@@ -33,6 +37,7 @@
 from utils.collect.nfl_schedules import get_schedule
 from utils.feature.asof import decision_cutoff_hours_default, fallback_cutoff_hours, get_decision_cutoff_hours, get_fallback_cutoff_hours
 from utils.feature.player_drive_level import _load_play_level_data
+from utils.feature.labels import DEFAULT_LABEL_VERSION, compute_td_labels
 from utils.train.injury_availability import (
     load_latest_artifact,
     predict_probabilities as predict_injury_probabilities,
@@ -1582,7 +1587,12 @@
     if flag_cols:
         df = df.with_columns([pl.col(col).cast(pl.Int8) for col in flag_cols])
     return df
-def build_player_game_level(*, start_date: date, end_date: date) -> None:
+def build_player_game_level(
+    *,
+    start_date: date,
+    end_date: date,
+    label_version: str | None = None,
+) -> None:
     """Aggregate play-level data to player-game level.
     
     Creates one row per (player, game) with accumulated stats.
@@ -1680,7 +1690,7 @@
     
     # Merge rows where same player had multiple roles in same game
     # (e.g., QB who also rushed, WR who also rushed)
-    df_merged = _merge_multi_role_players(df_all)
+    df_merged = _merge_multi_role_players(df_all, label_version=label_version or DEFAULT_LABEL_VERSION)
 
     df_merged = _append_zero_usage_players(df_merged, seasons_in_window)
     
@@ -3368,7 +3378,7 @@
     )
 
 
-def _merge_multi_role_players(df: pl.DataFrame) -> pl.DataFrame:
+def _merge_multi_role_players(df: pl.DataFrame, *, label_version: str | None = None) -> pl.DataFrame:
     """Merge stats for players who had multiple roles in same game.
     
     Example: QB who passed and rushed, WR who received and rushed.
@@ -3422,8 +3432,6 @@
         if col in merged.columns:
             merged = merged.with_columns(pl.col(col).fill_null(0))
 
-    # Fallback touchdown logic: if generic touchdown attribution is missing,
-    # derive it from rushing + receiving touchdowns.
     merged = merged.with_columns([
         pl.col("touchdowns").fill_null(0).alias("touchdowns"),
         pl.col("rushing_td_count").fill_null(0).alias("rushing_td_count"),
@@ -3435,17 +3443,5 @@
         pl.col("goal_to_go_carry").fill_null(0).alias("goal_to_go_carry"),
     ])
 
-    merged = merged.with_columns([
-        pl.when(pl.col("touchdowns") > 0)
-        .then(pl.col("touchdowns"))
-        .otherwise(pl.col("rushing_td_count") + pl.col("receiving_td_count"))
-        .cast(pl.Int64)
-        .alias("_total_touchdowns")
-    ])
-
-    merged = merged.with_columns([
-        (pl.col("_total_touchdowns") > 0).cast(pl.Int8).alias("anytime_td"),
-        pl.col("_total_touchdowns").alias("td_count"),
-    ]).drop("_total_touchdowns")
-    
+    merged = compute_td_labels(merged, version=label_version)
     return merged
diff --git a/utils/feature/targets.py b/utils/feature/targets.py
index 7738086dcbfda7432b937cc7d8095988cb0edff0..769ee8735c4024c4410ddd674b11112f093624dd
--- a/utils/feature/targets.py
+++ b/utils/feature/targets.py
@@ -7,6 +7,8 @@
 import polars as pl
 import logging
 
+from utils.feature.labels import DEFAULT_LABEL_VERSION, get_label_spec
+
 logger = logging.getLogger(__name__)
 
 
@@ -14,9 +16,16 @@
 NFL_TARGET_SCHEMA = {
     # Binary classification targets
     "anytime_td": pl.Int8,  # Primary MVP target: did player score a TD?
+    "anytime_td_offense": pl.Int8,
+    "anytime_td_all": pl.Int8,
+    "anytime_td_rush": pl.Int8,
+    "anytime_td_rec": pl.Int8,
+    "anytime_td_pass_thrown": pl.Int8,
     
     # Count/regression targets
     "td_count": pl.Int64,  # Number of TDs scored (receiving + rushing)
+    "td_count_offense": pl.Int64,
+    "td_count_all": pl.Int64,
     "passing_td": pl.Int64,  # Number of passing TDs (QB only)
     
     # Yardage regression targets
@@ -103,4 +112,40 @@
     pl.DataFrame
         DataFrame with validated target columns
     """
-    return validate_target_columns(df, strict=False)
\ No newline at end of file
+    return validate_target_columns(df, strict=False)
+
+
+def require_target_column(
+    df: pl.DataFrame,
+    target_col: str,
+    *,
+    label_version: str | None = None,
+    min_non_null: int = 1,
+) -> pl.DataFrame:
+    """Ensure the configured target column exists and is populated.
+
+    Raises a ValueError if the column is missing or entirely null.
+    """
+
+    if target_col not in df.columns:
+        alias_hint = ""
+        if label_version:
+            try:
+                spec = get_label_spec(label_version or DEFAULT_LABEL_VERSION)
+                if target_col in spec.aliases:
+                    alias_hint = f" Target maps to '{spec.aliases[target_col]}' under {spec.name}."
+            except Exception:
+                alias_hint = ""
+        raise ValueError(f"Target column '{target_col}' not found in feature frame.{alias_hint}")
+
+    series = df[target_col]
+    non_null = series.drop_nulls().height
+    if non_null < min_non_null:
+        raise ValueError(
+            f"Target column '{target_col}' has insufficient non-null rows "
+            f"({non_null}/{len(series)})."
+        )
+    nulls = len(series) - non_null
+    if nulls > 0:
+        logger.warning("Target %s contains %d null rows; they will be dropped.", target_col, nulls)
+    return df


thinking
**Verifying label_version defaults and polars expressions**

I'm carefully checking that the label_version default is consistently applied in player_game_level calls and that no call sites break from this change. I'm also making sure polars expressions involving aliased sums and arithmetic, like offense_total subtraction and clip_min usage, behave correctly within the pipeline without errors. Everything should stay compatible with existing training config validations and feature computations.

thinking
**Ensuring robust column handling in compute_td_labels**
file update
M /Users/jameswest/Desktop/nfl_predict/utils/feature/labels.py
@@ -115,2 +115,6 @@
     spec = get_label_spec(version)
+    required_cols = ["rushing_td_count", "receiving_td_count", "passing_td", "touchdowns"]
+    missing = [col for col in required_cols if col not in df.columns]
+    if missing:
+        df = df.with_columns([pl.lit(0).cast(pl.Int64).alias(col) for col in missing])
     rush = pl.col("rushing_td_count").fill_null(0).cast(pl.Int64)
apply_patch(auto_approved=true) exited 0 in 107ms:
Success. Updated the following files:
M utils/feature/labels.py
file update:
diff --git a/config/training.yaml b/config/training.yaml
index 3055a636b89249119408aaad970d3025956877db..3953818d861d0410246bff132110722a3ce44007
--- a/config/training.yaml
+++ b/config/training.yaml
@@ -475,6 +475,7 @@
   # Calibrated probability of scoring > 0 TDs.
   - name: 'anytime_td'
     target_col: 'anytime_td'
+    label_version: 'v1_any_offense'
     task_type: 'classification'
     input_predictions:
       - 'availability_active'
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 6c47a91d08f9d309f94323efd4708bb992dc4ce0..5ba68e8bf1acd3a789a76a8857674e6f6433017b
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -26,6 +26,7 @@
 from utils.feature.player_drive_level import build_player_drive_level
 from utils.feature.player_game_level import build_player_game_level
 from utils.feature.opponent_splits import build_opponent_splits
+from utils.feature.labels import DEFAULT_LABEL_VERSION, get_label_spec
 from utils.feature.targets import validate_target_columns
 from utils.feature.daily_totals import build_daily_cache_range
 from utils.feature.rolling_window import add_rolling_features
@@ -233,6 +234,7 @@
     output_path: Path | None = None,
     primary_output_path: Path | None = None,
     cutoff_label: str | None = None,
+    label_version: str | None = None,
 ) -> pl.DataFrame:
     """Run full feature pipeline up to *inclusive* `end_date` for a single cutoff window.
 
@@ -248,6 +250,7 @@
     primary_output = primary_output_path or target_output_path
     current_cutoff_hours = float(get_decision_cutoff_hours())
     clean_min_date, clean_max_date = (None, None)
+    label_version = label_version or DEFAULT_LABEL_VERSION
     if start_date is None or end_date is None:
         clean_min_date, clean_max_date = _get_clean_date_bounds()
 
@@ -294,7 +297,7 @@
             build_player_drive_level(start_date=cur, end_date=chunk_end)
             
             # 5. Player-game aggregations (for rolling window features)
-            build_player_game_level(start_date=cur, end_date=chunk_end)
+            build_player_game_level(start_date=cur, end_date=chunk_end, label_version=label_version)
 
             # advance to next slice
             cur += timedelta(days=chunk_days)
@@ -948,11 +951,19 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    # Log target distribution for anytime_td
-    if "anytime_td" in df_player_game_all.columns:
-        td_count = df_player_game_all["anytime_td"].sum()
-        td_rate = td_count / len(df_player_game_all) * 100
-        logging.info("    Anytime TD rate: %.2f%% (%d/%d)", td_rate, td_count, len(df_player_game_all))
+    spec = get_label_spec(label_version)
+    label_candidates = {spec.primary, "anytime_td"}
+    for label_col in label_candidates:
+        if label_col in df_player_game_all.columns:
+            td_count = df_player_game_all[label_col].sum()
+            td_rate = td_count / len(df_player_game_all) * 100
+            logging.info(
+                "    Label %s rate: %.2f%% (%d/%d)",
+                label_col,
+                td_rate,
+                td_count,
+                len(df_player_game_all),
+            )
     
     return df_player_game_all
 
@@ -965,6 +976,7 @@
     recompute_intermediate: bool = True,
     build_rolling: bool = True,
     cutoff_hours_list: Sequence[float] | None = None,
+    label_version: str | None = None,
 ) -> pl.DataFrame:
     """Build feature matrices for one or more decision cutoff horizons.
 
@@ -992,6 +1004,7 @@
                 output_path=output_path,
                 primary_output_path=primary_output,
                 cutoff_label=label,
+                label_version=label_version,
             )
         if idx == 0:
             primary_result = df
diff --git a/pipeline/train.py b/pipeline/train.py
index 265bc29f4861d2d4d26f54fd7f77304de8fe6742..fe70207dcdf25d209ee3ad55080b7ce826347c44
--- a/pipeline/train.py
+++ b/pipeline/train.py
@@ -98,6 +98,7 @@
     fit_team_conformal_sums,
     composite_sum_interval,
 )
+from utils.feature.targets import require_target_column
 
 # Ignore specific, noisy warnings from dependencies
 warnings.filterwarnings(
@@ -259,6 +260,7 @@
 
         # Per-problem attributes initialised later
         self.target_col = None
+        self.label_version = None
         self.feature_columns = None
 
         self.models = {}
@@ -2163,6 +2165,7 @@
             
             problem_copy = copy.deepcopy(problem)
             self.target_col = problem_copy['target_col']
+            self.label_version = problem_copy.get('label_version') or problem_copy.get("labels", {}).get("version")
             derived_cfg = problem_copy.get('derived_target')
             target_load_cols: list[str] = []
             if derived_cfg:
@@ -2269,6 +2272,12 @@
                 df_problem = df_problem.loc[:, ~df_problem.columns.duplicated()]
 
             df_problem = self._apply_problem_level_overrides(df_problem, problem_copy)
+            df_problem = require_target_column(
+                df_problem,
+                self.target_col,
+                label_version=self.label_version,
+                min_non_null=1,
+            )
             
             # Merge input predictions if required
             if input_preds:
diff --git a/tests/labels/test_labels.py b/tests/labels/test_labels.py
new file mode 100644
index 0000000000000000000000000000000000000000..71743f35f8a9ff386afeaa8a346bdf150f7b9164
--- /dev/null
+++ b/tests/labels/test_labels.py
@@ -0,0 +1,68 @@
+import polars as pl
+
+from utils.feature.labels import compute_td_labels, get_label_spec
+
+
+def _lookup(frame: pl.DataFrame, player_id: str) -> dict:
+    return frame.filter(pl.col("player_id") == player_id).to_dicts()[0]
+
+
+def test_compute_td_labels_offense_and_all_variants():
+    df = pl.DataFrame(
+        {
+            "player_id": ["rush", "rec", "pass", "def"],
+            "game_id": ["g1"] * 4,
+            "rushing_td_count": [1, 0, 0, 0],
+            "receiving_td_count": [0, 1, 0, 0],
+            "passing_td": [0, 0, 1, 0],
+            # Generic touchdown attribution (e.g., defensive return)
+            "touchdowns": [1, 1, 0, 1],
+        }
+    )
+
+    result = compute_td_labels(df, version="v1_any_offense")
+
+    rush = _lookup(result, "rush")
+    assert rush["anytime_td_offense"] == 1
+    assert rush["anytime_td_rush"] == 1
+    assert rush["anytime_td_rec"] == 0
+    assert rush["anytime_td_pass_thrown"] == 0
+    assert rush["td_count_offense"] == 1
+    assert rush["td_count_all"] == 1
+    assert rush["anytime_td"] == rush["anytime_td_offense"]
+
+    rec = _lookup(result, "rec")
+    assert rec["anytime_td_offense"] == 1
+    assert rec["anytime_td_rec"] == 1
+    assert rec["anytime_td_rush"] == 0
+
+    passer = _lookup(result, "pass")
+    assert passer["anytime_td_pass_thrown"] == 1
+    assert passer["anytime_td_offense"] == 1
+    assert passer["anytime_td_all"] == 1  # includes offensive TDs
+
+    defensive = _lookup(result, "def")
+    assert defensive["anytime_td_offense"] == 0  # no offensive scoring events
+    assert defensive["anytime_td_all"] == 1  # credited via generic touchdown
+    assert defensive["anytime_td"] == defensive["anytime_td_offense"]
+
+
+def test_label_version_any_all_aliases_anytime_td():
+    spec = get_label_spec("v1_any_all")
+    assert spec.primary == "anytime_td_all"
+
+    df = pl.DataFrame(
+        {
+            "player_id": ["all"],
+            "game_id": ["g1"],
+            "rushing_td_count": [0],
+            "receiving_td_count": [0],
+            "passing_td": [0],
+            "touchdowns": [1],
+        }
+    )
+    result = compute_td_labels(df, version="v1_any_all")
+    row = _lookup(result, "all")
+    # Alias ensures legacy anytime_td follows the version's primary definition.
+    assert row["anytime_td_all"] == 1
+    assert row["anytime_td"] == row["anytime_td_all"]
diff --git a/utils/feature/labels.py b/utils/feature/labels.py
new file mode 100644
index 0000000000000000000000000000000000000000..e5e5114da792e3c3558189e03b04f4ab2f69a4f5
--- /dev/null
+++ b/utils/feature/labels.py
@@ -0,0 +1,173 @@
+"""Label semantics and versioning for NFL player-level targets.
+
+This module centralizes anytime-TD label definitions so that:
+- Semantics are explicit and versioned.
+- Training can request a specific label column per problem.
+- Feature generation can emit multiple label variants for analysis.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass, field
+from typing import Dict, Iterable, Mapping
+
+import polars as pl
+
+
+@dataclass(frozen=True)
+class LabelRules:
+    """Rules controlling which TD components count toward a label."""
+
+    include_rush: bool = True
+    include_rec: bool = True
+    include_pass_thrown: bool = True  # credit passers for thrown TDs
+    include_other: bool = False  # fumble returns, defensive/special teams if present
+
+
+@dataclass(frozen=True)
+class LabelSpec:
+    """Container describing a label version."""
+
+    name: str
+    primary: str
+    labels: Mapping[str, LabelRules]
+    aliases: Mapping[str, str] = field(default_factory=dict)
+
+    @property
+    def all_columns(self) -> set[str]:
+        cols = set(self.labels.keys())
+        cols.update(self.aliases.keys())
+        return cols
+
+
+DEFAULT_LABEL_VERSION = "v1_any_offense"
+
+
+LABEL_VERSIONS: Dict[str, LabelSpec] = {
+    "v1_any_offense": LabelSpec(
+        name="v1_any_offense",
+        primary="anytime_td_offense",
+        labels={
+            "anytime_td_offense": LabelRules(include_other=False),
+            "anytime_td_rush": LabelRules(include_rush=True, include_rec=False, include_pass_thrown=False, include_other=False),
+            "anytime_td_rec": LabelRules(include_rush=False, include_rec=True, include_pass_thrown=False, include_other=False),
+            "anytime_td_pass_thrown": LabelRules(include_rush=False, include_rec=False, include_pass_thrown=True, include_other=False),
+            "anytime_td_all": LabelRules(include_other=True),
+        },
+        aliases={
+            # Maintain legacy column name as an alias to the offense-only label.
+            "anytime_td": "anytime_td_offense",
+            # Keep td_count pointing to the offense definition for backward compatibility.
+            "td_count": "td_count_offense",
+        },
+    ),
+    "v1_any_all": LabelSpec(
+        name="v1_any_all",
+        primary="anytime_td_all",
+        labels={
+            "anytime_td_all": LabelRules(include_other=True),
+            "anytime_td_offense": LabelRules(include_other=False),
+            "anytime_td_rush": LabelRules(include_rush=True, include_rec=False, include_pass_thrown=False, include_other=False),
+            "anytime_td_rec": LabelRules(include_rush=False, include_rec=True, include_pass_thrown=False, include_other=False),
+            "anytime_td_pass_thrown": LabelRules(include_rush=False, include_rec=False, include_pass_thrown=True, include_other=False),
+        },
+        aliases={
+            "anytime_td": "anytime_td_all",
+            "td_count": "td_count_all",
+        },
+    ),
+}
+
+
+def get_label_spec(version: str | None) -> LabelSpec:
+    """Return a concrete LabelSpec for the requested version (or default)."""
+
+    version = version or DEFAULT_LABEL_VERSION
+    if version not in LABEL_VERSIONS:
+        raise ValueError(
+            f"Unknown label_version '{version}'. "
+            f"Available: {sorted(LABEL_VERSIONS.keys())}"
+        )
+    return LABEL_VERSIONS[version]
+
+
+def _sum_expr(exprs: Iterable[pl.Expr]) -> pl.Expr:
+    exprs = list(exprs)
+    if not exprs:
+        return pl.lit(0).cast(pl.Int64)
+    acc = exprs[0]
+    for expr in exprs[1:]:
+        acc = acc + expr
+    return acc
+
+
+def compute_td_labels(df: pl.DataFrame, *, version: str | None = None) -> pl.DataFrame:
+    """Compute TD label columns according to a label version.
+
+    Parameters
+    ----------
+    df : pl.DataFrame
+        Player-game frame containing touchdown components.
+    version : str | None
+        Label version identifier. Defaults to DEFAULT_LABEL_VERSION.
+    """
+
+    spec = get_label_spec(version)
+    required_cols = ["rushing_td_count", "receiving_td_count", "passing_td", "touchdowns"]
+    missing = [col for col in required_cols if col not in df.columns]
+    if missing:
+        df = df.with_columns([pl.lit(0).cast(pl.Int64).alias(col) for col in missing])
+    rush = pl.col("rushing_td_count").fill_null(0).cast(pl.Int64)
+    rec = pl.col("receiving_td_count").fill_null(0).cast(pl.Int64)
+    passing = pl.col("passing_td").fill_null(0).cast(pl.Int64)
+    reported_total = pl.col("touchdowns").fill_null(0).cast(pl.Int64)
+
+    offense_total = _sum_expr([rush, rec, passing]).alias("_td_offense_total")
+    other_total = (reported_total - offense_total).clip_min(0).alias("_td_other_total")
+    all_total = (offense_total + other_total).alias("_td_all_total")
+
+    totals_exprs = [
+        offense_total,
+        other_total,
+        all_total,
+    ]
+
+    label_exprs: list[pl.Expr] = [
+        pl.col("_td_offense_total").alias("td_count_offense"),
+        pl.col("_td_all_total").alias("td_count_all"),
+    ]
+
+    for label_name, rules in spec.labels.items():
+        parts: list[pl.Expr] = []
+        if rules.include_rush:
+            parts.append(rush)
+        if rules.include_rec:
+            parts.append(rec)
+        if rules.include_pass_thrown:
+            parts.append(passing)
+        if rules.include_other:
+            parts.append(pl.col("_td_other_total"))
+        total_expr = _sum_expr(parts)
+        label_exprs.append((total_expr > 0).cast(pl.Int8).alias(label_name))
+
+    # Canonical counts for compatibility
+    if "td_count" not in df.columns:
+        # Fill td_count using the alias mapping; default to offense count.
+        target_alias = spec.aliases.get("td_count") or "td_count_offense"
+        label_exprs.append(pl.col(target_alias).alias("td_count"))
+
+    df = df.with_columns(totals_exprs).with_columns(label_exprs)
+
+    # Resolve aliases (e.g., anytime_td -> anytime_td_offense)
+    if spec.aliases:
+        alias_exprs = []
+        for alias_name, source_name in spec.aliases.items():
+            if source_name in df.columns:
+                alias_exprs.append(pl.col(source_name).alias(alias_name))
+        if alias_exprs:
+            df = df.with_columns(alias_exprs)
+
+    drop_cols = [col for col in ("_td_offense_total", "_td_other_total", "_td_all_total") if col in df.columns]
+    if drop_cols:
+        df = df.drop(drop_cols)
+    return df
diff --git a/utils/feature/player_game_level.py b/utils/feature/player_game_level.py
index b6fe516c5f03d575038eef554d5ab39ea5d5c90d..dd4f1f7fcc9de4d8c63390f0a160005eeae48e2f
--- a/utils/feature/player_game_level.py
+++ b/utils/feature/player_game_level.py
@@ -4,8 +4,12 @@
 Each player gets one row per game with their total stats.
 
 Target columns created:
-- anytime_td (binary): Did player score a TD (receiving or rushing)?
-- td_count (int): Number of TDs scored (receiving + rushing)
+- anytime_td_offense (binary): Did player score an offensive TD (rush/rec/pass thrown)?
+- anytime_td_all (binary): Did player score any TD (including defensive/special teams if present)?
+- anytime_td_rush / anytime_td_rec / anytime_td_pass_thrown: Type-specific TD flags.
+- anytime_td (binary): Legacy alias → current label version primary.
+- td_count_offense / td_count_all: TD counts aligned to label semantics.
+- td_count (int): Legacy alias for the primary td_count.
 - passing_td (int): Number of passing TDs (for QBs)
 - receiving_yards (float): Total receiving yards
 - rushing_yards (float): Total rushing yards
@@ -33,6 +37,7 @@
 from utils.collect.nfl_schedules import get_schedule
 from utils.feature.asof import decision_cutoff_hours_default, fallback_cutoff_hours, get_decision_cutoff_hours, get_fallback_cutoff_hours
 from utils.feature.player_drive_level import _load_play_level_data
+from utils.feature.labels import DEFAULT_LABEL_VERSION, compute_td_labels
 from utils.train.injury_availability import (
     load_latest_artifact,
     predict_probabilities as predict_injury_probabilities,
@@ -1582,7 +1587,12 @@
     if flag_cols:
         df = df.with_columns([pl.col(col).cast(pl.Int8) for col in flag_cols])
     return df
-def build_player_game_level(*, start_date: date, end_date: date) -> None:
+def build_player_game_level(
+    *,
+    start_date: date,
+    end_date: date,
+    label_version: str | None = None,
+) -> None:
     """Aggregate play-level data to player-game level.
     
     Creates one row per (player, game) with accumulated stats.
@@ -1680,7 +1690,7 @@
     
     # Merge rows where same player had multiple roles in same game
     # (e.g., QB who also rushed, WR who also rushed)
-    df_merged = _merge_multi_role_players(df_all)
+    df_merged = _merge_multi_role_players(df_all, label_version=label_version or DEFAULT_LABEL_VERSION)
 
     df_merged = _append_zero_usage_players(df_merged, seasons_in_window)
     
@@ -3368,7 +3378,7 @@
     )
 
 
-def _merge_multi_role_players(df: pl.DataFrame) -> pl.DataFrame:
+def _merge_multi_role_players(df: pl.DataFrame, *, label_version: str | None = None) -> pl.DataFrame:
     """Merge stats for players who had multiple roles in same game.
     
     Example: QB who passed and rushed, WR who received and rushed.
@@ -3422,8 +3432,6 @@
         if col in merged.columns:
             merged = merged.with_columns(pl.col(col).fill_null(0))
 
-    # Fallback touchdown logic: if generic touchdown attribution is missing,
-    # derive it from rushing + receiving touchdowns.
     merged = merged.with_columns([
         pl.col("touchdowns").fill_null(0).alias("touchdowns"),
         pl.col("rushing_td_count").fill_null(0).alias("rushing_td_count"),
@@ -3435,17 +3443,5 @@
         pl.col("goal_to_go_carry").fill_null(0).alias("goal_to_go_carry"),
     ])
 
-    merged = merged.with_columns([
-        pl.when(pl.col("touchdowns") > 0)
-        .then(pl.col("touchdowns"))
-        .otherwise(pl.col("rushing_td_count") + pl.col("receiving_td_count"))
-        .cast(pl.Int64)
-        .alias("_total_touchdowns")
-    ])
-
-    merged = merged.with_columns([
-        (pl.col("_total_touchdowns") > 0).cast(pl.Int8).alias("anytime_td"),
-        pl.col("_total_touchdowns").alias("td_count"),
-    ]).drop("_total_touchdowns")
-    
+    merged = compute_td_labels(merged, version=label_version)
     return merged
diff --git a/utils/feature/targets.py b/utils/feature/targets.py
index 7738086dcbfda7432b937cc7d8095988cb0edff0..769ee8735c4024c4410ddd674b11112f093624dd
--- a/utils/feature/targets.py
+++ b/utils/feature/targets.py
@@ -7,6 +7,8 @@
 import polars as pl
 import logging
 
+from utils.feature.labels import DEFAULT_LABEL_VERSION, get_label_spec
+
 logger = logging.getLogger(__name__)
 
 
@@ -14,9 +16,16 @@
 NFL_TARGET_SCHEMA = {
     # Binary classification targets
     "anytime_td": pl.Int8,  # Primary MVP target: did player score a TD?
+    "anytime_td_offense": pl.Int8,
+    "anytime_td_all": pl.Int8,
+    "anytime_td_rush": pl.Int8,
+    "anytime_td_rec": pl.Int8,
+    "anytime_td_pass_thrown": pl.Int8,
     
     # Count/regression targets
     "td_count": pl.Int64,  # Number of TDs scored (receiving + rushing)
+    "td_count_offense": pl.Int64,
+    "td_count_all": pl.Int64,
     "passing_td": pl.Int64,  # Number of passing TDs (QB only)
     
     # Yardage regression targets
@@ -103,4 +112,40 @@
     pl.DataFrame
         DataFrame with validated target columns
     """
-    return validate_target_columns(df, strict=False)
\ No newline at end of file
+    return validate_target_columns(df, strict=False)
+
+
+def require_target_column(
+    df: pl.DataFrame,
+    target_col: str,
+    *,
+    label_version: str | None = None,
+    min_non_null: int = 1,
+) -> pl.DataFrame:
+    """Ensure the configured target column exists and is populated.
+
+    Raises a ValueError if the column is missing or entirely null.
+    """
+
+    if target_col not in df.columns:
+        alias_hint = ""
+        if label_version:
+            try:
+                spec = get_label_spec(label_version or DEFAULT_LABEL_VERSION)
+                if target_col in spec.aliases:
+                    alias_hint = f" Target maps to '{spec.aliases[target_col]}' under {spec.name}."
+            except Exception:
+                alias_hint = ""
+        raise ValueError(f"Target column '{target_col}' not found in feature frame.{alias_hint}")
+
+    series = df[target_col]
+    non_null = series.drop_nulls().height
+    if non_null < min_non_null:
+        raise ValueError(
+            f"Target column '{target_col}' has insufficient non-null rows "
+            f"({non_null}/{len(series)})."
+        )
+    nulls = len(series) - non_null
+    if nulls > 0:
+        logger.warning("Target %s contains %d null rows; they will be dropped.", target_col, nulls)
+    return df

file update:
diff --git a/config/training.yaml b/config/training.yaml
index 3055a636b89249119408aaad970d3025956877db..3953818d861d0410246bff132110722a3ce44007
--- a/config/training.yaml
+++ b/config/training.yaml
@@ -475,6 +475,7 @@
   # Calibrated probability of scoring > 0 TDs.
   - name: 'anytime_td'
     target_col: 'anytime_td'
+    label_version: 'v1_any_offense'
     task_type: 'classification'
     input_predictions:
       - 'availability_active'
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 6c47a91d08f9d309f94323efd4708bb992dc4ce0..5ba68e8bf1acd3a789a76a8857674e6f6433017b
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -26,6 +26,7 @@
 from utils.feature.player_drive_level import build_player_drive_level
 from utils.feature.player_game_level import build_player_game_level
 from utils.feature.opponent_splits import build_opponent_splits
+from utils.feature.labels import DEFAULT_LABEL_VERSION, get_label_spec
 from utils.feature.targets import validate_target_columns
 from utils.feature.daily_totals import build_daily_cache_range
 from utils.feature.rolling_window import add_rolling_features
@@ -233,6 +234,7 @@
     output_path: Path | None = None,
     primary_output_path: Path | None = None,
     cutoff_label: str | None = None,
+    label_version: str | None = None,
 ) -> pl.DataFrame:
     """Run full feature pipeline up to *inclusive* `end_date` for a single cutoff window.
 
@@ -248,6 +250,7 @@
     primary_output = primary_output_path or target_output_path
     current_cutoff_hours = float(get_decision_cutoff_hours())
     clean_min_date, clean_max_date = (None, None)
+    label_version = label_version or DEFAULT_LABEL_VERSION
     if start_date is None or end_date is None:
         clean_min_date, clean_max_date = _get_clean_date_bounds()
 
@@ -294,7 +297,7 @@
             build_player_drive_level(start_date=cur, end_date=chunk_end)
             
             # 5. Player-game aggregations (for rolling window features)
-            build_player_game_level(start_date=cur, end_date=chunk_end)
+            build_player_game_level(start_date=cur, end_date=chunk_end, label_version=label_version)
 
             # advance to next slice
             cur += timedelta(days=chunk_days)
@@ -948,11 +951,19 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    # Log target distribution for anytime_td
-    if "anytime_td" in df_player_game_all.columns:
-        td_count = df_player_game_all["anytime_td"].sum()
-        td_rate = td_count / len(df_player_game_all) * 100
-        logging.info("    Anytime TD rate: %.2f%% (%d/%d)", td_rate, td_count, len(df_player_game_all))
+    spec = get_label_spec(label_version)
+    label_candidates = {spec.primary, "anytime_td"}
+    for label_col in label_candidates:
+        if label_col in df_player_game_all.columns:
+            td_count = df_player_game_all[label_col].sum()
+            td_rate = td_count / len(df_player_game_all) * 100
+            logging.info(
+                "    Label %s rate: %.2f%% (%d/%d)",
+                label_col,
+                td_rate,
+                td_count,
+                len(df_player_game_all),
+            )
     
     return df_player_game_all
 
@@ -965,6 +976,7 @@
     recompute_intermediate: bool = True,
     build_rolling: bool = True,
     cutoff_hours_list: Sequence[float] | None = None,
+    label_version: str | None = None,
 ) -> pl.DataFrame:
     """Build feature matrices for one or more decision cutoff horizons.
 
@@ -992,6 +1004,7 @@
                 output_path=output_path,
                 primary_output_path=primary_output,
                 cutoff_label=label,
+                label_version=label_version,
             )
         if idx == 0:
             primary_result = df
diff --git a/pipeline/train.py b/pipeline/train.py
index 265bc29f4861d2d4d26f54fd7f77304de8fe6742..fe70207dcdf25d209ee3ad55080b7ce826347c44
--- a/pipeline/train.py
+++ b/pipeline/train.py
@@ -98,6 +98,7 @@
     fit_team_conformal_sums,
     composite_sum_interval,
 )
+from utils.feature.targets import require_target_column
 
 # Ignore specific, noisy warnings from dependencies
 warnings.filterwarnings(
@@ -259,6 +260,7 @@
 
         # Per-problem attributes initialised later
         self.target_col = None
+        self.label_version = None
         self.feature_columns = None
 
         self.models = {}
@@ -2163,6 +2165,7 @@
             
             problem_copy = copy.deepcopy(problem)
             self.target_col = problem_copy['target_col']
+            self.label_version = problem_copy.get('label_version') or problem_copy.get("labels", {}).get("version")
             derived_cfg = problem_copy.get('derived_target')
             target_load_cols: list[str] = []
             if derived_cfg:
@@ -2269,6 +2272,12 @@
                 df_problem = df_problem.loc[:, ~df_problem.columns.duplicated()]
 
             df_problem = self._apply_problem_level_overrides(df_problem, problem_copy)
+            df_problem = require_target_column(
+                df_problem,
+                self.target_col,
+                label_version=self.label_version,
+                min_non_null=1,
+            )
             
             # Merge input predictions if required
             if input_preds:
diff --git a/tests/labels/test_labels.py b/tests/labels/test_labels.py
new file mode 100644
index 0000000000000000000000000000000000000000..71743f35f8a9ff386afeaa8a346bdf150f7b9164
--- /dev/null
+++ b/tests/labels/test_labels.py
@@ -0,0 +1,68 @@
+import polars as pl
+
+from utils.feature.labels import compute_td_labels, get_label_spec
+
+
+def _lookup(frame: pl.DataFrame, player_id: str) -> dict:
+    return frame.filter(pl.col("player_id") == player_id).to_dicts()[0]
+
+
+def test_compute_td_labels_offense_and_all_variants():
+    df = pl.DataFrame(
+        {
+            "player_id": ["rush", "rec", "pass", "def"],
+            "game_id": ["g1"] * 4,
+            "rushing_td_count": [1, 0, 0, 0],
+            "receiving_td_count": [0, 1, 0, 0],
+            "passing_td": [0, 0, 1, 0],
+            # Generic touchdown attribution (e.g., defensive return)
+            "touchdowns": [1, 1, 0, 1],
+        }
+    )
+
+    result = compute_td_labels(df, version="v1_any_offense")
+
+    rush = _lookup(result, "rush")
+    assert rush["anytime_td_offense"] == 1
+    assert rush["anytime_td_rush"] == 1
+    assert rush["anytime_td_rec"] == 0
+    assert rush["anytime_td_pass_thrown"] == 0
+    assert rush["td_count_offense"] == 1
+    assert rush["td_count_all"] == 1
+    assert rush["anytime_td"] == rush["anytime_td_offense"]
+
+    rec = _lookup(result, "rec")
+    assert rec["anytime_td_offense"] == 1
+    assert rec["anytime_td_rec"] == 1
+    assert rec["anytime_td_rush"] == 0
+
+    passer = _lookup(result, "pass")
+    assert passer["anytime_td_pass_thrown"] == 1
+    assert passer["anytime_td_offense"] == 1
+    assert passer["anytime_td_all"] == 1  # includes offensive TDs
+
+    defensive = _lookup(result, "def")
+    assert defensive["anytime_td_offense"] == 0  # no offensive scoring events
+    assert defensive["anytime_td_all"] == 1  # credited via generic touchdown
+    assert defensive["anytime_td"] == defensive["anytime_td_offense"]
+
+
+def test_label_version_any_all_aliases_anytime_td():
+    spec = get_label_spec("v1_any_all")
+    assert spec.primary == "anytime_td_all"
+
+    df = pl.DataFrame(
+        {
+            "player_id": ["all"],
+            "game_id": ["g1"],
+            "rushing_td_count": [0],
+            "receiving_td_count": [0],
+            "passing_td": [0],
+            "touchdowns": [1],
+        }
+    )
+    result = compute_td_labels(df, version="v1_any_all")
+    row = _lookup(result, "all")
+    # Alias ensures legacy anytime_td follows the version's primary definition.
+    assert row["anytime_td_all"] == 1
+    assert row["anytime_td"] == row["anytime_td_all"]
diff --git a/utils/feature/labels.py b/utils/feature/labels.py
new file mode 100644
index 0000000000000000000000000000000000000000..e5e5114da792e3c3558189e03b04f4ab2f69a4f5
--- /dev/null
+++ b/utils/feature/labels.py
@@ -0,0 +1,173 @@
+"""Label semantics and versioning for NFL player-level targets.
+
+This module centralizes anytime-TD label definitions so that:
+- Semantics are explicit and versioned.
+- Training can request a specific label column per problem.
+- Feature generation can emit multiple label variants for analysis.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass, field
+from typing import Dict, Iterable, Mapping
+
+import polars as pl
+
+
+@dataclass(frozen=True)
+class LabelRules:
+    """Rules controlling which TD components count toward a label."""
+
+    include_rush: bool = True
+    include_rec: bool = True
+    include_pass_thrown: bool = True  # credit passers for thrown TDs
+    include_other: bool = False  # fumble returns, defensive/special teams if present
+
+
+@dataclass(frozen=True)
+class LabelSpec:
+    """Container describing a label version."""
+
+    name: str
+    primary: str
+    labels: Mapping[str, LabelRules]
+    aliases: Mapping[str, str] = field(default_factory=dict)
+
+    @property
+    def all_columns(self) -> set[str]:
+        cols = set(self.labels.keys())
+        cols.update(self.aliases.keys())
+        return cols
+
+
+DEFAULT_LABEL_VERSION = "v1_any_offense"
+
+
+LABEL_VERSIONS: Dict[str, LabelSpec] = {
+    "v1_any_offense": LabelSpec(
+        name="v1_any_offense",
+        primary="anytime_td_offense",
+        labels={
+            "anytime_td_offense": LabelRules(include_other=False),
+            "anytime_td_rush": LabelRules(include_rush=True, include_rec=False, include_pass_thrown=False, include_other=False),
+            "anytime_td_rec": LabelRules(include_rush=False, include_rec=True, include_pass_thrown=False, include_other=False),
+            "anytime_td_pass_thrown": LabelRules(include_rush=False, include_rec=False, include_pass_thrown=True, include_other=False),
+            "anytime_td_all": LabelRules(include_other=True),
+        },
+        aliases={
+            # Maintain legacy column name as an alias to the offense-only label.
+            "anytime_td": "anytime_td_offense",
+            # Keep td_count pointing to the offense definition for backward compatibility.
+            "td_count": "td_count_offense",
+        },
+    ),
+    "v1_any_all": LabelSpec(
+        name="v1_any_all",
+        primary="anytime_td_all",
+        labels={
+            "anytime_td_all": LabelRules(include_other=True),
+            "anytime_td_offense": LabelRules(include_other=False),
+            "anytime_td_rush": LabelRules(include_rush=True, include_rec=False, include_pass_thrown=False, include_other=False),
+            "anytime_td_rec": LabelRules(include_rush=False, include_rec=True, include_pass_thrown=False, include_other=False),
+            "anytime_td_pass_thrown": LabelRules(include_rush=False, include_rec=False, include_pass_thrown=True, include_other=False),
+        },
+        aliases={
+            "anytime_td": "anytime_td_all",
+            "td_count": "td_count_all",
+        },
+    ),
+}
+
+
+def get_label_spec(version: str | None) -> LabelSpec:
+    """Return a concrete LabelSpec for the requested version (or default)."""
+
+    version = version or DEFAULT_LABEL_VERSION
+    if version not in LABEL_VERSIONS:
+        raise ValueError(
+            f"Unknown label_version '{version}'. "
+            f"Available: {sorted(LABEL_VERSIONS.keys())}"
+        )
+    return LABEL_VERSIONS[version]
+
+
+def _sum_expr(exprs: Iterable[pl.Expr]) -> pl.Expr:
+    exprs = list(exprs)
+    if not exprs:
+        return pl.lit(0).cast(pl.Int64)
+    acc = exprs[0]
+    for expr in exprs[1:]:
+        acc = acc + expr
+    return acc
+
+
+def compute_td_labels(df: pl.DataFrame, *, version: str | None = None) -> pl.DataFrame:
+    """Compute TD label columns according to a label version.
+
+    Parameters
+    ----------
+    df : pl.DataFrame
+        Player-game frame containing touchdown components.
+    version : str | None
+        Label version identifier. Defaults to DEFAULT_LABEL_VERSION.
+    """
+
+    spec = get_label_spec(version)
+    required_cols = ["rushing_td_count", "receiving_td_count", "passing_td", "touchdowns"]
+    missing = [col for col in required_cols if col not in df.columns]
+    if missing:
+        df = df.with_columns([pl.lit(0).cast(pl.Int64).alias(col) for col in missing])
+    rush = pl.col("rushing_td_count").fill_null(0).cast(pl.Int64)
+    rec = pl.col("receiving_td_count").fill_null(0).cast(pl.Int64)
+    passing = pl.col("passing_td").fill_null(0).cast(pl.Int64)
+    reported_total = pl.col("touchdowns").fill_null(0).cast(pl.Int64)
+
+    offense_total = _sum_expr([rush, rec, passing]).alias("_td_offense_total")
+    other_total = (reported_total - offense_total).clip_min(0).alias("_td_other_total")
+    all_total = (offense_total + other_total).alias("_td_all_total")
+
+    totals_exprs = [
+        offense_total,
+        other_total,
+        all_total,
+    ]
+
+    label_exprs: list[pl.Expr] = [
+        pl.col("_td_offense_total").alias("td_count_offense"),
+        pl.col("_td_all_total").alias("td_count_all"),
+    ]
+
+    for label_name, rules in spec.labels.items():
+        parts: list[pl.Expr] = []
+        if rules.include_rush:
+            parts.append(rush)
+        if rules.include_rec:
+            parts.append(rec)
+        if rules.include_pass_thrown:
+            parts.append(passing)
+        if rules.include_other:
+            parts.append(pl.col("_td_other_total"))
+        total_expr = _sum_expr(parts)
+        label_exprs.append((total_expr > 0).cast(pl.Int8).alias(label_name))
+
+    # Canonical counts for compatibility
+    if "td_count" not in df.columns:
+        # Fill td_count using the alias mapping; default to offense count.
+        target_alias = spec.aliases.get("td_count") or "td_count_offense"
+        label_exprs.append(pl.col(target_alias).alias("td_count"))
+
+    df = df.with_columns(totals_exprs).with_columns(label_exprs)
+
+    # Resolve aliases (e.g., anytime_td -> anytime_td_offense)
+    if spec.aliases:
+        alias_exprs = []
+        for alias_name, source_name in spec.aliases.items():
+            if source_name in df.columns:
+                alias_exprs.append(pl.col(source_name).alias(alias_name))
+        if alias_exprs:
+            df = df.with_columns(alias_exprs)
+
+    drop_cols = [col for col in ("_td_offense_total", "_td_other_total", "_td_all_total") if col in df.columns]
+    if drop_cols:
+        df = df.drop(drop_cols)
+    return df
diff --git a/utils/feature/player_game_level.py b/utils/feature/player_game_level.py
index b6fe516c5f03d575038eef554d5ab39ea5d5c90d..dd4f1f7fcc9de4d8c63390f0a160005eeae48e2f
--- a/utils/feature/player_game_level.py
+++ b/utils/feature/player_game_level.py
@@ -4,8 +4,12 @@
 Each player gets one row per game with their total stats.
 
 Target columns created:
-- anytime_td (binary): Did player score a TD (receiving or rushing)?
-- td_count (int): Number of TDs scored (receiving + rushing)
+- anytime_td_offense (binary): Did player score an offensive TD (rush/rec/pass thrown)?
+- anytime_td_all (binary): Did player score any TD (including defensive/special teams if present)?
+- anytime_td_rush / anytime_td_rec / anytime_td_pass_thrown: Type-specific TD flags.
+- anytime_td (binary): Legacy alias → current label version primary.
+- td_count_offense / td_count_all: TD counts aligned to label semantics.
+- td_count (int): Legacy alias for the primary td_count.
 - passing_td (int): Number of passing TDs (for QBs)
 - receiving_yards (float): Total receiving yards
 - rushing_yards (float): Total rushing yards
@@ -33,6 +37,7 @@
 from utils.collect.nfl_schedules import get_schedule
 from utils.feature.asof import decision_cutoff_hours_default, fallback_cutoff_hours, get_decision_cutoff_hours, get_fallback_cutoff_hours
 from utils.feature.player_drive_level import _load_play_level_data
+from utils.feature.labels import DEFAULT_LABEL_VERSION, compute_td_labels
 from utils.train.injury_availability import (
     load_latest_artifact,
     predict_probabilities as predict_injury_probabilities,
@@ -1582,7 +1587,12 @@
     if flag_cols:
         df = df.with_columns([pl.col(col).cast(pl.Int8) for col in flag_cols])
     return df
-def build_player_game_level(*, start_date: date, end_date: date) -> None:
+def build_player_game_level(
+    *,
+    start_date: date,
+    end_date: date,
+    label_version: str | None = None,
+) -> None:
     """Aggregate play-level data to player-game level.
     
     Creates one row per (player, game) with accumulated stats.
@@ -1680,7 +1690,7 @@
     
     # Merge rows where same player had multiple roles in same game
     # (e.g., QB who also rushed, WR who also rushed)
-    df_merged = _merge_multi_role_players(df_all)
+    df_merged = _merge_multi_role_players(df_all, label_version=label_version or DEFAULT_LABEL_VERSION)
 
     df_merged = _append_zero_usage_players(df_merged, seasons_in_window)
     
@@ -3368,7 +3378,7 @@
     )
 
 
-def _merge_multi_role_players(df: pl.DataFrame) -> pl.DataFrame:
+def _merge_multi_role_players(df: pl.DataFrame, *, label_version: str | None = None) -> pl.DataFrame:
     """Merge stats for players who had multiple roles in same game.
     
     Example: QB who passed and rushed, WR who received and rushed.
@@ -3422,8 +3432,6 @@
         if col in merged.columns:
             merged = merged.with_columns(pl.col(col).fill_null(0))
 
-    # Fallback touchdown logic: if generic touchdown attribution is missing,
-    # derive it from rushing + receiving touchdowns.
     merged = merged.with_columns([
         pl.col("touchdowns").fill_null(0).alias("touchdowns"),
         pl.col("rushing_td_count").fill_null(0).alias("rushing_td_count"),
@@ -3435,17 +3443,5 @@
         pl.col("goal_to_go_carry").fill_null(0).alias("goal_to_go_carry"),
     ])
 
-    merged = merged.with_columns([
-        pl.when(pl.col("touchdowns") > 0)
-        .then(pl.col("touchdowns"))
-        .otherwise(pl.col("rushing_td_count") + pl.col("receiving_td_count"))
-        .cast(pl.Int64)
-        .alias("_total_touchdowns")
-    ])
-
-    merged = merged.with_columns([
-        (pl.col("_total_touchdowns") > 0).cast(pl.Int8).alias("anytime_td"),
-        pl.col("_total_touchdowns").alias("td_count"),
-    ]).drop("_total_touchdowns")
-    
+    merged = compute_td_labels(merged, version=label_version)
     return merged
diff --git a/utils/feature/targets.py b/utils/feature/targets.py
index 7738086dcbfda7432b937cc7d8095988cb0edff0..769ee8735c4024c4410ddd674b11112f093624dd
--- a/utils/feature/targets.py
+++ b/utils/feature/targets.py
@@ -7,6 +7,8 @@
 import polars as pl
 import logging
 
+from utils.feature.labels import DEFAULT_LABEL_VERSION, get_label_spec
+
 logger = logging.getLogger(__name__)
 
 
@@ -14,9 +16,16 @@
 NFL_TARGET_SCHEMA = {
     # Binary classification targets
     "anytime_td": pl.Int8,  # Primary MVP target: did player score a TD?
+    "anytime_td_offense": pl.Int8,
+    "anytime_td_all": pl.Int8,
+    "anytime_td_rush": pl.Int8,
+    "anytime_td_rec": pl.Int8,
+    "anytime_td_pass_thrown": pl.Int8,
     
     # Count/regression targets
     "td_count": pl.Int64,  # Number of TDs scored (receiving + rushing)
+    "td_count_offense": pl.Int64,
+    "td_count_all": pl.Int64,
     "passing_td": pl.Int64,  # Number of passing TDs (QB only)
     
     # Yardage regression targets
@@ -103,4 +112,40 @@
     pl.DataFrame
         DataFrame with validated target columns
     """
-    return validate_target_columns(df, strict=False)
\ No newline at end of file
+    return validate_target_columns(df, strict=False)
+
+
+def require_target_column(
+    df: pl.DataFrame,
+    target_col: str,
+    *,
+    label_version: str | None = None,
+    min_non_null: int = 1,
+) -> pl.DataFrame:
+    """Ensure the configured target column exists and is populated.
+
+    Raises a ValueError if the column is missing or entirely null.
+    """
+
+    if target_col not in df.columns:
+        alias_hint = ""
+        if label_version:
+            try:
+                spec = get_label_spec(label_version or DEFAULT_LABEL_VERSION)
+                if target_col in spec.aliases:
+                    alias_hint = f" Target maps to '{spec.aliases[target_col]}' under {spec.name}."
+            except Exception:
+                alias_hint = ""
+        raise ValueError(f"Target column '{target_col}' not found in feature frame.{alias_hint}")
+
+    series = df[target_col]
+    non_null = series.drop_nulls().height
+    if non_null < min_non_null:
+        raise ValueError(
+            f"Target column '{target_col}' has insufficient non-null rows "
+            f"({non_null}/{len(series)})."
+        )
+    nulls = len(series) - non_null
+    if nulls > 0:
+        logger.warning("Target %s contains %d null rows; they will be dropped.", target_col, nulls)
+    return df


thinking
**Verifying label_version integration and imports**
exec
/bin/zsh -lc 'cd /Users/jameswest/Desktop/nfl_predict && rg "build_feature_matrix"' in /Users/jameswest/Desktop/nfl_predict succeeded in 761ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
utils/main/backtest_cutoffs.py:from pipeline.feature import build_feature_matrix
utils/main/backtest_cutoffs.py:        build_feature_matrix(
main.py:from pipeline.feature import build_feature_matrix, refresh_context_histories
main.py:        build_feature_matrix(
main.py:        "feature": lambda: build_feature_matrix(
pipeline/feature.py:__all__ = ["build_feature_matrix", "refresh_context_histories"]
pipeline/feature.py:def _build_feature_matrix_internal(
pipeline/feature.py:def build_feature_matrix(
pipeline/feature.py:            df = _build_feature_matrix_internal(
tests/test_rolling_window_extended.py:from pipeline.feature import build_feature_matrix, FINAL_OUT
tests/test_rolling_window_extended.py:        build_feature_matrix(start_date=start_date, end_date=end_date, chunk_days=2, save_output=True)
tests/test_rolling_window_extended.py:        build_feature_matrix(start_date=start_date, end_date=end_date, chunk_days=1, save_output=True)
docs/monitoring.md:- `pipeline/feature.build_feature_matrix` guards all snapshots (`injury`, `roster`, `odds`, `weather`) and logs the percentage of rows filtered when snapshots are missing or post-cutoff.
utils/general/backtest_cutoffs.py:from pipeline.feature import build_feature_matrix
utils/general/backtest_cutoffs.py:        build_feature_matrix(
codex_output.md:   python -c "from pipeline.feature import build_feature_matrix; \
codex_output.md:              build_feature_matrix(start_date=date(2024, 9, 5), \
codex_output.md:/bin/zsh -lc 'rg "build_feature_matrix" -n pipeline/feature.py' in /Users/jameswest/Desktop/nfl_predict succeeded in 760ms:
codex_output.md:66:__all__ = ["build_feature_matrix", "refresh_context_histories"]
file update:
diff --git a/config/training.yaml b/config/training.yaml
index 3055a636b89249119408aaad970d3025956877db..3953818d861d0410246bff132110722a3ce44007
--- a/config/training.yaml
+++ b/config/training.yaml
@@ -475,6 +475,7 @@
   # Calibrated probability of scoring > 0 TDs.
   - name: 'anytime_td'
     target_col: 'anytime_td'
+    label_version: 'v1_any_offense'
     task_type: 'classification'
     input_predictions:
       - 'availability_active'
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 6c47a91d08f9d309f94323efd4708bb992dc4ce0..5ba68e8bf1acd3a789a76a8857674e6f6433017b
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -26,6 +26,7 @@
 from utils.feature.player_drive_level import build_player_drive_level
 from utils.feature.player_game_level import build_player_game_level
 from utils.feature.opponent_splits import build_opponent_splits
+from utils.feature.labels import DEFAULT_LABEL_VERSION, get_label_spec
 from utils.feature.targets import validate_target_columns
 from utils.feature.daily_totals import build_daily_cache_range
 from utils.feature.rolling_window import add_rolling_features
@@ -233,6 +234,7 @@
     output_path: Path | None = None,
     primary_output_path: Path | None = None,
     cutoff_label: str | None = None,
+    label_version: str | None = None,
 ) -> pl.DataFrame:
     """Run full feature pipeline up to *inclusive* `end_date` for a single cutoff window.
 
@@ -248,6 +250,7 @@
     primary_output = primary_output_path or target_output_path
     current_cutoff_hours = float(get_decision_cutoff_hours())
     clean_min_date, clean_max_date = (None, None)
+    label_version = label_version or DEFAULT_LABEL_VERSION
     if start_date is None or end_date is None:
         clean_min_date, clean_max_date = _get_clean_date_bounds()
 
@@ -294,7 +297,7 @@
             build_player_drive_level(start_date=cur, end_date=chunk_end)
             
             # 5. Player-game aggregations (for rolling window features)
-            build_player_game_level(start_date=cur, end_date=chunk_end)
+            build_player_game_level(start_date=cur, end_date=chunk_end, label_version=label_version)
 
             # advance to next slice
             cur += timedelta(days=chunk_days)
@@ -948,11 +951,19 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    # Log target distribution for anytime_td
-    if "anytime_td" in df_player_game_all.columns:
-        td_count = df_player_game_all["anytime_td"].sum()
-        td_rate = td_count / len(df_player_game_all) * 100
-        logging.info("    Anytime TD rate: %.2f%% (%d/%d)", td_rate, td_count, len(df_player_game_all))
+    spec = get_label_spec(label_version)
+    label_candidates = {spec.primary, "anytime_td"}
+    for label_col in label_candidates:
+        if label_col in df_player_game_all.columns:
+            td_count = df_player_game_all[label_col].sum()
+            td_rate = td_count / len(df_player_game_all) * 100
+            logging.info(
+                "    Label %s rate: %.2f%% (%d/%d)",
+                label_col,
+                td_rate,
+                td_count,
+                len(df_player_game_all),
+            )
     
     return df_player_game_all
 
@@ -965,6 +976,7 @@
     recompute_intermediate: bool = True,
     build_rolling: bool = True,
     cutoff_hours_list: Sequence[float] | None = None,
+    label_version: str | None = None,
 ) -> pl.DataFrame:
     """Build feature matrices for one or more decision cutoff horizons.
 
@@ -992,6 +1004,7 @@
                 output_path=output_path,
                 primary_output_path=primary_output,
                 cutoff_label=label,
+                label_version=label_version,
             )
         if idx == 0:
             primary_result = df
diff --git a/pipeline/train.py b/pipeline/train.py
index 265bc29f4861d2d4d26f54fd7f77304de8fe6742..fe70207dcdf25d209ee3ad55080b7ce826347c44
--- a/pipeline/train.py
+++ b/pipeline/train.py
@@ -98,6 +98,7 @@
     fit_team_conformal_sums,
     composite_sum_interval,
 )
+from utils.feature.targets import require_target_column
 
 # Ignore specific, noisy warnings from dependencies
 warnings.filterwarnings(
@@ -259,6 +260,7 @@
 
         # Per-problem attributes initialised later
         self.target_col = None
+        self.label_version = None
         self.feature_columns = None
 
         self.models = {}
@@ -2163,6 +2165,7 @@
             
             problem_copy = copy.deepcopy(problem)
             self.target_col = problem_copy['target_col']
+            self.label_version = problem_copy.get('label_version') or problem_copy.get("labels", {}).get("version")
             derived_cfg = problem_copy.get('derived_target')
             target_load_cols: list[str] = []
             if derived_cfg:
@@ -2269,6 +2272,12 @@
                 df_problem = df_problem.loc[:, ~df_problem.columns.duplicated()]
 
             df_problem = self._apply_problem_level_overrides(df_problem, problem_copy)
+            df_problem = require_target_column(
+                df_problem,
+                self.target_col,
+                label_version=self.label_version,
+                min_non_null=1,
+            )
             
             # Merge input predictions if required
             if input_preds:
diff --git a/tests/labels/test_labels.py b/tests/labels/test_labels.py
new file mode 100644
index 0000000000000000000000000000000000000000..71743f35f8a9ff386afeaa8a346bdf150f7b9164
--- /dev/null
+++ b/tests/labels/test_labels.py
@@ -0,0 +1,68 @@
+import polars as pl
+
+from utils.feature.labels import compute_td_labels, get_label_spec
+
+
+def _lookup(frame: pl.DataFrame, player_id: str) -> dict:
+    return frame.filter(pl.col("player_id") == player_id).to_dicts()[0]
+
+
+def test_compute_td_labels_offense_and_all_variants():
+    df = pl.DataFrame(
+        {
+            "player_id": ["rush", "rec", "pass", "def"],
+            "game_id": ["g1"] * 4,
+            "rushing_td_count": [1, 0, 0, 0],
+            "receiving_td_count": [0, 1, 0, 0],
+            "passing_td": [0, 0, 1, 0],
+            # Generic touchdown attribution (e.g., defensive return)
+            "touchdowns": [1, 1, 0, 1],
+        }
+    )
+
+    result = compute_td_labels(df, version="v1_any_offense")
+
+    rush = _lookup(result, "rush")
+    assert rush["anytime_td_offense"] == 1
+    assert rush["anytime_td_rush"] == 1
+    assert rush["anytime_td_rec"] == 0
+    assert rush["anytime_td_pass_thrown"] == 0
+    assert rush["td_count_offense"] == 1
+    assert rush["td_count_all"] == 1
+    assert rush["anytime_td"] == rush["anytime_td_offense"]
+
+    rec = _lookup(result, "rec")
+    assert rec["anytime_td_offense"] == 1
+    assert rec["anytime_td_rec"] == 1
+    assert rec["anytime_td_rush"] == 0
+
+    passer = _lookup(result, "pass")
+    assert passer["anytime_td_pass_thrown"] == 1
+    assert passer["anytime_td_offense"] == 1
+    assert passer["anytime_td_all"] == 1  # includes offensive TDs
+
+    defensive = _lookup(result, "def")
+    assert defensive["anytime_td_offense"] == 0  # no offensive scoring events
+    assert defensive["anytime_td_all"] == 1  # credited via generic touchdown
+    assert defensive["anytime_td"] == defensive["anytime_td_offense"]
+
+
+def test_label_version_any_all_aliases_anytime_td():
+    spec = get_label_spec("v1_any_all")
+    assert spec.primary == "anytime_td_all"
+
+    df = pl.DataFrame(
+        {
+            "player_id": ["all"],
+            "game_id": ["g1"],
+            "rushing_td_count": [0],
+            "receiving_td_count": [0],
+            "passing_td": [0],
+            "touchdowns": [1],
+        }
+    )
+    result = compute_td_labels(df, version="v1_any_all")
+    row = _lookup(result, "all")
+    # Alias ensures legacy anytime_td follows the version's primary definition.
+    assert row["anytime_td_all"] == 1
+    assert row["anytime_td"] == row["anytime_td_all"]
diff --git a/utils/feature/labels.py b/utils/feature/labels.py
new file mode 100644
index 0000000000000000000000000000000000000000..e5e5114da792e3c3558189e03b04f4ab2f69a4f5
--- /dev/null
+++ b/utils/feature/labels.py
@@ -0,0 +1,173 @@
+"""Label semantics and versioning for NFL player-level targets.
+
+This module centralizes anytime-TD label definitions so that:
+- Semantics are explicit and versioned.
+- Training can request a specific label column per problem.
+- Feature generation can emit multiple label variants for analysis.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass, field
+from typing import Dict, Iterable, Mapping
+
+import polars as pl
+
+
+@dataclass(frozen=True)
+class LabelRules:
+    """Rules controlling which TD components count toward a label."""
+
+    include_rush: bool = True
+    include_rec: bool = True
+    include_pass_thrown: bool = True  # credit passers for thrown TDs
+    include_other: bool = False  # fumble returns, defensive/special teams if present
+
+
+@dataclass(frozen=True)
+class LabelSpec:
+    """Container describing a label version."""
+
+    name: str
+    primary: str
+    labels: Mapping[str, LabelRules]
+    aliases: Mapping[str, str] = field(default_factory=dict)
+
+    @property
+    def all_columns(self) -> set[str]:
+        cols = set(self.labels.keys())
+        cols.update(self.aliases.keys())
+        return cols
+
+
+DEFAULT_LABEL_VERSION = "v1_any_offense"
+
+
+LABEL_VERSIONS: Dict[str, LabelSpec] = {
+    "v1_any_offense": LabelSpec(
+        name="v1_any_offense",
+        primary="anytime_td_offense",
+        labels={
+            "anytime_td_offense": LabelRules(include_other=False),
+            "anytime_td_rush": LabelRules(include_rush=True, include_rec=False, include_pass_thrown=False, include_other=False),
+            "anytime_td_rec": LabelRules(include_rush=False, include_rec=True, include_pass_thrown=False, include_other=False),
+            "anytime_td_pass_thrown": LabelRules(include_rush=False, include_rec=False, include_pass_thrown=True, include_other=False),
+            "anytime_td_all": LabelRules(include_other=True),
+        },
+        aliases={
+            # Maintain legacy column name as an alias to the offense-only label.
+            "anytime_td": "anytime_td_offense",
+            # Keep td_count pointing to the offense definition for backward compatibility.
+            "td_count": "td_count_offense",
+        },
+    ),
+    "v1_any_all": LabelSpec(
+        name="v1_any_all",
+        primary="anytime_td_all",
+        labels={
+            "anytime_td_all": LabelRules(include_other=True),
+            "anytime_td_offense": LabelRules(include_other=False),
+            "anytime_td_rush": LabelRules(include_rush=True, include_rec=False, include_pass_thrown=False, include_other=False),
+            "anytime_td_rec": LabelRules(include_rush=False, include_rec=True, include_pass_thrown=False, include_other=False),
+            "anytime_td_pass_thrown": LabelRules(include_rush=False, include_rec=False, include_pass_thrown=True, include_other=False),
+        },
+        aliases={
+            "anytime_td": "anytime_td_all",
+            "td_count": "td_count_all",
+        },
+    ),
+}
+
+
+def get_label_spec(version: str | None) -> LabelSpec:
+    """Return a concrete LabelSpec for the requested version (or default)."""
+
+    version = version or DEFAULT_LABEL_VERSION
+    if version not in LABEL_VERSIONS:
+        raise ValueError(
+            f"Unknown label_version '{version}'. "
+            f"Available: {sorted(LABEL_VERSIONS.keys())}"
+        )
+    return LABEL_VERSIONS[version]
+
+
+def _sum_expr(exprs: Iterable[pl.Expr]) -> pl.Expr:
+    exprs = list(exprs)
+    if not exprs:
+        return pl.lit(0).cast(pl.Int64)
+    acc = exprs[0]
+    for expr in exprs[1:]:
+        acc = acc + expr
+    return acc
+
+
+def compute_td_labels(df: pl.DataFrame, *, version: str | None = None) -> pl.DataFrame:
+    """Compute TD label columns according to a label version.
+
+    Parameters
+    ----------
+    df : pl.DataFrame
+        Player-game frame containing touchdown components.
+    version : str | None
+        Label version identifier. Defaults to DEFAULT_LABEL_VERSION.
+    """
+
+    spec = get_label_spec(version)
+    required_cols = ["rushing_td_count", "receiving_td_count", "passing_td", "touchdowns"]
+    missing = [col for col in required_cols if col not in df.columns]
+    if missing:
+        df = df.with_columns([pl.lit(0).cast(pl.Int64).alias(col) for col in missing])
+    rush = pl.col("rushing_td_count").fill_null(0).cast(pl.Int64)
+    rec = pl.col("receiving_td_count").fill_null(0).cast(pl.Int64)
+    passing = pl.col("passing_td").fill_null(0).cast(pl.Int64)
+    reported_total = pl.col("touchdowns").fill_null(0).cast(pl.Int64)
+
+    offense_total = _sum_expr([rush, rec, passing]).alias("_td_offense_total")
+    other_total = (reported_total - offense_total).clip_min(0).alias("_td_other_total")
+    all_total = (offense_total + other_total).alias("_td_all_total")
+
+    totals_exprs = [
+        offense_total,
+        other_total,
+        all_total,
+    ]
+
+    label_exprs: list[pl.Expr] = [
+        pl.col("_td_offense_total").alias("td_count_offense"),
+        pl.col("_td_all_total").alias("td_count_all"),
+    ]
+
+    for label_name, rules in spec.labels.items():
+        parts: list[pl.Expr] = []
+        if rules.include_rush:
+            parts.append(rush)
+        if rules.include_rec:
+            parts.append(rec)
+        if rules.include_pass_thrown:
+            parts.append(passing)
+        if rules.include_other:
+            parts.append(pl.col("_td_other_total"))
+        total_expr = _sum_expr(parts)
+        label_exprs.append((total_expr > 0).cast(pl.Int8).alias(label_name))
+
+    # Canonical counts for compatibility
+    if "td_count" not in df.columns:
+        # Fill td_count using the alias mapping; default to offense count.
+        target_alias = spec.aliases.get("td_count") or "td_count_offense"
+        label_exprs.append(pl.col(target_alias).alias("td_count"))
+
+    df = df.with_columns(totals_exprs).with_columns(label_exprs)
+
+    # Resolve aliases (e.g., anytime_td -> anytime_td_offense)
+    if spec.aliases:
+        alias_exprs = []
+        for alias_name, source_name in spec.aliases.items():
+            if source_name in df.columns:
+                alias_exprs.append(pl.col(source_name).alias(alias_name))
+        if alias_exprs:
+            df = df.with_columns(alias_exprs)
+
+    drop_cols = [col for col in ("_td_offense_total", "_td_other_total", "_td_all_total") if col in df.columns]
+    if drop_cols:
+        df = df.drop(drop_cols)
+    return df
diff --git a/utils/feature/player_game_level.py b/utils/feature/player_game_level.py
index b6fe516c5f03d575038eef554d5ab39ea5d5c90d..dd4f1f7fcc9de4d8c63390f0a160005eeae48e2f
--- a/utils/feature/player_game_level.py
+++ b/utils/feature/player_game_level.py
@@ -4,8 +4,12 @@
 Each player gets one row per game with their total stats.
 
 Target columns created:
-- anytime_td (binary): Did player score a TD (receiving or rushing)?
-- td_count (int): Number of TDs scored (receiving + rushing)
+- anytime_td_offense (binary): Did player score an offensive TD (rush/rec/pass thrown)?
+- anytime_td_all (binary): Did player score any TD (including defensive/special teams if present)?
+- anytime_td_rush / anytime_td_rec / anytime_td_pass_thrown: Type-specific TD flags.
+- anytime_td (binary): Legacy alias → current label version primary.
+- td_count_offense / td_count_all: TD counts aligned to label semantics.
+- td_count (int): Legacy alias for the primary td_count.
 - passing_td (int): Number of passing TDs (for QBs)
 - receiving_yards (float): Total receiving yards
 - rushing_yards (float): Total rushing yards
@@ -33,6 +37,7 @@
 from utils.collect.nfl_schedules import get_schedule
 from utils.feature.asof import decision_cutoff_hours_default, fallback_cutoff_hours, get_decision_cutoff_hours, get_fallback_cutoff_hours
 from utils.feature.player_drive_level import _load_play_level_data
+from utils.feature.labels import DEFAULT_LABEL_VERSION, compute_td_labels
 from utils.train.injury_availability import (
     load_latest_artifact,
     predict_probabilities as predict_injury_probabilities,
@@ -1582,7 +1587,12 @@
     if flag_cols:
         df = df.with_columns([pl.col(col).cast(pl.Int8) for col in flag_cols])
     return df
-def build_player_game_level(*, start_date: date, end_date: date) -> None:
+def build_player_game_level(
+    *,
+    start_date: date,
+    end_date: date,
+    label_version: str | None = None,
+) -> None:
     """Aggregate play-level data to player-game level.
     
     Creates one row per (player, game) with accumulated stats.
@@ -1680,7 +1690,7 @@
     
     # Merge rows where same player had multiple roles in same game
     # (e.g., QB who also rushed, WR who also rushed)
-    df_merged = _merge_multi_role_players(df_all)
+    df_merged = _merge_multi_role_players(df_all, label_version=label_version or DEFAULT_LABEL_VERSION)
 
     df_merged = _append_zero_usage_players(df_merged, seasons_in_window)
     
@@ -3368,7 +3378,7 @@
     )
 
 
-def _merge_multi_role_players(df: pl.DataFrame) -> pl.DataFrame:
+def _merge_multi_role_players(df: pl.DataFrame, *, label_version: str | None = None) -> pl.DataFrame:
     """Merge stats for players who had multiple roles in same game.
     
     Example: QB who passed and rushed, WR who received and rushed.
@@ -3422,8 +3432,6 @@
         if col in merged.columns:
             merged = merged.with_columns(pl.col(col).fill_null(0))
 
-    # Fallback touchdown logic: if generic touchdown attribution is missing,
-    # derive it from rushing + receiving touchdowns.
     merged = merged.with_columns([
         pl.col("touchdowns").fill_null(0).alias("touchdowns"),
         pl.col("rushing_td_count").fill_null(0).alias("rushing_td_count"),
@@ -3435,17 +3443,5 @@
         pl.col("goal_to_go_carry").fill_null(0).alias("goal_to_go_carry"),
     ])
 
-    merged = merged.with_columns([
-        pl.when(pl.col("touchdowns") > 0)
-        .then(pl.col("touchdowns"))
-        .otherwise(pl.col("rushing_td_count") + pl.col("receiving_td_count"))
-        .cast(pl.Int64)
-        .alias("_total_touchdowns")
-    ])
-
-    merged = merged.with_columns([
-        (pl.col("_total_touchdowns") > 0).cast(pl.Int8).alias("anytime_td"),
-        pl.col("_total_touchdowns").alias("td_count"),
-    ]).drop("_total_touchdowns")
-    
+    merged = compute_td_labels(merged, version=label_version)
     return merged
diff --git a/utils/feature/targets.py b/utils/feature/targets.py
index 7738086dcbfda7432b937cc7d8095988cb0edff0..769ee8735c4024c4410ddd674b11112f093624dd
--- a/utils/feature/targets.py
+++ b/utils/feature/targets.py
@@ -7,6 +7,8 @@
 import polars as pl
 import logging
 
+from utils.feature.labels import DEFAULT_LABEL_VERSION, get_label_spec
+
 logger = logging.getLogger(__name__)
 
 
@@ -14,9 +16,16 @@
 NFL_TARGET_SCHEMA = {
     # Binary classification targets
     "anytime_td": pl.Int8,  # Primary MVP target: did player score a TD?
+    "anytime_td_offense": pl.Int8,
+    "anytime_td_all": pl.Int8,
+    "anytime_td_rush": pl.Int8,
+    "anytime_td_rec": pl.Int8,
+    "anytime_td_pass_thrown": pl.Int8,
     
     # Count/regression targets
     "td_count": pl.Int64,  # Number of TDs scored (receiving + rushing)
+    "td_count_offense": pl.Int64,
+    "td_count_all": pl.Int64,
     "passing_td": pl.Int64,  # Number of passing TDs (QB only)
     
     # Yardage regression targets
@@ -103,4 +112,40 @@
     pl.DataFrame
         DataFrame with validated target columns
     """
-    return validate_target_columns(df, strict=False)
\ No newline at end of file
+    return validate_target_columns(df, strict=False)
+
+
+def require_target_column(
+    df: pl.DataFrame,
+    target_col: str,
+    *,
+    label_version: str | None = None,
+    min_non_null: int = 1,
+) -> pl.DataFrame:
+    """Ensure the configured target column exists and is populated.
+
+    Raises a ValueError if the column is missing or entirely null.
+    """
+
+    if target_col not in df.columns:
+        alias_hint = ""
+        if label_version:
+            try:
+                spec = get_label_spec(label_version or DEFAULT_LABEL_VERSION)
+                if target_col in spec.aliases:
+                    alias_hint = f" Target maps to '{spec.aliases[target_col]}' under {spec.name}."
+            except Exception:
+                alias_hint = ""
+        raise ValueError(f"Target column '{target_col}' not found in feature frame.{alias_hint}")
+
+    series = df[target_col]
+    non_null = series.drop_nulls().height
+    if non_null < min_non_null:
+        raise ValueError(
+            f"Target column '{target_col}' has insufficient non-null rows "
+            f"({non_null}/{len(series)})."
+        )
+    nulls = len(series) - non_null
+    if nulls > 0:
+        logger.warning("Target %s contains %d null rows; they will be dropped.", target_col, nulls)
+    return df


thinking
**Checking call sites for signature changes**
exec
/bin/zsh -lc "cd /Users/jameswest/Desktop/nfl_predict && rg \"build_player_game_level\\(\"" in /Users/jameswest/Desktop/nfl_predict succeeded in 855ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
pipeline/feature.py:            build_player_game_level(start_date=cur, end_date=chunk_end, label_version=label_version)
utils/feature/player_game_level.py:def build_player_game_level(
file update:
diff --git a/config/training.yaml b/config/training.yaml
index 3055a636b89249119408aaad970d3025956877db..3953818d861d0410246bff132110722a3ce44007
--- a/config/training.yaml
+++ b/config/training.yaml
@@ -475,6 +475,7 @@
   # Calibrated probability of scoring > 0 TDs.
   - name: 'anytime_td'
     target_col: 'anytime_td'
+    label_version: 'v1_any_offense'
     task_type: 'classification'
     input_predictions:
       - 'availability_active'
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 6c47a91d08f9d309f94323efd4708bb992dc4ce0..5ba68e8bf1acd3a789a76a8857674e6f6433017b
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -26,6 +26,7 @@
 from utils.feature.player_drive_level import build_player_drive_level
 from utils.feature.player_game_level import build_player_game_level
 from utils.feature.opponent_splits import build_opponent_splits
+from utils.feature.labels import DEFAULT_LABEL_VERSION, get_label_spec
 from utils.feature.targets import validate_target_columns
 from utils.feature.daily_totals import build_daily_cache_range
 from utils.feature.rolling_window import add_rolling_features
@@ -233,6 +234,7 @@
     output_path: Path | None = None,
     primary_output_path: Path | None = None,
     cutoff_label: str | None = None,
+    label_version: str | None = None,
 ) -> pl.DataFrame:
     """Run full feature pipeline up to *inclusive* `end_date` for a single cutoff window.
 
@@ -248,6 +250,7 @@
     primary_output = primary_output_path or target_output_path
     current_cutoff_hours = float(get_decision_cutoff_hours())
     clean_min_date, clean_max_date = (None, None)
+    label_version = label_version or DEFAULT_LABEL_VERSION
     if start_date is None or end_date is None:
         clean_min_date, clean_max_date = _get_clean_date_bounds()
 
@@ -294,7 +297,7 @@
             build_player_drive_level(start_date=cur, end_date=chunk_end)
             
             # 5. Player-game aggregations (for rolling window features)
-            build_player_game_level(start_date=cur, end_date=chunk_end)
+            build_player_game_level(start_date=cur, end_date=chunk_end, label_version=label_version)
 
             # advance to next slice
             cur += timedelta(days=chunk_days)
@@ -948,11 +951,19 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    # Log target distribution for anytime_td
-    if "anytime_td" in df_player_game_all.columns:
-        td_count = df_player_game_all["anytime_td"].sum()
-        td_rate = td_count / len(df_player_game_all) * 100
-        logging.info("    Anytime TD rate: %.2f%% (%d/%d)", td_rate, td_count, len(df_player_game_all))
+    spec = get_label_spec(label_version)
+    label_candidates = {spec.primary, "anytime_td"}
+    for label_col in label_candidates:
+        if label_col in df_player_game_all.columns:
+            td_count = df_player_game_all[label_col].sum()
+            td_rate = td_count / len(df_player_game_all) * 100
+            logging.info(
+                "    Label %s rate: %.2f%% (%d/%d)",
+                label_col,
+                td_rate,
+                td_count,
+                len(df_player_game_all),
+            )
     
     return df_player_game_all
 
@@ -965,6 +976,7 @@
     recompute_intermediate: bool = True,
     build_rolling: bool = True,
     cutoff_hours_list: Sequence[float] | None = None,
+    label_version: str | None = None,
 ) -> pl.DataFrame:
     """Build feature matrices for one or more decision cutoff horizons.
 
@@ -992,6 +1004,7 @@
                 output_path=output_path,
                 primary_output_path=primary_output,
                 cutoff_label=label,
+                label_version=label_version,
             )
         if idx == 0:
             primary_result = df
diff --git a/pipeline/train.py b/pipeline/train.py
index 265bc29f4861d2d4d26f54fd7f77304de8fe6742..fe70207dcdf25d209ee3ad55080b7ce826347c44
--- a/pipeline/train.py
+++ b/pipeline/train.py
@@ -98,6 +98,7 @@
     fit_team_conformal_sums,
     composite_sum_interval,
 )
+from utils.feature.targets import require_target_column
 
 # Ignore specific, noisy warnings from dependencies
 warnings.filterwarnings(
@@ -259,6 +260,7 @@
 
         # Per-problem attributes initialised later
         self.target_col = None
+        self.label_version = None
         self.feature_columns = None
 
         self.models = {}
@@ -2163,6 +2165,7 @@
             
             problem_copy = copy.deepcopy(problem)
             self.target_col = problem_copy['target_col']
+            self.label_version = problem_copy.get('label_version') or problem_copy.get("labels", {}).get("version")
             derived_cfg = problem_copy.get('derived_target')
             target_load_cols: list[str] = []
             if derived_cfg:
@@ -2269,6 +2272,12 @@
                 df_problem = df_problem.loc[:, ~df_problem.columns.duplicated()]
 
             df_problem = self._apply_problem_level_overrides(df_problem, problem_copy)
+            df_problem = require_target_column(
+                df_problem,
+                self.target_col,
+                label_version=self.label_version,
+                min_non_null=1,
+            )
             
             # Merge input predictions if required
             if input_preds:
diff --git a/tests/labels/test_labels.py b/tests/labels/test_labels.py
new file mode 100644
index 0000000000000000000000000000000000000000..71743f35f8a9ff386afeaa8a346bdf150f7b9164
--- /dev/null
+++ b/tests/labels/test_labels.py
@@ -0,0 +1,68 @@
+import polars as pl
+
+from utils.feature.labels import compute_td_labels, get_label_spec
+
+
+def _lookup(frame: pl.DataFrame, player_id: str) -> dict:
+    return frame.filter(pl.col("player_id") == player_id).to_dicts()[0]
+
+
+def test_compute_td_labels_offense_and_all_variants():
+    df = pl.DataFrame(
+        {
+            "player_id": ["rush", "rec", "pass", "def"],
+            "game_id": ["g1"] * 4,
+            "rushing_td_count": [1, 0, 0, 0],
+            "receiving_td_count": [0, 1, 0, 0],
+            "passing_td": [0, 0, 1, 0],
+            # Generic touchdown attribution (e.g., defensive return)
+            "touchdowns": [1, 1, 0, 1],
+        }
+    )
+
+    result = compute_td_labels(df, version="v1_any_offense")
+
+    rush = _lookup(result, "rush")
+    assert rush["anytime_td_offense"] == 1
+    assert rush["anytime_td_rush"] == 1
+    assert rush["anytime_td_rec"] == 0
+    assert rush["anytime_td_pass_thrown"] == 0
+    assert rush["td_count_offense"] == 1
+    assert rush["td_count_all"] == 1
+    assert rush["anytime_td"] == rush["anytime_td_offense"]
+
+    rec = _lookup(result, "rec")
+    assert rec["anytime_td_offense"] == 1
+    assert rec["anytime_td_rec"] == 1
+    assert rec["anytime_td_rush"] == 0
+
+    passer = _lookup(result, "pass")
+    assert passer["anytime_td_pass_thrown"] == 1
+    assert passer["anytime_td_offense"] == 1
+    assert passer["anytime_td_all"] == 1  # includes offensive TDs
+
+    defensive = _lookup(result, "def")
+    assert defensive["anytime_td_offense"] == 0  # no offensive scoring events
+    assert defensive["anytime_td_all"] == 1  # credited via generic touchdown
+    assert defensive["anytime_td"] == defensive["anytime_td_offense"]
+
+
+def test_label_version_any_all_aliases_anytime_td():
+    spec = get_label_spec("v1_any_all")
+    assert spec.primary == "anytime_td_all"
+
+    df = pl.DataFrame(
+        {
+            "player_id": ["all"],
+            "game_id": ["g1"],
+            "rushing_td_count": [0],
+            "receiving_td_count": [0],
+            "passing_td": [0],
+            "touchdowns": [1],
+        }
+    )
+    result = compute_td_labels(df, version="v1_any_all")
+    row = _lookup(result, "all")
+    # Alias ensures legacy anytime_td follows the version's primary definition.
+    assert row["anytime_td_all"] == 1
+    assert row["anytime_td"] == row["anytime_td_all"]
diff --git a/utils/feature/labels.py b/utils/feature/labels.py
new file mode 100644
index 0000000000000000000000000000000000000000..e5e5114da792e3c3558189e03b04f4ab2f69a4f5
--- /dev/null
+++ b/utils/feature/labels.py
@@ -0,0 +1,173 @@
+"""Label semantics and versioning for NFL player-level targets.
+
+This module centralizes anytime-TD label definitions so that:
+- Semantics are explicit and versioned.
+- Training can request a specific label column per problem.
+- Feature generation can emit multiple label variants for analysis.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass, field
+from typing import Dict, Iterable, Mapping
+
+import polars as pl
+
+
+@dataclass(frozen=True)
+class LabelRules:
+    """Rules controlling which TD components count toward a label."""
+
+    include_rush: bool = True
+    include_rec: bool = True
+    include_pass_thrown: bool = True  # credit passers for thrown TDs
+    include_other: bool = False  # fumble returns, defensive/special teams if present
+
+
+@dataclass(frozen=True)
+class LabelSpec:
+    """Container describing a label version."""
+
+    name: str
+    primary: str
+    labels: Mapping[str, LabelRules]
+    aliases: Mapping[str, str] = field(default_factory=dict)
+
+    @property
+    def all_columns(self) -> set[str]:
+        cols = set(self.labels.keys())
+        cols.update(self.aliases.keys())
+        return cols
+
+
+DEFAULT_LABEL_VERSION = "v1_any_offense"
+
+
+LABEL_VERSIONS: Dict[str, LabelSpec] = {
+    "v1_any_offense": LabelSpec(
+        name="v1_any_offense",
+        primary="anytime_td_offense",
+        labels={
+            "anytime_td_offense": LabelRules(include_other=False),
+            "anytime_td_rush": LabelRules(include_rush=True, include_rec=False, include_pass_thrown=False, include_other=False),
+            "anytime_td_rec": LabelRules(include_rush=False, include_rec=True, include_pass_thrown=False, include_other=False),
+            "anytime_td_pass_thrown": LabelRules(include_rush=False, include_rec=False, include_pass_thrown=True, include_other=False),
+            "anytime_td_all": LabelRules(include_other=True),
+        },
+        aliases={
+            # Maintain legacy column name as an alias to the offense-only label.
+            "anytime_td": "anytime_td_offense",
+            # Keep td_count pointing to the offense definition for backward compatibility.
+            "td_count": "td_count_offense",
+        },
+    ),
+    "v1_any_all": LabelSpec(
+        name="v1_any_all",
+        primary="anytime_td_all",
+        labels={
+            "anytime_td_all": LabelRules(include_other=True),
+            "anytime_td_offense": LabelRules(include_other=False),
+            "anytime_td_rush": LabelRules(include_rush=True, include_rec=False, include_pass_thrown=False, include_other=False),
+            "anytime_td_rec": LabelRules(include_rush=False, include_rec=True, include_pass_thrown=False, include_other=False),
+            "anytime_td_pass_thrown": LabelRules(include_rush=False, include_rec=False, include_pass_thrown=True, include_other=False),
+        },
+        aliases={
+            "anytime_td": "anytime_td_all",
+            "td_count": "td_count_all",
+        },
+    ),
+}
+
+
+def get_label_spec(version: str | None) -> LabelSpec:
+    """Return a concrete LabelSpec for the requested version (or default)."""
+
+    version = version or DEFAULT_LABEL_VERSION
+    if version not in LABEL_VERSIONS:
+        raise ValueError(
+            f"Unknown label_version '{version}'. "
+            f"Available: {sorted(LABEL_VERSIONS.keys())}"
+        )
+    return LABEL_VERSIONS[version]
+
+
+def _sum_expr(exprs: Iterable[pl.Expr]) -> pl.Expr:
+    exprs = list(exprs)
+    if not exprs:
+        return pl.lit(0).cast(pl.Int64)
+    acc = exprs[0]
+    for expr in exprs[1:]:
+        acc = acc + expr
+    return acc
+
+
+def compute_td_labels(df: pl.DataFrame, *, version: str | None = None) -> pl.DataFrame:
+    """Compute TD label columns according to a label version.
+
+    Parameters
+    ----------
+    df : pl.DataFrame
+        Player-game frame containing touchdown components.
+    version : str | None
+        Label version identifier. Defaults to DEFAULT_LABEL_VERSION.
+    """
+
+    spec = get_label_spec(version)
+    required_cols = ["rushing_td_count", "receiving_td_count", "passing_td", "touchdowns"]
+    missing = [col for col in required_cols if col not in df.columns]
+    if missing:
+        df = df.with_columns([pl.lit(0).cast(pl.Int64).alias(col) for col in missing])
+    rush = pl.col("rushing_td_count").fill_null(0).cast(pl.Int64)
+    rec = pl.col("receiving_td_count").fill_null(0).cast(pl.Int64)
+    passing = pl.col("passing_td").fill_null(0).cast(pl.Int64)
+    reported_total = pl.col("touchdowns").fill_null(0).cast(pl.Int64)
+
+    offense_total = _sum_expr([rush, rec, passing]).alias("_td_offense_total")
+    other_total = (reported_total - offense_total).clip_min(0).alias("_td_other_total")
+    all_total = (offense_total + other_total).alias("_td_all_total")
+
+    totals_exprs = [
+        offense_total,
+        other_total,
+        all_total,
+    ]
+
+    label_exprs: list[pl.Expr] = [
+        pl.col("_td_offense_total").alias("td_count_offense"),
+        pl.col("_td_all_total").alias("td_count_all"),
+    ]
+
+    for label_name, rules in spec.labels.items():
+        parts: list[pl.Expr] = []
+        if rules.include_rush:
+            parts.append(rush)
+        if rules.include_rec:
+            parts.append(rec)
+        if rules.include_pass_thrown:
+            parts.append(passing)
+        if rules.include_other:
+            parts.append(pl.col("_td_other_total"))
+        total_expr = _sum_expr(parts)
+        label_exprs.append((total_expr > 0).cast(pl.Int8).alias(label_name))
+
+    # Canonical counts for compatibility
+    if "td_count" not in df.columns:
+        # Fill td_count using the alias mapping; default to offense count.
+        target_alias = spec.aliases.get("td_count") or "td_count_offense"
+        label_exprs.append(pl.col(target_alias).alias("td_count"))
+
+    df = df.with_columns(totals_exprs).with_columns(label_exprs)
+
+    # Resolve aliases (e.g., anytime_td -> anytime_td_offense)
+    if spec.aliases:
+        alias_exprs = []
+        for alias_name, source_name in spec.aliases.items():
+            if source_name in df.columns:
+                alias_exprs.append(pl.col(source_name).alias(alias_name))
+        if alias_exprs:
+            df = df.with_columns(alias_exprs)
+
+    drop_cols = [col for col in ("_td_offense_total", "_td_other_total", "_td_all_total") if col in df.columns]
+    if drop_cols:
+        df = df.drop(drop_cols)
+    return df
diff --git a/utils/feature/player_game_level.py b/utils/feature/player_game_level.py
index b6fe516c5f03d575038eef554d5ab39ea5d5c90d..dd4f1f7fcc9de4d8c63390f0a160005eeae48e2f
--- a/utils/feature/player_game_level.py
+++ b/utils/feature/player_game_level.py
@@ -4,8 +4,12 @@
 Each player gets one row per game with their total stats.
 
 Target columns created:
-- anytime_td (binary): Did player score a TD (receiving or rushing)?
-- td_count (int): Number of TDs scored (receiving + rushing)
+- anytime_td_offense (binary): Did player score an offensive TD (rush/rec/pass thrown)?
+- anytime_td_all (binary): Did player score any TD (including defensive/special teams if present)?
+- anytime_td_rush / anytime_td_rec / anytime_td_pass_thrown: Type-specific TD flags.
+- anytime_td (binary): Legacy alias → current label version primary.
+- td_count_offense / td_count_all: TD counts aligned to label semantics.
+- td_count (int): Legacy alias for the primary td_count.
 - passing_td (int): Number of passing TDs (for QBs)
 - receiving_yards (float): Total receiving yards
 - rushing_yards (float): Total rushing yards
@@ -33,6 +37,7 @@
 from utils.collect.nfl_schedules import get_schedule
 from utils.feature.asof import decision_cutoff_hours_default, fallback_cutoff_hours, get_decision_cutoff_hours, get_fallback_cutoff_hours
 from utils.feature.player_drive_level import _load_play_level_data
+from utils.feature.labels import DEFAULT_LABEL_VERSION, compute_td_labels
 from utils.train.injury_availability import (
     load_latest_artifact,
     predict_probabilities as predict_injury_probabilities,
@@ -1582,7 +1587,12 @@
     if flag_cols:
         df = df.with_columns([pl.col(col).cast(pl.Int8) for col in flag_cols])
     return df
-def build_player_game_level(*, start_date: date, end_date: date) -> None:
+def build_player_game_level(
+    *,
+    start_date: date,
+    end_date: date,
+    label_version: str | None = None,
+) -> None:
     """Aggregate play-level data to player-game level.
     
     Creates one row per (player, game) with accumulated stats.
@@ -1680,7 +1690,7 @@
     
     # Merge rows where same player had multiple roles in same game
     # (e.g., QB who also rushed, WR who also rushed)
-    df_merged = _merge_multi_role_players(df_all)
+    df_merged = _merge_multi_role_players(df_all, label_version=label_version or DEFAULT_LABEL_VERSION)
 
     df_merged = _append_zero_usage_players(df_merged, seasons_in_window)
     
@@ -3368,7 +3378,7 @@
     )
 
 
-def _merge_multi_role_players(df: pl.DataFrame) -> pl.DataFrame:
+def _merge_multi_role_players(df: pl.DataFrame, *, label_version: str | None = None) -> pl.DataFrame:
     """Merge stats for players who had multiple roles in same game.
     
     Example: QB who passed and rushed, WR who received and rushed.
@@ -3422,8 +3432,6 @@
         if col in merged.columns:
             merged = merged.with_columns(pl.col(col).fill_null(0))
 
-    # Fallback touchdown logic: if generic touchdown attribution is missing,
-    # derive it from rushing + receiving touchdowns.
     merged = merged.with_columns([
         pl.col("touchdowns").fill_null(0).alias("touchdowns"),
         pl.col("rushing_td_count").fill_null(0).alias("rushing_td_count"),
@@ -3435,17 +3443,5 @@
         pl.col("goal_to_go_carry").fill_null(0).alias("goal_to_go_carry"),
     ])
 
-    merged = merged.with_columns([
-        pl.when(pl.col("touchdowns") > 0)
-        .then(pl.col("touchdowns"))
-        .otherwise(pl.col("rushing_td_count") + pl.col("receiving_td_count"))
-        .cast(pl.Int64)
-        .alias("_total_touchdowns")
-    ])
-
-    merged = merged.with_columns([
-        (pl.col("_total_touchdowns") > 0).cast(pl.Int8).alias("anytime_td"),
-        pl.col("_total_touchdowns").alias("td_count"),
-    ]).drop("_total_touchdowns")
-    
+    merged = compute_td_labels(merged, version=label_version)
     return merged
diff --git a/utils/feature/targets.py b/utils/feature/targets.py
index 7738086dcbfda7432b937cc7d8095988cb0edff0..769ee8735c4024c4410ddd674b11112f093624dd
--- a/utils/feature/targets.py
+++ b/utils/feature/targets.py
@@ -7,6 +7,8 @@
 import polars as pl
 import logging
 
+from utils.feature.labels import DEFAULT_LABEL_VERSION, get_label_spec
+
 logger = logging.getLogger(__name__)
 
 
@@ -14,9 +16,16 @@
 NFL_TARGET_SCHEMA = {
     # Binary classification targets
     "anytime_td": pl.Int8,  # Primary MVP target: did player score a TD?
+    "anytime_td_offense": pl.Int8,
+    "anytime_td_all": pl.Int8,
+    "anytime_td_rush": pl.Int8,
+    "anytime_td_rec": pl.Int8,
+    "anytime_td_pass_thrown": pl.Int8,
     
     # Count/regression targets
     "td_count": pl.Int64,  # Number of TDs scored (receiving + rushing)
+    "td_count_offense": pl.Int64,
+    "td_count_all": pl.Int64,
     "passing_td": pl.Int64,  # Number of passing TDs (QB only)
     
     # Yardage regression targets
@@ -103,4 +112,40 @@
     pl.DataFrame
         DataFrame with validated target columns
     """
-    return validate_target_columns(df, strict=False)
\ No newline at end of file
+    return validate_target_columns(df, strict=False)
+
+
+def require_target_column(
+    df: pl.DataFrame,
+    target_col: str,
+    *,
+    label_version: str | None = None,
+    min_non_null: int = 1,
+) -> pl.DataFrame:
+    """Ensure the configured target column exists and is populated.
+
+    Raises a ValueError if the column is missing or entirely null.
+    """
+
+    if target_col not in df.columns:
+        alias_hint = ""
+        if label_version:
+            try:
+                spec = get_label_spec(label_version or DEFAULT_LABEL_VERSION)
+                if target_col in spec.aliases:
+                    alias_hint = f" Target maps to '{spec.aliases[target_col]}' under {spec.name}."
+            except Exception:
+                alias_hint = ""
+        raise ValueError(f"Target column '{target_col}' not found in feature frame.{alias_hint}")
+
+    series = df[target_col]
+    non_null = series.drop_nulls().height
+    if non_null < min_non_null:
+        raise ValueError(
+            f"Target column '{target_col}' has insufficient non-null rows "
+            f"({non_null}/{len(series)})."
+        )
+    nulls = len(series) - non_null
+    if nulls > 0:
+        logger.warning("Target %s contains %d null rows; they will be dropped.", target_col, nulls)
+    return df


thinking
**Verifying label updates and running tests**
exec
/bin/zsh -lc 'cd /Users/jameswest/Desktop/nfl_predict && pytest tests/labels/test_labels.py -q' in /Users/jameswest/Desktop/nfl_predict exited 127 in 742ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
zsh:1: command not found: pytest
file update:
diff --git a/config/training.yaml b/config/training.yaml
index 3055a636b89249119408aaad970d3025956877db..3953818d861d0410246bff132110722a3ce44007
--- a/config/training.yaml
+++ b/config/training.yaml
@@ -475,6 +475,7 @@
   # Calibrated probability of scoring > 0 TDs.
   - name: 'anytime_td'
     target_col: 'anytime_td'
+    label_version: 'v1_any_offense'
     task_type: 'classification'
     input_predictions:
       - 'availability_active'
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 6c47a91d08f9d309f94323efd4708bb992dc4ce0..5ba68e8bf1acd3a789a76a8857674e6f6433017b
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -26,6 +26,7 @@
 from utils.feature.player_drive_level import build_player_drive_level
 from utils.feature.player_game_level import build_player_game_level
 from utils.feature.opponent_splits import build_opponent_splits
+from utils.feature.labels import DEFAULT_LABEL_VERSION, get_label_spec
 from utils.feature.targets import validate_target_columns
 from utils.feature.daily_totals import build_daily_cache_range
 from utils.feature.rolling_window import add_rolling_features
@@ -233,6 +234,7 @@
     output_path: Path | None = None,
     primary_output_path: Path | None = None,
     cutoff_label: str | None = None,
+    label_version: str | None = None,
 ) -> pl.DataFrame:
     """Run full feature pipeline up to *inclusive* `end_date` for a single cutoff window.
 
@@ -248,6 +250,7 @@
     primary_output = primary_output_path or target_output_path
     current_cutoff_hours = float(get_decision_cutoff_hours())
     clean_min_date, clean_max_date = (None, None)
+    label_version = label_version or DEFAULT_LABEL_VERSION
     if start_date is None or end_date is None:
         clean_min_date, clean_max_date = _get_clean_date_bounds()
 
@@ -294,7 +297,7 @@
             build_player_drive_level(start_date=cur, end_date=chunk_end)
             
             # 5. Player-game aggregations (for rolling window features)
-            build_player_game_level(start_date=cur, end_date=chunk_end)
+            build_player_game_level(start_date=cur, end_date=chunk_end, label_version=label_version)
 
             # advance to next slice
             cur += timedelta(days=chunk_days)
@@ -948,11 +951,19 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    # Log target distribution for anytime_td
-    if "anytime_td" in df_player_game_all.columns:
-        td_count = df_player_game_all["anytime_td"].sum()
-        td_rate = td_count / len(df_player_game_all) * 100
-        logging.info("    Anytime TD rate: %.2f%% (%d/%d)", td_rate, td_count, len(df_player_game_all))
+    spec = get_label_spec(label_version)
+    label_candidates = {spec.primary, "anytime_td"}
+    for label_col in label_candidates:
+        if label_col in df_player_game_all.columns:
+            td_count = df_player_game_all[label_col].sum()
+            td_rate = td_count / len(df_player_game_all) * 100
+            logging.info(
+                "    Label %s rate: %.2f%% (%d/%d)",
+                label_col,
+                td_rate,
+                td_count,
+                len(df_player_game_all),
+            )
     
     return df_player_game_all
 
@@ -965,6 +976,7 @@
     recompute_intermediate: bool = True,
     build_rolling: bool = True,
     cutoff_hours_list: Sequence[float] | None = None,
+    label_version: str | None = None,
 ) -> pl.DataFrame:
     """Build feature matrices for one or more decision cutoff horizons.
 
@@ -992,6 +1004,7 @@
                 output_path=output_path,
                 primary_output_path=primary_output,
                 cutoff_label=label,
+                label_version=label_version,
             )
         if idx == 0:
             primary_result = df
diff --git a/pipeline/train.py b/pipeline/train.py
index 265bc29f4861d2d4d26f54fd7f77304de8fe6742..fe70207dcdf25d209ee3ad55080b7ce826347c44
--- a/pipeline/train.py
+++ b/pipeline/train.py
@@ -98,6 +98,7 @@
     fit_team_conformal_sums,
     composite_sum_interval,
 )
+from utils.feature.targets import require_target_column
 
 # Ignore specific, noisy warnings from dependencies
 warnings.filterwarnings(
@@ -259,6 +260,7 @@
 
         # Per-problem attributes initialised later
         self.target_col = None
+        self.label_version = None
         self.feature_columns = None
 
         self.models = {}
@@ -2163,6 +2165,7 @@
             
             problem_copy = copy.deepcopy(problem)
             self.target_col = problem_copy['target_col']
+            self.label_version = problem_copy.get('label_version') or problem_copy.get("labels", {}).get("version")
             derived_cfg = problem_copy.get('derived_target')
             target_load_cols: list[str] = []
             if derived_cfg:
@@ -2269,6 +2272,12 @@
                 df_problem = df_problem.loc[:, ~df_problem.columns.duplicated()]
 
             df_problem = self._apply_problem_level_overrides(df_problem, problem_copy)
+            df_problem = require_target_column(
+                df_problem,
+                self.target_col,
+                label_version=self.label_version,
+                min_non_null=1,
+            )
             
             # Merge input predictions if required
             if input_preds:
diff --git a/tests/labels/test_labels.py b/tests/labels/test_labels.py
new file mode 100644
index 0000000000000000000000000000000000000000..71743f35f8a9ff386afeaa8a346bdf150f7b9164
--- /dev/null
+++ b/tests/labels/test_labels.py
@@ -0,0 +1,68 @@
+import polars as pl
+
+from utils.feature.labels import compute_td_labels, get_label_spec
+
+
+def _lookup(frame: pl.DataFrame, player_id: str) -> dict:
+    return frame.filter(pl.col("player_id") == player_id).to_dicts()[0]
+
+
+def test_compute_td_labels_offense_and_all_variants():
+    df = pl.DataFrame(
+        {
+            "player_id": ["rush", "rec", "pass", "def"],
+            "game_id": ["g1"] * 4,
+            "rushing_td_count": [1, 0, 0, 0],
+            "receiving_td_count": [0, 1, 0, 0],
+            "passing_td": [0, 0, 1, 0],
+            # Generic touchdown attribution (e.g., defensive return)
+            "touchdowns": [1, 1, 0, 1],
+        }
+    )
+
+    result = compute_td_labels(df, version="v1_any_offense")
+
+    rush = _lookup(result, "rush")
+    assert rush["anytime_td_offense"] == 1
+    assert rush["anytime_td_rush"] == 1
+    assert rush["anytime_td_rec"] == 0
+    assert rush["anytime_td_pass_thrown"] == 0
+    assert rush["td_count_offense"] == 1
+    assert rush["td_count_all"] == 1
+    assert rush["anytime_td"] == rush["anytime_td_offense"]
+
+    rec = _lookup(result, "rec")
+    assert rec["anytime_td_offense"] == 1
+    assert rec["anytime_td_rec"] == 1
+    assert rec["anytime_td_rush"] == 0
+
+    passer = _lookup(result, "pass")
+    assert passer["anytime_td_pass_thrown"] == 1
+    assert passer["anytime_td_offense"] == 1
+    assert passer["anytime_td_all"] == 1  # includes offensive TDs
+
+    defensive = _lookup(result, "def")
+    assert defensive["anytime_td_offense"] == 0  # no offensive scoring events
+    assert defensive["anytime_td_all"] == 1  # credited via generic touchdown
+    assert defensive["anytime_td"] == defensive["anytime_td_offense"]
+
+
+def test_label_version_any_all_aliases_anytime_td():
+    spec = get_label_spec("v1_any_all")
+    assert spec.primary == "anytime_td_all"
+
+    df = pl.DataFrame(
+        {
+            "player_id": ["all"],
+            "game_id": ["g1"],
+            "rushing_td_count": [0],
+            "receiving_td_count": [0],
+            "passing_td": [0],
+            "touchdowns": [1],
+        }
+    )
+    result = compute_td_labels(df, version="v1_any_all")
+    row = _lookup(result, "all")
+    # Alias ensures legacy anytime_td follows the version's primary definition.
+    assert row["anytime_td_all"] == 1
+    assert row["anytime_td"] == row["anytime_td_all"]
diff --git a/utils/feature/labels.py b/utils/feature/labels.py
new file mode 100644
index 0000000000000000000000000000000000000000..e5e5114da792e3c3558189e03b04f4ab2f69a4f5
--- /dev/null
+++ b/utils/feature/labels.py
@@ -0,0 +1,173 @@
+"""Label semantics and versioning for NFL player-level targets.
+
+This module centralizes anytime-TD label definitions so that:
+- Semantics are explicit and versioned.
+- Training can request a specific label column per problem.
+- Feature generation can emit multiple label variants for analysis.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass, field
+from typing import Dict, Iterable, Mapping
+
+import polars as pl
+
+
+@dataclass(frozen=True)
+class LabelRules:
+    """Rules controlling which TD components count toward a label."""
+
+    include_rush: bool = True
+    include_rec: bool = True
+    include_pass_thrown: bool = True  # credit passers for thrown TDs
+    include_other: bool = False  # fumble returns, defensive/special teams if present
+
+
+@dataclass(frozen=True)
+class LabelSpec:
+    """Container describing a label version."""
+
+    name: str
+    primary: str
+    labels: Mapping[str, LabelRules]
+    aliases: Mapping[str, str] = field(default_factory=dict)
+
+    @property
+    def all_columns(self) -> set[str]:
+        cols = set(self.labels.keys())
+        cols.update(self.aliases.keys())
+        return cols
+
+
+DEFAULT_LABEL_VERSION = "v1_any_offense"
+
+
+LABEL_VERSIONS: Dict[str, LabelSpec] = {
+    "v1_any_offense": LabelSpec(
+        name="v1_any_offense",
+        primary="anytime_td_offense",
+        labels={
+            "anytime_td_offense": LabelRules(include_other=False),
+            "anytime_td_rush": LabelRules(include_rush=True, include_rec=False, include_pass_thrown=False, include_other=False),
+            "anytime_td_rec": LabelRules(include_rush=False, include_rec=True, include_pass_thrown=False, include_other=False),
+            "anytime_td_pass_thrown": LabelRules(include_rush=False, include_rec=False, include_pass_thrown=True, include_other=False),
+            "anytime_td_all": LabelRules(include_other=True),
+        },
+        aliases={
+            # Maintain legacy column name as an alias to the offense-only label.
+            "anytime_td": "anytime_td_offense",
+            # Keep td_count pointing to the offense definition for backward compatibility.
+            "td_count": "td_count_offense",
+        },
+    ),
+    "v1_any_all": LabelSpec(
+        name="v1_any_all",
+        primary="anytime_td_all",
+        labels={
+            "anytime_td_all": LabelRules(include_other=True),
+            "anytime_td_offense": LabelRules(include_other=False),
+            "anytime_td_rush": LabelRules(include_rush=True, include_rec=False, include_pass_thrown=False, include_other=False),
+            "anytime_td_rec": LabelRules(include_rush=False, include_rec=True, include_pass_thrown=False, include_other=False),
+            "anytime_td_pass_thrown": LabelRules(include_rush=False, include_rec=False, include_pass_thrown=True, include_other=False),
+        },
+        aliases={
+            "anytime_td": "anytime_td_all",
+            "td_count": "td_count_all",
+        },
+    ),
+}
+
+
+def get_label_spec(version: str | None) -> LabelSpec:
+    """Return a concrete LabelSpec for the requested version (or default)."""
+
+    version = version or DEFAULT_LABEL_VERSION
+    if version not in LABEL_VERSIONS:
+        raise ValueError(
+            f"Unknown label_version '{version}'. "
+            f"Available: {sorted(LABEL_VERSIONS.keys())}"
+        )
+    return LABEL_VERSIONS[version]
+
+
+def _sum_expr(exprs: Iterable[pl.Expr]) -> pl.Expr:
+    exprs = list(exprs)
+    if not exprs:
+        return pl.lit(0).cast(pl.Int64)
+    acc = exprs[0]
+    for expr in exprs[1:]:
+        acc = acc + expr
+    return acc
+
+
+def compute_td_labels(df: pl.DataFrame, *, version: str | None = None) -> pl.DataFrame:
+    """Compute TD label columns according to a label version.
+
+    Parameters
+    ----------
+    df : pl.DataFrame
+        Player-game frame containing touchdown components.
+    version : str | None
+        Label version identifier. Defaults to DEFAULT_LABEL_VERSION.
+    """
+
+    spec = get_label_spec(version)
+    required_cols = ["rushing_td_count", "receiving_td_count", "passing_td", "touchdowns"]
+    missing = [col for col in required_cols if col not in df.columns]
+    if missing:
+        df = df.with_columns([pl.lit(0).cast(pl.Int64).alias(col) for col in missing])
+    rush = pl.col("rushing_td_count").fill_null(0).cast(pl.Int64)
+    rec = pl.col("receiving_td_count").fill_null(0).cast(pl.Int64)
+    passing = pl.col("passing_td").fill_null(0).cast(pl.Int64)
+    reported_total = pl.col("touchdowns").fill_null(0).cast(pl.Int64)
+
+    offense_total = _sum_expr([rush, rec, passing]).alias("_td_offense_total")
+    other_total = (reported_total - offense_total).clip_min(0).alias("_td_other_total")
+    all_total = (offense_total + other_total).alias("_td_all_total")
+
+    totals_exprs = [
+        offense_total,
+        other_total,
+        all_total,
+    ]
+
+    label_exprs: list[pl.Expr] = [
+        pl.col("_td_offense_total").alias("td_count_offense"),
+        pl.col("_td_all_total").alias("td_count_all"),
+    ]
+
+    for label_name, rules in spec.labels.items():
+        parts: list[pl.Expr] = []
+        if rules.include_rush:
+            parts.append(rush)
+        if rules.include_rec:
+            parts.append(rec)
+        if rules.include_pass_thrown:
+            parts.append(passing)
+        if rules.include_other:
+            parts.append(pl.col("_td_other_total"))
+        total_expr = _sum_expr(parts)
+        label_exprs.append((total_expr > 0).cast(pl.Int8).alias(label_name))
+
+    # Canonical counts for compatibility
+    if "td_count" not in df.columns:
+        # Fill td_count using the alias mapping; default to offense count.
+        target_alias = spec.aliases.get("td_count") or "td_count_offense"
+        label_exprs.append(pl.col(target_alias).alias("td_count"))
+
+    df = df.with_columns(totals_exprs).with_columns(label_exprs)
+
+    # Resolve aliases (e.g., anytime_td -> anytime_td_offense)
+    if spec.aliases:
+        alias_exprs = []
+        for alias_name, source_name in spec.aliases.items():
+            if source_name in df.columns:
+                alias_exprs.append(pl.col(source_name).alias(alias_name))
+        if alias_exprs:
+            df = df.with_columns(alias_exprs)
+
+    drop_cols = [col for col in ("_td_offense_total", "_td_other_total", "_td_all_total") if col in df.columns]
+    if drop_cols:
+        df = df.drop(drop_cols)
+    return df
diff --git a/utils/feature/player_game_level.py b/utils/feature/player_game_level.py
index b6fe516c5f03d575038eef554d5ab39ea5d5c90d..dd4f1f7fcc9de4d8c63390f0a160005eeae48e2f
--- a/utils/feature/player_game_level.py
+++ b/utils/feature/player_game_level.py
@@ -4,8 +4,12 @@
 Each player gets one row per game with their total stats.
 
 Target columns created:
-- anytime_td (binary): Did player score a TD (receiving or rushing)?
-- td_count (int): Number of TDs scored (receiving + rushing)
+- anytime_td_offense (binary): Did player score an offensive TD (rush/rec/pass thrown)?
+- anytime_td_all (binary): Did player score any TD (including defensive/special teams if present)?
+- anytime_td_rush / anytime_td_rec / anytime_td_pass_thrown: Type-specific TD flags.
+- anytime_td (binary): Legacy alias → current label version primary.
+- td_count_offense / td_count_all: TD counts aligned to label semantics.
+- td_count (int): Legacy alias for the primary td_count.
 - passing_td (int): Number of passing TDs (for QBs)
 - receiving_yards (float): Total receiving yards
 - rushing_yards (float): Total rushing yards
@@ -33,6 +37,7 @@
 from utils.collect.nfl_schedules import get_schedule
 from utils.feature.asof import decision_cutoff_hours_default, fallback_cutoff_hours, get_decision_cutoff_hours, get_fallback_cutoff_hours
 from utils.feature.player_drive_level import _load_play_level_data
+from utils.feature.labels import DEFAULT_LABEL_VERSION, compute_td_labels
 from utils.train.injury_availability import (
     load_latest_artifact,
     predict_probabilities as predict_injury_probabilities,
@@ -1582,7 +1587,12 @@
     if flag_cols:
         df = df.with_columns([pl.col(col).cast(pl.Int8) for col in flag_cols])
     return df
-def build_player_game_level(*, start_date: date, end_date: date) -> None:
+def build_player_game_level(
+    *,
+    start_date: date,
+    end_date: date,
+    label_version: str | None = None,
+) -> None:
     """Aggregate play-level data to player-game level.
     
     Creates one row per (player, game) with accumulated stats.
@@ -1680,7 +1690,7 @@
     
     # Merge rows where same player had multiple roles in same game
     # (e.g., QB who also rushed, WR who also rushed)
-    df_merged = _merge_multi_role_players(df_all)
+    df_merged = _merge_multi_role_players(df_all, label_version=label_version or DEFAULT_LABEL_VERSION)
 
     df_merged = _append_zero_usage_players(df_merged, seasons_in_window)
     
@@ -3368,7 +3378,7 @@
     )
 
 
-def _merge_multi_role_players(df: pl.DataFrame) -> pl.DataFrame:
+def _merge_multi_role_players(df: pl.DataFrame, *, label_version: str | None = None) -> pl.DataFrame:
     """Merge stats for players who had multiple roles in same game.
     
     Example: QB who passed and rushed, WR who received and rushed.
@@ -3422,8 +3432,6 @@
         if col in merged.columns:
             merged = merged.with_columns(pl.col(col).fill_null(0))
 
-    # Fallback touchdown logic: if generic touchdown attribution is missing,
-    # derive it from rushing + receiving touchdowns.
     merged = merged.with_columns([
         pl.col("touchdowns").fill_null(0).alias("touchdowns"),
         pl.col("rushing_td_count").fill_null(0).alias("rushing_td_count"),
@@ -3435,17 +3443,5 @@
         pl.col("goal_to_go_carry").fill_null(0).alias("goal_to_go_carry"),
     ])
 
-    merged = merged.with_columns([
-        pl.when(pl.col("touchdowns") > 0)
-        .then(pl.col("touchdowns"))
-        .otherwise(pl.col("rushing_td_count") + pl.col("receiving_td_count"))
-        .cast(pl.Int64)
-        .alias("_total_touchdowns")
-    ])
-
-    merged = merged.with_columns([
-        (pl.col("_total_touchdowns") > 0).cast(pl.Int8).alias("anytime_td"),
-        pl.col("_total_touchdowns").alias("td_count"),
-    ]).drop("_total_touchdowns")
-    
+    merged = compute_td_labels(merged, version=label_version)
     return merged
diff --git a/utils/feature/targets.py b/utils/feature/targets.py
index 7738086dcbfda7432b937cc7d8095988cb0edff0..769ee8735c4024c4410ddd674b11112f093624dd
--- a/utils/feature/targets.py
+++ b/utils/feature/targets.py
@@ -7,6 +7,8 @@
 import polars as pl
 import logging
 
+from utils.feature.labels import DEFAULT_LABEL_VERSION, get_label_spec
+
 logger = logging.getLogger(__name__)
 
 
@@ -14,9 +16,16 @@
 NFL_TARGET_SCHEMA = {
     # Binary classification targets
     "anytime_td": pl.Int8,  # Primary MVP target: did player score a TD?
+    "anytime_td_offense": pl.Int8,
+    "anytime_td_all": pl.Int8,
+    "anytime_td_rush": pl.Int8,
+    "anytime_td_rec": pl.Int8,
+    "anytime_td_pass_thrown": pl.Int8,
     
     # Count/regression targets
     "td_count": pl.Int64,  # Number of TDs scored (receiving + rushing)
+    "td_count_offense": pl.Int64,
+    "td_count_all": pl.Int64,
     "passing_td": pl.Int64,  # Number of passing TDs (QB only)
     
     # Yardage regression targets
@@ -103,4 +112,40 @@
     pl.DataFrame
         DataFrame with validated target columns
     """
-    return validate_target_columns(df, strict=False)
\ No newline at end of file
+    return validate_target_columns(df, strict=False)
+
+
+def require_target_column(
+    df: pl.DataFrame,
+    target_col: str,
+    *,
+    label_version: str | None = None,
+    min_non_null: int = 1,
+) -> pl.DataFrame:
+    """Ensure the configured target column exists and is populated.
+
+    Raises a ValueError if the column is missing or entirely null.
+    """
+
+    if target_col not in df.columns:
+        alias_hint = ""
+        if label_version:
+            try:
+                spec = get_label_spec(label_version or DEFAULT_LABEL_VERSION)
+                if target_col in spec.aliases:
+                    alias_hint = f" Target maps to '{spec.aliases[target_col]}' under {spec.name}."
+            except Exception:
+                alias_hint = ""
+        raise ValueError(f"Target column '{target_col}' not found in feature frame.{alias_hint}")
+
+    series = df[target_col]
+    non_null = series.drop_nulls().height
+    if non_null < min_non_null:
+        raise ValueError(
+            f"Target column '{target_col}' has insufficient non-null rows "
+            f"({non_null}/{len(series)})."
+        )
+    nulls = len(series) - non_null
+    if nulls > 0:
+        logger.warning("Target %s contains %d null rows; they will be dropped.", target_col, nulls)
+    return df


thinking
**Assessing test environment and dependencies**
exec
/bin/zsh -lc 'cd /Users/jameswest/Desktop/nfl_predict && git status --short' in /Users/jameswest/Desktop/nfl_predict succeeded in 779ms:
/opt/homebrew/Library/Homebrew/cmd/shellenv.sh: line 18: /bin/ps: Operation not permitted
 M codex_meta_loop.py
 M docs/rolling_window_implementation.md
 M pipeline/feature.py
 M pipeline/predict.py
 M pipeline/train.py
 M tests/test_training_config_features.py
 M utils/collect/visual_crossing_weather.py
 M utils/collect/weather_forecasts.py
 M utils/feature/player_game_level.py
 M utils/feature/rolling_window.py
 M utils/feature/stats.py
 M utils/feature/targets.py
 M utils/general/constants.py
 M utils/train/persist.py
?? .codex_meta_logs/
?? _tmp_can_write
?? codex_output.md
?? docs/pre_snap_semantics.md
?? testfile
file update:
diff --git a/config/training.yaml b/config/training.yaml
index 3055a636b89249119408aaad970d3025956877db..3953818d861d0410246bff132110722a3ce44007
--- a/config/training.yaml
+++ b/config/training.yaml
@@ -475,6 +475,7 @@
   # Calibrated probability of scoring > 0 TDs.
   - name: 'anytime_td'
     target_col: 'anytime_td'
+    label_version: 'v1_any_offense'
     task_type: 'classification'
     input_predictions:
       - 'availability_active'
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 6c47a91d08f9d309f94323efd4708bb992dc4ce0..5ba68e8bf1acd3a789a76a8857674e6f6433017b
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -26,6 +26,7 @@
 from utils.feature.player_drive_level import build_player_drive_level
 from utils.feature.player_game_level import build_player_game_level
 from utils.feature.opponent_splits import build_opponent_splits
+from utils.feature.labels import DEFAULT_LABEL_VERSION, get_label_spec
 from utils.feature.targets import validate_target_columns
 from utils.feature.daily_totals import build_daily_cache_range
 from utils.feature.rolling_window import add_rolling_features
@@ -233,6 +234,7 @@
     output_path: Path | None = None,
     primary_output_path: Path | None = None,
     cutoff_label: str | None = None,
+    label_version: str | None = None,
 ) -> pl.DataFrame:
     """Run full feature pipeline up to *inclusive* `end_date` for a single cutoff window.
 
@@ -248,6 +250,7 @@
     primary_output = primary_output_path or target_output_path
     current_cutoff_hours = float(get_decision_cutoff_hours())
     clean_min_date, clean_max_date = (None, None)
+    label_version = label_version or DEFAULT_LABEL_VERSION
     if start_date is None or end_date is None:
         clean_min_date, clean_max_date = _get_clean_date_bounds()
 
@@ -294,7 +297,7 @@
             build_player_drive_level(start_date=cur, end_date=chunk_end)
             
             # 5. Player-game aggregations (for rolling window features)
-            build_player_game_level(start_date=cur, end_date=chunk_end)
+            build_player_game_level(start_date=cur, end_date=chunk_end, label_version=label_version)
 
             # advance to next slice
             cur += timedelta(days=chunk_days)
@@ -948,11 +951,19 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    # Log target distribution for anytime_td
-    if "anytime_td" in df_player_game_all.columns:
-        td_count = df_player_game_all["anytime_td"].sum()
-        td_rate = td_count / len(df_player_game_all) * 100
-        logging.info("    Anytime TD rate: %.2f%% (%d/%d)", td_rate, td_count, len(df_player_game_all))
+    spec = get_label_spec(label_version)
+    label_candidates = {spec.primary, "anytime_td"}
+    for label_col in label_candidates:
+        if label_col in df_player_game_all.columns:
+            td_count = df_player_game_all[label_col].sum()
+            td_rate = td_count / len(df_player_game_all) * 100
+            logging.info(
+                "    Label %s rate: %.2f%% (%d/%d)",
+                label_col,
+                td_rate,
+                td_count,
+                len(df_player_game_all),
+            )
     
     return df_player_game_all
 
@@ -965,6 +976,7 @@
     recompute_intermediate: bool = True,
     build_rolling: bool = True,
     cutoff_hours_list: Sequence[float] | None = None,
+    label_version: str | None = None,
 ) -> pl.DataFrame:
     """Build feature matrices for one or more decision cutoff horizons.
 
@@ -992,6 +1004,7 @@
                 output_path=output_path,
                 primary_output_path=primary_output,
                 cutoff_label=label,
+                label_version=label_version,
             )
         if idx == 0:
             primary_result = df
diff --git a/pipeline/train.py b/pipeline/train.py
index 265bc29f4861d2d4d26f54fd7f77304de8fe6742..fe70207dcdf25d209ee3ad55080b7ce826347c44
--- a/pipeline/train.py
+++ b/pipeline/train.py
@@ -98,6 +98,7 @@
     fit_team_conformal_sums,
     composite_sum_interval,
 )
+from utils.feature.targets import require_target_column
 
 # Ignore specific, noisy warnings from dependencies
 warnings.filterwarnings(
@@ -259,6 +260,7 @@
 
         # Per-problem attributes initialised later
         self.target_col = None
+        self.label_version = None
         self.feature_columns = None
 
         self.models = {}
@@ -2163,6 +2165,7 @@
             
             problem_copy = copy.deepcopy(problem)
             self.target_col = problem_copy['target_col']
+            self.label_version = problem_copy.get('label_version') or problem_copy.get("labels", {}).get("version")
             derived_cfg = problem_copy.get('derived_target')
             target_load_cols: list[str] = []
             if derived_cfg:
@@ -2269,6 +2272,12 @@
                 df_problem = df_problem.loc[:, ~df_problem.columns.duplicated()]
 
             df_problem = self._apply_problem_level_overrides(df_problem, problem_copy)
+            df_problem = require_target_column(
+                df_problem,
+                self.target_col,
+                label_version=self.label_version,
+                min_non_null=1,
+            )
             
             # Merge input predictions if required
             if input_preds:
diff --git a/tests/labels/test_labels.py b/tests/labels/test_labels.py
new file mode 100644
index 0000000000000000000000000000000000000000..71743f35f8a9ff386afeaa8a346bdf150f7b9164
--- /dev/null
+++ b/tests/labels/test_labels.py
@@ -0,0 +1,68 @@
+import polars as pl
+
+from utils.feature.labels import compute_td_labels, get_label_spec
+
+
+def _lookup(frame: pl.DataFrame, player_id: str) -> dict:
+    return frame.filter(pl.col("player_id") == player_id).to_dicts()[0]
+
+
+def test_compute_td_labels_offense_and_all_variants():
+    df = pl.DataFrame(
+        {
+            "player_id": ["rush", "rec", "pass", "def"],
+            "game_id": ["g1"] * 4,
+            "rushing_td_count": [1, 0, 0, 0],
+            "receiving_td_count": [0, 1, 0, 0],
+            "passing_td": [0, 0, 1, 0],
+            # Generic touchdown attribution (e.g., defensive return)
+            "touchdowns": [1, 1, 0, 1],
+        }
+    )
+
+    result = compute_td_labels(df, version="v1_any_offense")
+
+    rush = _lookup(result, "rush")
+    assert rush["anytime_td_offense"] == 1
+    assert rush["anytime_td_rush"] == 1
+    assert rush["anytime_td_rec"] == 0
+    assert rush["anytime_td_pass_thrown"] == 0
+    assert rush["td_count_offense"] == 1
+    assert rush["td_count_all"] == 1
+    assert rush["anytime_td"] == rush["anytime_td_offense"]
+
+    rec = _lookup(result, "rec")
+    assert rec["anytime_td_offense"] == 1
+    assert rec["anytime_td_rec"] == 1
+    assert rec["anytime_td_rush"] == 0
+
+    passer = _lookup(result, "pass")
+    assert passer["anytime_td_pass_thrown"] == 1
+    assert passer["anytime_td_offense"] == 1
+    assert passer["anytime_td_all"] == 1  # includes offensive TDs
+
+    defensive = _lookup(result, "def")
+    assert defensive["anytime_td_offense"] == 0  # no offensive scoring events
+    assert defensive["anytime_td_all"] == 1  # credited via generic touchdown
+    assert defensive["anytime_td"] == defensive["anytime_td_offense"]
+
+
+def test_label_version_any_all_aliases_anytime_td():
+    spec = get_label_spec("v1_any_all")
+    assert spec.primary == "anytime_td_all"
+
+    df = pl.DataFrame(
+        {
+            "player_id": ["all"],
+            "game_id": ["g1"],
+            "rushing_td_count": [0],
+            "receiving_td_count": [0],
+            "passing_td": [0],
+            "touchdowns": [1],
+        }
+    )
+    result = compute_td_labels(df, version="v1_any_all")
+    row = _lookup(result, "all")
+    # Alias ensures legacy anytime_td follows the version's primary definition.
+    assert row["anytime_td_all"] == 1
+    assert row["anytime_td"] == row["anytime_td_all"]
diff --git a/utils/feature/labels.py b/utils/feature/labels.py
new file mode 100644
index 0000000000000000000000000000000000000000..e5e5114da792e3c3558189e03b04f4ab2f69a4f5
--- /dev/null
+++ b/utils/feature/labels.py
@@ -0,0 +1,173 @@
+"""Label semantics and versioning for NFL player-level targets.
+
+This module centralizes anytime-TD label definitions so that:
+- Semantics are explicit and versioned.
+- Training can request a specific label column per problem.
+- Feature generation can emit multiple label variants for analysis.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass, field
+from typing import Dict, Iterable, Mapping
+
+import polars as pl
+
+
+@dataclass(frozen=True)
+class LabelRules:
+    """Rules controlling which TD components count toward a label."""
+
+    include_rush: bool = True
+    include_rec: bool = True
+    include_pass_thrown: bool = True  # credit passers for thrown TDs
+    include_other: bool = False  # fumble returns, defensive/special teams if present
+
+
+@dataclass(frozen=True)
+class LabelSpec:
+    """Container describing a label version."""
+
+    name: str
+    primary: str
+    labels: Mapping[str, LabelRules]
+    aliases: Mapping[str, str] = field(default_factory=dict)
+
+    @property
+    def all_columns(self) -> set[str]:
+        cols = set(self.labels.keys())
+        cols.update(self.aliases.keys())
+        return cols
+
+
+DEFAULT_LABEL_VERSION = "v1_any_offense"
+
+
+LABEL_VERSIONS: Dict[str, LabelSpec] = {
+    "v1_any_offense": LabelSpec(
+        name="v1_any_offense",
+        primary="anytime_td_offense",
+        labels={
+            "anytime_td_offense": LabelRules(include_other=False),
+            "anytime_td_rush": LabelRules(include_rush=True, include_rec=False, include_pass_thrown=False, include_other=False),
+            "anytime_td_rec": LabelRules(include_rush=False, include_rec=True, include_pass_thrown=False, include_other=False),
+            "anytime_td_pass_thrown": LabelRules(include_rush=False, include_rec=False, include_pass_thrown=True, include_other=False),
+            "anytime_td_all": LabelRules(include_other=True),
+        },
+        aliases={
+            # Maintain legacy column name as an alias to the offense-only label.
+            "anytime_td": "anytime_td_offense",
+            # Keep td_count pointing to the offense definition for backward compatibility.
+            "td_count": "td_count_offense",
+        },
+    ),
+    "v1_any_all": LabelSpec(
+        name="v1_any_all",
+        primary="anytime_td_all",
+        labels={
+            "anytime_td_all": LabelRules(include_other=True),
+            "anytime_td_offense": LabelRules(include_other=False),
+            "anytime_td_rush": LabelRules(include_rush=True, include_rec=False, include_pass_thrown=False, include_other=False),
+            "anytime_td_rec": LabelRules(include_rush=False, include_rec=True, include_pass_thrown=False, include_other=False),
+            "anytime_td_pass_thrown": LabelRules(include_rush=False, include_rec=False, include_pass_thrown=True, include_other=False),
+        },
+        aliases={
+            "anytime_td": "anytime_td_all",
+            "td_count": "td_count_all",
+        },
+    ),
+}
+
+
+def get_label_spec(version: str | None) -> LabelSpec:
+    """Return a concrete LabelSpec for the requested version (or default)."""
+
+    version = version or DEFAULT_LABEL_VERSION
+    if version not in LABEL_VERSIONS:
+        raise ValueError(
+            f"Unknown label_version '{version}'. "
+            f"Available: {sorted(LABEL_VERSIONS.keys())}"
+        )
+    return LABEL_VERSIONS[version]
+
+
+def _sum_expr(exprs: Iterable[pl.Expr]) -> pl.Expr:
+    exprs = list(exprs)
+    if not exprs:
+        return pl.lit(0).cast(pl.Int64)
+    acc = exprs[0]
+    for expr in exprs[1:]:
+        acc = acc + expr
+    return acc
+
+
+def compute_td_labels(df: pl.DataFrame, *, version: str | None = None) -> pl.DataFrame:
+    """Compute TD label columns according to a label version.
+
+    Parameters
+    ----------
+    df : pl.DataFrame
+        Player-game frame containing touchdown components.
+    version : str | None
+        Label version identifier. Defaults to DEFAULT_LABEL_VERSION.
+    """
+
+    spec = get_label_spec(version)
+    required_cols = ["rushing_td_count", "receiving_td_count", "passing_td", "touchdowns"]
+    missing = [col for col in required_cols if col not in df.columns]
+    if missing:
+        df = df.with_columns([pl.lit(0).cast(pl.Int64).alias(col) for col in missing])
+    rush = pl.col("rushing_td_count").fill_null(0).cast(pl.Int64)
+    rec = pl.col("receiving_td_count").fill_null(0).cast(pl.Int64)
+    passing = pl.col("passing_td").fill_null(0).cast(pl.Int64)
+    reported_total = pl.col("touchdowns").fill_null(0).cast(pl.Int64)
+
+    offense_total = _sum_expr([rush, rec, passing]).alias("_td_offense_total")
+    other_total = (reported_total - offense_total).clip_min(0).alias("_td_other_total")
+    all_total = (offense_total + other_total).alias("_td_all_total")
+
+    totals_exprs = [
+        offense_total,
+        other_total,
+        all_total,
+    ]
+
+    label_exprs: list[pl.Expr] = [
+        pl.col("_td_offense_total").alias("td_count_offense"),
+        pl.col("_td_all_total").alias("td_count_all"),
+    ]
+
+    for label_name, rules in spec.labels.items():
+        parts: list[pl.Expr] = []
+        if rules.include_rush:
+            parts.append(rush)
+        if rules.include_rec:
+            parts.append(rec)
+        if rules.include_pass_thrown:
+            parts.append(passing)
+        if rules.include_other:
+            parts.append(pl.col("_td_other_total"))
+        total_expr = _sum_expr(parts)
+        label_exprs.append((total_expr > 0).cast(pl.Int8).alias(label_name))
+
+    # Canonical counts for compatibility
+    if "td_count" not in df.columns:
+        # Fill td_count using the alias mapping; default to offense count.
+        target_alias = spec.aliases.get("td_count") or "td_count_offense"
+        label_exprs.append(pl.col(target_alias).alias("td_count"))
+
+    df = df.with_columns(totals_exprs).with_columns(label_exprs)
+
+    # Resolve aliases (e.g., anytime_td -> anytime_td_offense)
+    if spec.aliases:
+        alias_exprs = []
+        for alias_name, source_name in spec.aliases.items():
+            if source_name in df.columns:
+                alias_exprs.append(pl.col(source_name).alias(alias_name))
+        if alias_exprs:
+            df = df.with_columns(alias_exprs)
+
+    drop_cols = [col for col in ("_td_offense_total", "_td_other_total", "_td_all_total") if col in df.columns]
+    if drop_cols:
+        df = df.drop(drop_cols)
+    return df
diff --git a/utils/feature/player_game_level.py b/utils/feature/player_game_level.py
index b6fe516c5f03d575038eef554d5ab39ea5d5c90d..dd4f1f7fcc9de4d8c63390f0a160005eeae48e2f
--- a/utils/feature/player_game_level.py
+++ b/utils/feature/player_game_level.py
@@ -4,8 +4,12 @@
 Each player gets one row per game with their total stats.
 
 Target columns created:
-- anytime_td (binary): Did player score a TD (receiving or rushing)?
-- td_count (int): Number of TDs scored (receiving + rushing)
+- anytime_td_offense (binary): Did player score an offensive TD (rush/rec/pass thrown)?
+- anytime_td_all (binary): Did player score any TD (including defensive/special teams if present)?
+- anytime_td_rush / anytime_td_rec / anytime_td_pass_thrown: Type-specific TD flags.
+- anytime_td (binary): Legacy alias → current label version primary.
+- td_count_offense / td_count_all: TD counts aligned to label semantics.
+- td_count (int): Legacy alias for the primary td_count.
 - passing_td (int): Number of passing TDs (for QBs)
 - receiving_yards (float): Total receiving yards
 - rushing_yards (float): Total rushing yards
@@ -33,6 +37,7 @@
 from utils.collect.nfl_schedules import get_schedule
 from utils.feature.asof import decision_cutoff_hours_default, fallback_cutoff_hours, get_decision_cutoff_hours, get_fallback_cutoff_hours
 from utils.feature.player_drive_level import _load_play_level_data
+from utils.feature.labels import DEFAULT_LABEL_VERSION, compute_td_labels
 from utils.train.injury_availability import (
     load_latest_artifact,
     predict_probabilities as predict_injury_probabilities,
@@ -1582,7 +1587,12 @@
     if flag_cols:
         df = df.with_columns([pl.col(col).cast(pl.Int8) for col in flag_cols])
     return df
-def build_player_game_level(*, start_date: date, end_date: date) -> None:
+def build_player_game_level(
+    *,
+    start_date: date,
+    end_date: date,
+    label_version: str | None = None,
+) -> None:
     """Aggregate play-level data to player-game level.
     
     Creates one row per (player, game) with accumulated stats.
@@ -1680,7 +1690,7 @@
     
     # Merge rows where same player had multiple roles in same game
     # (e.g., QB who also rushed, WR who also rushed)
-    df_merged = _merge_multi_role_players(df_all)
+    df_merged = _merge_multi_role_players(df_all, label_version=label_version or DEFAULT_LABEL_VERSION)
 
     df_merged = _append_zero_usage_players(df_merged, seasons_in_window)
     
@@ -3368,7 +3378,7 @@
     )
 
 
-def _merge_multi_role_players(df: pl.DataFrame) -> pl.DataFrame:
+def _merge_multi_role_players(df: pl.DataFrame, *, label_version: str | None = None) -> pl.DataFrame:
     """Merge stats for players who had multiple roles in same game.
     
     Example: QB who passed and rushed, WR who received and rushed.
@@ -3422,8 +3432,6 @@
         if col in merged.columns:
             merged = merged.with_columns(pl.col(col).fill_null(0))
 
-    # Fallback touchdown logic: if generic touchdown attribution is missing,
-    # derive it from rushing + receiving touchdowns.
     merged = merged.with_columns([
         pl.col("touchdowns").fill_null(0).alias("touchdowns"),
         pl.col("rushing_td_count").fill_null(0).alias("rushing_td_count"),
@@ -3435,17 +3443,5 @@
         pl.col("goal_to_go_carry").fill_null(0).alias("goal_to_go_carry"),
     ])
 
-    merged = merged.with_columns([
-        pl.when(pl.col("touchdowns") > 0)
-        .then(pl.col("touchdowns"))
-        .otherwise(pl.col("rushing_td_count") + pl.col("receiving_td_count"))
-        .cast(pl.Int64)
-        .alias("_total_touchdowns")
-    ])
-
-    merged = merged.with_columns([
-        (pl.col("_total_touchdowns") > 0).cast(pl.Int8).alias("anytime_td"),
-        pl.col("_total_touchdowns").alias("td_count"),
-    ]).drop("_total_touchdowns")
-    
+    merged = compute_td_labels(merged, version=label_version)
     return merged
diff --git a/utils/feature/targets.py b/utils/feature/targets.py
index 7738086dcbfda7432b937cc7d8095988cb0edff0..769ee8735c4024c4410ddd674b11112f093624dd
--- a/utils/feature/targets.py
+++ b/utils/feature/targets.py
@@ -7,6 +7,8 @@
 import polars as pl
 import logging
 
+from utils.feature.labels import DEFAULT_LABEL_VERSION, get_label_spec
+
 logger = logging.getLogger(__name__)
 
 
@@ -14,9 +16,16 @@
 NFL_TARGET_SCHEMA = {
     # Binary classification targets
     "anytime_td": pl.Int8,  # Primary MVP target: did player score a TD?
+    "anytime_td_offense": pl.Int8,
+    "anytime_td_all": pl.Int8,
+    "anytime_td_rush": pl.Int8,
+    "anytime_td_rec": pl.Int8,
+    "anytime_td_pass_thrown": pl.Int8,
     
     # Count/regression targets
     "td_count": pl.Int64,  # Number of TDs scored (receiving + rushing)
+    "td_count_offense": pl.Int64,
+    "td_count_all": pl.Int64,
     "passing_td": pl.Int64,  # Number of passing TDs (QB only)
     
     # Yardage regression targets
@@ -103,4 +112,40 @@
     pl.DataFrame
         DataFrame with validated target columns
     """
-    return validate_target_columns(df, strict=False)
\ No newline at end of file
+    return validate_target_columns(df, strict=False)
+
+
+def require_target_column(
+    df: pl.DataFrame,
+    target_col: str,
+    *,
+    label_version: str | None = None,
+    min_non_null: int = 1,
+) -> pl.DataFrame:
+    """Ensure the configured target column exists and is populated.
+
+    Raises a ValueError if the column is missing or entirely null.
+    """
+
+    if target_col not in df.columns:
+        alias_hint = ""
+        if label_version:
+            try:
+                spec = get_label_spec(label_version or DEFAULT_LABEL_VERSION)
+                if target_col in spec.aliases:
+                    alias_hint = f" Target maps to '{spec.aliases[target_col]}' under {spec.name}."
+            except Exception:
+                alias_hint = ""
+        raise ValueError(f"Target column '{target_col}' not found in feature frame.{alias_hint}")
+
+    series = df[target_col]
+    non_null = series.drop_nulls().height
+    if non_null < min_non_null:
+        raise ValueError(
+            f"Target column '{target_col}' has insufficient non-null rows "
+            f"({non_null}/{len(series)})."
+        )
+    nulls = len(series) - non_null
+    if nulls > 0:
+        logger.warning("Target %s contains %d null rows; they will be dropped.", target_col, nulls)
+    return df


thinking
**Reviewing code updates and permission issues**

thinking
**Preparing final summary message**
codex
Introduced versioned anytime-TD labels and explicit target wiring. TD semantics now live in `utils/feature/labels.py` with v1 specs, aliases, and helper `compute_td_labels`; player-game aggregation uses it to emit offense/all/type-specific labels and aligned td_count columns (`utils/feature/player_game_level.py`). Feature pipeline now accepts a `label_version`, passes it into aggregation, and logs rates for the primary label while defaulting to `v1_any_offense` (`pipeline/feature.py`). Training now records per-problem `label_version` from config, enforces the configured target exists via `require_target_column`, and raises early if missing (`pipeline/train.py`, `utils/feature/targets.py`). Added config hook for label version under the anytime_td problem (`config/training.yaml`) and a focused label semantics test suite (`tests/labels/test_labels.py`).

Tests: `pytest tests/labels/test_labels.py -q` (pytest not available in environment).

Git: Unable to stage/commit because writing to `.git` is denied in this environment (e.g., `git add` fails creating `.git/index.lock`). Working tree remains dirty.

PROGRESS: Implemented P0 label-version scaffold (specs, generation, target enforcement, config hook) and added unit coverage; remaining plan items (leak guardrails, decision-time odds/injuries, CV, docs, broader evaluation) are still outstanding.
file update:
diff --git a/config/training.yaml b/config/training.yaml
index 3055a636b89249119408aaad970d3025956877db..3953818d861d0410246bff132110722a3ce44007
--- a/config/training.yaml
+++ b/config/training.yaml
@@ -475,6 +475,7 @@
   # Calibrated probability of scoring > 0 TDs.
   - name: 'anytime_td'
     target_col: 'anytime_td'
+    label_version: 'v1_any_offense'
     task_type: 'classification'
     input_predictions:
       - 'availability_active'
diff --git a/pipeline/feature.py b/pipeline/feature.py
index 6c47a91d08f9d309f94323efd4708bb992dc4ce0..5ba68e8bf1acd3a789a76a8857674e6f6433017b
--- a/pipeline/feature.py
+++ b/pipeline/feature.py
@@ -26,6 +26,7 @@
 from utils.feature.player_drive_level import build_player_drive_level
 from utils.feature.player_game_level import build_player_game_level
 from utils.feature.opponent_splits import build_opponent_splits
+from utils.feature.labels import DEFAULT_LABEL_VERSION, get_label_spec
 from utils.feature.targets import validate_target_columns
 from utils.feature.daily_totals import build_daily_cache_range
 from utils.feature.rolling_window import add_rolling_features
@@ -233,6 +234,7 @@
     output_path: Path | None = None,
     primary_output_path: Path | None = None,
     cutoff_label: str | None = None,
+    label_version: str | None = None,
 ) -> pl.DataFrame:
     """Run full feature pipeline up to *inclusive* `end_date` for a single cutoff window.
 
@@ -248,6 +250,7 @@
     primary_output = primary_output_path or target_output_path
     current_cutoff_hours = float(get_decision_cutoff_hours())
     clean_min_date, clean_max_date = (None, None)
+    label_version = label_version or DEFAULT_LABEL_VERSION
     if start_date is None or end_date is None:
         clean_min_date, clean_max_date = _get_clean_date_bounds()
 
@@ -294,7 +297,7 @@
             build_player_drive_level(start_date=cur, end_date=chunk_end)
             
             # 5. Player-game aggregations (for rolling window features)
-            build_player_game_level(start_date=cur, end_date=chunk_end)
+            build_player_game_level(start_date=cur, end_date=chunk_end, label_version=label_version)
 
             # advance to next slice
             cur += timedelta(days=chunk_days)
@@ -948,11 +951,19 @@
                  df_player_game_all["game_date"].min(), 
                  df_player_game_all["game_date"].max())
     
-    # Log target distribution for anytime_td
-    if "anytime_td" in df_player_game_all.columns:
-        td_count = df_player_game_all["anytime_td"].sum()
-        td_rate = td_count / len(df_player_game_all) * 100
-        logging.info("    Anytime TD rate: %.2f%% (%d/%d)", td_rate, td_count, len(df_player_game_all))
+    spec = get_label_spec(label_version)
+    label_candidates = {spec.primary, "anytime_td"}
+    for label_col in label_candidates:
+        if label_col in df_player_game_all.columns:
+            td_count = df_player_game_all[label_col].sum()
+            td_rate = td_count / len(df_player_game_all) * 100
+            logging.info(
+                "    Label %s rate: %.2f%% (%d/%d)",
+                label_col,
+                td_rate,
+                td_count,
+                len(df_player_game_all),
+            )
     
     return df_player_game_all
 
@@ -965,6 +976,7 @@
     recompute_intermediate: bool = True,
     build_rolling: bool = True,
     cutoff_hours_list: Sequence[float] | None = None,
+    label_version: str | None = None,
 ) -> pl.DataFrame:
     """Build feature matrices for one or more decision cutoff horizons.
 
@@ -992,6 +1004,7 @@
                 output_path=output_path,
                 primary_output_path=primary_output,
                 cutoff_label=label,
+                label_version=label_version,
             )
         if idx == 0:
             primary_result = df
diff --git a/pipeline/train.py b/pipeline/train.py
index 265bc29f4861d2d4d26f54fd7f77304de8fe6742..fe70207dcdf25d209ee3ad55080b7ce826347c44
--- a/pipeline/train.py
+++ b/pipeline/train.py
@@ -98,6 +98,7 @@
     fit_team_conformal_sums,
     composite_sum_interval,
 )
+from utils.feature.targets import require_target_column
 
 # Ignore specific, noisy warnings from dependencies
 warnings.filterwarnings(
@@ -259,6 +260,7 @@
 
         # Per-problem attributes initialised later
         self.target_col = None
+        self.label_version = None
         self.feature_columns = None
 
         self.models = {}
@@ -2163,6 +2165,7 @@
             
             problem_copy = copy.deepcopy(problem)
             self.target_col = problem_copy['target_col']
+            self.label_version = problem_copy.get('label_version') or problem_copy.get("labels", {}).get("version")
             derived_cfg = problem_copy.get('derived_target')
             target_load_cols: list[str] = []
             if derived_cfg:
@@ -2269,6 +2272,12 @@
                 df_problem = df_problem.loc[:, ~df_problem.columns.duplicated()]
 
             df_problem = self._apply_problem_level_overrides(df_problem, problem_copy)
+            df_problem = require_target_column(
+                df_problem,
+                self.target_col,
+                label_version=self.label_version,
+                min_non_null=1,
+            )
             
             # Merge input predictions if required
             if input_preds:
diff --git a/tests/labels/test_labels.py b/tests/labels/test_labels.py
new file mode 100644
index 0000000000000000000000000000000000000000..71743f35f8a9ff386afeaa8a346bdf150f7b9164
--- /dev/null
+++ b/tests/labels/test_labels.py
@@ -0,0 +1,68 @@
+import polars as pl
+
+from utils.feature.labels import compute_td_labels, get_label_spec
+
+
+def _lookup(frame: pl.DataFrame, player_id: str) -> dict:
+    return frame.filter(pl.col("player_id") == player_id).to_dicts()[0]
+
+
+def test_compute_td_labels_offense_and_all_variants():
+    df = pl.DataFrame(
+        {
+            "player_id": ["rush", "rec", "pass", "def"],
+            "game_id": ["g1"] * 4,
+            "rushing_td_count": [1, 0, 0, 0],
+            "receiving_td_count": [0, 1, 0, 0],
+            "passing_td": [0, 0, 1, 0],
+            # Generic touchdown attribution (e.g., defensive return)
+            "touchdowns": [1, 1, 0, 1],
+        }
+    )
+
+    result = compute_td_labels(df, version="v1_any_offense")
+
+    rush = _lookup(result, "rush")
+    assert rush["anytime_td_offense"] == 1
+    assert rush["anytime_td_rush"] == 1
+    assert rush["anytime_td_rec"] == 0
+    assert rush["anytime_td_pass_thrown"] == 0
+    assert rush["td_count_offense"] == 1
+    assert rush["td_count_all"] == 1
+    assert rush["anytime_td"] == rush["anytime_td_offense"]
+
+    rec = _lookup(result, "rec")
+    assert rec["anytime_td_offense"] == 1
+    assert rec["anytime_td_rec"] == 1
+    assert rec["anytime_td_rush"] == 0
+
+    passer = _lookup(result, "pass")
+    assert passer["anytime_td_pass_thrown"] == 1
+    assert passer["anytime_td_offense"] == 1
+    assert passer["anytime_td_all"] == 1  # includes offensive TDs
+
+    defensive = _lookup(result, "def")
+    assert defensive["anytime_td_offense"] == 0  # no offensive scoring events
+    assert defensive["anytime_td_all"] == 1  # credited via generic touchdown
+    assert defensive["anytime_td"] == defensive["anytime_td_offense"]
+
+
+def test_label_version_any_all_aliases_anytime_td():
+    spec = get_label_spec("v1_any_all")
+    assert spec.primary == "anytime_td_all"
+
+    df = pl.DataFrame(
+        {
+            "player_id": ["all"],
+            "game_id": ["g1"],
+            "rushing_td_count": [0],
+            "receiving_td_count": [0],
+            "passing_td": [0],
+            "touchdowns": [1],
+        }
+    )
+    result = compute_td_labels(df, version="v1_any_all")
+    row = _lookup(result, "all")
+    # Alias ensures legacy anytime_td follows the version's primary definition.
+    assert row["anytime_td_all"] == 1
+    assert row["anytime_td"] == row["anytime_td_all"]
diff --git a/utils/feature/labels.py b/utils/feature/labels.py
new file mode 100644
index 0000000000000000000000000000000000000000..e5e5114da792e3c3558189e03b04f4ab2f69a4f5
--- /dev/null
+++ b/utils/feature/labels.py
@@ -0,0 +1,173 @@
+"""Label semantics and versioning for NFL player-level targets.
+
+This module centralizes anytime-TD label definitions so that:
+- Semantics are explicit and versioned.
+- Training can request a specific label column per problem.
+- Feature generation can emit multiple label variants for analysis.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass, field
+from typing import Dict, Iterable, Mapping
+
+import polars as pl
+
+
+@dataclass(frozen=True)
+class LabelRules:
+    """Rules controlling which TD components count toward a label."""
+
+    include_rush: bool = True
+    include_rec: bool = True
+    include_pass_thrown: bool = True  # credit passers for thrown TDs
+    include_other: bool = False  # fumble returns, defensive/special teams if present
+
+
+@dataclass(frozen=True)
+class LabelSpec:
+    """Container describing a label version."""
+
+    name: str
+    primary: str
+    labels: Mapping[str, LabelRules]
+    aliases: Mapping[str, str] = field(default_factory=dict)
+
+    @property
+    def all_columns(self) -> set[str]:
+        cols = set(self.labels.keys())
+        cols.update(self.aliases.keys())
+        return cols
+
+
+DEFAULT_LABEL_VERSION = "v1_any_offense"
+
+
+LABEL_VERSIONS: Dict[str, LabelSpec] = {
+    "v1_any_offense": LabelSpec(
+        name="v1_any_offense",
+        primary="anytime_td_offense",
+        labels={
+            "anytime_td_offense": LabelRules(include_other=False),
+            "anytime_td_rush": LabelRules(include_rush=True, include_rec=False, include_pass_thrown=False, include_other=False),
+            "anytime_td_rec": LabelRules(include_rush=False, include_rec=True, include_pass_thrown=False, include_other=False),
+            "anytime_td_pass_thrown": LabelRules(include_rush=False, include_rec=False, include_pass_thrown=True, include_other=False),
+            "anytime_td_all": LabelRules(include_other=True),
+        },
+        aliases={
+            # Maintain legacy column name as an alias to the offense-only label.
+            "anytime_td": "anytime_td_offense",
+            # Keep td_count pointing to the offense definition for backward compatibility.
+            "td_count": "td_count_offense",
+        },
+    ),
+    "v1_any_all": LabelSpec(
+        name="v1_any_all",
+        primary="anytime_td_all",
+        labels={
+            "anytime_td_all": LabelRules(include_other=True),
+            "anytime_td_offense": LabelRules(include_other=False),
+            "anytime_td_rush": LabelRules(include_rush=True, include_rec=False, include_pass_thrown=False, include_other=False),
+            "anytime_td_rec": LabelRules(include_rush=False, include_rec=True, include_pass_thrown=False, include_other=False),
+            "anytime_td_pass_thrown": LabelRules(include_rush=False, include_rec=False, include_pass_thrown=True, include_other=False),
+        },
+        aliases={
+            "anytime_td": "anytime_td_all",
+            "td_count": "td_count_all",
+        },
+    ),
+}
+
+
+def get_label_spec(version: str | None) -> LabelSpec:
+    """Return a concrete LabelSpec for the requested version (or default)."""
+
+    version = version or DEFAULT_LABEL_VERSION
+    if version not in LABEL_VERSIONS:
+        raise ValueError(
+            f"Unknown label_version '{version}'. "
+            f"Available: {sorted(LABEL_VERSIONS.keys())}"
+        )
+    return LABEL_VERSIONS[version]
+
+
+def _sum_expr(exprs: Iterable[pl.Expr]) -> pl.Expr:
+    exprs = list(exprs)
+    if not exprs:
+        return pl.lit(0).cast(pl.Int64)
+    acc = exprs[0]
+    for expr in exprs[1:]:
+        acc = acc + expr
+    return acc
+
+
+def compute_td_labels(df: pl.DataFrame, *, version: str | None = None) -> pl.DataFrame:
+    """Compute TD label columns according to a label version.
+
+    Parameters
+    ----------
+    df : pl.DataFrame
+        Player-game frame containing touchdown components.
+    version : str | None
+        Label version identifier. Defaults to DEFAULT_LABEL_VERSION.
+    """
+
+    spec = get_label_spec(version)
+    required_cols = ["rushing_td_count", "receiving_td_count", "passing_td", "touchdowns"]
+    missing = [col for col in required_cols if col not in df.columns]
+    if missing:
+        df = df.with_columns([pl.lit(0).cast(pl.Int64).alias(col) for col in missing])
+    rush = pl.col("rushing_td_count").fill_null(0).cast(pl.Int64)
+    rec = pl.col("receiving_td_count").fill_null(0).cast(pl.Int64)
+    passing = pl.col("passing_td").fill_null(0).cast(pl.Int64)
+    reported_total = pl.col("touchdowns").fill_null(0).cast(pl.Int64)
+
+    offense_total = _sum_expr([rush, rec, passing]).alias("_td_offense_total")
+    other_total = (reported_total - offense_total).clip_min(0).alias("_td_other_total")
+    all_total = (offense_total + other_total).alias("_td_all_total")
+
+    totals_exprs = [
+        offense_total,
+        other_total,
+        all_total,
+    ]
+
+    label_exprs: list[pl.Expr] = [
+        pl.col("_td_offense_total").alias("td_count_offense"),
+        pl.col("_td_all_total").alias("td_count_all"),
+    ]
+
+    for label_name, rules in spec.labels.items():
+        parts: list[pl.Expr] = []
+        if rules.include_rush:
+            parts.append(rush)
+        if rules.include_rec:
+            parts.append(rec)
+        if rules.include_pass_thrown:
+            parts.append(passing)
+        if rules.include_other:
+            parts.append(pl.col("_td_other_total"))
+        total_expr = _sum_expr(parts)
+        label_exprs.append((total_expr > 0).cast(pl.Int8).alias(label_name))
+
+    # Canonical counts for compatibility
+    if "td_count" not in df.columns:
+        # Fill td_count using the alias mapping; default to offense count.
+        target_alias = spec.aliases.get("td_count") or "td_count_offense"
+        label_exprs.append(pl.col(target_alias).alias("td_count"))
+
+    df = df.with_columns(totals_exprs).with_columns(label_exprs)
+
+    # Resolve aliases (e.g., anytime_td -> anytime_td_offense)
+    if spec.aliases:
+        alias_exprs = []
+        for alias_name, source_name in spec.aliases.items():
+            if source_name in df.columns:
+                alias_exprs.append(pl.col(source_name).alias(alias_name))
+        if alias_exprs:
+            df = df.with_columns(alias_exprs)
+
+    drop_cols = [col for col in ("_td_offense_total", "_td_other_total", "_td_all_total") if col in df.columns]
+    if drop_cols:
+        df = df.drop(drop_cols)
+    return df
diff --git a/utils/feature/player_game_level.py b/utils/feature/player_game_level.py
index b6fe516c5f03d575038eef554d5ab39ea5d5c90d..dd4f1f7fcc9de4d8c63390f0a160005eeae48e2f
--- a/utils/feature/player_game_level.py
+++ b/utils/feature/player_game_level.py
@@ -4,8 +4,12 @@
 Each player gets one row per game with their total stats.
 
 Target columns created:
-- anytime_td (binary): Did player score a TD (receiving or rushing)?
-- td_count (int): Number of TDs scored (receiving + rushing)
+- anytime_td_offense (binary): Did player score an offensive TD (rush/rec/pass thrown)?
+- anytime_td_all (binary): Did player score any TD (including defensive/special teams if present)?
+- anytime_td_rush / anytime_td_rec / anytime_td_pass_thrown: Type-specific TD flags.
+- anytime_td (binary): Legacy alias → current label version primary.
+- td_count_offense / td_count_all: TD counts aligned to label semantics.
+- td_count (int): Legacy alias for the primary td_count.
 - passing_td (int): Number of passing TDs (for QBs)
 - receiving_yards (float): Total receiving yards
 - rushing_yards (float): Total rushing yards
@@ -33,6 +37,7 @@
 from utils.collect.nfl_schedules import get_schedule
 from utils.feature.asof import decision_cutoff_hours_default, fallback_cutoff_hours, get_decision_cutoff_hours, get_fallback_cutoff_hours
 from utils.feature.player_drive_level import _load_play_level_data
+from utils.feature.labels import DEFAULT_LABEL_VERSION, compute_td_labels
 from utils.train.injury_availability import (
     load_latest_artifact,
     predict_probabilities as predict_injury_probabilities,
@@ -1582,7 +1587,12 @@
     if flag_cols:
         df = df.with_columns([pl.col(col).cast(pl.Int8) for col in flag_cols])
     return df
-def build_player_game_level(*, start_date: date, end_date: date) -> None:
+def build_player_game_level(
+    *,
+    start_date: date,
+    end_date: date,
+    label_version: str | None = None,
+) -> None:
     """Aggregate play-level data to player-game level.
     
     Creates one row per (player, game) with accumulated stats.
@@ -1680,7 +1690,7 @@
     
     # Merge rows where same player had multiple roles in same game
     # (e.g., QB who also rushed, WR who also rushed)
-    df_merged = _merge_multi_role_players(df_all)
+    df_merged = _merge_multi_role_players(df_all, label_version=label_version or DEFAULT_LABEL_VERSION)
 
     df_merged = _append_zero_usage_players(df_merged, seasons_in_window)
     
@@ -3368,7 +3378,7 @@
     )
 
 
-def _merge_multi_role_players(df: pl.DataFrame) -> pl.DataFrame:
+def _merge_multi_role_players(df: pl.DataFrame, *, label_version: str | None = None) -> pl.DataFrame:
     """Merge stats for players who had multiple roles in same game.
     
     Example: QB who passed and rushed, WR who received and rushed.
@@ -3422,8 +3432,6 @@
         if col in merged.columns:
             merged = merged.with_columns(pl.col(col).fill_null(0))
 
-    # Fallback touchdown logic: if generic touchdown attribution is missing,
-    # derive it from rushing + receiving touchdowns.
     merged = merged.with_columns([
         pl.col("touchdowns").fill_null(0).alias("touchdowns"),
         pl.col("rushing_td_count").fill_null(0).alias("rushing_td_count"),
@@ -3435,17 +3443,5 @@
         pl.col("goal_to_go_carry").fill_null(0).alias("goal_to_go_carry"),
     ])
 
-    merged = merged.with_columns([
-        pl.when(pl.col("touchdowns") > 0)
-        .then(pl.col("touchdowns"))
-        .otherwise(pl.col("rushing_td_count") + pl.col("receiving_td_count"))
-        .cast(pl.Int64)
-        .alias("_total_touchdowns")
-    ])
-
-    merged = merged.with_columns([
-        (pl.col("_total_touchdowns") > 0).cast(pl.Int8).alias("anytime_td"),
-        pl.col("_total_touchdowns").alias("td_count"),
-    ]).drop("_total_touchdowns")
-    
+    merged = compute_td_labels(merged, version=label_version)
     return merged
diff --git a/utils/feature/targets.py b/utils/feature/targets.py
index 7738086dcbfda7432b937cc7d8095988cb0edff0..769ee8735c4024c4410ddd674b11112f093624dd
--- a/utils/feature/targets.py
+++ b/utils/feature/targets.py
@@ -7,6 +7,8 @@
 import polars as pl
 import logging
 
+from utils.feature.labels import DEFAULT_LABEL_VERSION, get_label_spec
+
 logger = logging.getLogger(__name__)
 
 
@@ -14,9 +16,16 @@
 NFL_TARGET_SCHEMA = {
     # Binary classification targets
     "anytime_td": pl.Int8,  # Primary MVP target: did player score a TD?
+    "anytime_td_offense": pl.Int8,
+    "anytime_td_all": pl.Int8,
+    "anytime_td_rush": pl.Int8,
+    "anytime_td_rec": pl.Int8,
+    "anytime_td_pass_thrown": pl.Int8,
     
     # Count/regression targets
     "td_count": pl.Int64,  # Number of TDs scored (receiving + rushing)
+    "td_count_offense": pl.Int64,
+    "td_count_all": pl.Int64,
     "passing_td": pl.Int64,  # Number of passing TDs (QB only)
     
     # Yardage regression targets
@@ -103,4 +112,40 @@
     pl.DataFrame
         DataFrame with validated target columns
     """
-    return validate_target_columns(df, strict=False)
\ No newline at end of file
+    return validate_target_columns(df, strict=False)
+
+
+def require_target_column(
+    df: pl.DataFrame,
+    target_col: str,
+    *,
+    label_version: str | None = None,
+    min_non_null: int = 1,
+) -> pl.DataFrame:
+    """Ensure the configured target column exists and is populated.
+
+    Raises a ValueError if the column is missing or entirely null.
+    """
+
+    if target_col not in df.columns:
+        alias_hint = ""
+        if label_version:
+            try:
+                spec = get_label_spec(label_version or DEFAULT_LABEL_VERSION)
+                if target_col in spec.aliases:
+                    alias_hint = f" Target maps to '{spec.aliases[target_col]}' under {spec.name}."
+            except Exception:
+                alias_hint = ""
+        raise ValueError(f"Target column '{target_col}' not found in feature frame.{alias_hint}")
+
+    series = df[target_col]
+    non_null = series.drop_nulls().height
+    if non_null < min_non_null:
+        raise ValueError(
+            f"Target column '{target_col}' has insufficient non-null rows "
+            f"({non_null}/{len(series)})."
+        )
+    nulls = len(series) - non_null
+    if nulls > 0:
+        logger.warning("Target %s contains %d null rows; they will be dropped.", target_col, nulls)
+    return df

tokens used
101,757
Introduced versioned anytime-TD labels and explicit target wiring. TD semantics now live in `utils/feature/labels.py` with v1 specs, aliases, and helper `compute_td_labels`; player-game aggregation uses it to emit offense/all/type-specific labels and aligned td_count columns (`utils/feature/player_game_level.py`). Feature pipeline now accepts a `label_version`, passes it into aggregation, and logs rates for the primary label while defaulting to `v1_any_offense` (`pipeline/feature.py`). Training now records per-problem `label_version` from config, enforces the configured target exists via `require_target_column`, and raises early if missing (`pipeline/train.py`, `utils/feature/targets.py`). Added config hook for label version under the anytime_td problem (`config/training.yaml`) and a focused label semantics test suite (`tests/labels/test_labels.py`).

Tests: `pytest tests/labels/test_labels.py -q` (pytest not available in environment).

Git: Unable to stage/commit because writing to `.git` is denied in this environment (e.g., `git add` fails creating `.git/index.lock`). Working tree remains dirty.

PROGRESS: Implemented P0 label-version scaffold (specs, generation, target enforcement, config hook) and added unit coverage; remaining plan items (leak guardrails, decision-time odds/injuries, CV, docs, broader evaluation) are still outstanding.
